import {
  shared_exports
} from "./chunk-M5W23TMN.js";
import {
  Abs,
  Acos,
  Acosh,
  Add,
  AddN,
  All,
  Any,
  ArgMax,
  ArgMin,
  Asin,
  Asinh,
  Atan,
  Atan2,
  Atanh,
  AvgPool,
  AvgPool3D,
  AvgPool3DGrad,
  AvgPoolGrad,
  BatchMatMul,
  BatchToSpaceND,
  Bincount,
  BroadcastArgs,
  Cast,
  Ceil,
  ClipByValue,
  Complex,
  ComplexAbs,
  Concat,
  Conv2D,
  Conv2DBackpropFilter,
  Conv2DBackpropInput,
  Conv3D,
  Conv3DBackpropFilterV2,
  Conv3DBackpropInputV2,
  Cos,
  Cosh,
  CropAndResize,
  Cumprod,
  Cumsum,
  DataStorage,
  DenseBincount,
  DepthToSpace,
  DepthwiseConv2dNative,
  DepthwiseConv2dNativeBackpropFilter,
  DepthwiseConv2dNativeBackpropInput,
  Diag,
  Dilation2D,
  Dilation2DBackpropFilter,
  Dilation2DBackpropInput,
  Draw,
  Einsum,
  Elu,
  EluGrad,
  Equal,
  Erf,
  Exp,
  ExpandDims,
  Expm1,
  FFT,
  Fill,
  FlipLeftRight,
  Floor,
  FloorDiv,
  FromPixels,
  FusedBatchNorm,
  FusedConv2D,
  FusedDepthwiseConv2D,
  GatherNd,
  GatherV2,
  Greater,
  GreaterEqual,
  IFFT,
  Identity,
  Imag,
  IsFinite,
  IsInf,
  IsNan,
  KernelBackend,
  LRN,
  LRNGrad,
  LeakyRelu,
  Less,
  LessEqual,
  LinSpace,
  Log,
  Log1p,
  LogicalAnd,
  LogicalNot,
  LogicalOr,
  Max,
  MaxPool,
  MaxPool3D,
  MaxPool3DGrad,
  MaxPoolGrad,
  MaxPoolWithArgmax,
  Maximum,
  Mean,
  Min,
  Minimum,
  MirrorPad,
  Mod,
  Multinomial,
  Multiply,
  Neg,
  NonMaxSuppressionV3,
  NonMaxSuppressionV5,
  NotEqual,
  OP_SCOPE_SUFFIX,
  OneHot,
  OnesLike,
  Pack,
  PadV2,
  Pow,
  Prelu,
  Prod,
  Range,
  Real,
  RealDiv,
  Reciprocal,
  Relu,
  Relu6,
  Reshape,
  ResizeBilinear,
  ResizeBilinearGrad,
  ResizeNearestNeighbor,
  ResizeNearestNeighborGrad,
  Reverse,
  RotateWithOffset,
  Round,
  Rsqrt,
  ScatterNd,
  SearchSorted,
  Select,
  Selu,
  Sigmoid,
  Sign,
  Sin,
  Sinh,
  Slice,
  Softmax,
  Softplus,
  SpaceToBatchND,
  SparseSegmentMean,
  SparseSegmentSum,
  SparseToDense,
  SplitV,
  Sqrt,
  Square,
  SquaredDifference,
  Step,
  StridedSlice,
  StringNGrams,
  Sub,
  Sum,
  Tan,
  Tanh,
  Tensor,
  TensorScatterUpdate,
  Tile,
  TopK,
  Transform,
  Transpose,
  Unpack,
  UnsortedSegmentSum,
  ZerosLike,
  _FusedMatMul,
  abs,
  acos,
  acosh,
  add,
  addN,
  all,
  any,
  argMax,
  argMin,
  asin,
  asinh,
  atan,
  atan2,
  atanh,
  avgPool,
  avgPool3d,
  backend,
  backend_util_exports,
  basicLSTMCell,
  batchNorm,
  batchNorm2d,
  batchNorm3d,
  batchNorm4d,
  batchToSpaceND,
  bincount,
  bitwiseAnd,
  booleanMaskAsync,
  broadcastArgs,
  broadcastTo,
  broadcast_util_exports,
  browser_exports,
  buffer,
  cast,
  ceil,
  clipByValue,
  clone,
  complex,
  concat,
  concat1d,
  concat2d,
  concat3d,
  concat4d,
  conv1d,
  conv2d,
  conv2dTranspose,
  conv3d,
  conv3dTranspose,
  cos,
  cosh,
  cosineWindow,
  cumprod,
  cumsum,
  decodeWeightsStream,
  denseBincount,
  depthToSpace,
  depthwiseConv2d,
  diag,
  dilation2d,
  dispose,
  div,
  divNoNan,
  dot,
  dropout,
  einsum,
  elu,
  enclosingPowerOfTwo,
  engine,
  ensureShape,
  env,
  equal,
  erf,
  euclideanNorm,
  exp,
  expandDims,
  expm1,
  eye,
  fft,
  fill,
  floor,
  floorDiv,
  fused_ops_exports,
  gather,
  gatherND,
  getBackend,
  greater,
  greaterEqual,
  ifft,
  imag,
  image,
  inTopKAsync,
  io_exports,
  irfft,
  isFinite as isFinite2,
  isInf,
  isNaN as isNaN2,
  keep,
  kernel_impls_exports,
  leakyRelu,
  less,
  lessEqual,
  linalg,
  linspace,
  localResponseNormalization,
  log,
  log1p,
  logSigmoid,
  logSoftmax,
  logSumExp,
  logicalAnd,
  logicalNot,
  logicalOr,
  logicalXor,
  losses,
  lowerBound,
  matMul,
  max,
  maxPool,
  maxPool3d,
  maxPoolWithArgmax,
  maximum,
  mean,
  meshgrid,
  min,
  minimum,
  mirrorPad,
  mod,
  moments,
  movingAverage,
  mul,
  multiRNNCell,
  multinomial,
  neg,
  norm,
  notEqual,
  oneHot,
  ones,
  onesLike,
  op,
  outerProduct,
  pad,
  pad1d,
  pad2d,
  pad3d,
  pad4d,
  pool,
  pow,
  prelu,
  print,
  prod,
  raggedGather,
  raggedRange,
  raggedTensorToTensor,
  rand,
  randomGamma,
  randomNormal,
  randomStandardNormal,
  randomUniform,
  randomUniformInt,
  range,
  real,
  reciprocal,
  registerBackend,
  registerKernel,
  relu,
  relu6,
  reshape,
  reverse,
  reverse1d,
  reverse2d,
  reverse3d,
  reverse4d,
  rfft,
  round,
  rsqrt,
  scalar,
  scatterND,
  searchSorted,
  selu,
  separableConv2d,
  setdiff1dAsync,
  sigmoid,
  sign,
  signal,
  sin,
  sinh,
  slice,
  slice1d,
  slice2d,
  slice3d,
  slice4d,
  slice_util_exports,
  softmax,
  softplus,
  spaceToBatchND,
  sparse,
  sparseToDense,
  spectral,
  split,
  sqrt,
  square,
  squaredDifference,
  squeeze,
  stack,
  step,
  stridedSlice,
  string,
  sub,
  sum,
  sumOutType,
  tan,
  tanh,
  tensor,
  tensor1d,
  tensor2d,
  tensor3d,
  tensor4d,
  tensor5d,
  tensor6d,
  tensorScatterUpdate,
  tidy,
  tile,
  topk,
  transpose,
  truncatedNormal,
  unique,
  unsortedSegmentSum,
  unstack,
  upcastType,
  upperBound,
  util_exports,
  variable,
  where,
  whereAsync,
  zeros,
  zerosLike
} from "./chunk-FBGRPOGW.js";
import {
  __commonJS,
  __export,
  __toESM
} from "./chunk-HM4MQYWN.js";

// node_modules/@mediapipe/pose/pose.js
var require_pose = __commonJS({
  "node_modules/@mediapipe/pose/pose.js"(exports) {
    (function() {
      "use strict";
      var x;
      function aa(a) {
        var b = 0;
        return function() {
          return b < a.length ? { done: false, value: a[b++] } : { done: true };
        };
      }
      var ba = "function" == typeof Object.defineProperties ? Object.defineProperty : function(a, b, c) {
        if (a == Array.prototype || a == Object.prototype)
          return a;
        a[b] = c.value;
        return a;
      };
      function ca(a) {
        a = ["object" == typeof globalThis && globalThis, a, "object" == typeof window && window, "object" == typeof self && self, "object" == typeof global && global];
        for (var b = 0; b < a.length; ++b) {
          var c = a[b];
          if (c && c.Math == Math)
            return c;
        }
        throw Error("Cannot find global object");
      }
      var y = ca(this);
      function z(a, b) {
        if (b)
          a: {
            var c = y;
            a = a.split(".");
            for (var d = 0; d < a.length - 1; d++) {
              var e = a[d];
              if (!(e in c))
                break a;
              c = c[e];
            }
            a = a[a.length - 1];
            d = c[a];
            b = b(d);
            b != d && null != b && ba(c, a, { configurable: true, writable: true, value: b });
          }
      }
      z("Symbol", function(a) {
        function b(g) {
          if (this instanceof b)
            throw new TypeError("Symbol is not a constructor");
          return new c(d + (g || "") + "_" + e++, g);
        }
        function c(g, f) {
          this.h = g;
          ba(this, "description", { configurable: true, writable: true, value: f });
        }
        if (a)
          return a;
        c.prototype.toString = function() {
          return this.h;
        };
        var d = "jscomp_symbol_" + (1e9 * Math.random() >>> 0) + "_", e = 0;
        return b;
      });
      z("Symbol.iterator", function(a) {
        if (a)
          return a;
        a = Symbol("Symbol.iterator");
        for (var b = "Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array".split(" "), c = 0; c < b.length; c++) {
          var d = y[b[c]];
          "function" === typeof d && "function" != typeof d.prototype[a] && ba(d.prototype, a, { configurable: true, writable: true, value: function() {
            return da(aa(this));
          } });
        }
        return a;
      });
      function da(a) {
        a = { next: a };
        a[Symbol.iterator] = function() {
          return this;
        };
        return a;
      }
      function A(a) {
        var b = "undefined" != typeof Symbol && Symbol.iterator && a[Symbol.iterator];
        return b ? b.call(a) : { next: aa(a) };
      }
      function ea(a) {
        if (!(a instanceof Array)) {
          a = A(a);
          for (var b, c = []; !(b = a.next()).done; )
            c.push(b.value);
          a = c;
        }
        return a;
      }
      var fa = "function" == typeof Object.assign ? Object.assign : function(a, b) {
        for (var c = 1; c < arguments.length; c++) {
          var d = arguments[c];
          if (d)
            for (var e in d)
              Object.prototype.hasOwnProperty.call(d, e) && (a[e] = d[e]);
        }
        return a;
      };
      z("Object.assign", function(a) {
        return a || fa;
      });
      var ha = "function" == typeof Object.create ? Object.create : function(a) {
        function b() {
        }
        b.prototype = a;
        return new b();
      }, ia;
      if ("function" == typeof Object.setPrototypeOf)
        ia = Object.setPrototypeOf;
      else {
        var ja;
        a: {
          var ka = { a: true }, la = {};
          try {
            la.__proto__ = ka;
            ja = la.a;
            break a;
          } catch (a) {
          }
          ja = false;
        }
        ia = ja ? function(a, b) {
          a.__proto__ = b;
          if (a.__proto__ !== b)
            throw new TypeError(a + " is not extensible");
          return a;
        } : null;
      }
      var ma = ia;
      function na(a, b) {
        a.prototype = ha(b.prototype);
        a.prototype.constructor = a;
        if (ma)
          ma(a, b);
        else
          for (var c in b)
            if ("prototype" != c)
              if (Object.defineProperties) {
                var d = Object.getOwnPropertyDescriptor(b, c);
                d && Object.defineProperty(a, c, d);
              } else
                a[c] = b[c];
        a.za = b.prototype;
      }
      function oa() {
        this.m = false;
        this.j = null;
        this.i = void 0;
        this.h = 1;
        this.v = this.s = 0;
        this.l = null;
      }
      function pa(a) {
        if (a.m)
          throw new TypeError("Generator is already running");
        a.m = true;
      }
      oa.prototype.u = function(a) {
        this.i = a;
      };
      function qa(a, b) {
        a.l = { ma: b, na: true };
        a.h = a.s || a.v;
      }
      oa.prototype.return = function(a) {
        this.l = { return: a };
        this.h = this.v;
      };
      function D2(a, b, c) {
        a.h = c;
        return { value: b };
      }
      function ra(a) {
        this.h = new oa();
        this.i = a;
      }
      function sa(a, b) {
        pa(a.h);
        var c = a.h.j;
        if (c)
          return ta(a, "return" in c ? c["return"] : function(d) {
            return { value: d, done: true };
          }, b, a.h.return);
        a.h.return(b);
        return ua(a);
      }
      function ta(a, b, c, d) {
        try {
          var e = b.call(a.h.j, c);
          if (!(e instanceof Object))
            throw new TypeError("Iterator result " + e + " is not an object");
          if (!e.done)
            return a.h.m = false, e;
          var g = e.value;
        } catch (f) {
          return a.h.j = null, qa(a.h, f), ua(a);
        }
        a.h.j = null;
        d.call(a.h, g);
        return ua(a);
      }
      function ua(a) {
        for (; a.h.h; )
          try {
            var b = a.i(a.h);
            if (b)
              return a.h.m = false, { value: b.value, done: false };
          } catch (c) {
            a.h.i = void 0, qa(a.h, c);
          }
        a.h.m = false;
        if (a.h.l) {
          b = a.h.l;
          a.h.l = null;
          if (b.na)
            throw b.ma;
          return { value: b.return, done: true };
        }
        return { value: void 0, done: true };
      }
      function va(a) {
        this.next = function(b) {
          pa(a.h);
          a.h.j ? b = ta(a, a.h.j.next, b, a.h.u) : (a.h.u(b), b = ua(a));
          return b;
        };
        this.throw = function(b) {
          pa(a.h);
          a.h.j ? b = ta(a, a.h.j["throw"], b, a.h.u) : (qa(a.h, b), b = ua(a));
          return b;
        };
        this.return = function(b) {
          return sa(a, b);
        };
        this[Symbol.iterator] = function() {
          return this;
        };
      }
      function wa(a) {
        function b(d) {
          return a.next(d);
        }
        function c(d) {
          return a.throw(d);
        }
        return new Promise(function(d, e) {
          function g(f) {
            f.done ? d(f.value) : Promise.resolve(f.value).then(b, c).then(g, e);
          }
          g(a.next());
        });
      }
      function E(a) {
        return wa(new va(new ra(a)));
      }
      z("Promise", function(a) {
        function b(f) {
          this.i = 0;
          this.j = void 0;
          this.h = [];
          this.u = false;
          var h = this.l();
          try {
            f(h.resolve, h.reject);
          } catch (k) {
            h.reject(k);
          }
        }
        function c() {
          this.h = null;
        }
        function d(f) {
          return f instanceof b ? f : new b(function(h) {
            h(f);
          });
        }
        if (a)
          return a;
        c.prototype.i = function(f) {
          if (null == this.h) {
            this.h = [];
            var h = this;
            this.j(function() {
              h.m();
            });
          }
          this.h.push(f);
        };
        var e = y.setTimeout;
        c.prototype.j = function(f) {
          e(f, 0);
        };
        c.prototype.m = function() {
          for (; this.h && this.h.length; ) {
            var f = this.h;
            this.h = [];
            for (var h = 0; h < f.length; ++h) {
              var k = f[h];
              f[h] = null;
              try {
                k();
              } catch (l) {
                this.l(l);
              }
            }
          }
          this.h = null;
        };
        c.prototype.l = function(f) {
          this.j(function() {
            throw f;
          });
        };
        b.prototype.l = function() {
          function f(l) {
            return function(m) {
              k || (k = true, l.call(h, m));
            };
          }
          var h = this, k = false;
          return { resolve: f(this.I), reject: f(this.m) };
        };
        b.prototype.I = function(f) {
          if (f === this)
            this.m(new TypeError("A Promise cannot resolve to itself"));
          else if (f instanceof b)
            this.L(f);
          else {
            a:
              switch (typeof f) {
                case "object":
                  var h = null != f;
                  break a;
                case "function":
                  h = true;
                  break a;
                default:
                  h = false;
              }
            h ? this.F(f) : this.s(f);
          }
        };
        b.prototype.F = function(f) {
          var h = void 0;
          try {
            h = f.then;
          } catch (k) {
            this.m(k);
            return;
          }
          "function" == typeof h ? this.M(h, f) : this.s(f);
        };
        b.prototype.m = function(f) {
          this.v(2, f);
        };
        b.prototype.s = function(f) {
          this.v(1, f);
        };
        b.prototype.v = function(f, h) {
          if (0 != this.i)
            throw Error("Cannot settle(" + f + ", " + h + "): Promise already settled in state" + this.i);
          this.i = f;
          this.j = h;
          2 === this.i && this.K();
          this.H();
        };
        b.prototype.K = function() {
          var f = this;
          e(function() {
            if (f.D()) {
              var h = y.console;
              "undefined" !== typeof h && h.error(f.j);
            }
          }, 1);
        };
        b.prototype.D = function() {
          if (this.u)
            return false;
          var f = y.CustomEvent, h = y.Event, k = y.dispatchEvent;
          if ("undefined" === typeof k)
            return true;
          "function" === typeof f ? f = new f("unhandledrejection", { cancelable: true }) : "function" === typeof h ? f = new h("unhandledrejection", { cancelable: true }) : (f = y.document.createEvent("CustomEvent"), f.initCustomEvent("unhandledrejection", false, true, f));
          f.promise = this;
          f.reason = this.j;
          return k(f);
        };
        b.prototype.H = function() {
          if (null != this.h) {
            for (var f = 0; f < this.h.length; ++f)
              g.i(this.h[f]);
            this.h = null;
          }
        };
        var g = new c();
        b.prototype.L = function(f) {
          var h = this.l();
          f.T(h.resolve, h.reject);
        };
        b.prototype.M = function(f, h) {
          var k = this.l();
          try {
            f.call(h, k.resolve, k.reject);
          } catch (l) {
            k.reject(l);
          }
        };
        b.prototype.then = function(f, h) {
          function k(p, n) {
            return "function" == typeof p ? function(q2) {
              try {
                l(p(q2));
              } catch (t2) {
                m(t2);
              }
            } : n;
          }
          var l, m, r = new b(function(p, n) {
            l = p;
            m = n;
          });
          this.T(k(f, l), k(h, m));
          return r;
        };
        b.prototype.catch = function(f) {
          return this.then(void 0, f);
        };
        b.prototype.T = function(f, h) {
          function k() {
            switch (l.i) {
              case 1:
                f(l.j);
                break;
              case 2:
                h(l.j);
                break;
              default:
                throw Error("Unexpected state: " + l.i);
            }
          }
          var l = this;
          null == this.h ? g.i(k) : this.h.push(k);
          this.u = true;
        };
        b.resolve = d;
        b.reject = function(f) {
          return new b(function(h, k) {
            k(f);
          });
        };
        b.race = function(f) {
          return new b(function(h, k) {
            for (var l = A(f), m = l.next(); !m.done; m = l.next())
              d(m.value).T(h, k);
          });
        };
        b.all = function(f) {
          var h = A(f), k = h.next();
          return k.done ? d([]) : new b(function(l, m) {
            function r(q2) {
              return function(t2) {
                p[q2] = t2;
                n--;
                0 == n && l(p);
              };
            }
            var p = [], n = 0;
            do
              p.push(void 0), n++, d(k.value).T(r(p.length - 1), m), k = h.next();
            while (!k.done);
          });
        };
        return b;
      });
      function xa(a, b) {
        a instanceof String && (a += "");
        var c = 0, d = false, e = { next: function() {
          if (!d && c < a.length) {
            var g = c++;
            return { value: b(g, a[g]), done: false };
          }
          d = true;
          return { done: true, value: void 0 };
        } };
        e[Symbol.iterator] = function() {
          return e;
        };
        return e;
      }
      z("Array.prototype.keys", function(a) {
        return a ? a : function() {
          return xa(this, function(b) {
            return b;
          });
        };
      });
      z("Array.prototype.fill", function(a) {
        return a ? a : function(b, c, d) {
          var e = this.length || 0;
          0 > c && (c = Math.max(0, e + c));
          if (null == d || d > e)
            d = e;
          d = Number(d);
          0 > d && (d = Math.max(0, e + d));
          for (c = Number(c || 0); c < d; c++)
            this[c] = b;
          return this;
        };
      });
      function F(a) {
        return a ? a : Array.prototype.fill;
      }
      z("Int8Array.prototype.fill", F);
      z("Uint8Array.prototype.fill", F);
      z("Uint8ClampedArray.prototype.fill", F);
      z("Int16Array.prototype.fill", F);
      z("Uint16Array.prototype.fill", F);
      z("Int32Array.prototype.fill", F);
      z("Uint32Array.prototype.fill", F);
      z("Float32Array.prototype.fill", F);
      z("Float64Array.prototype.fill", F);
      z("Object.is", function(a) {
        return a ? a : function(b, c) {
          return b === c ? 0 !== b || 1 / b === 1 / c : b !== b && c !== c;
        };
      });
      z("Array.prototype.includes", function(a) {
        return a ? a : function(b, c) {
          var d = this;
          d instanceof String && (d = String(d));
          var e = d.length;
          c = c || 0;
          for (0 > c && (c = Math.max(c + e, 0)); c < e; c++) {
            var g = d[c];
            if (g === b || Object.is(g, b))
              return true;
          }
          return false;
        };
      });
      z("String.prototype.includes", function(a) {
        return a ? a : function(b, c) {
          if (null == this)
            throw new TypeError("The 'this' value for String.prototype.includes must not be null or undefined");
          if (b instanceof RegExp)
            throw new TypeError("First argument to String.prototype.includes must not be a regular expression");
          return -1 !== this.indexOf(b, c || 0);
        };
      });
      var ya = this || self;
      function G2(a, b) {
        a = a.split(".");
        var c = ya;
        a[0] in c || "undefined" == typeof c.execScript || c.execScript("var " + a[0]);
        for (var d; a.length && (d = a.shift()); )
          a.length || void 0 === b ? c[d] && c[d] !== Object.prototype[d] ? c = c[d] : c = c[d] = {} : c[d] = b;
      }
      ;
      function Aa(a) {
        var b;
        a: {
          if (b = ya.navigator) {
            if (b = b.userAgent)
              break a;
          }
          b = "";
        }
        return -1 != b.indexOf(a);
      }
      ;
      var Ba = Array.prototype.map ? function(a, b) {
        return Array.prototype.map.call(a, b, void 0);
      } : function(a, b) {
        for (var c = a.length, d = Array(c), e = "string" === typeof a ? a.split("") : a, g = 0; g < c; g++)
          g in e && (d[g] = b.call(void 0, e[g], g, a));
        return d;
      };
      var Ca = {}, Da = null;
      function Ea(a) {
        var b = a.length, c = 3 * b / 4;
        c % 3 ? c = Math.floor(c) : -1 != "=.".indexOf(a[b - 1]) && (c = -1 != "=.".indexOf(a[b - 2]) ? c - 2 : c - 1);
        var d = new Uint8Array(c), e = 0;
        Fa(a, function(g) {
          d[e++] = g;
        });
        return e !== c ? d.subarray(0, e) : d;
      }
      function Fa(a, b) {
        function c(k) {
          for (; d < a.length; ) {
            var l = a.charAt(d++), m = Da[l];
            if (null != m)
              return m;
            if (!/^[\s\xa0]*$/.test(l))
              throw Error("Unknown base64 encoding at char: " + l);
          }
          return k;
        }
        Ga();
        for (var d = 0; ; ) {
          var e = c(-1), g = c(0), f = c(64), h = c(64);
          if (64 === h && -1 === e)
            break;
          b(e << 2 | g >> 4);
          64 != f && (b(g << 4 & 240 | f >> 2), 64 != h && b(f << 6 & 192 | h));
        }
      }
      function Ga() {
        if (!Da) {
          Da = {};
          for (var a = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split(""), b = ["+/=", "+/", "-_=", "-_.", "-_"], c = 0; 5 > c; c++) {
            var d = a.concat(b[c].split(""));
            Ca[c] = d;
            for (var e = 0; e < d.length; e++) {
              var g = d[e];
              void 0 === Da[g] && (Da[g] = e);
            }
          }
        }
      }
      ;
      var Ha = "undefined" !== typeof Uint8Array, Ia = !(Aa("Trident") || Aa("MSIE")) && "function" === typeof ya.btoa;
      function Ja(a) {
        if (!Ia) {
          var b;
          void 0 === b && (b = 0);
          Ga();
          b = Ca[b];
          for (var c = Array(Math.floor(a.length / 3)), d = b[64] || "", e = 0, g = 0; e < a.length - 2; e += 3) {
            var f = a[e], h = a[e + 1], k = a[e + 2], l = b[f >> 2];
            f = b[(f & 3) << 4 | h >> 4];
            h = b[(h & 15) << 2 | k >> 6];
            k = b[k & 63];
            c[g++] = l + f + h + k;
          }
          l = 0;
          k = d;
          switch (a.length - e) {
            case 2:
              l = a[e + 1], k = b[(l & 15) << 2] || d;
            case 1:
              a = a[e], c[g] = b[a >> 2] + b[(a & 3) << 4 | l >> 4] + k + d;
          }
          return c.join("");
        }
        for (b = ""; 10240 < a.length; )
          b += String.fromCharCode.apply(null, a.subarray(0, 10240)), a = a.subarray(10240);
        b += String.fromCharCode.apply(
          null,
          a
        );
        return btoa(b);
      }
      var Ka = RegExp("[-_.]", "g");
      function La(a) {
        switch (a) {
          case "-":
            return "+";
          case "_":
            return "/";
          case ".":
            return "=";
          default:
            return "";
        }
      }
      function Ma(a) {
        if (!Ia)
          return Ea(a);
        Ka.test(a) && (a = a.replace(Ka, La));
        a = atob(a);
        for (var b = new Uint8Array(a.length), c = 0; c < a.length; c++)
          b[c] = a.charCodeAt(c);
        return b;
      }
      var Na;
      function Oa() {
        return Na || (Na = new Uint8Array(0));
      }
      var Pa = {};
      var Qa = "function" === typeof Uint8Array.prototype.slice, H2 = 0, K2 = 0;
      function Ra(a) {
        var b = 0 > a;
        a = Math.abs(a);
        var c = a >>> 0;
        a = Math.floor((a - c) / 4294967296);
        b && (c = A(Sa(c, a)), b = c.next().value, a = c.next().value, c = b);
        H2 = c >>> 0;
        K2 = a >>> 0;
      }
      var Ta = "function" === typeof BigInt;
      function Sa(a, b) {
        b = ~b;
        a ? a = ~a + 1 : b += 1;
        return [a, b];
      }
      ;
      function Ua(a, b) {
        this.i = a >>> 0;
        this.h = b >>> 0;
      }
      function Va(a) {
        if (!a)
          return Wa || (Wa = new Ua(0, 0));
        if (!/^-?\d+$/.test(a))
          return null;
        if (16 > a.length)
          Ra(Number(a));
        else if (Ta)
          a = BigInt(a), H2 = Number(a & BigInt(4294967295)) >>> 0, K2 = Number(a >> BigInt(32) & BigInt(4294967295));
        else {
          var b = +("-" === a[0]);
          K2 = H2 = 0;
          for (var c = a.length, d = b, e = (c - b) % 6 + b; e <= c; d = e, e += 6)
            d = Number(a.slice(d, e)), K2 *= 1e6, H2 = 1e6 * H2 + d, 4294967296 <= H2 && (K2 += H2 / 4294967296 | 0, H2 %= 4294967296);
          b && (b = A(Sa(H2, K2)), a = b.next().value, b = b.next().value, H2 = a, K2 = b);
        }
        return new Ua(H2, K2);
      }
      var Wa;
      function Xa(a, b) {
        return Error("Invalid wire type: " + a + " (at position " + b + ")");
      }
      function Ya() {
        return Error("Failed to read varint, encoding is invalid.");
      }
      function Za(a, b) {
        return Error("Tried to read past the end of the data " + b + " > " + a);
      }
      ;
      function L2() {
        throw Error("Invalid UTF8");
      }
      function $a(a, b) {
        b = String.fromCharCode.apply(null, b);
        return null == a ? b : a + b;
      }
      var ab = void 0, bb, cb = "undefined" !== typeof TextDecoder, db, eb = "undefined" !== typeof TextEncoder;
      var fb;
      function gb(a) {
        if (a !== Pa)
          throw Error("illegal external caller");
      }
      function hb(a, b) {
        gb(b);
        this.V = a;
        if (null != a && 0 === a.length)
          throw Error("ByteString should be constructed with non-empty values");
      }
      function ib() {
        return fb || (fb = new hb(null, Pa));
      }
      function jb(a) {
        gb(Pa);
        var b = a.V;
        b = null == b || Ha && null != b && b instanceof Uint8Array ? b : "string" === typeof b ? Ma(b) : null;
        return null == b ? b : a.V = b;
      }
      ;
      function kb(a) {
        if ("string" === typeof a)
          return { buffer: Ma(a), C: false };
        if (Array.isArray(a))
          return { buffer: new Uint8Array(a), C: false };
        if (a.constructor === Uint8Array)
          return { buffer: a, C: false };
        if (a.constructor === ArrayBuffer)
          return { buffer: new Uint8Array(a), C: false };
        if (a.constructor === hb)
          return { buffer: jb(a) || Oa(), C: true };
        if (a instanceof Uint8Array)
          return { buffer: new Uint8Array(a.buffer, a.byteOffset, a.byteLength), C: false };
        throw Error("Type not convertible to a Uint8Array, expected a Uint8Array, an ArrayBuffer, a base64 encoded string, a ByteString or an Array of numbers");
      }
      ;
      function lb(a, b) {
        this.i = null;
        this.m = false;
        this.h = this.j = this.l = 0;
        mb(this, a, b);
      }
      function mb(a, b, c) {
        c = void 0 === c ? {} : c;
        a.S = void 0 === c.S ? false : c.S;
        b && (b = kb(b), a.i = b.buffer, a.m = b.C, a.l = 0, a.j = a.i.length, a.h = a.l);
      }
      lb.prototype.reset = function() {
        this.h = this.l;
      };
      function M(a, b) {
        a.h = b;
        if (b > a.j)
          throw Za(a.j, b);
      }
      function nb(a) {
        var b = a.i, c = a.h, d = b[c++], e = d & 127;
        if (d & 128 && (d = b[c++], e |= (d & 127) << 7, d & 128 && (d = b[c++], e |= (d & 127) << 14, d & 128 && (d = b[c++], e |= (d & 127) << 21, d & 128 && (d = b[c++], e |= d << 28, d & 128 && b[c++] & 128 && b[c++] & 128 && b[c++] & 128 && b[c++] & 128 && b[c++] & 128)))))
          throw Ya();
        M(a, c);
        return e;
      }
      function ob(a, b) {
        if (0 > b)
          throw Error("Tried to read a negative byte length: " + b);
        var c = a.h, d = c + b;
        if (d > a.j)
          throw Za(b, a.j - c);
        a.h = d;
        return c;
      }
      var pb = [];
      function qb() {
        this.h = [];
      }
      qb.prototype.length = function() {
        return this.h.length;
      };
      qb.prototype.end = function() {
        var a = this.h;
        this.h = [];
        return a;
      };
      function rb(a, b, c) {
        for (; 0 < c || 127 < b; )
          a.h.push(b & 127 | 128), b = (b >>> 7 | c << 25) >>> 0, c >>>= 7;
        a.h.push(b);
      }
      function N2(a, b) {
        for (; 127 < b; )
          a.h.push(b & 127 | 128), b >>>= 7;
        a.h.push(b);
      }
      ;
      function sb(a, b) {
        if (pb.length) {
          var c = pb.pop();
          mb(c, a, b);
          a = c;
        } else
          a = new lb(a, b);
        this.h = a;
        this.j = this.h.h;
        this.i = this.l = -1;
        this.setOptions(b);
      }
      sb.prototype.setOptions = function(a) {
        a = void 0 === a ? {} : a;
        this.ca = void 0 === a.ca ? false : a.ca;
      };
      sb.prototype.reset = function() {
        this.h.reset();
        this.j = this.h.h;
        this.i = this.l = -1;
      };
      function tb(a) {
        var b = a.h;
        if (b.h == b.j)
          return false;
        a.j = a.h.h;
        var c = nb(a.h) >>> 0;
        b = c >>> 3;
        c &= 7;
        if (!(0 <= c && 5 >= c))
          throw Xa(c, a.j);
        if (1 > b)
          throw Error("Invalid field number: " + b + " (at position " + a.j + ")");
        a.l = b;
        a.i = c;
        return true;
      }
      function ub(a) {
        switch (a.i) {
          case 0:
            if (0 != a.i)
              ub(a);
            else
              a: {
                a = a.h;
                for (var b = a.h, c = b + 10, d = a.i; b < c; )
                  if (0 === (d[b++] & 128)) {
                    M(a, b);
                    break a;
                  }
                throw Ya();
              }
            break;
          case 1:
            a = a.h;
            M(a, a.h + 8);
            break;
          case 2:
            2 != a.i ? ub(a) : (b = nb(a.h) >>> 0, a = a.h, M(a, a.h + b));
            break;
          case 5:
            a = a.h;
            M(a, a.h + 4);
            break;
          case 3:
            b = a.l;
            do {
              if (!tb(a))
                throw Error("Unmatched start-group tag: stream EOF");
              if (4 == a.i) {
                if (a.l != b)
                  throw Error("Unmatched end-group tag");
                break;
              }
              ub(a);
            } while (1);
            break;
          default:
            throw Xa(a.i, a.j);
        }
      }
      var vb = [];
      function wb() {
        this.j = [];
        this.i = 0;
        this.h = new qb();
      }
      function O(a, b) {
        0 !== b.length && (a.j.push(b), a.i += b.length);
      }
      function xb(a, b) {
        if (b = b.R) {
          O(a, a.h.end());
          for (var c = 0; c < b.length; c++)
            O(a, jb(b[c]) || Oa());
        }
      }
      ;
      var P = "function" === typeof Symbol && "symbol" === typeof Symbol() ? Symbol() : void 0;
      function Q2(a, b) {
        if (P)
          return a[P] |= b;
        if (void 0 !== a.A)
          return a.A |= b;
        Object.defineProperties(a, { A: { value: b, configurable: true, writable: true, enumerable: false } });
        return b;
      }
      function yb(a, b) {
        P ? a[P] && (a[P] &= ~b) : void 0 !== a.A && (a.A &= ~b);
      }
      function R(a) {
        var b;
        P ? b = a[P] : b = a.A;
        return null == b ? 0 : b;
      }
      function S(a, b) {
        P ? a[P] = b : void 0 !== a.A ? a.A = b : Object.defineProperties(a, { A: { value: b, configurable: true, writable: true, enumerable: false } });
      }
      function zb(a) {
        Q2(a, 1);
        return a;
      }
      function Ab(a, b) {
        S(b, (a | 0) & -51);
      }
      function Bb(a, b) {
        S(b, (a | 18) & -41);
      }
      ;
      var Cb = {};
      function Db(a) {
        return null !== a && "object" === typeof a && !Array.isArray(a) && a.constructor === Object;
      }
      var Eb, Fb = [];
      S(Fb, 23);
      Eb = Object.freeze(Fb);
      function Gb(a) {
        if (R(a.o) & 2)
          throw Error("Cannot mutate an immutable Message");
      }
      function Hb(a) {
        var b = a.length;
        (b = b ? a[b - 1] : void 0) && Db(b) ? b.g = 1 : (b = {}, a.push((b.g = 1, b)));
      }
      ;
      function Ib(a) {
        var b = a.i + a.G;
        return a.B || (a.B = a.o[b] = {});
      }
      function T(a, b) {
        return -1 === b ? null : b >= a.i ? a.B ? a.B[b] : void 0 : a.o[b + a.G];
      }
      function V2(a, b, c, d) {
        Gb(a);
        Jb(a, b, c, d);
      }
      function Jb(a, b, c, d) {
        a.j && (a.j = void 0);
        b >= a.i || d ? Ib(a)[b] = c : (a.o[b + a.G] = c, (a = a.B) && b in a && delete a[b]);
      }
      function Kb(a, b, c, d) {
        var e = T(a, b);
        Array.isArray(e) || (e = Eb);
        var g = R(e);
        g & 1 || zb(e);
        if (d)
          g & 2 || Q2(e, 2), c & 1 || Object.freeze(e);
        else {
          d = !(c & 2);
          var f = g & 2;
          c & 1 || !f ? d && g & 16 && !f && yb(e, 16) : (e = zb(Array.prototype.slice.call(e)), Jb(a, b, e));
        }
        return e;
      }
      function Lb(a, b) {
        var c = T(a, b);
        var d = null == c ? c : "number" === typeof c || "NaN" === c || "Infinity" === c || "-Infinity" === c ? Number(c) : void 0;
        null != d && d !== c && Jb(a, b, d);
        return d;
      }
      function Mb(a, b, c, d, e) {
        a.h || (a.h = {});
        var g = a.h[c], f = Kb(a, c, 3, e);
        if (!g) {
          var h = f;
          g = [];
          var k = !!(R(a.o) & 16);
          f = !!(R(h) & 2);
          var l = h;
          !e && f && (h = Array.prototype.slice.call(h));
          for (var m = f, r = 0; r < h.length; r++) {
            var p = h[r];
            var n = b, q2 = false;
            q2 = void 0 === q2 ? false : q2;
            p = Array.isArray(p) ? new n(p) : q2 ? new n() : void 0;
            if (void 0 !== p) {
              n = p.o;
              var t2 = q2 = R(n);
              f && (t2 |= 2);
              k && (t2 |= 16);
              t2 != q2 && S(n, t2);
              n = t2;
              m = m || !!(2 & n);
              g.push(p);
            }
          }
          a.h[c] = g;
          k = R(h);
          b = k | 33;
          b = m ? b & -9 : b | 8;
          k != b && (m = h, Object.isFrozen(m) && (m = Array.prototype.slice.call(m)), S(m, b), h = m);
          l !== h && Jb(
            a,
            c,
            h
          );
          (e || d && f) && Q2(g, 2);
          d && Object.freeze(g);
          return g;
        }
        e || (e = Object.isFrozen(g), d && !e ? Object.freeze(g) : !d && e && (g = Array.prototype.slice.call(g), a.h[c] = g));
        return g;
      }
      function Nb(a, b, c) {
        var d = !!(R(a.o) & 2);
        b = Mb(a, b, c, d, d);
        a = Kb(a, c, 3, d);
        if (!(d || R(a) & 8)) {
          for (d = 0; d < b.length; d++) {
            c = b[d];
            if (R(c.o) & 2) {
              var e = Ob(c, false);
              e.j = c;
            } else
              e = c;
            c !== e && (b[d] = e, a[d] = e.o);
          }
          Q2(a, 8);
        }
        return b;
      }
      function W2(a, b, c) {
        if (null != c && "number" !== typeof c)
          throw Error("Value of float/double field must be a number|null|undefined, found " + typeof c + ": " + c);
        V2(a, b, c);
      }
      function Pb(a, b, c, d, e) {
        Gb(a);
        var g = Mb(a, c, b, false, false);
        c = null != d ? d : new c();
        a = Kb(a, b, 2, false);
        void 0 != e ? (g.splice(e, 0, c), a.splice(e, 0, c.o)) : (g.push(c), a.push(c.o));
        c.C() && yb(a, 8);
        return c;
      }
      function Qb(a, b) {
        return null == a ? b : a;
      }
      function X2(a, b, c) {
        c = void 0 === c ? 0 : c;
        return Qb(Lb(a, b), c);
      }
      ;
      var Rb;
      function Sb(a) {
        switch (typeof a) {
          case "number":
            return isFinite(a) ? a : String(a);
          case "object":
            if (a)
              if (Array.isArray(a)) {
                if (0 !== (R(a) & 128))
                  return a = Array.prototype.slice.call(a), Hb(a), a;
              } else {
                if (Ha && null != a && a instanceof Uint8Array)
                  return Ja(a);
                if (a instanceof hb) {
                  var b = a.V;
                  return null == b ? "" : "string" === typeof b ? b : a.V = Ja(b);
                }
              }
        }
        return a;
      }
      ;
      function Tb(a, b, c, d) {
        if (null != a) {
          if (Array.isArray(a))
            a = Ub(a, b, c, void 0 !== d);
          else if (Db(a)) {
            var e = {}, g;
            for (g in a)
              e[g] = Tb(a[g], b, c, d);
            a = e;
          } else
            a = b(a, d);
          return a;
        }
      }
      function Ub(a, b, c, d) {
        var e = R(a);
        d = d ? !!(e & 16) : void 0;
        a = Array.prototype.slice.call(a);
        for (var g = 0; g < a.length; g++)
          a[g] = Tb(a[g], b, c, d);
        c(e, a);
        return a;
      }
      function Vb(a) {
        return a.ja === Cb ? a.toJSON() : Sb(a);
      }
      function Wb(a, b) {
        a & 128 && Hb(b);
      }
      ;
      function Xb(a, b, c) {
        c = void 0 === c ? Bb : c;
        if (null != a) {
          if (Ha && a instanceof Uint8Array)
            return a.length ? new hb(new Uint8Array(a), Pa) : ib();
          if (Array.isArray(a)) {
            var d = R(a);
            if (d & 2)
              return a;
            if (b && !(d & 32) && (d & 16 || 0 === d))
              return S(a, d | 2), a;
            a = Ub(a, Xb, d & 4 ? Bb : c, true);
            b = R(a);
            b & 4 && b & 2 && Object.freeze(a);
            return a;
          }
          return a.ja === Cb ? Yb(a) : a;
        }
      }
      function Zb(a, b, c, d, e, g, f) {
        if (a = a.h && a.h[c]) {
          d = R(a);
          d & 2 ? d = a : (g = Ba(a, Yb), Bb(d, g), Object.freeze(g), d = g);
          Gb(b);
          f = null == d ? Eb : zb([]);
          if (null != d) {
            g = !!d.length;
            for (a = 0; a < d.length; a++) {
              var h = d[a];
              g = g && !(R(h.o) & 2);
              f[a] = h.o;
            }
            g = (g ? 8 : 0) | 1;
            a = R(f);
            (a & g) !== g && (Object.isFrozen(f) && (f = Array.prototype.slice.call(f)), S(f, a | g));
            b.h || (b.h = {});
            b.h[c] = d;
          } else
            b.h && (b.h[c] = void 0);
          Jb(b, c, f, e);
        } else
          V2(b, c, Xb(d, g, f), e);
      }
      function Yb(a) {
        if (R(a.o) & 2)
          return a;
        a = Ob(a, true);
        Q2(a.o, 2);
        return a;
      }
      function Ob(a, b) {
        var c = a.o, d = [];
        Q2(d, 16);
        var e = a.constructor.h;
        e && d.push(e);
        e = a.B;
        if (e) {
          d.length = c.length;
          d.fill(void 0, d.length, c.length);
          var g = {};
          d[d.length - 1] = g;
        }
        0 !== (R(c) & 128) && Hb(d);
        b = b || a.C() ? Bb : Ab;
        g = a.constructor;
        Rb = d;
        d = new g(d);
        Rb = void 0;
        a.R && (d.R = a.R.slice());
        g = !!(R(c) & 16);
        for (var f = e ? c.length - 1 : c.length, h = 0; h < f; h++)
          Zb(a, d, h - a.G, c[h], false, g, b);
        if (e)
          for (var k in e)
            Zb(a, d, +k, e[k], true, g, b);
        return d;
      }
      ;
      function Y2(a, b, c) {
        null == a && (a = Rb);
        Rb = void 0;
        var d = this.constructor.i || 0, e = 0 < d, g = this.constructor.h, f = false;
        if (null == a) {
          a = g ? [g] : [];
          var h = 48;
          var k = true;
          e && (d = 0, h |= 128);
          S(a, h);
        } else {
          if (!Array.isArray(a))
            throw Error();
          if (g && g !== a[0])
            throw Error();
          var l = h = Q2(a, 0);
          if (k = 0 !== (16 & l))
            (f = 0 !== (32 & l)) || (l |= 32);
          if (e)
            if (128 & l)
              d = 0;
            else {
              if (0 < a.length) {
                var m = a[a.length - 1];
                if (Db(m) && "g" in m) {
                  d = 0;
                  l |= 128;
                  delete m.g;
                  var r = true, p;
                  for (p in m) {
                    r = false;
                    break;
                  }
                  r && a.pop();
                }
              }
            }
          else if (128 & l)
            throw Error();
          h !== l && S(a, l);
        }
        this.G = (g ? 0 : -1) - d;
        this.h = void 0;
        this.o = a;
        a: {
          g = this.o.length;
          d = g - 1;
          if (g && (g = this.o[d], Db(g))) {
            this.B = g;
            this.i = d - this.G;
            break a;
          }
          void 0 !== b && -1 < b ? (this.i = Math.max(b, d + 1 - this.G), this.B = void 0) : this.i = Number.MAX_VALUE;
        }
        if (!e && this.B && "g" in this.B)
          throw Error('Unexpected "g" flag in sparse object of message that is not a group type.');
        if (c) {
          b = k && !f && true;
          e = this.i;
          var n;
          for (k = 0; k < c.length; k++)
            f = c[k], f < e ? (f += this.G, (d = a[f]) ? $b(d, b) : a[f] = Eb) : (n || (n = Ib(this)), (d = n[f]) ? $b(d, b) : n[f] = Eb);
        }
      }
      Y2.prototype.toJSON = function() {
        return Ub(this.o, Vb, Wb);
      };
      Y2.prototype.C = function() {
        return !!(R(this.o) & 2);
      };
      function $b(a, b) {
        if (Array.isArray(a)) {
          var c = R(a), d = 1;
          !b || c & 2 || (d |= 16);
          (c & d) !== d && S(a, c | d);
        }
      }
      Y2.prototype.ja = Cb;
      Y2.prototype.toString = function() {
        return this.o.toString();
      };
      function ac(a, b, c) {
        if (c) {
          var d = {}, e;
          for (e in c) {
            var g = c[e], f = g.ra;
            f || (d.J = g.xa || g.oa.W, g.ia ? (d.aa = bc(g.ia), f = function(h) {
              return function(k, l, m) {
                return h.J(k, l, m, h.aa);
              };
            }(d)) : g.ka ? (d.Z = cc(g.da.P, g.ka), f = function(h) {
              return function(k, l, m) {
                return h.J(k, l, m, h.Z);
              };
            }(d)) : f = d.J, g.ra = f);
            f(b, a, g.da);
            d = { J: d.J, aa: d.aa, Z: d.Z };
          }
        }
        xb(b, a);
      }
      var dc = Symbol();
      function ec(a, b, c) {
        return a[dc] || (a[dc] = function(d, e) {
          return b(d, e, c);
        });
      }
      function fc(a) {
        var b = a[dc];
        if (!b) {
          var c = gc(a);
          b = function(d, e) {
            return hc(d, e, c);
          };
          a[dc] = b;
        }
        return b;
      }
      function ic(a) {
        var b = a.ia;
        if (b)
          return fc(b);
        if (b = a.wa)
          return ec(a.da.P, b, a.ka);
      }
      function jc(a) {
        var b = ic(a), c = a.da, d = a.oa.U;
        return b ? function(e, g) {
          return d(e, g, c, b);
        } : function(e, g) {
          return d(e, g, c);
        };
      }
      function kc(a, b) {
        var c = a[b];
        "function" == typeof c && 0 === c.length && (c = c(), a[b] = c);
        return Array.isArray(c) && (lc in c || mc in c || 0 < c.length && "function" == typeof c[0]) ? c : void 0;
      }
      function nc(a, b, c, d, e, g) {
        b.P = a[0];
        var f = 1;
        if (a.length > f && "number" !== typeof a[f]) {
          var h = a[f++];
          c(b, h);
        }
        for (; f < a.length; ) {
          c = a[f++];
          for (var k = f + 1; k < a.length && "number" !== typeof a[k]; )
            k++;
          h = a[f++];
          k -= f;
          switch (k) {
            case 0:
              d(b, c, h);
              break;
            case 1:
              (k = kc(a, f)) ? (f++, e(b, c, h, k)) : d(b, c, h, a[f++]);
              break;
            case 2:
              k = f++;
              k = kc(a, k);
              e(b, c, h, k, a[f++]);
              break;
            case 3:
              g(b, c, h, a[f++], a[f++], a[f++]);
              break;
            case 4:
              g(b, c, h, a[f++], a[f++], a[f++], a[f++]);
              break;
            default:
              throw Error("unexpected number of binary field arguments: " + k);
          }
        }
        return b;
      }
      var oc = Symbol();
      function bc(a) {
        var b = a[oc];
        if (!b) {
          var c = pc(a);
          b = function(d, e) {
            return qc(d, e, c);
          };
          a[oc] = b;
        }
        return b;
      }
      function cc(a, b) {
        var c = a[oc];
        c || (c = function(d, e) {
          return ac(d, e, b);
        }, a[oc] = c);
        return c;
      }
      var mc = Symbol();
      function rc(a, b) {
        a.push(b);
      }
      function sc(a, b, c) {
        a.push(b, c.W);
      }
      function tc(a, b, c, d) {
        var e = bc(d), g = pc(d).P, f = c.W;
        a.push(b, function(h, k, l) {
          return f(h, k, l, g, e);
        });
      }
      function uc(a, b, c, d, e, g) {
        var f = cc(d, g), h = c.W;
        a.push(b, function(k, l, m) {
          return h(k, l, m, d, f);
        });
      }
      function pc(a) {
        var b = a[mc];
        if (b)
          return b;
        b = nc(a, a[mc] = [], rc, sc, tc, uc);
        lc in a && mc in a && (a.length = 0);
        return b;
      }
      var lc = Symbol();
      function vc(a, b) {
        a[0] = b;
      }
      function wc(a, b, c, d) {
        var e = c.U;
        a[b] = d ? function(g, f, h) {
          return e(g, f, h, d);
        } : e;
      }
      function xc(a, b, c, d, e) {
        var g = c.U, f = fc(d), h = gc(d).P;
        a[b] = function(k, l, m) {
          return g(k, l, m, h, f, e);
        };
      }
      function yc(a, b, c, d, e, g, f) {
        var h = c.U, k = ec(d, e, g);
        a[b] = function(l, m, r) {
          return h(l, m, r, d, k, f);
        };
      }
      function gc(a) {
        var b = a[lc];
        if (b)
          return b;
        b = nc(a, a[lc] = {}, vc, wc, xc, yc);
        lc in a && mc in a && (a.length = 0);
        return b;
      }
      function hc(a, b, c) {
        for (; tb(b) && 4 != b.i; ) {
          var d = b.l, e = c[d];
          if (!e) {
            var g = c[0];
            g && (g = g[d]) && (e = c[d] = jc(g));
          }
          if (!e || !e(b, a, d)) {
            e = b;
            d = a;
            g = e.j;
            ub(e);
            var f = e;
            if (!f.ca) {
              e = f.h.h - g;
              f.h.h = g;
              f = f.h;
              if (0 == e)
                e = ib();
              else {
                g = ob(f, e);
                if (f.S && f.m)
                  e = f.i.subarray(g, g + e);
                else {
                  f = f.i;
                  var h = g;
                  e = g + e;
                  e = h === e ? Oa() : Qa ? f.slice(h, e) : new Uint8Array(f.subarray(h, e));
                }
                e = 0 == e.length ? ib() : new hb(e, Pa);
              }
              (g = d.R) ? g.push(e) : d.R = [e];
            }
          }
        }
        return a;
      }
      function qc(a, b, c) {
        for (var d = c.length, e = 1 == d % 2, g = e ? 1 : 0; g < d; g += 2)
          (0, c[g + 1])(b, a, c[g]);
        ac(a, b, e ? c[0] : void 0);
      }
      function zc(a, b) {
        return { U: a, W: b };
      }
      var Z2 = zc(function(a, b, c) {
        if (5 !== a.i)
          return false;
        a = a.h;
        var d = a.i, e = a.h, g = d[e];
        var f = d[e + 1];
        var h = d[e + 2];
        d = d[e + 3];
        M(a, a.h + 4);
        f = (g << 0 | f << 8 | h << 16 | d << 24) >>> 0;
        a = 2 * (f >> 31) + 1;
        g = f >>> 23 & 255;
        f &= 8388607;
        V2(b, c, 255 == g ? f ? NaN : Infinity * a : 0 == g ? a * Math.pow(2, -149) * f : a * Math.pow(2, g - 150) * (f + Math.pow(2, 23)));
        return true;
      }, function(a, b, c) {
        b = Lb(b, c);
        if (null != b) {
          N2(a.h, 8 * c + 5);
          a = a.h;
          var d = +b;
          0 === d ? 0 < 1 / d ? H2 = K2 = 0 : (K2 = 0, H2 = 2147483648) : isNaN(d) ? (K2 = 0, H2 = 2147483647) : (d = (c = 0 > d ? -2147483648 : 0) ? -d : d, 34028234663852886e22 < d ? (K2 = 0, H2 = (c | 2139095040) >>> 0) : 11754943508222875e-54 > d ? (d = Math.round(d / Math.pow(2, -149)), K2 = 0, H2 = (c | d) >>> 0) : (b = Math.floor(Math.log(d) / Math.LN2), d *= Math.pow(2, -b), d = Math.round(8388608 * d), 16777216 <= d && ++b, K2 = 0, H2 = (c | b + 127 << 23 | d & 8388607) >>> 0));
          c = H2;
          a.h.push(c >>> 0 & 255);
          a.h.push(c >>> 8 & 255);
          a.h.push(c >>> 16 & 255);
          a.h.push(c >>> 24 & 255);
        }
      }), Ac = zc(function(a, b, c) {
        if (0 !== a.i)
          return false;
        var d = a.h, e = 0, g = a = 0, f = d.i, h = d.h;
        do {
          var k = f[h++];
          e |= (k & 127) << g;
          g += 7;
        } while (32 > g && k & 128);
        32 < g && (a |= (k & 127) >> 4);
        for (g = 3; 32 > g && k & 128; g += 7)
          k = f[h++], a |= (k & 127) << g;
        M(
          d,
          h
        );
        if (128 > k) {
          d = e >>> 0;
          k = a >>> 0;
          if (a = k & 2147483648)
            d = ~d + 1 >>> 0, k = ~k >>> 0, 0 == d && (k = k + 1 >>> 0);
          d = 4294967296 * k + (d >>> 0);
        } else
          throw Ya();
        V2(b, c, a ? -d : d);
        return true;
      }, function(a, b, c) {
        b = T(b, c);
        null != b && ("string" === typeof b && Va(b), null != b && (N2(a.h, 8 * c), "number" === typeof b ? (a = a.h, Ra(b), rb(a, H2, K2)) : (c = Va(b), rb(a.h, c.i, c.h))));
      }), Bc = zc(function(a, b, c) {
        if (0 !== a.i)
          return false;
        V2(b, c, nb(a.h));
        return true;
      }, function(a, b, c) {
        b = T(b, c);
        if (null != b && null != b)
          if (N2(a.h, 8 * c), a = a.h, c = b, 0 <= c)
            N2(a, c);
          else {
            for (b = 0; 9 > b; b++)
              a.h.push(c & 127 | 128), c >>= 7;
            a.h.push(1);
          }
      }), Cc = zc(function(a, b, c) {
        if (2 !== a.i)
          return false;
        var d = nb(a.h) >>> 0;
        a = a.h;
        var e = ob(a, d);
        a = a.i;
        if (cb) {
          var g = a, f;
          (f = bb) || (f = bb = new TextDecoder("utf-8", { fatal: true }));
          a = e + d;
          g = 0 === e && a === g.length ? g : g.subarray(e, a);
          try {
            var h = f.decode(g);
          } catch (r) {
            if (void 0 === ab) {
              try {
                f.decode(new Uint8Array([128]));
              } catch (p) {
              }
              try {
                f.decode(new Uint8Array([97])), ab = true;
              } catch (p) {
                ab = false;
              }
            }
            !ab && (bb = void 0);
            throw r;
          }
        } else {
          h = e;
          d = h + d;
          e = [];
          for (var k = null, l, m; h < d; )
            l = a[h++], 128 > l ? e.push(l) : 224 > l ? h >= d ? L2() : (m = a[h++], 194 > l || 128 !== (m & 192) ? (h--, L2()) : e.push((l & 31) << 6 | m & 63)) : 240 > l ? h >= d - 1 ? L2() : (m = a[h++], 128 !== (m & 192) || 224 === l && 160 > m || 237 === l && 160 <= m || 128 !== ((g = a[h++]) & 192) ? (h--, L2()) : e.push((l & 15) << 12 | (m & 63) << 6 | g & 63)) : 244 >= l ? h >= d - 2 ? L2() : (m = a[h++], 128 !== (m & 192) || 0 !== (l << 28) + (m - 144) >> 30 || 128 !== ((g = a[h++]) & 192) || 128 !== ((f = a[h++]) & 192) ? (h--, L2()) : (l = (l & 7) << 18 | (m & 63) << 12 | (g & 63) << 6 | f & 63, l -= 65536, e.push((l >> 10 & 1023) + 55296, (l & 1023) + 56320))) : L2(), 8192 <= e.length && (k = $a(k, e), e.length = 0);
          h = $a(k, e);
        }
        V2(b, c, h);
        return true;
      }, function(a, b, c) {
        b = T(b, c);
        if (null != b) {
          var d = false;
          d = void 0 === d ? false : d;
          if (eb) {
            if (d && /(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])/.test(b))
              throw Error("Found an unpaired surrogate");
            b = (db || (db = new TextEncoder())).encode(b);
          } else {
            for (var e = 0, g = new Uint8Array(3 * b.length), f = 0; f < b.length; f++) {
              var h = b.charCodeAt(f);
              if (128 > h)
                g[e++] = h;
              else {
                if (2048 > h)
                  g[e++] = h >> 6 | 192;
                else {
                  if (55296 <= h && 57343 >= h) {
                    if (56319 >= h && f < b.length) {
                      var k = b.charCodeAt(++f);
                      if (56320 <= k && 57343 >= k) {
                        h = 1024 * (h - 55296) + k - 56320 + 65536;
                        g[e++] = h >> 18 | 240;
                        g[e++] = h >> 12 & 63 | 128;
                        g[e++] = h >> 6 & 63 | 128;
                        g[e++] = h & 63 | 128;
                        continue;
                      } else
                        f--;
                    }
                    if (d)
                      throw Error("Found an unpaired surrogate");
                    h = 65533;
                  }
                  g[e++] = h >> 12 | 224;
                  g[e++] = h >> 6 & 63 | 128;
                }
                g[e++] = h & 63 | 128;
              }
            }
            b = e === g.length ? g : g.subarray(0, e);
          }
          N2(a.h, 8 * c + 2);
          N2(a.h, b.length);
          O(a, a.h.end());
          O(a, b);
        }
      }), Dc = zc(function(a, b, c, d, e) {
        if (2 !== a.i)
          return false;
        b = Pb(b, c, d);
        c = a.h.j;
        d = nb(a.h) >>> 0;
        var g = a.h.h + d, f = g - c;
        0 >= f && (a.h.j = g, e(b, a, void 0, void 0, void 0), f = g - a.h.h);
        if (f)
          throw Error("Message parsing ended unexpectedly. Expected to read " + (d + " bytes, instead read " + (d - f) + " bytes, either the data ended unexpectedly or the message misreported its own length"));
        a.h.h = g;
        a.h.j = c;
        return true;
      }, function(a, b, c, d, e) {
        b = Nb(b, d, c);
        if (null != b)
          for (d = 0; d < b.length; d++) {
            var g = a;
            N2(g.h, 8 * c + 2);
            var f = g.h.end();
            O(g, f);
            f.push(g.i);
            g = f;
            e(b[d], a);
            f = a;
            var h = g.pop();
            for (h = f.i + f.h.length() - h; 127 < h; )
              g.push(h & 127 | 128), h >>>= 7, f.i++;
            g.push(h);
            f.i++;
          }
      });
      function Ec(a) {
        return function(b, c) {
          a: {
            if (vb.length) {
              var d = vb.pop();
              d.setOptions(c);
              mb(d.h, b, c);
              b = d;
            } else
              b = new sb(b, c);
            try {
              var e = gc(a);
              var g = hc(new e.P(), b, e);
              break a;
            } finally {
              e = b.h, e.i = null, e.m = false, e.l = 0, e.j = 0, e.h = 0, e.S = false, b.l = -1, b.i = -1, 100 > vb.length && vb.push(b);
            }
            g = void 0;
          }
          return g;
        };
      }
      function Fc(a) {
        return function() {
          var b = new wb();
          qc(this, b, pc(a));
          O(b, b.h.end());
          for (var c = new Uint8Array(b.i), d = b.j, e = d.length, g = 0, f = 0; f < e; f++) {
            var h = d[f];
            c.set(h, g);
            g += h.length;
          }
          b.j = [c];
          return c;
        };
      }
      ;
      function Gc(a) {
        Y2.call(this, a);
      }
      na(Gc, Y2);
      var Hc = [Gc, 1, Bc, 2, Z2, 3, Cc, 4, Cc];
      Gc.prototype.l = Fc(Hc);
      function Ic(a) {
        Y2.call(this, a, -1, Jc);
      }
      na(Ic, Y2);
      Ic.prototype.addClassification = function(a, b) {
        Pb(this, 1, Gc, a, b);
        return this;
      };
      var Jc = [1], Kc = Ec([Ic, 1, Dc, Hc]);
      function Lc(a) {
        Y2.call(this, a);
      }
      na(Lc, Y2);
      var Mc = [Lc, 1, Z2, 2, Z2, 3, Z2, 4, Z2, 5, Z2];
      Lc.prototype.l = Fc(Mc);
      function Nc(a) {
        Y2.call(this, a, -1, Oc);
      }
      na(Nc, Y2);
      var Oc = [1], Pc = Ec([Nc, 1, Dc, Mc]);
      function Qc(a) {
        Y2.call(this, a);
      }
      na(Qc, Y2);
      var Rc = [Qc, 1, Z2, 2, Z2, 3, Z2, 4, Z2, 5, Z2, 6, Ac], Sc = Ec(Rc);
      Qc.prototype.l = Fc(Rc);
      function Tc(a, b, c) {
        c = a.createShader(0 === c ? a.VERTEX_SHADER : a.FRAGMENT_SHADER);
        a.shaderSource(c, b);
        a.compileShader(c);
        if (!a.getShaderParameter(c, a.COMPILE_STATUS))
          throw Error("Could not compile WebGL shader.\n\n" + a.getShaderInfoLog(c));
        return c;
      }
      ;
      function Uc(a) {
        return Nb(a, Gc, 1).map(function(b) {
          var c = T(b, 1);
          return { index: null == c ? 0 : c, qa: X2(b, 2), label: null != T(b, 3) ? Qb(T(b, 3), "") : void 0, displayName: null != T(b, 4) ? Qb(T(b, 4), "") : void 0 };
        });
      }
      ;
      function Vc(a) {
        return { x: X2(a, 1), y: X2(a, 2), z: X2(a, 3), visibility: null != Lb(a, 4) ? X2(a, 4) : void 0 };
      }
      function Wc(a) {
        return Nb(Pc(a), Lc, 1).map(Vc);
      }
      ;
      function Xc(a, b) {
        this.i = a;
        this.h = b;
        this.m = 0;
      }
      function Yc(a, b, c) {
        Zc(a, b);
        if ("function" === typeof a.h.canvas.transferToImageBitmap)
          return Promise.resolve(a.h.canvas.transferToImageBitmap());
        if (c)
          return Promise.resolve(a.h.canvas);
        if ("function" === typeof createImageBitmap)
          return createImageBitmap(a.h.canvas);
        void 0 === a.j && (a.j = document.createElement("canvas"));
        return new Promise(function(d) {
          a.j.height = a.h.canvas.height;
          a.j.width = a.h.canvas.width;
          a.j.getContext("2d", {}).drawImage(a.h.canvas, 0, 0, a.h.canvas.width, a.h.canvas.height);
          d(a.j);
        });
      }
      function Zc(a, b) {
        var c = a.h;
        if (void 0 === a.s) {
          var d = Tc(c, "\n  attribute vec2 aVertex;\n  attribute vec2 aTex;\n  varying vec2 vTex;\n  void main(void) {\n    gl_Position = vec4(aVertex, 0.0, 1.0);\n    vTex = aTex;\n  }", 0), e = Tc(c, "\n  precision mediump float;\n  varying vec2 vTex;\n  uniform sampler2D sampler0;\n  void main(){\n    gl_FragColor = texture2D(sampler0, vTex);\n  }", 1), g = c.createProgram();
          c.attachShader(g, d);
          c.attachShader(g, e);
          c.linkProgram(g);
          if (!c.getProgramParameter(g, c.LINK_STATUS))
            throw Error("Could not compile WebGL program.\n\n" + c.getProgramInfoLog(g));
          d = a.s = g;
          c.useProgram(d);
          e = c.getUniformLocation(d, "sampler0");
          a.l = { O: c.getAttribLocation(d, "aVertex"), N: c.getAttribLocation(d, "aTex"), ya: e };
          a.v = c.createBuffer();
          c.bindBuffer(c.ARRAY_BUFFER, a.v);
          c.enableVertexAttribArray(a.l.O);
          c.vertexAttribPointer(a.l.O, 2, c.FLOAT, false, 0, 0);
          c.bufferData(c.ARRAY_BUFFER, new Float32Array([-1, -1, -1, 1, 1, 1, 1, -1]), c.STATIC_DRAW);
          c.bindBuffer(c.ARRAY_BUFFER, null);
          a.u = c.createBuffer();
          c.bindBuffer(c.ARRAY_BUFFER, a.u);
          c.enableVertexAttribArray(a.l.N);
          c.vertexAttribPointer(
            a.l.N,
            2,
            c.FLOAT,
            false,
            0,
            0
          );
          c.bufferData(c.ARRAY_BUFFER, new Float32Array([0, 1, 0, 0, 1, 0, 1, 1]), c.STATIC_DRAW);
          c.bindBuffer(c.ARRAY_BUFFER, null);
          c.uniform1i(e, 0);
        }
        d = a.l;
        c.useProgram(a.s);
        c.canvas.width = b.width;
        c.canvas.height = b.height;
        c.viewport(0, 0, b.width, b.height);
        c.activeTexture(c.TEXTURE0);
        a.i.bindTexture2d(b.glName);
        c.enableVertexAttribArray(d.O);
        c.bindBuffer(c.ARRAY_BUFFER, a.v);
        c.vertexAttribPointer(d.O, 2, c.FLOAT, false, 0, 0);
        c.enableVertexAttribArray(d.N);
        c.bindBuffer(c.ARRAY_BUFFER, a.u);
        c.vertexAttribPointer(
          d.N,
          2,
          c.FLOAT,
          false,
          0,
          0
        );
        c.bindFramebuffer(c.DRAW_FRAMEBUFFER ? c.DRAW_FRAMEBUFFER : c.FRAMEBUFFER, null);
        c.clearColor(0, 0, 0, 0);
        c.clear(c.COLOR_BUFFER_BIT);
        c.colorMask(true, true, true, true);
        c.drawArrays(c.TRIANGLE_FAN, 0, 4);
        c.disableVertexAttribArray(d.O);
        c.disableVertexAttribArray(d.N);
        c.bindBuffer(c.ARRAY_BUFFER, null);
        a.i.bindTexture2d(0);
      }
      function $c(a) {
        this.h = a;
      }
      ;
      var ad = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 9, 1, 7, 0, 65, 0, 253, 15, 26, 11]);
      function bd(a, b) {
        return b + a;
      }
      function cd(a, b) {
        window[a] = b;
      }
      function dd(a) {
        var b = document.createElement("script");
        b.setAttribute("src", a);
        b.setAttribute("crossorigin", "anonymous");
        return new Promise(function(c) {
          b.addEventListener("load", function() {
            c();
          }, false);
          b.addEventListener("error", function() {
            c();
          }, false);
          document.body.appendChild(b);
        });
      }
      function ed() {
        return E(function(a) {
          switch (a.h) {
            case 1:
              return a.s = 2, D2(a, WebAssembly.instantiate(ad), 4);
            case 4:
              a.h = 3;
              a.s = 0;
              break;
            case 2:
              return a.s = 0, a.l = null, a.return(false);
            case 3:
              return a.return(true);
          }
        });
      }
      function fd(a) {
        this.h = a;
        this.listeners = {};
        this.l = {};
        this.L = {};
        this.s = {};
        this.v = {};
        this.M = this.u = this.ga = true;
        this.I = Promise.resolve();
        this.fa = "";
        this.D = {};
        this.locateFile = a && a.locateFile || bd;
        if ("object" === typeof window)
          var b = window.location.pathname.toString().substring(0, window.location.pathname.toString().lastIndexOf("/")) + "/";
        else if ("undefined" !== typeof location)
          b = location.pathname.toString().substring(0, location.pathname.toString().lastIndexOf("/")) + "/";
        else
          throw Error("solutions can only be loaded on a web page or in a web worker");
        this.ha = b;
        if (a.options) {
          b = A(Object.keys(a.options));
          for (var c = b.next(); !c.done; c = b.next()) {
            c = c.value;
            var d = a.options[c].default;
            void 0 !== d && (this.l[c] = "function" === typeof d ? d() : d);
          }
        }
      }
      x = fd.prototype;
      x.close = function() {
        this.j && this.j.delete();
        return Promise.resolve();
      };
      function gd(a) {
        var b, c, d, e, g, f, h, k, l, m, r;
        return E(function(p) {
          switch (p.h) {
            case 1:
              if (!a.ga)
                return p.return();
              b = void 0 === a.h.files ? [] : "function" === typeof a.h.files ? a.h.files(a.l) : a.h.files;
              return D2(p, ed(), 2);
            case 2:
              c = p.i;
              if ("object" === typeof window)
                return cd("createMediapipeSolutionsWasm", { locateFile: a.locateFile }), cd("createMediapipeSolutionsPackedAssets", { locateFile: a.locateFile }), f = b.filter(function(n) {
                  return void 0 !== n.data;
                }), h = b.filter(function(n) {
                  return void 0 === n.data;
                }), k = Promise.all(f.map(function(n) {
                  var q2 = hd(a, n.url);
                  if (void 0 !== n.path) {
                    var t2 = n.path;
                    q2 = q2.then(function(w) {
                      a.overrideFile(t2, w);
                      return Promise.resolve(w);
                    });
                  }
                  return q2;
                })), l = Promise.all(h.map(function(n) {
                  return void 0 === n.simd || n.simd && c || !n.simd && !c ? dd(a.locateFile(n.url, a.ha)) : Promise.resolve();
                })).then(function() {
                  var n, q2, t2;
                  return E(function(w) {
                    if (1 == w.h)
                      return n = window.createMediapipeSolutionsWasm, q2 = window.createMediapipeSolutionsPackedAssets, t2 = a, D2(w, n(q2), 2);
                    t2.i = w.i;
                    w.h = 0;
                  });
                }), m = function() {
                  return E(function(n) {
                    a.h.graph && a.h.graph.url ? n = D2(
                      n,
                      hd(a, a.h.graph.url),
                      0
                    ) : (n.h = 0, n = void 0);
                    return n;
                  });
                }(), D2(p, Promise.all([l, k, m]), 7);
              if ("function" !== typeof importScripts)
                throw Error("solutions can only be loaded on a web page or in a web worker");
              d = b.filter(function(n) {
                return void 0 === n.simd || n.simd && c || !n.simd && !c;
              }).map(function(n) {
                return a.locateFile(n.url, a.ha);
              });
              importScripts.apply(null, ea(d));
              e = a;
              return D2(p, createMediapipeSolutionsWasm(Module), 6);
            case 6:
              e.i = p.i;
              a.m = new OffscreenCanvas(1, 1);
              a.i.canvas = a.m;
              g = a.i.GL.createContext(a.m, {
                antialias: false,
                alpha: false,
                va: "undefined" !== typeof WebGL2RenderingContext ? 2 : 1
              });
              a.i.GL.makeContextCurrent(g);
              p.h = 4;
              break;
            case 7:
              a.m = document.createElement("canvas");
              r = a.m.getContext("webgl2", {});
              if (!r && (r = a.m.getContext("webgl", {}), !r))
                return alert("Failed to create WebGL canvas context when passing video frame."), p.return();
              a.K = r;
              a.i.canvas = a.m;
              a.i.createContext(a.m, true, true, {});
            case 4:
              a.j = new a.i.SolutionWasm(), a.ga = false, p.h = 0;
          }
        });
      }
      function id(a) {
        var b, c, d, e, g, f, h, k;
        return E(function(l) {
          if (1 == l.h) {
            if (a.h.graph && a.h.graph.url && a.fa === a.h.graph.url)
              return l.return();
            a.u = true;
            if (!a.h.graph || !a.h.graph.url) {
              l.h = 2;
              return;
            }
            a.fa = a.h.graph.url;
            return D2(l, hd(a, a.h.graph.url), 3);
          }
          2 != l.h && (b = l.i, a.j.loadGraph(b));
          c = A(Object.keys(a.D));
          for (d = c.next(); !d.done; d = c.next())
            e = d.value, a.j.overrideFile(e, a.D[e]);
          a.D = {};
          if (a.h.listeners)
            for (g = A(a.h.listeners), f = g.next(); !f.done; f = g.next())
              h = f.value, jd(a, h);
          k = a.l;
          a.l = {};
          a.setOptions(k);
          l.h = 0;
        });
      }
      x.reset = function() {
        var a = this;
        return E(function(b) {
          a.j && (a.j.reset(), a.s = {}, a.v = {});
          b.h = 0;
        });
      };
      x.setOptions = function(a, b) {
        var c = this;
        if (b = b || this.h.options) {
          for (var d = [], e = [], g = {}, f = A(Object.keys(a)), h = f.next(); !h.done; g = { X: g.X, Y: g.Y }, h = f.next())
            if (h = h.value, !(h in this.l && this.l[h] === a[h])) {
              this.l[h] = a[h];
              var k = b[h];
              void 0 !== k && (k.onChange && (g.X = k.onChange, g.Y = a[h], d.push(function(l) {
                return function() {
                  var m;
                  return E(function(r) {
                    if (1 == r.h)
                      return D2(r, l.X(l.Y), 2);
                    m = r.i;
                    true === m && (c.u = true);
                    r.h = 0;
                  });
                };
              }(g))), k.graphOptionXref && (h = Object.assign(
                {},
                { calculatorName: "", calculatorIndex: 0 },
                k.graphOptionXref,
                { valueNumber: 1 === k.type ? a[h] : 0, valueBoolean: 0 === k.type ? a[h] : false, valueString: 2 === k.type ? a[h] : "" }
              ), e.push(h)));
            }
          if (0 !== d.length || 0 !== e.length)
            this.u = true, this.H = (void 0 === this.H ? [] : this.H).concat(e), this.F = (void 0 === this.F ? [] : this.F).concat(d);
        }
      };
      function kd(a) {
        var b, c, d, e, g, f, h;
        return E(function(k) {
          switch (k.h) {
            case 1:
              if (!a.u)
                return k.return();
              if (!a.F) {
                k.h = 2;
                break;
              }
              b = A(a.F);
              c = b.next();
            case 3:
              if (c.done) {
                k.h = 5;
                break;
              }
              d = c.value;
              return D2(k, d(), 4);
            case 4:
              c = b.next();
              k.h = 3;
              break;
            case 5:
              a.F = void 0;
            case 2:
              if (a.H) {
                e = new a.i.GraphOptionChangeRequestList();
                g = A(a.H);
                for (f = g.next(); !f.done; f = g.next())
                  h = f.value, e.push_back(h);
                a.j.changeOptions(e);
                e.delete();
                a.H = void 0;
              }
              a.u = false;
              k.h = 0;
          }
        });
      }
      x.initialize = function() {
        var a = this;
        return E(function(b) {
          return 1 == b.h ? D2(b, gd(a), 2) : 3 != b.h ? D2(b, id(a), 3) : D2(b, kd(a), 0);
        });
      };
      function hd(a, b) {
        var c, d;
        return E(function(e) {
          if (b in a.L)
            return e.return(a.L[b]);
          c = a.locateFile(b, "");
          d = fetch(c).then(function(g) {
            return g.arrayBuffer();
          });
          a.L[b] = d;
          return e.return(d);
        });
      }
      x.overrideFile = function(a, b) {
        this.j ? this.j.overrideFile(a, b) : this.D[a] = b;
      };
      x.clearOverriddenFiles = function() {
        this.D = {};
        this.j && this.j.clearOverriddenFiles();
      };
      x.send = function(a, b) {
        var c = this, d, e, g, f, h, k, l, m, r;
        return E(function(p) {
          switch (p.h) {
            case 1:
              if (!c.h.inputs)
                return p.return();
              d = 1e3 * (void 0 === b || null === b ? performance.now() : b);
              return D2(p, c.I, 2);
            case 2:
              return D2(p, c.initialize(), 3);
            case 3:
              e = new c.i.PacketDataList();
              g = A(Object.keys(a));
              for (f = g.next(); !f.done; f = g.next())
                if (h = f.value, k = c.h.inputs[h]) {
                  a: {
                    var n = a[h];
                    switch (k.type) {
                      case "video":
                        var q2 = c.s[k.stream];
                        q2 || (q2 = new Xc(c.i, c.K), c.s[k.stream] = q2);
                        0 === q2.m && (q2.m = q2.i.createTexture());
                        if ("undefined" !== typeof HTMLVideoElement && n instanceof HTMLVideoElement) {
                          var t2 = n.videoWidth;
                          var w = n.videoHeight;
                        } else
                          "undefined" !== typeof HTMLImageElement && n instanceof HTMLImageElement ? (t2 = n.naturalWidth, w = n.naturalHeight) : (t2 = n.width, w = n.height);
                        w = { glName: q2.m, width: t2, height: w };
                        t2 = q2.h;
                        t2.canvas.width = w.width;
                        t2.canvas.height = w.height;
                        t2.activeTexture(t2.TEXTURE0);
                        q2.i.bindTexture2d(q2.m);
                        t2.texImage2D(t2.TEXTURE_2D, 0, t2.RGBA, t2.RGBA, t2.UNSIGNED_BYTE, n);
                        q2.i.bindTexture2d(0);
                        q2 = w;
                        break a;
                      case "detections":
                        q2 = c.s[k.stream];
                        q2 || (q2 = new $c(c.i), c.s[k.stream] = q2);
                        q2.data || (q2.data = new q2.h.DetectionListData());
                        q2.data.reset(n.length);
                        for (w = 0; w < n.length; ++w) {
                          t2 = n[w];
                          var v = q2.data, B2 = v.setBoundingBox, J2 = w;
                          var I = t2.la;
                          var u = new Qc();
                          W2(u, 1, I.sa);
                          W2(u, 2, I.ta);
                          W2(u, 3, I.height);
                          W2(u, 4, I.width);
                          W2(u, 5, I.rotation);
                          V2(u, 6, I.pa);
                          I = u.l();
                          B2.call(v, J2, I);
                          if (t2.ea)
                            for (v = 0; v < t2.ea.length; ++v) {
                              u = t2.ea[v];
                              B2 = q2.data;
                              J2 = B2.addNormalizedLandmark;
                              I = w;
                              u = Object.assign({}, u, { visibility: u.visibility ? u.visibility : 0 });
                              var C = new Lc();
                              W2(C, 1, u.x);
                              W2(C, 2, u.y);
                              W2(C, 3, u.z);
                              u.visibility && W2(C, 4, u.visibility);
                              u = C.l();
                              J2.call(
                                B2,
                                I,
                                u
                              );
                            }
                          if (t2.ba)
                            for (v = 0; v < t2.ba.length; ++v)
                              B2 = q2.data, J2 = B2.addClassification, I = w, u = t2.ba[v], C = new Gc(), W2(C, 2, u.qa), u.index && V2(C, 1, u.index), u.label && V2(C, 3, u.label), u.displayName && V2(C, 4, u.displayName), u = C.l(), J2.call(B2, I, u);
                        }
                        q2 = q2.data;
                        break a;
                      default:
                        q2 = {};
                    }
                  }
                  l = q2;
                  m = k.stream;
                  switch (k.type) {
                    case "video":
                      e.pushTexture2d(Object.assign({}, l, { stream: m, timestamp: d }));
                      break;
                    case "detections":
                      r = l;
                      r.stream = m;
                      r.timestamp = d;
                      e.pushDetectionList(r);
                      break;
                    default:
                      throw Error("Unknown input config type: '" + k.type + "'");
                  }
                }
              c.j.send(e);
              return D2(p, c.I, 4);
            case 4:
              e.delete(), p.h = 0;
          }
        });
      };
      function ld(a, b, c) {
        var d, e, g, f, h, k, l, m, r, p, n, q2, t2, w;
        return E(function(v) {
          switch (v.h) {
            case 1:
              if (!c)
                return v.return(b);
              d = {};
              e = 0;
              g = A(Object.keys(c));
              for (f = g.next(); !f.done; f = g.next())
                h = f.value, k = c[h], "string" !== typeof k && "texture" === k.type && void 0 !== b[k.stream] && ++e;
              1 < e && (a.M = false);
              l = A(Object.keys(c));
              f = l.next();
            case 2:
              if (f.done) {
                v.h = 4;
                break;
              }
              m = f.value;
              r = c[m];
              if ("string" === typeof r)
                return t2 = d, w = m, D2(v, md(a, m, b[r]), 14);
              p = b[r.stream];
              if ("detection_list" === r.type) {
                if (p) {
                  var B2 = p.getRectList();
                  for (var J2 = p.getLandmarksList(), I = p.getClassificationsList(), u = [], C = 0; C < B2.size(); ++C) {
                    var U2 = Sc(B2.get(C)), pd = X2(U2, 1), qd = X2(U2, 2), rd = X2(U2, 3), sd = X2(U2, 4), td = X2(U2, 5, 0), za = void 0;
                    za = void 0 === za ? 0 : za;
                    U2 = { la: { sa: pd, ta: qd, height: rd, width: sd, rotation: td, pa: Qb(T(U2, 6), za) }, ea: Wc(J2.get(C)), ba: Uc(Kc(I.get(C))) };
                    u.push(U2);
                  }
                  B2 = u;
                } else
                  B2 = [];
                d[m] = B2;
                v.h = 7;
                break;
              }
              if ("proto_list" === r.type) {
                if (p) {
                  B2 = Array(p.size());
                  for (J2 = 0; J2 < p.size(); J2++)
                    B2[J2] = p.get(J2);
                  p.delete();
                } else
                  B2 = [];
                d[m] = B2;
                v.h = 7;
                break;
              }
              if (void 0 === p) {
                v.h = 3;
                break;
              }
              if ("float_list" === r.type) {
                d[m] = p;
                v.h = 7;
                break;
              }
              if ("proto" === r.type) {
                d[m] = p;
                v.h = 7;
                break;
              }
              if ("texture" !== r.type)
                throw Error("Unknown output config type: '" + r.type + "'");
              n = a.v[m];
              n || (n = new Xc(a.i, a.K), a.v[m] = n);
              return D2(v, Yc(n, p, a.M), 13);
            case 13:
              q2 = v.i, d[m] = q2;
            case 7:
              r.transform && d[m] && (d[m] = r.transform(d[m]));
              v.h = 3;
              break;
            case 14:
              t2[w] = v.i;
            case 3:
              f = l.next();
              v.h = 2;
              break;
            case 4:
              return v.return(d);
          }
        });
      }
      function md(a, b, c) {
        var d;
        return E(function(e) {
          return "number" === typeof c || c instanceof Uint8Array || c instanceof a.i.Uint8BlobList ? e.return(c) : c instanceof a.i.Texture2dDataOut ? (d = a.v[b], d || (d = new Xc(a.i, a.K), a.v[b] = d), e.return(Yc(d, c, a.M))) : e.return(void 0);
        });
      }
      function jd(a, b) {
        for (var c = b.name || "$", d = [].concat(ea(b.wants)), e = new a.i.StringList(), g = A(b.wants), f = g.next(); !f.done; f = g.next())
          e.push_back(f.value);
        g = a.i.PacketListener.implement({ onResults: function(h) {
          for (var k = {}, l = 0; l < b.wants.length; ++l)
            k[d[l]] = h.get(l);
          var m = a.listeners[c];
          m && (a.I = ld(a, k, b.outs).then(function(r) {
            r = m(r);
            for (var p = 0; p < b.wants.length; ++p) {
              var n = k[d[p]];
              "object" === typeof n && n.hasOwnProperty && n.hasOwnProperty("delete") && n.delete();
            }
            r && (a.I = r);
          }));
        } });
        a.j.attachMultiListener(e, g);
        e.delete();
      }
      x.onResults = function(a, b) {
        this.listeners[b || "$"] = a;
      };
      G2("Solution", fd);
      G2("OptionType", { BOOL: 0, NUMBER: 1, ua: 2, 0: "BOOL", 1: "NUMBER", 2: "STRING" });
      function nd(a) {
        void 0 === a && (a = 0);
        switch (a) {
          case 1:
            return "pose_landmark_full.tflite";
          case 2:
            return "pose_landmark_heavy.tflite";
          default:
            return "pose_landmark_lite.tflite";
        }
      }
      function od(a) {
        var b = this;
        a = a || {};
        this.h = new fd({ locateFile: a.locateFile, files: function(c) {
          return [{ url: "pose_solution_packed_assets_loader.js" }, { simd: false, url: "pose_solution_wasm_bin.js" }, { simd: true, url: "pose_solution_simd_wasm_bin.js" }, { data: true, url: nd(c.modelComplexity) }];
        }, graph: { url: "pose_web.binarypb" }, listeners: [{ wants: ["pose_landmarks", "world_landmarks", "segmentation_mask", "image_transformed"], outs: { image: { type: "texture", stream: "image_transformed" }, poseLandmarks: {
          type: "proto",
          stream: "pose_landmarks",
          transform: Wc
        }, poseWorldLandmarks: { type: "proto", stream: "world_landmarks", transform: Wc }, segmentationMask: { type: "texture", stream: "segmentation_mask" } } }], inputs: { image: { type: "video", stream: "input_frames_gpu" } }, options: {
          useCpuInference: { type: 0, graphOptionXref: { calculatorType: "InferenceCalculator", fieldName: "use_cpu_inference" }, default: "object" !== typeof window || void 0 === window.navigator ? false : "iPad Simulator;iPhone Simulator;iPod Simulator;iPad;iPhone;iPod".split(";").includes(navigator.platform) || navigator.userAgent.includes("Mac") && "ontouchend" in document },
          selfieMode: { type: 0, graphOptionXref: { calculatorType: "GlScalerCalculator", calculatorIndex: 1, fieldName: "flip_horizontal" } },
          modelComplexity: { type: 1, graphOptionXref: { calculatorType: "ConstantSidePacketCalculator", calculatorName: "ConstantSidePacketCalculatorModelComplexity", fieldName: "int_value" }, onChange: function(c) {
            var d, e, g;
            return E(function(f) {
              if (1 == f.h)
                return d = nd(c), e = "third_party/mediapipe/modules/pose_landmark/" + d, D2(f, hd(b.h, d), 2);
              g = f.i;
              b.h.overrideFile(e, g);
              return f.return(true);
            });
          } },
          smoothLandmarks: { type: 0, graphOptionXref: { calculatorType: "ConstantSidePacketCalculator", calculatorName: "ConstantSidePacketCalculatorSmoothLandmarks", fieldName: "bool_value" } },
          enableSegmentation: { type: 0, graphOptionXref: { calculatorType: "ConstantSidePacketCalculator", calculatorName: "ConstantSidePacketCalculatorEnableSegmentation", fieldName: "bool_value" } },
          smoothSegmentation: { type: 0, graphOptionXref: {
            calculatorType: "ConstantSidePacketCalculator",
            calculatorName: "ConstantSidePacketCalculatorSmoothSegmentation",
            fieldName: "bool_value"
          } },
          minDetectionConfidence: { type: 1, graphOptionXref: { calculatorType: "TensorsToDetectionsCalculator", calculatorName: "poselandmarkgpu__posedetectiongpu__TensorsToDetectionsCalculator", fieldName: "min_score_thresh" } },
          minTrackingConfidence: { type: 1, graphOptionXref: { calculatorType: "ThresholdingCalculator", calculatorName: "poselandmarkgpu__poselandmarkbyroigpu__tensorstoposelandmarksandsegmentation__ThresholdingCalculator", fieldName: "threshold" } }
        } });
      }
      x = od.prototype;
      x.reset = function() {
        this.h.reset();
      };
      x.close = function() {
        this.h.close();
        return Promise.resolve();
      };
      x.onResults = function(a) {
        this.h.onResults(a);
      };
      x.initialize = function() {
        var a = this;
        return E(function(b) {
          return D2(b, a.h.initialize(), 0);
        });
      };
      x.send = function(a, b) {
        var c = this;
        return E(function(d) {
          return D2(d, c.h.send(a, b), 0);
        });
      };
      x.setOptions = function(a) {
        this.h.setOptions(a);
      };
      G2("Pose", od);
      G2("POSE_CONNECTIONS", [[0, 1], [1, 2], [2, 3], [3, 7], [0, 4], [4, 5], [5, 6], [6, 8], [9, 10], [11, 12], [11, 13], [13, 15], [15, 17], [15, 19], [15, 21], [17, 19], [12, 14], [14, 16], [16, 18], [16, 20], [16, 22], [18, 20], [11, 23], [12, 24], [23, 24], [23, 25], [24, 26], [25, 27], [26, 28], [27, 29], [28, 30], [29, 31], [30, 32], [27, 31], [28, 32]]);
      G2("POSE_LANDMARKS", { NOSE: 0, LEFT_EYE_INNER: 1, LEFT_EYE: 2, LEFT_EYE_OUTER: 3, RIGHT_EYE_INNER: 4, RIGHT_EYE: 5, RIGHT_EYE_OUTER: 6, LEFT_EAR: 7, RIGHT_EAR: 8, LEFT_RIGHT: 9, RIGHT_LEFT: 10, LEFT_SHOULDER: 11, RIGHT_SHOULDER: 12, LEFT_ELBOW: 13, RIGHT_ELBOW: 14, LEFT_WRIST: 15, RIGHT_WRIST: 16, LEFT_PINKY: 17, RIGHT_PINKY: 18, LEFT_INDEX: 19, RIGHT_INDEX: 20, LEFT_THUMB: 21, RIGHT_THUMB: 22, LEFT_HIP: 23, RIGHT_HIP: 24, LEFT_KNEE: 25, RIGHT_KNEE: 26, LEFT_ANKLE: 27, RIGHT_ANKLE: 28, LEFT_HEEL: 29, RIGHT_HEEL: 30, LEFT_FOOT_INDEX: 31, RIGHT_FOOT_INDEX: 32 });
      G2("POSE_LANDMARKS_LEFT", { LEFT_EYE_INNER: 1, LEFT_EYE: 2, LEFT_EYE_OUTER: 3, LEFT_EAR: 7, LEFT_RIGHT: 9, LEFT_SHOULDER: 11, LEFT_ELBOW: 13, LEFT_WRIST: 15, LEFT_PINKY: 17, LEFT_INDEX: 19, LEFT_THUMB: 21, LEFT_HIP: 23, LEFT_KNEE: 25, LEFT_ANKLE: 27, LEFT_HEEL: 29, LEFT_FOOT_INDEX: 31 });
      G2("POSE_LANDMARKS_RIGHT", { RIGHT_EYE_INNER: 4, RIGHT_EYE: 5, RIGHT_EYE_OUTER: 6, RIGHT_EAR: 8, RIGHT_LEFT: 10, RIGHT_SHOULDER: 12, RIGHT_ELBOW: 14, RIGHT_WRIST: 16, RIGHT_PINKY: 18, RIGHT_INDEX: 20, RIGHT_THUMB: 22, RIGHT_HIP: 24, RIGHT_KNEE: 26, RIGHT_ANKLE: 28, RIGHT_HEEL: 30, RIGHT_FOOT_INDEX: 32 });
      G2("POSE_LANDMARKS_NEUTRAL", { NOSE: 0 });
      G2("VERSION", "0.5.1675469404");
    }).call(exports);
  }
});

// node_modules/@tensorflow-models/pose-detection/dist/pose-detection.esm.js
var import_pose = __toESM(require_pose());

// node_modules/@tensorflow/tfjs-converter/dist/flags.js
var ENV = env();
ENV.registerFlag("KEEP_INTERMEDIATE_TENSORS", () => false, (debugValue) => {
  if (debugValue) {
    console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
  }
});

// node_modules/@tensorflow/tfjs-converter/dist/data/compiled_api.js
var DataType;
(function(DataType2) {
  DataType2[DataType2["DT_INVALID"] = 0] = "DT_INVALID";
  DataType2[DataType2["DT_FLOAT"] = 1] = "DT_FLOAT";
  DataType2[DataType2["DT_DOUBLE"] = 2] = "DT_DOUBLE";
  DataType2[DataType2["DT_INT32"] = 3] = "DT_INT32";
  DataType2[DataType2["DT_UINT8"] = 4] = "DT_UINT8";
  DataType2[DataType2["DT_INT16"] = 5] = "DT_INT16";
  DataType2[DataType2["DT_INT8"] = 6] = "DT_INT8";
  DataType2[DataType2["DT_STRING"] = 7] = "DT_STRING";
  DataType2[DataType2["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
  DataType2[DataType2["DT_INT64"] = 9] = "DT_INT64";
  DataType2[DataType2["DT_BOOL"] = 10] = "DT_BOOL";
  DataType2[DataType2["DT_QINT8"] = 11] = "DT_QINT8";
  DataType2[DataType2["DT_QUINT8"] = 12] = "DT_QUINT8";
  DataType2[DataType2["DT_QINT32"] = 13] = "DT_QINT32";
  DataType2[DataType2["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
  DataType2[DataType2["DT_QINT16"] = 15] = "DT_QINT16";
  DataType2[DataType2["DT_QUINT16"] = 16] = "DT_QUINT16";
  DataType2[DataType2["DT_UINT16"] = 17] = "DT_UINT16";
  DataType2[DataType2["DT_COMPLEX128"] = 18] = "DT_COMPLEX128";
  DataType2[DataType2["DT_HALF"] = 19] = "DT_HALF";
  DataType2[DataType2["DT_RESOURCE"] = 20] = "DT_RESOURCE";
  DataType2[DataType2["DT_VARIANT"] = 21] = "DT_VARIANT";
  DataType2[DataType2["DT_UINT32"] = 22] = "DT_UINT32";
  DataType2[DataType2["DT_UINT64"] = 23] = "DT_UINT64";
  DataType2[DataType2["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
  DataType2[DataType2["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
  DataType2[DataType2["DT_INT32_REF"] = 103] = "DT_INT32_REF";
  DataType2[DataType2["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
  DataType2[DataType2["DT_INT16_REF"] = 105] = "DT_INT16_REF";
  DataType2[DataType2["DT_INT8_REF"] = 106] = "DT_INT8_REF";
  DataType2[DataType2["DT_STRING_REF"] = 107] = "DT_STRING_REF";
  DataType2[DataType2["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
  DataType2[DataType2["DT_INT64_REF"] = 109] = "DT_INT64_REF";
  DataType2[DataType2["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
  DataType2[DataType2["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
  DataType2[DataType2["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
  DataType2[DataType2["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
  DataType2[DataType2["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
  DataType2[DataType2["DT_QINT16_REF"] = 115] = "DT_QINT16_REF";
  DataType2[DataType2["DT_QUINT16_REF"] = 116] = "DT_QUINT16_REF";
  DataType2[DataType2["DT_UINT16_REF"] = 117] = "DT_UINT16_REF";
  DataType2[DataType2["DT_COMPLEX128_REF"] = 118] = "DT_COMPLEX128_REF";
  DataType2[DataType2["DT_HALF_REF"] = 119] = "DT_HALF_REF";
  DataType2[DataType2["DT_RESOURCE_REF"] = 120] = "DT_RESOURCE_REF";
  DataType2[DataType2["DT_VARIANT_REF"] = 121] = "DT_VARIANT_REF";
  DataType2[DataType2["DT_UINT32_REF"] = 122] = "DT_UINT32_REF";
  DataType2[DataType2["DT_UINT64_REF"] = 123] = "DT_UINT64_REF";
})(DataType || (DataType = {}));
var SaverDef;
(function(SaverDef2) {
  let CheckpointFormatVersion;
  (function(CheckpointFormatVersion2) {
    CheckpointFormatVersion2[CheckpointFormatVersion2["LEGACY"] = 0] = "LEGACY";
    CheckpointFormatVersion2[CheckpointFormatVersion2["V1"] = 1] = "V1";
    CheckpointFormatVersion2[CheckpointFormatVersion2["V2"] = 2] = "V2";
  })(CheckpointFormatVersion = SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
})(SaverDef || (SaverDef = {}));

// node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/register.js
var CUSTOM_OPS = {};
function getRegisteredOp(name) {
  return CUSTOM_OPS[name];
}

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/utils.js
function getParamValue(paramName, node, tensorMap, context, resourceManager) {
  const inputParam = node.inputParams[paramName];
  if (inputParam && inputParam.inputIndexStart !== void 0) {
    const start = inputParam.inputIndexStart;
    const end = inputParam.inputIndexEnd === 0 ? void 0 : inputParam.inputIndexEnd === void 0 ? start + 1 : inputParam.inputIndexEnd;
    const shiftedStart = start < 0 ? node.inputNames.length + start : start;
    if (inputParam.type === "tensor") {
      return getTensor(node.inputNames[shiftedStart], tensorMap, context, resourceManager);
    }
    if (inputParam.type === "tensors") {
      const inputs = node.inputs.slice(start, end);
      const inputNames = node.inputNames.slice(start, end).filter((_name, index) => {
        var _a;
        return ((_a = inputs[index]) === null || _a === void 0 ? void 0 : _a.op) !== "NoOp";
      });
      return inputNames.map((name) => getTensor(name, tensorMap, context, resourceManager));
    }
    const tensor2 = getTensor(node.inputNames[shiftedStart], tensorMap, context, resourceManager);
    const data = tensor2.dataSync();
    return inputParam.type === "number" ? data[0] : util_exports.toNestedArray(tensor2.shape, data);
  }
  const attrParam = node.attrParams[paramName];
  return attrParam && attrParam.value;
}
function getTensor(name, tensorsMap, context, resourceManager) {
  const [nodeName, index] = parseNodeName(name, context);
  if (resourceManager != null) {
    const tensor2 = resourceManager.getHashTableHandleByName(nodeName);
    if (tensor2 != null) {
      return tensor2;
    }
  }
  const contextId = context.currentContextIds.find((contextId2) => {
    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId2)];
  });
  return contextId !== void 0 ? tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] : void 0;
}
function getTensorsForCurrentContext(name, tensorsMap, context) {
  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];
}
function getNodeNameAndIndex(inputName, context) {
  const [nodeName, index, outputName] = parseNodeName(inputName, context);
  return [
    getNodeNameWithContextId(nodeName, context && context.currentContextId),
    index,
    outputName
  ];
}
function getNodeNameWithContextId(name, contextId) {
  return !!contextId ? `${name}-${contextId}` : name;
}
function parseNodeName(name, context) {
  if (name === "") {
    return ["", 0, void 0];
  }
  const isCacheEnabled = context != null && context.parseNodeNameCache != null;
  if (isCacheEnabled) {
    const cachedResult = context.parseNodeNameCache.get(name);
    if (cachedResult != null) {
      return cachedResult;
    }
  }
  const parts = name.split(":");
  let result;
  if (parts.length === 1) {
    result = [name, 0, void 0];
  } else {
    const nodeName = parts[0];
    const outputName = parts.length === 3 ? parts[1] : void 0;
    const index = Number(parts[parts.length - 1]);
    result = [nodeName, index, outputName];
  }
  if (isCacheEnabled) {
    context.parseNodeNameCache.set(name, result);
  }
  return result;
}
function getPadding(node, tensorMap, context) {
  let pad2 = getParamValue("pad", node, tensorMap, context);
  if (pad2 === "explicit") {
    pad2 = getParamValue("explicitPaddings", node, tensorMap, context);
    const explicitPadding = [[0, 0], [0, 0], [0, 0], [0, 0]];
    for (let i = 0; i < 4; i++) {
      explicitPadding[i][0] = pad2[i * 2];
      explicitPadding[i][1] = pad2[i * 2 + 1];
    }
    return explicitPadding;
  }
  return pad2;
}
function cloneTensor(tensor2) {
  return tensor2.kept ? tensor2 : clone(tensor2);
}

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js
var arithmetic_exports = {};
__export(arithmetic_exports, {
  json: () => json
});
var json = [
  {
    "tfOpName": "Add",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "AddV2",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "AddN",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "tensors",
        "type": "tensors"
      }
    ]
  },
  {
    "tfOpName": "BiasAdd",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sub",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "RealDiv",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Div",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "DivNoNan",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "FloorDiv",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Mul",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Maximum",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Minimum",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Pow",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "SquaredDifference",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Mod",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "FloorMod",
    "category": "arithmetic",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js
var basic_math_exports = {};
__export(basic_math_exports, {
  json: () => json2
});
var json2 = [
  {
    "tfOpName": "Abs",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Acos",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Asin",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Atan",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Atan2",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "y",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Ceil",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "ClipByValue",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "clipValueMin",
        "type": "number"
      },
      {
        "start": 2,
        "name": "clipValueMax",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Complex",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "real",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "imag",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "ComplexAbs",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Cos",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Cosh",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Elu",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Exp",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Floor",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Log",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Imag",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "Tout",
        "name": "outputType",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Neg",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Real",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "Tout",
        "name": "outputType",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Prelu",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "alpha",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Relu",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Relu6",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Selu",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sigmoid",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sin",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sinh",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sqrt",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Rsqrt",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Square",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Tan",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Tanh",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sign",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Round",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Expm1",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Log1p",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Reciprocal",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Softplus",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Asinh",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Acosh",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Atanh",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Erf",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LeakyRelu",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "alpha",
        "name": "alpha",
        "type": "number",
        "defaultValue": 0.2
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "IsNan",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "IsFinite",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "IsInf",
    "category": "basic_math",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/control.js
var control_exports = {};
__export(control_exports, {
  json: () => json3
});
var json3 = [
  {
    "tfOpName": "EmptyTensorList",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "elementShape",
        "type": "shape"
      },
      {
        "start": 1,
        "name": "maxNumElements",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "LoopCond",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "pred",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "Switch",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "data",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "pred",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "Merge",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "tensors",
        "type": "tensors"
      }
    ]
  },
  {
    "tfOpName": "Enter",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "frame_name",
        "name": "frameName",
        "type": "string"
      },
      {
        "tfName": "is_constant",
        "name": "isConstant",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Exit",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "NextIteration",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "TensorArrayV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "size",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "element_shape",
        "name": "elementShape",
        "type": "shape"
      },
      {
        "tfName": "dynamic_size",
        "name": "dynamicSize",
        "type": "bool"
      },
      {
        "tfName": "clear_after_read",
        "name": "clearAfterRead",
        "type": "bool"
      },
      {
        "tfName": "identical_element_shapes",
        "name": "identicalElementShapes",
        "type": "bool"
      },
      {
        "tfName": "tensor_array_name",
        "name": "name",
        "type": "string"
      }
    ]
  },
  {
    "tfOpName": "TensorArrayWriteV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "index",
        "type": "number"
      },
      {
        "start": 2,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "flowIn",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "TensorArrayReadV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "index",
        "type": "number"
      },
      {
        "start": 2,
        "name": "flowIn",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "TensorArrayGatherV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "flowIn",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "element_shape",
        "name": "elementShape",
        "type": "shape"
      }
    ]
  },
  {
    "tfOpName": "TensorArrayScatterV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "flowIn",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorArrayConcatV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "flowIn",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "element_shape_except0",
        "name": "elementShapeExcept0",
        "type": "shape",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "TensorArraySplitV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "lengths",
        "type": "number[]"
      },
      {
        "start": 3,
        "name": "flowIn",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorArraySizeV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "flowIn",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "TensorArrayCloseV3",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorArrayId",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "StatelessIf",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "cond",
        "type": "tensor"
      },
      {
        "start": 1,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "then_branch",
        "name": "thenBranch",
        "type": "func"
      },
      {
        "tfName": "else_branch",
        "name": "elseBranch",
        "type": "func"
      }
    ]
  },
  {
    "tfOpName": "If",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "cond",
        "type": "tensor"
      },
      {
        "start": 1,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "then_branch",
        "name": "thenBranch",
        "type": "func"
      },
      {
        "tfName": "else_branch",
        "name": "elseBranch",
        "type": "func"
      }
    ]
  },
  {
    "tfOpName": "StatelessWhile",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "cond",
        "name": "cond",
        "type": "func"
      },
      {
        "tfName": "body",
        "name": "body",
        "type": "func"
      }
    ]
  },
  {
    "tfOpName": "While",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "cond",
        "name": "cond",
        "type": "func"
      },
      {
        "tfName": "body",
        "name": "body",
        "type": "func"
      }
    ]
  },
  {
    "tfOpName": "TensorListScatter",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "elementShape",
        "type": "shape"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListScatterV2",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "elementShape",
        "type": "shape"
      },
      {
        "start": 3,
        "name": "numElements",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListGather",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "elementShape",
        "type": "shape"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListGetItem",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "index",
        "type": "number"
      },
      {
        "start": 2,
        "name": "elementShape",
        "type": "shape"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListSetItem",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "index",
        "type": "number"
      },
      {
        "start": 2,
        "name": "tensor",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListReserve",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "elementShape",
        "type": "shape"
      },
      {
        "start": 1,
        "name": "numElements",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListFromTensor",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "elementShape",
        "type": "shape"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListStack",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "elementShape",
        "type": "shape"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      },
      {
        "tfName": "num_elements",
        "name": "numElements",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListSplit",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "elementShape",
        "type": "shape"
      },
      {
        "start": 2,
        "name": "lengths",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListConcat",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "element_shape",
        "name": "elementShape",
        "type": "shape"
      },
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListConcatV2",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "element_shape",
        "name": "elementShape",
        "type": "shape"
      },
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListPopBack",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "elementShape",
        "type": "shape"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListPushBack",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "tensor",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "element_dtype",
        "name": "elementDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TensorListLength",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "TensorListResize",
    "category": "control",
    "inputs": [
      {
        "start": 0,
        "name": "tensorListId",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "size",
        "type": "number"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js
var convolution_exports = {};
__export(convolution_exports, {
  json: () => json4
});
var json4 = [
  {
    "tfOpName": "AvgPool",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      {
        "tfName": "ksize",
        "name": "kernelSize",
        "type": "number[]"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "MaxPool",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      {
        "tfName": "ksize",
        "name": "kernelSize",
        "type": "number[]"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": [],
        "notSupported": true
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "MaxPoolWithArgmax",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "ksize",
        "name": "kernelSize",
        "type": "number[]"
      },
      {
        "tfName": "include_batch_in_index",
        "name": "includeBatchInIndex",
        "type": "bool"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "AvgPool3D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      {
        "tfName": "ksize",
        "name": "kernelSize",
        "type": "number[]"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "MaxPool3D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      {
        "tfName": "ksize",
        "name": "kernelSize",
        "type": "number[]"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Conv1D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "stride",
        "name": "stride",
        "type": "number"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NWC"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "dilation",
        "name": "dilation",
        "type": "number",
        "defaultValue": 1
      }
    ]
  },
  {
    "tfOpName": "Conv2D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "useCudnnOnGpu",
        "name": "useCudnnOnGpu",
        "type": "bool"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "_FusedConv2D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      },
      {
        "start": 2,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "num_args",
        "name": "numArgs",
        "type": "number"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "use_cudnn_on_gpu",
        "name": "useCudnnOnGpu",
        "type": "bool",
        "defaultValue": true
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]",
        "defaultValue": [
          1,
          1,
          1,
          1
        ]
      },
      {
        "tfName": "fused_ops",
        "name": "fusedOps",
        "type": "string[]",
        "defaultValue": []
      },
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-4
      },
      {
        "tfName": "leakyrelu_alpha",
        "name": "leakyreluAlpha",
        "type": "number",
        "defaultValue": 0.2
      }
    ]
  },
  {
    "tfOpName": "Conv2DBackpropInput",
    "category": "convolution",
    "inputs": [
      {
        "start": 2,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      },
      {
        "start": 0,
        "name": "outputShape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "DepthwiseConv2d",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "input",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "DepthwiseConv2dNative",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "input",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "FusedDepthwiseConv2dNative",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      },
      {
        "start": 2,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "num_args",
        "name": "numArgs",
        "type": "number"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]",
        "defaultValue": [
          1,
          1,
          1,
          1
        ]
      },
      {
        "tfName": "fused_ops",
        "name": "fusedOps",
        "type": "string[]",
        "defaultValue": []
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      }
    ]
  },
  {
    "tfOpName": "Conv3D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "Dilation2D",
    "category": "convolution",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "filter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "strides",
        "name": "strides",
        "type": "number[]"
      },
      {
        "tfName": "rates",
        "name": "dilations",
        "type": "number[]"
      },
      {
        "tfName": "padding",
        "name": "pad",
        "type": "string"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/creation.js
var creation_exports = {};
__export(creation_exports, {
  json: () => json5
});
var json5 = [
  {
    "tfOpName": "Fill",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      },
      {
        "start": 1,
        "name": "value",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "LinSpace",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "start",
        "type": "number"
      },
      {
        "start": 1,
        "name": "stop",
        "type": "number"
      },
      {
        "start": 2,
        "name": "num",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "OneHot",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "depth",
        "type": "number"
      },
      {
        "start": 2,
        "name": "onValue",
        "type": "number",
        "defaultValue": 1
      },
      {
        "start": 3,
        "name": "offValue",
        "type": "number",
        "defaultValue": 0
      }
    ],
    "attrs": [
      {
        "tfName": "axis",
        "name": "axis",
        "type": "number",
        "notSupported": true
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "Ones",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "OnesLike",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "RandomStandardNormal",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "seed",
        "name": "seed",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      },
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "T",
        "name": "T",
        "type": "number",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "RandomUniform",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "minval",
        "name": "minval",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "maxval",
        "name": "maxval",
        "type": "number",
        "defaultValue": 1
      },
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "seed",
        "name": "seed",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      },
      {
        "tfName": "T",
        "name": "T",
        "type": "number",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "RandomUniformInt",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "minval",
        "name": "minval",
        "type": "number"
      },
      {
        "tfName": "maxval",
        "name": "maxval",
        "type": "number"
      },
      {
        "tfName": "seed",
        "name": "seed",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Range",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "start",
        "type": "number"
      },
      {
        "start": 1,
        "name": "stop",
        "type": "number"
      },
      {
        "start": 2,
        "name": "step",
        "type": "number",
        "defaultValue": 0
      }
    ],
    "attrs": [
      {
        "tfName": "Tidx",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "TruncatedNormal",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "means",
        "name": "mean",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "stddev",
        "name": "stdDev",
        "type": "number",
        "defaultValue": 1
      },
      {
        "tfName": "seed",
        "name": "seed",
        "type": "number"
      },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      },
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "T",
        "name": "T",
        "type": "number",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Zeros",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "ZerosLike",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "Multinomial",
    "category": "creation",
    "inputs": [
      {
        "start": 0,
        "name": "logits",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "numSamples",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "seed",
        "name": "seed",
        "type": "number"
      },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      },
      {
        "tfName": "output_dtype",
        "name": "output_dtype",
        "type": "dtype"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js
var dynamic_exports = {};
__export(dynamic_exports, {
  json: () => json6
});
var json6 = [
  {
    "tfOpName": "NonMaxSuppressionV2",
    "category": "dynamic",
    "inputs": [
      {
        "start": 0,
        "name": "boxes",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scores",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "maxOutputSize",
        "type": "number"
      },
      {
        "start": 3,
        "name": "iouThreshold",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "NonMaxSuppressionV3",
    "category": "dynamic",
    "inputs": [
      {
        "start": 0,
        "name": "boxes",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scores",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "maxOutputSize",
        "type": "number"
      },
      {
        "start": 3,
        "name": "iouThreshold",
        "type": "number"
      },
      {
        "start": 4,
        "name": "scoreThreshold",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "NonMaxSuppressionV4",
    "category": "dynamic",
    "inputs": [
      {
        "start": 0,
        "name": "boxes",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scores",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "maxOutputSize",
        "type": "number"
      },
      {
        "start": 3,
        "name": "iouThreshold",
        "type": "number"
      },
      {
        "start": 4,
        "name": "scoreThreshold",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "T_threshold",
        "name": "threshold",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "pad_to_max_output_size",
        "name": "padToMaxOutputSize",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "NonMaxSuppressionV5",
    "category": "dynamic",
    "inputs": [
      {
        "start": 0,
        "name": "boxes",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scores",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "maxOutputSize",
        "type": "number"
      },
      {
        "start": 3,
        "name": "iouThreshold",
        "type": "number"
      },
      {
        "start": 4,
        "name": "scoreThreshold",
        "type": "number"
      },
      {
        "start": 5,
        "name": "softNmsSigma",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "Where",
    "category": "dynamic",
    "inputs": [
      {
        "start": 0,
        "name": "condition",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "ListDiff",
    "category": "dynamic",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "y",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js
var evaluation_exports = {};
__export(evaluation_exports, {
  json: () => json7
});
var json7 = [
  {
    "tfOpName": "LowerBound",
    "category": "evaluation",
    "inputs": [
      {
        "start": 0,
        "name": "sortedSequence",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "values",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "TopKV2",
    "category": "evaluation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "k",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "sorted",
        "name": "sorted",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "UpperBound",
    "category": "evaluation",
    "inputs": [
      {
        "start": 0,
        "name": "sortedSequence",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "values",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "Unique",
    "category": "evaluation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "UniqueV2",
    "category": "evaluation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/graph.js
var graph_exports = {};
__export(graph_exports, {
  json: () => json8
});
var json8 = [
  {
    "tfOpName": "PlaceholderWithDefault",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "default",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "shape",
        "name": "shape",
        "type": "shape"
      },
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "Placeholder",
    "category": "graph",
    "attrs": [
      {
        "tfName": "shape",
        "name": "shape",
        "type": "shape"
      },
      {
        "tfName": "dtype",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "Const",
    "category": "graph"
  },
  {
    "tfOpName": "Identity",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "IdentityN",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "x",
        "type": "tensors"
      }
    ]
  },
  {
    "tfOpName": "Snapshot",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "Rank",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "Size",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "Shape",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "ShapeN",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "x",
        "type": "tensors"
      }
    ]
  },
  {
    "tfOpName": "Print",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "data",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "message",
        "name": "message",
        "type": "string"
      },
      {
        "tfName": "first_n",
        "name": "firstN",
        "type": "number",
        "notSupported": true
      },
      {
        "tfName": "summarize",
        "name": "summarize",
        "type": "number",
        "defaultValue": 3
      }
    ]
  },
  {
    "tfOpName": "NoOp",
    "category": "graph",
    "inputs": []
  },
  {
    "tfOpName": "StopGradient",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "FakeQuantWithMinMaxVars",
    "category": "graph",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "min",
        "name": "min",
        "type": "number"
      },
      {
        "tfName": "max",
        "name": "max",
        "type": "number"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js
var hash_table_exports = {};
__export(hash_table_exports, {
  json: () => json9
});
var json9 = [
  {
    "tfOpName": "HashTable",
    "category": "hash_table",
    "inputs": [],
    "attrs": [
      {
        "tfName": "shared_name",
        "name": "sharedName",
        "type": "string"
      },
      {
        "tfName": "use_node_name_sharing",
        "name": "useNodeNameSharing",
        "type": "bool"
      },
      {
        "tfName": "key_dtype",
        "name": "keyDType",
        "type": "dtype"
      },
      {
        "tfName": "value_dtype",
        "name": "valueDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "HashTableV2",
    "category": "hash_table",
    "inputs": [],
    "attrs": [
      {
        "tfName": "shared_name",
        "name": "sharedName",
        "type": "string"
      },
      {
        "tfName": "use_node_name_sharing",
        "name": "useNodeNameSharing",
        "type": "bool"
      },
      {
        "tfName": "key_dtype",
        "name": "keyDType",
        "type": "dtype"
      },
      {
        "tfName": "value_dtype",
        "name": "valueDType",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "LookupTableImport",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "keys",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "values",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "Tin",
        "name": "tIn",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableImportV2",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "keys",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "values",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "Tin",
        "name": "tIn",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableFind",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "keys",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "defaultValue",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "Tin",
        "name": "tIn",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableFindV2",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "keys",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "defaultValue",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "Tin",
        "name": "tIn",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableSize",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "LookupTableSizeV2",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "InitializeTable",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "keys",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "values",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "InitializeTableV2",
    "category": "hash_table",
    "inputs": [
      {
        "start": 0,
        "name": "tableHandle",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "keys",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "values",
        "type": "tensor"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/image.js
var image_exports = {};
__export(image_exports, {
  json: () => json10
});
var json10 = [
  {
    "tfOpName": "ResizeBilinear",
    "category": "image",
    "inputs": [
      {
        "start": 0,
        "name": "images",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "size",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "align_corners",
        "name": "alignCorners",
        "type": "bool"
      },
      {
        "tfName": "half_pixel_centers",
        "name": "halfPixelCenters",
        "type": "bool"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "ResizeNearestNeighbor",
    "category": "image",
    "inputs": [
      {
        "start": 0,
        "name": "images",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "size",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "align_corners",
        "name": "alignCorners",
        "type": "bool"
      },
      {
        "tfName": "half_pixel_centers",
        "name": "halfPixelCenters",
        "type": "bool"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "CropAndResize",
    "category": "image",
    "inputs": [
      {
        "start": 0,
        "name": "image",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "boxes",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "boxInd",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "cropSize",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "method",
        "name": "method",
        "type": "string"
      },
      {
        "tfName": "extrapolation_value",
        "name": "extrapolationValue",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "ImageProjectiveTransformV3",
    "category": "image",
    "inputs": [
      {
        "start": 0,
        "name": "images",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "transforms",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "outputShape",
        "type": "number[]"
      },
      {
        "start": 3,
        "name": "fillValue",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "interpolation",
        "name": "interpolation",
        "type": "string"
      },
      {
        "tfName": "fill_mode",
        "name": "fillMode",
        "type": "string"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/logical.js
var logical_exports = {};
__export(logical_exports, {
  json: () => json11
});
var json11 = [
  {
    "tfOpName": "Equal",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "NotEqual",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Greater",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "GreaterEqual",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Less",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LessEqual",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LogicalAnd",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LogicalNot",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LogicalOr",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Select",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "condition",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "SelectV2",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "condition",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "BitwiseAnd",
    "category": "logical",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "y",
        "type": "tensor"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js
var matrices_exports = {};
__export(matrices_exports, {
  json: () => json12
});
var json12 = [
  {
    "tfOpName": "_FusedMatMul",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      },
      {
        "start": 2,
        "end": 0,
        "name": "args",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "num_args",
        "name": "numArgs",
        "type": "number"
      },
      {
        "tfName": "fused_ops",
        "name": "fusedOps",
        "type": "string[]",
        "defaultValue": []
      },
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-4
      },
      {
        "tfName": "transpose_a",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "transpose_b",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "leakyrelu_alpha",
        "name": "leakyreluAlpha",
        "type": "number",
        "defaultValue": 0.2
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "MatMul",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "transpose_a",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "transpose_b",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "BatchMatMul",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "adj_x",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "adj_y",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "BatchMatMulV2",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "b",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "adj_x",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "adj_y",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Transpose",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "perm",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Einsum",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "tensors",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "equation",
        "name": "equation",
        "type": "string"
      },
      {
        "tfName": "N",
        "name": "n",
        "type": "number",
        "defaultValue": 2
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "MatrixBandPart",
    "category": "matrices",
    "inputs": [
      {
        "start": 0,
        "name": "a",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "numLower",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "numUpper",
        "type": "tensor"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js
var normalization_exports = {};
__export(normalization_exports, {
  json: () => json13
});
var json13 = [
  {
    "tfOpName": "EuclideanNorm",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool",
        "defaultValue": false
      }
    ]
  },
  {
    "tfOpName": "FusedBatchNorm",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scale",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "offset",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "mean",
        "type": "tensor"
      },
      {
        "start": 4,
        "name": "variance",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-3
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "FusedBatchNormV2",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scale",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "offset",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "mean",
        "type": "tensor"
      },
      {
        "start": 4,
        "name": "variance",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-3
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "FusedBatchNormV3",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "scale",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "offset",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "mean",
        "type": "tensor"
      },
      {
        "start": 4,
        "name": "variance",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-3
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LRN",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "depth_radius",
        "name": "radius",
        "type": "number",
        "defaultValue": 5
      },
      {
        "tfName": "bias",
        "name": "bias",
        "type": "number",
        "defaultValue": 1
      },
      {
        "tfName": "alpha",
        "name": "alpha",
        "type": "number",
        "defaultValue": 1
      },
      {
        "tfName": "beta",
        "name": "beta",
        "type": "number",
        "defaultValue": 0.5
      }
    ]
  },
  {
    "tfOpName": "Softmax",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "LogSoftmax",
    "category": "normalization",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js
var reduction_exports = {};
__export(reduction_exports, {
  json: () => json14
});
var json14 = [
  {
    "tfOpName": "Bincount",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "size",
        "type": "number"
      },
      {
        "start": 2,
        "name": "weights",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "DenseBincount",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "size",
        "type": "number"
      },
      {
        "start": 2,
        "name": "weights",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "binary_output",
        "name": "binaryOutput",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Max",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Mean",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Min",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Sum",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "All",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Any",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "ArgMax",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "ArgMin",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "Prod",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool"
      },
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Cumprod",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "exclusive",
        "name": "exclusive",
        "type": "bool"
      },
      {
        "tfName": "reverse",
        "name": "reverse",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "Cumsum",
    "category": "reduction",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "exclusive",
        "name": "exclusive",
        "type": "bool"
      },
      {
        "tfName": "reverse",
        "name": "reverse",
        "type": "bool"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js
var slice_join_exports = {};
__export(slice_join_exports, {
  json: () => json15
});
var json15 = [
  {
    "tfOpName": "ConcatV2",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "end": -1,
        "name": "tensors",
        "type": "tensors"
      },
      {
        "start": -1,
        "name": "axis",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "N",
        "name": "n",
        "type": "number",
        "defaultValue": 2
      }
    ]
  },
  {
    "tfOpName": "Concat",
    "category": "slice_join",
    "inputs": [
      {
        "start": 1,
        "end": 0,
        "name": "tensors",
        "type": "tensors"
      },
      {
        "start": 0,
        "name": "axis",
        "type": "number"
      }
    ],
    "attrs": [
      {
        "tfName": "N",
        "name": "n",
        "type": "number",
        "defaultValue": 2
      }
    ]
  },
  {
    "tfOpName": "GatherV2",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "axis",
        "type": "number",
        "defaultValue": 0
      }
    ],
    "attrs": [
      {
        "tfName": "batch_dims",
        "name": "batchDims",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "Gather",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "validate_indices",
        "name": "validateIndices",
        "type": "bool",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Reverse",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "dims",
        "type": "bool[]"
      }
    ]
  },
  {
    "tfOpName": "ReverseV2",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "Slice",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "begin",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "size",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "StridedSlice",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "begin",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "end",
        "type": "number[]"
      },
      {
        "start": 3,
        "name": "strides",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "begin_mask",
        "name": "beginMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "end_mask",
        "name": "endMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "new_axis_mask",
        "name": "newAxisMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "ellipsis_mask",
        "name": "ellipsisMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "shrink_axis_mask",
        "name": "shrinkAxisMask",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "Pack",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "end": 0,
        "name": "tensors",
        "type": "tensors"
      }
    ],
    "attrs": [
      {
        "tfName": "axis",
        "name": "axis",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "Unpack",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "axis",
        "name": "axis",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "num",
        "name": "num",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Tile",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "reps",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "Split",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "axis",
        "type": "number",
        "defaultValue": 0
      },
      {
        "start": 1,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "num_split",
        "name": "numOrSizeSplits",
        "type": "number",
        "defaultValue": 1
      }
    ]
  },
  {
    "tfOpName": "SplitV",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "numOrSizeSplits",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "axis",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "ScatterNd",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "values",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "shape",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "GatherNd",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "SparseToDense",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "sparseIndices",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "outputShape",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "sparseValues",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "defaultValue",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "validate_indices",
        "name": "validateIndices",
        "type": "bool",
        "defaultValue": false,
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "TensorScatterUpdate",
    "category": "slice_join",
    "inputs": [
      {
        "start": 0,
        "name": "tensor",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "values",
        "type": "tensor"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js
var sparse_exports = {};
__export(sparse_exports, {
  json: () => json16
});
var json16 = [
  {
    "tfOpName": "SparseFillEmptyRows",
    "category": "sparse",
    "inputs": [
      {
        "start": 0,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "values",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "denseShape",
        "type": "tensor"
      },
      {
        "start": 3,
        "name": "defaultValue",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "SparseReshape",
    "category": "sparse",
    "inputs": [
      {
        "start": 0,
        "name": "inputIndices",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "inputShape",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "newShape",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "T",
        "name": "dtype",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "SparseSegmentMean",
    "category": "sparse",
    "inputs": [
      {
        "start": 0,
        "name": "data",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "segmentIds",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "SparseSegmentSum",
    "category": "sparse",
    "inputs": [
      {
        "start": 0,
        "name": "data",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "indices",
        "type": "tensor"
      },
      {
        "start": 2,
        "name": "segmentIds",
        "type": "tensor"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js
var spectral_exports = {};
__export(spectral_exports, {
  json: () => json17
});
var json17 = [
  {
    "tfOpName": "FFT",
    "category": "spectral",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "IFFT",
    "category": "spectral",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ]
  },
  {
    "tfOpName": "RFFT",
    "category": "spectral",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "fft_length",
        "type": "number",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "IRFFT",
    "category": "spectral",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "fft_length",
        "type": "number",
        "notSupported": true
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/string.js
var string_exports = {};
__export(string_exports, {
  json: () => json18
});
var json18 = [
  {
    "tfOpName": "StaticRegexReplace",
    "category": "string",
    "inputs": [
      {
        "start": 0,
        "name": "input",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "pattern",
        "name": "pattern",
        "type": "string"
      },
      {
        "tfName": "rewrite",
        "name": "rewrite",
        "type": "string"
      },
      {
        "tfName": "replace_global",
        "name": "replaceGlobal",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "StringNGrams",
    "category": "string",
    "inputs": [
      {
        "start": 0,
        "name": "data",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "dataSplits",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "separator",
        "name": "separator",
        "type": "string"
      },
      {
        "tfName": "ngram_widths",
        "name": "nGramWidths",
        "type": "number[]"
      },
      {
        "tfName": "left_pad",
        "name": "leftPad",
        "type": "string"
      },
      {
        "tfName": "right_pad",
        "name": "rightPad",
        "type": "string"
      },
      {
        "tfName": "pad_width",
        "name": "padWidth",
        "type": "number"
      },
      {
        "tfName": "preserve_short_sequences",
        "name": "preserveShortSequences",
        "type": "bool"
      }
    ],
    "outputs": [
      "ngrams",
      "ngrams_splits"
    ]
  },
  {
    "tfOpName": "StringSplit",
    "category": "string",
    "inputs": [
      {
        "start": 0,
        "name": "input",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "delimiter",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "skip_empty",
        "name": "skipEmpty",
        "type": "bool"
      }
    ],
    "outputs": [
      "indices",
      "values",
      "shape"
    ]
  },
  {
    "tfOpName": "StringToHashBucketFast",
    "category": "string",
    "inputs": [
      {
        "start": 0,
        "name": "input",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "num_buckets",
        "name": "numBuckets",
        "type": "number"
      }
    ]
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js
var transformation_exports = {};
__export(transformation_exports, {
  json: () => json19
});
var json19 = [
  {
    "tfOpName": "Cast",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "SrcT",
        "name": "sdtype",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "DstT",
        "name": "dtype",
        "type": "dtype"
      }
    ]
  },
  {
    "tfOpName": "ExpandDims",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "axis",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "MirrorPad",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "padding",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "mode",
        "name": "mode",
        "type": "string"
      }
    ]
  },
  {
    "tfOpName": "Pad",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "padding",
        "type": "number[]"
      }
    ],
    "attrs": [
      {
        "tfName": "constant_value",
        "name": "constantValue",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "PadV2",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "padding",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "constantValue",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "Reshape",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "shape",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "EnsureShape",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "shape",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "Squeeze",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "axis",
        "tfDeprecatedName": "squeeze_dims",
        "name": "axis",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "SpaceToBatchND",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "blockShape",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "paddings",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "BatchToSpaceND",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "blockShape",
        "type": "number[]"
      },
      {
        "start": 2,
        "name": "crops",
        "type": "number[]"
      }
    ]
  },
  {
    "tfOpName": "DepthToSpace",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      }
    ],
    "attrs": [
      {
        "tfName": "block_size",
        "name": "blockSize",
        "type": "number"
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string"
      }
    ]
  },
  {
    "tfOpName": "BroadcastTo",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "x",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "shape",
        "type": "number[]"
      }
    ],
    "attrs": []
  },
  {
    "tfOpName": "BroadcastArgs",
    "category": "transformation",
    "inputs": [
      {
        "start": 0,
        "name": "s0",
        "type": "tensor"
      },
      {
        "start": 1,
        "name": "s1",
        "type": "tensor"
      }
    ],
    "attrs": []
  }
];

// node_modules/@tensorflow/tfjs-converter/dist/operations/operation_mapper.js
var OperationMapper = class {
  // Singleton instance for the mapper
  static get Instance() {
    return this._instance || (this._instance = new this());
  }
  // Loads the op mapping from the JSON file.
  constructor() {
    const ops = [
      arithmetic_exports,
      basic_math_exports,
      control_exports,
      convolution_exports,
      creation_exports,
      dynamic_exports,
      evaluation_exports,
      graph_exports,
      hash_table_exports,
      image_exports,
      logical_exports,
      matrices_exports,
      normalization_exports,
      reduction_exports,
      slice_join_exports,
      sparse_exports,
      spectral_exports,
      string_exports,
      transformation_exports
    ];
    const mappersJson = [].concat(...ops.map((op2) => op2.json));
    this.opMappers = mappersJson.reduce((map, mapper) => {
      map[mapper.tfOpName] = mapper;
      return map;
    }, {});
  }
  // Converts the model inference graph from Tensorflow GraphDef to local
  // representation for TensorFlow.js API
  transformGraph(graph, signature = {}) {
    const tfNodes = graph.node;
    const placeholders = [];
    const weights = [];
    const initNodes = [];
    const nodes = tfNodes.reduce((map, node) => {
      map[node.name] = this.mapNode(node);
      if (node.op.startsWith("Placeholder")) {
        placeholders.push(map[node.name]);
      } else if (node.op === "Const") {
        weights.push(map[node.name]);
      } else if (node.input == null || node.input.length === 0) {
        initNodes.push(map[node.name]);
      }
      return map;
    }, {});
    let inputs = [];
    const outputs = [];
    let inputNodeNameToKey = {};
    let outputNodeNameToKey = {};
    if (signature != null) {
      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);
      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);
    }
    const allNodes = Object.keys(nodes);
    allNodes.forEach((key) => {
      const node = nodes[key];
      node.inputNames.forEach((name, index) => {
        const [nodeName, , outputName] = getNodeNameAndIndex(name);
        const inputNode = nodes[nodeName];
        if (inputNode.outputs != null) {
          const outputIndex = inputNode.outputs.indexOf(outputName);
          if (outputIndex !== -1) {
            const inputName = `${nodeName}:${outputIndex}`;
            node.inputNames[index] = inputName;
          }
        }
        node.inputs.push(inputNode);
        inputNode.children.push(node);
      });
    });
    if (Object.keys(outputNodeNameToKey).length === 0) {
      allNodes.forEach((key) => {
        const node = nodes[key];
        if (node.children.length === 0) {
          outputs.push(node);
        }
      });
    } else {
      Object.keys(outputNodeNameToKey).forEach((name) => {
        const [nodeName] = getNodeNameAndIndex(name);
        const node = nodes[nodeName];
        if (node != null) {
          node.signatureKey = outputNodeNameToKey[name];
          outputs.push(node);
        }
      });
    }
    if (Object.keys(inputNodeNameToKey).length > 0) {
      Object.keys(inputNodeNameToKey).forEach((name) => {
        const [nodeName] = getNodeNameAndIndex(name);
        const node = nodes[nodeName];
        if (node) {
          node.signatureKey = inputNodeNameToKey[name];
          inputs.push(node);
        }
      });
    } else {
      inputs = placeholders;
    }
    let functions = {};
    if (graph.library != null && graph.library.function != null) {
      functions = graph.library.function.reduce((functions2, func) => {
        functions2[func.signature.name] = this.mapFunction(func);
        return functions2;
      }, {});
    }
    const result = { nodes, inputs, outputs, weights, placeholders, signature, functions };
    if (initNodes.length > 0) {
      result.initNodes = initNodes;
    }
    return result;
  }
  mapSignatureEntries(entries) {
    return Object.keys(entries || {}).reduce((prev, curr) => {
      prev[entries[curr].name] = curr;
      return prev;
    }, {});
  }
  mapNode(node) {
    const mapper = getRegisteredOp(node.op) || this.opMappers[node.op] || {};
    if (node.attr == null) {
      node.attr = {};
    }
    const newNode = {
      name: node.name,
      op: node.op,
      category: mapper.category,
      inputNames: (node.input || []).map((input) => input.startsWith("^") ? input.slice(1) : input),
      inputs: [],
      children: [],
      inputParams: {},
      attrParams: {},
      rawAttrs: node.attr,
      outputs: mapper.outputs
    };
    if (mapper.inputs != null) {
      newNode.inputParams = mapper.inputs.reduce((map, param) => {
        map[param.name] = {
          type: param.type,
          inputIndexStart: param.start,
          inputIndexEnd: param.end
        };
        return map;
      }, {});
    }
    if (mapper.attrs != null) {
      newNode.attrParams = mapper.attrs.reduce((map, param) => {
        const type = param.type;
        let value = void 0;
        switch (param.type) {
          case "string":
            value = getStringParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getStringParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "string[]":
            value = getStringArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getStringArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "number":
            value = getNumberParam(node.attr, param.tfName, param.defaultValue || 0);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getNumberParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "number[]":
            value = getNumericArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getNumericArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "bool":
            value = getBoolParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getBoolParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "bool[]":
            value = getBoolArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getBoolArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "shape":
            value = getTensorShapeParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getTensorShapeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "shape[]":
            value = getTensorShapeArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getTensorShapeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "dtype":
            value = getDtypeParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getDtypeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "dtype[]":
            value = getDtypeArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getDtypeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "func":
            value = getFuncParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getFuncParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "tensor":
          case "tensors":
            break;
          default:
            throw new Error(`Unsupported param type: ${param.type} for op: ${node.op}`);
        }
        map[param.name] = { value, type };
        return map;
      }, {});
    }
    return newNode;
  }
  // map the TFunctionDef to TFJS graph object
  mapFunction(functionDef) {
    const tfNodes = functionDef.nodeDef;
    const placeholders = [];
    const weights = [];
    let nodes = {};
    if (tfNodes != null) {
      nodes = tfNodes.reduce((map, node) => {
        map[node.name] = this.mapNode(node);
        if (node.op === "Const") {
          weights.push(map[node.name]);
        }
        return map;
      }, {});
    }
    const inputs = [];
    const outputs = [];
    functionDef.signature.inputArg.forEach((arg) => {
      const [nodeName] = getNodeNameAndIndex(arg.name);
      const node = {
        name: nodeName,
        op: "Placeholder",
        inputs: [],
        inputNames: [],
        category: "graph",
        inputParams: {},
        attrParams: { dtype: { value: parseDtypeParam(arg.type), type: "dtype" } },
        children: []
      };
      node.signatureKey = arg.name;
      inputs.push(node);
      nodes[nodeName] = node;
    });
    const allNodes = Object.keys(nodes);
    allNodes.forEach((key) => {
      const node = nodes[key];
      node.inputNames.forEach((name, index) => {
        const [nodeName, , outputName] = getNodeNameAndIndex(name);
        const inputNode = nodes[nodeName];
        if (inputNode.outputs != null) {
          const outputIndex = inputNode.outputs.indexOf(outputName);
          if (outputIndex !== -1) {
            const inputName = `${nodeName}:${outputIndex}`;
            node.inputNames[index] = inputName;
          }
        }
        node.inputs.push(inputNode);
        inputNode.children.push(node);
      });
    });
    const returnNodeMap = functionDef.ret;
    functionDef.signature.outputArg.forEach((output) => {
      const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);
      const node = nodes[nodeName];
      if (node != null) {
        node.defaultOutput = index;
        outputs.push(node);
      }
    });
    const signature = this.mapArgsToSignature(functionDef);
    return { nodes, inputs, outputs, weights, placeholders, signature };
  }
  mapArgsToSignature(functionDef) {
    return {
      methodName: functionDef.signature.name,
      inputs: functionDef.signature.inputArg.reduce((map, arg) => {
        map[arg.name] = this.mapArgToTensorInfo(arg);
        return map;
      }, {}),
      outputs: functionDef.signature.outputArg.reduce((map, arg) => {
        map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);
        return map;
      }, {})
    };
  }
  mapArgToTensorInfo(arg, nameMap) {
    let name = arg.name;
    if (nameMap != null) {
      name = nameMap[name];
    }
    return { name, dtype: arg.type };
  }
};
function decodeBase64(text) {
  const global2 = env().global;
  if (typeof global2.atob !== "undefined") {
    return global2.atob(text);
  } else if (typeof Buffer !== "undefined") {
    return new Buffer(text, "base64").toString();
  } else {
    throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
  }
}
function parseStringParam(s, keepCase) {
  const value = Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);
  return keepCase ? value : value.toLowerCase();
}
function getStringParam(attrs, name, def, keepCase = false) {
  const param = attrs[name];
  if (param != null) {
    return parseStringParam(param.s, keepCase);
  }
  return def;
}
function getBoolParam(attrs, name, def) {
  const param = attrs[name];
  return param ? param.b : def;
}
function getNumberParam(attrs, name, def) {
  const param = attrs[name] || {};
  const value = param["i"] != null ? param["i"] : param["f"] != null ? param["f"] : def;
  return typeof value === "number" ? value : parseInt(value, 10);
}
function parseDtypeParam(value) {
  if (typeof value === "string") {
    value = DataType[value];
  }
  switch (value) {
    case DataType.DT_FLOAT:
    case DataType.DT_HALF:
      return "float32";
    case DataType.DT_INT32:
    case DataType.DT_INT64:
    case DataType.DT_INT8:
    case DataType.DT_UINT8:
      return "int32";
    case DataType.DT_BOOL:
      return "bool";
    case DataType.DT_DOUBLE:
      return "float32";
    case DataType.DT_STRING:
      return "string";
    case DataType.DT_COMPLEX64:
    case DataType.DT_COMPLEX128:
      return "complex64";
    default:
      return null;
  }
}
function getFuncParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.func) {
    return param.func.name;
  }
  return def;
}
function getDtypeParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.type) {
    return parseDtypeParam(param.type);
  }
  return def;
}
function getDtypeArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.list && param.list.type) {
    return param.list.type.map((v) => parseDtypeParam(v));
  }
  return def;
}
function parseTensorShapeParam(shape) {
  if (shape.unknownRank) {
    return void 0;
  }
  if (shape.dim != null) {
    return shape.dim.map((dim) => typeof dim.size === "number" ? dim.size : parseInt(dim.size, 10));
  }
  return [];
}
function getTensorShapeParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.shape) {
    return parseTensorShapeParam(param.shape);
  }
  return def;
}
function getNumericArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param) {
    return ((param.list.f && param.list.f.length ? param.list.f : param.list.i) || []).map((v) => typeof v === "number" ? v : parseInt(v, 10));
  }
  return def;
}
function getStringArrayParam(attrs, name, def, keepCase = false) {
  const param = attrs[name];
  if (param && param.list && param.list.s) {
    return param.list.s.map((v) => {
      return parseStringParam(v, keepCase);
    });
  }
  return def;
}
function getTensorShapeArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.list && param.list.shape) {
    return param.list.shape.map((v) => {
      return parseTensorShapeParam(v);
    });
  }
  return def;
}
function getBoolArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.list && param.list.b) {
    return param.list.b;
  }
  return def;
}

// node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js
var NodeValueImpl = class {
  constructor(node, tensorMap, context) {
    this.node = node;
    this.tensorMap = tensorMap;
    this.context = context;
    this.inputs = [];
    this.attrs = {};
    this.inputs = node.inputNames.map((name) => this.getInput(name));
    if (node.rawAttrs != null) {
      this.attrs = Object.keys(node.rawAttrs).reduce((attrs, key) => {
        attrs[key] = this.getAttr(key);
        return attrs;
      }, {});
    }
  }
  /**
   * Return the value of the attribute or input param.
   * @param name String: name of attribute or input param.
   */
  getInput(name) {
    return getTensor(name, this.tensorMap, this.context);
  }
  /**
   * Return the value of the attribute or input param.
   * @param name String: name of attribute or input param.
   */
  getAttr(name, defaultValue) {
    const value = this.node.rawAttrs[name];
    if (value.tensor != null) {
      return getTensor(name, this.tensorMap, this.context);
    }
    if (value.i != null || value.f != null) {
      return getNumberParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.s != null) {
      return getStringParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.b != null) {
      return getBoolParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.shape != null) {
      return getTensorShapeParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.type != null) {
      return getDtypeParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.list != null) {
      if (value.list.i != null || value.list.f != null) {
        return getNumericArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.s != null) {
        return getStringArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.shape != null) {
        return getTensorShapeArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.b != null) {
        return getBoolArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.type != null) {
        return getDtypeArrayParam(this.node.rawAttrs, name, defaultValue);
      }
    }
    return defaultValue;
  }
};

// node_modules/@tensorflow/tfjs-core/dist/ops/ops_for_converter.js
var ops_for_converter_exports = {};
__export(ops_for_converter_exports, {
  OP_SCOPE_SUFFIX: () => OP_SCOPE_SUFFIX,
  abs: () => abs,
  acos: () => acos,
  acosh: () => acosh,
  add: () => add,
  addN: () => addN,
  all: () => all,
  any: () => any,
  argMax: () => argMax,
  argMin: () => argMin,
  asin: () => asin,
  asinh: () => asinh,
  atan: () => atan,
  atan2: () => atan2,
  atanh: () => atanh,
  avgPool: () => avgPool,
  avgPool3d: () => avgPool3d,
  basicLSTMCell: () => basicLSTMCell,
  batchNorm: () => batchNorm,
  batchNorm2d: () => batchNorm2d,
  batchNorm3d: () => batchNorm3d,
  batchNorm4d: () => batchNorm4d,
  batchToSpaceND: () => batchToSpaceND,
  bincount: () => bincount,
  bitwiseAnd: () => bitwiseAnd,
  booleanMaskAsync: () => booleanMaskAsync,
  broadcastArgs: () => broadcastArgs,
  broadcastTo: () => broadcastTo,
  buffer: () => buffer,
  cast: () => cast,
  ceil: () => ceil,
  clipByValue: () => clipByValue,
  clone: () => clone,
  complex: () => complex,
  concat: () => concat,
  concat1d: () => concat1d,
  concat2d: () => concat2d,
  concat3d: () => concat3d,
  concat4d: () => concat4d,
  conv1d: () => conv1d,
  conv2d: () => conv2d,
  conv2dTranspose: () => conv2dTranspose,
  conv3d: () => conv3d,
  conv3dTranspose: () => conv3dTranspose,
  cos: () => cos,
  cosh: () => cosh,
  cosineWindow: () => cosineWindow,
  cumprod: () => cumprod,
  cumsum: () => cumsum,
  denseBincount: () => denseBincount,
  depthToSpace: () => depthToSpace,
  depthwiseConv2d: () => depthwiseConv2d,
  diag: () => diag,
  dilation2d: () => dilation2d,
  div: () => div,
  divNoNan: () => divNoNan,
  dot: () => dot,
  dropout: () => dropout,
  einsum: () => einsum,
  elu: () => elu,
  enclosingPowerOfTwo: () => enclosingPowerOfTwo,
  ensureShape: () => ensureShape,
  equal: () => equal,
  erf: () => erf,
  euclideanNorm: () => euclideanNorm,
  exp: () => exp,
  expandDims: () => expandDims,
  expm1: () => expm1,
  eye: () => eye,
  fft: () => fft,
  fill: () => fill,
  floor: () => floor,
  floorDiv: () => floorDiv,
  fused: () => fused_ops_exports,
  gather: () => gather,
  gatherND: () => gatherND,
  greater: () => greater,
  greaterEqual: () => greaterEqual,
  ifft: () => ifft,
  imag: () => imag,
  image: () => image,
  inTopKAsync: () => inTopKAsync,
  irfft: () => irfft,
  isFinite: () => isFinite2,
  isInf: () => isInf,
  isNaN: () => isNaN2,
  leakyRelu: () => leakyRelu,
  less: () => less,
  lessEqual: () => lessEqual,
  linalg: () => linalg,
  linspace: () => linspace,
  localResponseNormalization: () => localResponseNormalization,
  log: () => log,
  log1p: () => log1p,
  logSigmoid: () => logSigmoid,
  logSoftmax: () => logSoftmax,
  logSumExp: () => logSumExp,
  logicalAnd: () => logicalAnd,
  logicalNot: () => logicalNot,
  logicalOr: () => logicalOr,
  logicalXor: () => logicalXor,
  losses: () => losses,
  lowerBound: () => lowerBound,
  matMul: () => matMul,
  max: () => max,
  maxPool: () => maxPool,
  maxPool3d: () => maxPool3d,
  maxPoolWithArgmax: () => maxPoolWithArgmax,
  maximum: () => maximum,
  mean: () => mean,
  meshgrid: () => meshgrid,
  min: () => min,
  minimum: () => minimum,
  mirrorPad: () => mirrorPad,
  mod: () => mod,
  moments: () => moments,
  movingAverage: () => movingAverage,
  mul: () => mul,
  multiRNNCell: () => multiRNNCell,
  multinomial: () => multinomial,
  neg: () => neg,
  norm: () => norm,
  notEqual: () => notEqual,
  oneHot: () => oneHot,
  ones: () => ones,
  onesLike: () => onesLike,
  op: () => op,
  outerProduct: () => outerProduct,
  pad: () => pad,
  pad1d: () => pad1d,
  pad2d: () => pad2d,
  pad3d: () => pad3d,
  pad4d: () => pad4d,
  pool: () => pool,
  pow: () => pow,
  prelu: () => prelu,
  print: () => print,
  prod: () => prod,
  raggedGather: () => raggedGather,
  raggedRange: () => raggedRange,
  raggedTensorToTensor: () => raggedTensorToTensor,
  rand: () => rand,
  randomGamma: () => randomGamma,
  randomNormal: () => randomNormal,
  randomStandardNormal: () => randomStandardNormal,
  randomUniform: () => randomUniform,
  randomUniformInt: () => randomUniformInt,
  range: () => range,
  real: () => real,
  reciprocal: () => reciprocal,
  relu: () => relu,
  relu6: () => relu6,
  reshape: () => reshape,
  reverse: () => reverse,
  reverse1d: () => reverse1d,
  reverse2d: () => reverse2d,
  reverse3d: () => reverse3d,
  reverse4d: () => reverse4d,
  rfft: () => rfft,
  round: () => round,
  rsqrt: () => rsqrt,
  scalar: () => scalar,
  scatterND: () => scatterND,
  searchSorted: () => searchSorted,
  selu: () => selu,
  separableConv2d: () => separableConv2d,
  setdiff1dAsync: () => setdiff1dAsync,
  sigmoid: () => sigmoid,
  sign: () => sign,
  signal: () => signal,
  sin: () => sin,
  sinh: () => sinh,
  slice: () => slice,
  slice1d: () => slice1d,
  slice2d: () => slice2d,
  slice3d: () => slice3d,
  slice4d: () => slice4d,
  softmax: () => softmax,
  softplus: () => softplus,
  spaceToBatchND: () => spaceToBatchND,
  sparse: () => sparse,
  sparseToDense: () => sparseToDense,
  spectral: () => spectral,
  split: () => split,
  sqrt: () => sqrt,
  square: () => square,
  squaredDifference: () => squaredDifference,
  squeeze: () => squeeze,
  stack: () => stack,
  step: () => step,
  stridedSlice: () => stridedSlice,
  string: () => string,
  sub: () => sub,
  sum: () => sum,
  tan: () => tan,
  tanh: () => tanh,
  tensor: () => tensor,
  tensor1d: () => tensor1d,
  tensor2d: () => tensor2d,
  tensor3d: () => tensor3d,
  tensor4d: () => tensor4d,
  tensor5d: () => tensor5d,
  tensor6d: () => tensor6d,
  tensorScatterUpdate: () => tensorScatterUpdate,
  tile: () => tile,
  topk: () => topk,
  transpose: () => transpose,
  truncatedNormal: () => truncatedNormal,
  unique: () => unique,
  unsortedSegmentSum: () => unsortedSegmentSum,
  unstack: () => unstack,
  upperBound: () => upperBound,
  variable: () => variable,
  where: () => where,
  whereAsync: () => whereAsync,
  zeros: () => zeros,
  zerosLike: () => zerosLike
});

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js
var executeOp = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "BiasAdd":
    case "AddV2":
    case "Add": {
      return [ops.add(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "AddN": {
      return [ops.addN(getParamValue("tensors", node, tensorMap, context))];
    }
    case "FloorMod":
    case "Mod":
      return [ops.mod(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    case "Mul":
      return [ops.mul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    case "RealDiv":
    case "Div": {
      return [ops.div(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "DivNoNan": {
      return [ops.divNoNan(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "FloorDiv": {
      return [ops.floorDiv(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Sub": {
      return [ops.sub(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Minimum": {
      return [ops.minimum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Maximum": {
      return [ops.maximum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Pow": {
      return [ops.pow(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "SquaredDifference": {
      return [ops.squaredDifference(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js
var executeOp2 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Abs":
    case "ComplexAbs":
      return [ops.abs(getParamValue("x", node, tensorMap, context))];
    case "Acos":
      return [ops.acos(getParamValue("x", node, tensorMap, context))];
    case "Acosh":
      return [ops.acosh(getParamValue("x", node, tensorMap, context))];
    case "Asin":
      return [ops.asin(getParamValue("x", node, tensorMap, context))];
    case "Asinh":
      return [ops.asinh(getParamValue("x", node, tensorMap, context))];
    case "Atan":
      return [ops.atan(getParamValue("x", node, tensorMap, context))];
    case "Atan2":
      return [ops.atan2(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
    case "Atanh":
      return [ops.atanh(getParamValue("x", node, tensorMap, context))];
    case "Ceil":
      return [ops.ceil(getParamValue("x", node, tensorMap, context))];
    case "Complex":
      return [ops.complex(getParamValue("real", node, tensorMap, context), getParamValue("imag", node, tensorMap, context))];
    case "Cos":
      return [ops.cos(getParamValue("x", node, tensorMap, context))];
    case "Cosh":
      return [ops.cosh(getParamValue("x", node, tensorMap, context))];
    case "Elu":
      return [ops.elu(getParamValue("x", node, tensorMap, context))];
    case "Erf":
      return [ops.erf(getParamValue("x", node, tensorMap, context))];
    case "Exp":
      return [ops.exp(getParamValue("x", node, tensorMap, context))];
    case "Expm1": {
      return [ops.expm1(getParamValue("x", node, tensorMap, context))];
    }
    case "Floor":
      return [ops.floor(getParamValue("x", node, tensorMap, context))];
    case "Log":
      return [ops.log(getParamValue("x", node, tensorMap, context))];
    case "Log1p": {
      return [ops.log1p(getParamValue("x", node, tensorMap, context))];
    }
    case "Imag":
      return [ops.imag(getParamValue("x", node, tensorMap, context))];
    case "Neg":
      return [ops.neg(getParamValue("x", node, tensorMap, context))];
    case "Reciprocal": {
      return [ops.reciprocal(getParamValue("x", node, tensorMap, context))];
    }
    case "Real":
      return [ops.real(getParamValue("x", node, tensorMap, context))];
    case "Relu":
      return [ops.relu(getParamValue("x", node, tensorMap, context))];
    case "Round": {
      return [ops.round(getParamValue("x", node, tensorMap, context))];
    }
    case "Selu":
      return [ops.selu(getParamValue("x", node, tensorMap, context))];
    case "Sigmoid":
      return [ops.sigmoid(getParamValue("x", node, tensorMap, context))];
    case "Sin":
      return [ops.sin(getParamValue("x", node, tensorMap, context))];
    case "Sign": {
      return [ops.sign(getParamValue("x", node, tensorMap, context))];
    }
    case "Sinh": {
      return [ops.sinh(getParamValue("x", node, tensorMap, context))];
    }
    case "Softplus": {
      return [ops.softplus(getParamValue("x", node, tensorMap, context))];
    }
    case "Sqrt": {
      return [ops.sqrt(getParamValue("x", node, tensorMap, context))];
    }
    case "Square": {
      return [ops.square(getParamValue("x", node, tensorMap, context))];
    }
    case "Tanh": {
      return [ops.tanh(getParamValue("x", node, tensorMap, context))];
    }
    case "Tan":
      return [ops.tan(getParamValue("x", node, tensorMap, context))];
    case "ClipByValue":
      return [ops.clipByValue(getParamValue("x", node, tensorMap, context), getParamValue("clipValueMin", node, tensorMap, context), getParamValue("clipValueMax", node, tensorMap, context))];
    case "Relu6":
      return [ops.relu6(getParamValue("x", node, tensorMap, context))];
    case "Rsqrt":
      return [ops.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];
    case "LeakyRelu":
      return [ops.leakyRelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
    case "Prelu":
      return [ops.prelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
    case "IsNan":
      return [ops.isNaN(getTensor(node.inputNames[0], tensorMap, context))];
    case "IsInf":
      return [ops.isInf(getTensor(node.inputNames[0], tensorMap, context))];
    case "IsFinite":
      return [ops.isFinite(getTensor(node.inputNames[0], tensorMap, context))];
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_utils.js
function assertShapesMatchAllowUndefinedSize(shapeA, shapeB, errorMessagePrefix = "") {
  if (typeof shapeA === "number" || typeof shapeB === "number") {
    return;
  }
  util_exports.assert(shapeA.length === shapeB.length, () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
  for (let i = 0; i < shapeA.length; i++) {
    const dim0 = shapeA[i];
    const dim1 = shapeB[i];
    util_exports.assert(dim0 < 0 || dim1 < 0 || dim0 === dim1, () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
  }
}
function fullDefinedShape(elementShape) {
  if (typeof elementShape === "number" || elementShape.some((dim) => dim < 0)) {
    return false;
  }
  return true;
}
function inferElementShape(listElementShape, tensors, elementShape) {
  let partialShape = mergeElementShape(listElementShape, elementShape);
  const notfullDefinedShape = !fullDefinedShape(partialShape);
  if (notfullDefinedShape && tensors.length === 0) {
    throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${partialShape}`);
  }
  if (notfullDefinedShape) {
    tensors.forEach((tensor2) => {
      partialShape = mergeElementShape(tensor2.shape, partialShape);
    });
  }
  if (!fullDefinedShape(partialShape)) {
    throw new Error(`Non-fully-defined elementShape: ${partialShape}`);
  }
  return partialShape;
}
function mergeElementShape(elementShapeA, elementShapeB) {
  if (typeof elementShapeA === "number") {
    return elementShapeB;
  }
  if (typeof elementShapeB === "number") {
    return elementShapeA;
  }
  if (elementShapeA.length !== elementShapeB.length) {
    throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${elementShapeB}`);
  }
  const result = [];
  for (let i = 0; i < elementShapeA.length; ++i) {
    const dim0 = elementShapeA[i];
    const dim1 = elementShapeB[i];
    if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {
      throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${elementShapeB}`);
    }
    result[i] = dim0 >= 0 ? dim0 : dim1;
  }
  return result;
}

// node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js
var TensorArray = class {
  constructor(name, dtype, maxSize, elementShape, identicalElementShapes, dynamicSize, clearAfterRead) {
    this.name = name;
    this.dtype = dtype;
    this.maxSize = maxSize;
    this.elementShape = elementShape;
    this.identicalElementShapes = identicalElementShapes;
    this.dynamicSize = dynamicSize;
    this.clearAfterRead = clearAfterRead;
    this.tensors = [];
    this.closed_ = false;
    this.idTensor = scalar(0);
    keep(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  get closed() {
    return this.closed_;
  }
  /**
   * Dispose the tensors and idTensor and mark the TensoryArray as closed.
   */
  clearAndClose(keepIds) {
    this.tensors.forEach((tensor2) => {
      if (keepIds == null || !keepIds.has(tensor2.tensor.id)) {
        tensor2.tensor.dispose();
      }
    });
    this.tensors = [];
    this.closed_ = true;
    this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  /**
   * Read the value at location index in the TensorArray.
   * @param index Number the index to read from.
   */
  read(index) {
    if (this.closed_) {
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    }
    if (index < 0 || index >= this.size()) {
      throw new Error(`Tried to read from index ${index}, but array size is: ${this.size()}`);
    }
    const tensorWithState = this.tensors[index];
    if (tensorWithState.cleared) {
      throw new Error(`TensorArray ${this.name}: Could not read index ${index} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);
    }
    if (this.clearAfterRead) {
      tensorWithState.cleared = true;
    }
    tensorWithState.read = true;
    return tensorWithState.tensor;
  }
  /**
   * Helper method to read multiple tensors from the specified indices.
   */
  readMany(indices) {
    return indices.map((index) => this.read(index));
  }
  /**
   * Write value into the index of the TensorArray.
   * @param index number the index to write to.
   * @param tensor
   */
  write(index, tensor2) {
    if (this.closed_) {
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    }
    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {
      throw new Error(`Tried to write to index ${index}, but array is not resizeable and size is: ${this.maxSize}`);
    }
    const t2 = this.tensors[index] || {};
    if (tensor2.dtype !== this.dtype) {
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index},
          because the value dtype is ${tensor2.dtype}, but TensorArray dtype is ${this.dtype}.`);
    }
    if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0)) {
      this.elementShape = tensor2.shape;
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, `TensorArray ${this.name}: Could not write to TensorArray index ${index}.`);
    if (t2.read) {
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been read.`);
    }
    if (t2.written) {
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been written.`);
    }
    t2.tensor = tensor2;
    keep(tensor2);
    t2.written = true;
    this.tensors[index] = t2;
  }
  /**
   * Helper method to write multiple tensors to the specified indices.
   */
  writeMany(indices, tensors) {
    if (indices.length !== tensors.length) {
      throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${indices.length} is not the same as tensors size: ${tensors.length}.`);
    }
    indices.forEach((i, index) => this.write(i, tensors[index]));
  }
  /**
   * Return selected values in the TensorArray as a packed Tensor. All of
   * selected values must have been written and their shapes must all match.
   * @param [indices] number[] Optional. Taking values in [0, max_value). If the
   *    TensorArray is not dynamic, max_value=size(). If not specified returns
   *    all tensors in the original order.
   * @param [dtype]
   */
  gather(indices, dtype) {
    if (!!dtype && dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${dtype}`);
    }
    if (!indices) {
      indices = [];
      for (let i = 0; i < this.size(); i++) {
        indices.push(i);
      }
    } else {
      indices = indices.slice(0, this.size());
    }
    if (indices.length === 0) {
      return tensor([], [0].concat(this.elementShape));
    }
    const tensors = this.readMany(indices);
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: ");
    return stack(tensors, 0);
  }
  /**
   * Return the values in the TensorArray as a concatenated Tensor.
   */
  concat(dtype) {
    if (!!dtype && dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${dtype}`);
    }
    if (this.size() === 0) {
      return tensor([], [0].concat(this.elementShape));
    }
    const indices = [];
    for (let i = 0; i < this.size(); i++) {
      indices.push(i);
    }
    const tensors = this.readMany(indices);
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, `TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${tensors[0].shape})`);
    return concat(tensors, 0);
  }
  /**
   * Scatter the values of a Tensor in specific indices of a TensorArray.
   * @param indices number[] values in [0, max_value). If the
   *    TensorArray is not dynamic, max_value=size().
   * @param tensor Tensor input tensor.
   */
  scatter(indices, tensor2) {
    if (tensor2.dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor2.dtype}`);
    }
    if (indices.length !== tensor2.shape[0]) {
      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor2.shape[0]}`);
    }
    const maxIndex = Math.max(...indices);
    if (!this.dynamicSize && maxIndex >= this.maxSize) {
      throw new Error(`Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);
    }
    this.writeMany(indices, unstack(tensor2, 0));
  }
  /**
   * Split the values of a Tensor into the TensorArray.
   * @param length number[] with the lengths to use when splitting value along
   *    its first dimension.
   * @param tensor Tensor, the tensor to split.
   */
  split(length, tensor2) {
    if (tensor2.dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor2.dtype}`);
    }
    let totalLength = 0;
    const cumulativeLengths = length.map((len) => {
      totalLength += len;
      return totalLength;
    });
    if (totalLength !== tensor2.shape[0]) {
      throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${totalLength}, and tensor's shape is: ${tensor2.shape}`);
    }
    if (!this.dynamicSize && length.length !== this.maxSize) {
      throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${length.length}), and the TensorArray is not marked as dynamically resizeable`);
    }
    const elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
    const tensors = [];
    tidy(() => {
      tensor2 = reshape(tensor2, [1, totalLength, elementPerRow]);
      for (let i = 0; i < length.length; ++i) {
        const previousLength = i === 0 ? 0 : cumulativeLengths[i - 1];
        const indices2 = [0, previousLength, 0];
        const sizes = [1, length[i], elementPerRow];
        tensors[i] = reshape(slice(tensor2, indices2, sizes), this.elementShape);
      }
      return tensors;
    });
    const indices = [];
    for (let i = 0; i < length.length; i++) {
      indices[i] = i;
    }
    this.writeMany(indices, tensors);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_list.js
var TensorList = class _TensorList {
  get id() {
    return this.idTensor.id;
  }
  /**
   *
   * @param tensors list of tensors
   * @param elementShape shape of each tensor, this can be a single number (any
   * shape is allowed) or partial shape (dim = -1).
   * @param elementDtype data type of each tensor
   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1
   *   meaning that the size of `tensors` is unbounded.
   */
  constructor(tensors, elementShape, elementDtype, maxNumElements = -1) {
    this.tensors = tensors;
    this.elementShape = elementShape;
    this.elementDtype = elementDtype;
    if (tensors != null) {
      tensors.forEach((tensor2) => {
        if (elementDtype !== tensor2.dtype) {
          throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${tensor2.dtype}`);
        }
        assertShapesMatchAllowUndefinedSize(elementShape, tensor2.shape, "TensorList shape mismatch: ");
        keep(tensor2);
      });
    }
    this.idTensor = scalar(0);
    this.maxNumElements = maxNumElements;
    keep(this.idTensor);
  }
  /**
   * Get a new TensorList containing a copy of the underlying tensor container.
   */
  copy() {
    return new _TensorList([...this.tensors], this.elementShape, this.elementDtype);
  }
  /**
   * Dispose the tensors and idTensor and clear the tensor list.
   */
  clearAndClose(keepIds) {
    this.tensors.forEach((tensor2) => {
      if (keepIds == null || !keepIds.has(tensor2.id)) {
        tensor2.dispose();
      }
    });
    this.tensors.length = 0;
    this.idTensor.dispose();
  }
  /**
   * The size of the tensors in the tensor list.
   */
  size() {
    return this.tensors.length;
  }
  /**
   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)
   * tf.Tensor.
   * @param elementShape shape of each tensor
   * @param elementDtype data type of each tensor
   * @param numElements the number of elements to stack
   */
  stack(elementShape, elementDtype, numElements = -1) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    if (numElements !== -1 && this.tensors.length !== numElements) {
      throw new Error(`Operation expected a list with ${numElements} elements but got a list with ${this.tensors.length} elements.`);
    }
    assertShapesMatchAllowUndefinedSize(elementShape, this.elementShape, "TensorList shape mismatch: ");
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    return tidy(() => {
      const reshapedTensors = this.tensors.map((tensor2) => reshape(tensor2, outputElementShape));
      return stack(reshapedTensors, 0);
    });
  }
  /**
   * Pop a tensor from the end of the list.
   * @param elementShape shape of the tensor
   * @param elementDtype data type of the tensor
   */
  popBack(elementShape, elementDtype) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    if (this.size() === 0) {
      throw new Error("Trying to pop from an empty list.");
    }
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    const tensor2 = this.tensors.pop();
    tensor2.kept = false;
    assertShapesMatchAllowUndefinedSize(tensor2.shape, elementShape, "TensorList shape mismatch: ");
    return reshape(tensor2, outputElementShape);
  }
  /**
   * Push a tensor to the end of the list.
   * @param tensor Tensor to be pushed.
   */
  pushBack(tensor2) {
    if (tensor2.dtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${tensor2.dtype}, but list elements ${this.elementDtype}`);
    }
    assertShapesMatchAllowUndefinedSize(tensor2.shape, this.elementShape, "TensorList shape mismatch: ");
    if (this.maxNumElements === this.size()) {
      throw new Error(`Trying to push element into a full list.`);
    }
    keep(tensor2);
    this.tensors.push(tensor2);
  }
  /**
   * Update the size of the list.
   * @param size the new size of the list.
   */
  resize(size) {
    if (size < 0) {
      throw new Error(`TensorListResize expects size to be non-negative. Got: ${size}`);
    }
    if (this.maxNumElements !== -1 && size > this.maxNumElements) {
      throw new Error(`TensorListResize input size ${size} is greater maxNumElement ${this.maxNumElements}.`);
    }
    const destTensorList = new _TensorList([], this.elementShape, this.elementDtype, this.maxNumElements);
    destTensorList.tensors.length = size;
    for (let i = 0; i < Math.min(this.tensors.length, size); ++i) {
      destTensorList.tensors[i] = this.tensors[i];
    }
    return destTensorList;
  }
  /**
   * Retrieve the element at the provided index
   * @param elementShape shape of the tensor
   * @param elementDtype dtype of the tensor
   * @param elementIndex index of the tensor
   */
  getItem(elementIndex, elementShape, elementDtype) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    if (elementIndex < 0 || elementIndex > this.tensors.length) {
      throw new Error(`Trying to access element ${elementIndex} in a list with ${this.tensors.length} elements.`);
    }
    if (this.tensors[elementIndex] == null) {
      throw new Error(`element at index ${elementIndex} is null.`);
    }
    assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape, elementShape, "TensorList shape mismatch: ");
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    return reshape(this.tensors[elementIndex], outputElementShape);
  }
  /**
   * Set the tensor at the index
   * @param elementIndex index of the tensor
   * @param tensor the tensor to be inserted into the list
   */
  setItem(elementIndex, tensor2) {
    if (tensor2.dtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${tensor2.dtype}, but list elements ${this.elementDtype}`);
    }
    if (elementIndex < 0 || this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {
      throw new Error(`Trying to set element ${elementIndex} in a list with max ${this.maxNumElements} elements.`);
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, "TensorList shape mismatch: ");
    keep(tensor2);
    if (this.tensors[elementIndex] != null) {
      this.tensors[elementIndex].kept = false;
    }
    this.tensors[elementIndex] = tensor2;
  }
  /**
   * Return selected values in the TensorList as a stacked Tensor. All of
   * selected values must have been written and their shapes must all match.
   * @param indices indices of tensors to gather
   * @param elementDtype output tensor dtype
   * @param elementShape output tensor element shape
   */
  gather(indices, elementDtype, elementShape) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
    indices = indices.slice(0, this.size());
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    if (indices.length === 0) {
      return tensor([], [0].concat(outputElementShape));
    }
    return tidy(() => {
      const tensors = indices.map((i) => reshape(this.tensors[i], outputElementShape));
      return stack(tensors, 0);
    });
  }
  /**
   * Return the values in the TensorList as a concatenated Tensor.
   * @param elementDtype output tensor dtype
   * @param elementShape output tensor element shape
   */
  concat(elementDtype, elementShape) {
    if (!!elementDtype && elementDtype !== this.elementDtype) {
      throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${elementDtype}`);
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    if (this.size() === 0) {
      return tensor([], [0].concat(outputElementShape));
    }
    return tidy(() => {
      const tensors = this.tensors.map((t2) => reshape(t2, outputElementShape));
      return concat(tensors, 0);
    });
  }
};
function fromTensor(tensor2, elementShape, elementDtype) {
  const dtype = tensor2.dtype;
  if (tensor2.shape.length < 1) {
    throw new Error(`Tensor must be at least a vector, but saw shape: ${tensor2.shape}`);
  }
  if (tensor2.dtype !== elementDtype) {
    throw new Error(`Invalid data types; op elements ${tensor2.dtype}, but list elements ${elementDtype}`);
  }
  const tensorElementShape = tensor2.shape.slice(1);
  assertShapesMatchAllowUndefinedSize(tensorElementShape, elementShape, "TensorList shape mismatch: ");
  const tensorList = unstack(tensor2);
  return new TensorList(tensorList, elementShape, dtype);
}
function reserve(elementShape, elementDtype, numElements, maxNumElements) {
  return new TensorList([], elementShape, elementDtype, maxNumElements);
}
function scatter(tensor2, indices, elementShape, numElements) {
  if (indices.length !== tensor2.shape[0]) {
    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor2.shape[0]}`);
  }
  const maxIndex = Math.max(...indices);
  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {
    throw new Error(`Max index must be < array size (${maxIndex}  vs. ${numElements})`);
  }
  const list = new TensorList([], elementShape, tensor2.dtype, numElements);
  const tensors = unstack(tensor2, 0);
  indices.forEach((value, index) => {
    list.setItem(value, tensors[index]);
  });
  return list;
}
function split2(tensor2, length, elementShape) {
  let totalLength = 0;
  const cumulativeLengths = length.map((len) => {
    totalLength += len;
    return totalLength;
  });
  if (totalLength !== tensor2.shape[0]) {
    throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${totalLength}, and tensor's shape is: ${tensor2.shape}`);
  }
  const shapeWithoutFirstDim = tensor2.shape.slice(1);
  const outputElementShape = mergeElementShape(shapeWithoutFirstDim, elementShape);
  const elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
  const tensors = tidy(() => {
    const tensors2 = [];
    tensor2 = reshape(tensor2, [1, totalLength, elementPerRow]);
    for (let i = 0; i < length.length; ++i) {
      const previousLength = i === 0 ? 0 : cumulativeLengths[i - 1];
      const indices = [0, previousLength, 0];
      const sizes = [1, length[i], elementPerRow];
      tensors2[i] = reshape(slice(tensor2, indices, sizes), outputElementShape);
    }
    tensor2.dispose();
    return tensors2;
  });
  const list = new TensorList([], elementShape, tensor2.dtype, length.length);
  for (let i = 0; i < tensors.length; i++) {
    list.setItem(i, tensors[i]);
  }
  return list;
}

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js
var executeOp3 = async (node, tensorMap, context) => {
  switch (node.op) {
    case "If":
    case "StatelessIf": {
      const thenFunc = getParamValue("thenBranch", node, tensorMap, context);
      const elseFunc = getParamValue("elseBranch", node, tensorMap, context);
      const cond = getParamValue("cond", node, tensorMap, context);
      const args = getParamValue("args", node, tensorMap, context);
      const condValue = await cond.data();
      if (condValue[0]) {
        return context.functionMap[thenFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
      } else {
        return context.functionMap[elseFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
      }
    }
    case "While":
    case "StatelessWhile": {
      const bodyFunc = getParamValue("body", node, tensorMap, context);
      const condFunc = getParamValue("cond", node, tensorMap, context);
      const args = getParamValue("args", node, tensorMap, context);
      const condResult = await context.functionMap[condFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
      const argIds = args.map((tensor2) => tensor2.id);
      let condValue = await condResult[0].data();
      condResult.forEach((tensor2) => {
        if (!tensor2.kept && argIds.indexOf(tensor2.id) === -1) {
          tensor2.dispose();
        }
      });
      let result = args;
      while (condValue[0]) {
        const origResult = result;
        result = await context.functionMap[bodyFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap);
        const resultIds = result.map((tensor2) => tensor2.id);
        origResult.forEach((tensor2) => {
          if (!tensor2.kept && argIds.indexOf(tensor2.id) === -1 && resultIds.indexOf(tensor2.id) === -1) {
            tensor2.dispose();
          }
        });
        const condResult2 = await context.functionMap[condFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap);
        condValue = await condResult2[0].data();
        condResult2.forEach((tensor2) => {
          if (!tensor2.kept && argIds.indexOf(tensor2.id) === -1 && resultIds.indexOf(tensor2.id) === -1) {
            tensor2.dispose();
          }
        });
      }
      return result;
    }
    case "LoopCond": {
      const pred = getParamValue("pred", node, tensorMap, context);
      return [cloneTensor(pred)];
    }
    case "Switch": {
      const pred = getParamValue("pred", node, tensorMap, context);
      let data = getParamValue("data", node, tensorMap, context);
      if (!data.kept) {
        data = cloneTensor(data);
      }
      return (await pred.data())[0] ? [void 0, data] : [data, void 0];
    }
    case "Merge": {
      const inputName = node.inputNames.find((name) => getTensor(name, tensorMap, context) !== void 0);
      if (inputName) {
        const data = getTensor(inputName, tensorMap, context);
        return [cloneTensor(data)];
      }
      return void 0;
    }
    case "Enter": {
      const frameId = getParamValue("frameName", node, tensorMap, context);
      const data = getParamValue("tensor", node, tensorMap, context);
      context.enterFrame(frameId);
      return [cloneTensor(data)];
    }
    case "Exit": {
      const data = getParamValue("tensor", node, tensorMap, context);
      context.exitFrame();
      return [cloneTensor(data)];
    }
    case "NextIteration": {
      const data = getParamValue("tensor", node, tensorMap, context);
      context.nextIteration();
      return [cloneTensor(data)];
    }
    case "TensorArrayV3": {
      const size = getParamValue("size", node, tensorMap, context);
      const dtype = getParamValue("dtype", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const dynamicSize = getParamValue("dynamicSize", node, tensorMap, context);
      const clearAfterRead = getParamValue("clearAfterRead", node, tensorMap, context);
      const identicalElementShapes = getParamValue("identicalElementShapes", node, tensorMap, context);
      const name = getParamValue("name", node, tensorMap, context);
      const tensorArray = new TensorArray(name, dtype, size, elementShape, identicalElementShapes, dynamicSize, clearAfterRead);
      context.addTensorArray(tensorArray);
      return [tensorArray.idTensor, scalar(1)];
    }
    case "TensorArrayWriteV3": {
      const id = getParamValue("tensorArrayId", node, tensorMap, context);
      const index = getParamValue("index", node, tensorMap, context);
      const writeTensor = getParamValue("tensor", node, tensorMap, context);
      const writeTensorArray = context.getTensorArray(id.id);
      writeTensorArray.write(index, writeTensor);
      return [writeTensorArray.idTensor];
    }
    case "TensorArrayReadV3": {
      const readId = getParamValue("tensorArrayId", node, tensorMap, context);
      const readIndex = getParamValue("index", node, tensorMap, context);
      const readTensorArray = context.getTensorArray(readId.id);
      return [readTensorArray.read(readIndex)];
    }
    case "TensorArrayGatherV3": {
      const gatherId = getParamValue("tensorArrayId", node, tensorMap, context);
      const gatherIndices = getParamValue("indices", node, tensorMap, context);
      const gatherDtype = getParamValue("dtype", node, tensorMap, context);
      const gatherTensorArray = context.getTensorArray(gatherId.id);
      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];
    }
    case "TensorArrayScatterV3": {
      const scatterId = getParamValue("tensorArrayId", node, tensorMap, context);
      const scatterIndices = getParamValue("indices", node, tensorMap, context);
      const scatterTensor = getParamValue("tensor", node, tensorMap, context);
      const scatterTensorArray = context.getTensorArray(scatterId.id);
      scatterTensorArray.scatter(scatterIndices, scatterTensor);
      return [scatterTensorArray.idTensor];
    }
    case "TensorArrayConcatV3": {
      const concatId = getParamValue("tensorArrayId", node, tensorMap, context);
      const concatTensorArray = context.getTensorArray(concatId.id);
      const concatDtype = getParamValue("dtype", node, tensorMap, context);
      return [concatTensorArray.concat(concatDtype)];
    }
    case "TensorArraySplitV3": {
      const splitId = getParamValue("tensorArrayId", node, tensorMap, context);
      const splitTensor = getParamValue("tensor", node, tensorMap, context);
      const lengths = getParamValue("lengths", node, tensorMap, context);
      const splitTensorArray = context.getTensorArray(splitId.id);
      splitTensorArray.split(lengths, splitTensor);
      return [splitTensorArray.idTensor];
    }
    case "TensorArraySizeV3": {
      const sizeId = getParamValue("tensorArrayId", node, tensorMap, context);
      const sizeTensorArray = context.getTensorArray(sizeId.id);
      return [scalar(sizeTensorArray.size(), "int32")];
    }
    case "TensorArrayCloseV3": {
      const closeId = getParamValue("tensorArrayId", node, tensorMap, context);
      const closeTensorArray = context.getTensorArray(closeId.id);
      closeTensorArray.clearAndClose();
      return [closeTensorArray.idTensor];
    }
    case "TensorListSetItem": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const index = getParamValue("index", node, tensorMap, context);
      const writeTensor = getParamValue("tensor", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      tensorList.setItem(index, writeTensor);
      return [tensorList.idTensor];
    }
    case "TensorListGetItem": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const readIndex = getParamValue("index", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDType = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [tensorList.getItem(readIndex, elementShape, elementDType)];
    }
    case "TensorListScatterV2":
    case "TensorListScatter": {
      const scatterIndices = getParamValue("indices", node, tensorMap, context);
      const scatterTensor = getParamValue("tensor", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const numElements = getParamValue("numElements", node, tensorMap, context);
      const tensorList = scatter(scatterTensor, scatterIndices, elementShape, numElements);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListReserve":
    case "EmptyTensorList": {
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      let numElementsParam;
      if (node.op === "TensorListReserve") {
        numElementsParam = "numElements";
      } else {
        numElementsParam = "maxNumElements";
      }
      const numElements = getParamValue(numElementsParam, node, tensorMap, context);
      const maxNumElements = node.op === "TensorListReserve" ? -1 : numElements;
      const tensorList = reserve(elementShape, elementDtype, numElements, maxNumElements);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListGather": {
      const gatherId = getParamValue("tensorListId", node, tensorMap, context);
      const gatherIndices = getParamValue("indices", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = context.getTensorList(gatherId.id);
      return [tensorList.gather(gatherIndices, elementDtype, elementShape)];
    }
    case "TensorListStack": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      const numElements = getParamValue("numElements", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [tensorList.stack(elementShape, elementDtype, numElements)];
    }
    case "TensorListFromTensor": {
      const tensor2 = getParamValue("tensor", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = fromTensor(tensor2, elementShape, elementDtype);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListConcat":
    case "TensorListConcatV2": {
      const concatId = getParamValue("tensorListId", node, tensorMap, context);
      const tensorList = context.getTensorList(concatId.id);
      const concatDtype = getParamValue("dtype", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      return [tensorList.concat(concatDtype, elementShape)];
    }
    case "TensorListPushBack": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const writeTensor = getParamValue("tensor", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      tensorList.pushBack(writeTensor);
      return [tensorList.idTensor];
    }
    case "TensorListPopBack": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDType = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [tensorList.popBack(elementShape, elementDType)];
    }
    case "TensorListSplit": {
      const splitTensor = getParamValue("tensor", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const lengths = getParamValue("lengths", node, tensorMap, context);
      const tensorList = split2(splitTensor, lengths, elementShape);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListLength": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [scalar(tensorList.size(), "int32")];
    }
    case "TensorListResize": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      const srcTensorList = context.getTensorList(idTensor.id);
      const destTensorList = srcTensorList.resize(size);
      context.addTensorList(destTensorList);
      return [destTensorList.idTensor];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js
function fusedConvAndDepthWiseParams(node, tensorMap, context) {
  const [extraOp, activationFunc] = getParamValue("fusedOps", node, tensorMap, context);
  const isBiasAdd = extraOp === "biasadd";
  const noBiasAdd = !isBiasAdd;
  const isPrelu = activationFunc === "prelu";
  const isBatchNorm = extraOp === "fusedbatchnorm";
  const numArgs = getParamValue("numArgs", node, tensorMap, context);
  if (isBiasAdd) {
    if (isPrelu && numArgs !== 2) {
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
    }
    if (!isPrelu && isBiasAdd && numArgs !== 1) {
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
    }
  }
  if (isBatchNorm) {
    throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
  }
  const stride = getParamValue("strides", node, tensorMap, context);
  const pad2 = getPadding(node, tensorMap, context);
  const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
  const dilations = getParamValue("dilations", node, tensorMap, context);
  let [biasArg, preluArg] = getParamValue("args", node, tensorMap, context);
  if (noBiasAdd) {
    preluArg = biasArg;
    biasArg = void 0;
  }
  const leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
  return {
    stride,
    pad: pad2,
    dataFormat,
    dilations,
    biasArg,
    preluArg,
    activationFunc,
    leakyreluAlpha
  };
}
var executeOp4 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Conv1D": {
      const stride = getParamValue("stride", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      const dilation = getParamValue("dilation", node, tensorMap, context);
      return [ops.conv1d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), stride, pad2, dataFormat, dilation)];
    }
    case "Conv2D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getPadding(node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      const dilations = getParamValue("dilations", node, tensorMap, context);
      return [ops.conv2d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
    }
    case "_FusedConv2D": {
      const { stride, pad: pad2, dataFormat, dilations, biasArg, preluArg, activationFunc, leakyreluAlpha } = fusedConvAndDepthWiseParams(node, tensorMap, context);
      return [ops.fused.conv2d({
        x: getParamValue("x", node, tensorMap, context),
        filter: getParamValue("filter", node, tensorMap, context),
        strides: [stride[1], stride[2]],
        pad: pad2,
        dataFormat,
        dilations: [dilations[1], dilations[2]],
        bias: biasArg,
        activation: activationFunc,
        preluActivationWeights: preluArg,
        leakyreluAlpha
      })];
    }
    case "FusedDepthwiseConv2dNative": {
      const { stride, pad: pad2, dataFormat, dilations, biasArg, preluArg, activationFunc, leakyreluAlpha } = fusedConvAndDepthWiseParams(node, tensorMap, context);
      return [ops.fused.depthwiseConv2d({
        x: getParamValue("x", node, tensorMap, context),
        filter: getParamValue("filter", node, tensorMap, context),
        strides: [stride[1], stride[2]],
        pad: pad2,
        dataFormat,
        dilations: [dilations[1], dilations[2]],
        bias: biasArg,
        activation: activationFunc,
        preluActivationWeights: preluArg,
        leakyreluAlpha
      })];
    }
    case "Conv2DBackpropInput":
    case "Conv2dTranspose": {
      const shape = getParamValue("outputShape", node, tensorMap, context);
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getPadding(node, tensorMap, context);
      return [ops.conv2dTranspose(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), shape, [stride[1], stride[2]], pad2)];
    }
    case "DepthwiseConv2dNative":
    case "DepthwiseConv2d": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getPadding(node, tensorMap, context);
      const dilations = getParamValue("dilations", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      return [ops.depthwiseConv2d(getParamValue("input", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
    }
    case "Conv3D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      const dilations = getParamValue("dilations", node, tensorMap, context);
      return [ops.conv3d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2], stride[3]], pad2, dataFormat, [dilations[1], dilations[2], dilations[3]])];
    }
    case "AvgPool": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [ops.avgPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
    }
    case "MaxPool": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [ops.maxPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
    }
    case "MaxPoolWithArgmax": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      const includeBatchInIndex = getParamValue("includeBatchInIndex", node, tensorMap, context);
      const { result, indexes } = ops.maxPoolWithArgmax(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2, includeBatchInIndex);
      return [result, indexes];
    }
    case "AvgPool3D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [ops.avgPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
    }
    case "MaxPool3D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [ops.maxPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
    }
    case "Dilation2D": {
      const strides = getParamValue("strides", node, tensorMap, context);
      const pad2 = getParamValue("pad", node, tensorMap, context);
      const dilations = getParamValue("dilations", node, tensorMap, context);
      const strideHeight = strides[1];
      const strideWidth = strides[2];
      const dilationHeight = dilations[1];
      const dilationWidth = dilations[2];
      return [ops.dilation2d(
        getParamValue("x", node, tensorMap, context),
        getParamValue("filter", node, tensorMap, context),
        [strideHeight, strideWidth],
        pad2,
        [dilationHeight, dilationWidth],
        "NHWC"
        /* dataFormat */
      )];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js
var executeOp5 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Fill": {
      const shape = getParamValue("shape", node, tensorMap, context);
      const dtype = getParamValue("dtype", node, tensorMap, context);
      const value = getParamValue("value", node, tensorMap, context);
      return [ops.fill(shape, value, dtype)];
    }
    case "LinSpace": {
      const start = getParamValue("start", node, tensorMap, context);
      const stop = getParamValue("stop", node, tensorMap, context);
      const num = getParamValue("num", node, tensorMap, context);
      return [ops.linspace(start, stop, num)];
    }
    case "Multinomial": {
      const logits = getParamValue("logits", node, tensorMap, context);
      const numSamples = getParamValue("numSamples", node, tensorMap, context);
      const seed = getParamValue("seed", node, tensorMap, context);
      return [ops.multinomial(logits, numSamples, seed)];
    }
    case "OneHot": {
      const indices = getParamValue("indices", node, tensorMap, context);
      const depth = getParamValue("depth", node, tensorMap, context);
      const onValue = getParamValue("onValue", node, tensorMap, context);
      const offValue = getParamValue("offValue", node, tensorMap, context);
      const dtype = getParamValue("dtype", node, tensorMap, context);
      return [ops.oneHot(indices, depth, onValue, offValue, dtype)];
    }
    case "Ones": {
      return [ops.ones(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "OnesLike": {
      return [ops.onesLike(getParamValue("x", node, tensorMap, context))];
    }
    case "RandomStandardNormal": {
      return [ops.randomStandardNormal(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
    }
    case "RandomUniform": {
      return [ops.randomUniform(
        // tslint:disable-next-line:no-any
        getParamValue("shape", node, tensorMap, context),
        getParamValue("minval", node, tensorMap, context),
        getParamValue("maxval", node, tensorMap, context),
        getParamValue("dtype", node, tensorMap, context)
      )];
    }
    case "RandomUniformInt": {
      return [ops.randomUniformInt(getParamValue("shape", node, tensorMap, context), getParamValue("minval", node, tensorMap, context), getParamValue("maxval", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
    }
    case "Range": {
      const start = getParamValue("start", node, tensorMap, context);
      const stop = getParamValue("stop", node, tensorMap, context);
      const step3 = getParamValue("step", node, tensorMap, context);
      return [ops.range(start, stop, step3, getParamValue("dtype", node, tensorMap, context))];
    }
    case "TruncatedNormal": {
      const shape = getParamValue("shape", node, tensorMap, context);
      const mean3 = getParamValue("mean", node, tensorMap, context);
      const stdDev = getParamValue("stdDev", node, tensorMap, context);
      const seed = getParamValue("seed", node, tensorMap, context);
      return [ops.truncatedNormal(shape, mean3, stdDev, getParamValue("dtype", node, tensorMap, context), seed)];
    }
    case "Zeros": {
      return [ops.zeros(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "ZerosLike": {
      return [ops.zerosLike(getParamValue("x", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js
function nmsParams(node, tensorMap, context) {
  const boxes = getParamValue("boxes", node, tensorMap, context);
  const scores = getParamValue("scores", node, tensorMap, context);
  const maxOutputSize = getParamValue("maxOutputSize", node, tensorMap, context);
  const iouThreshold = getParamValue("iouThreshold", node, tensorMap, context);
  const scoreThreshold = getParamValue("scoreThreshold", node, tensorMap, context);
  const softNmsSigma = getParamValue("softNmsSigma", node, tensorMap, context);
  return {
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    softNmsSigma
  };
}
var executeOp6 = async (node, tensorMap, context, resourceManager, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "NonMaxSuppressionV5": {
      const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = nmsParams(node, tensorMap, context);
      const result = await ops.image.nonMaxSuppressionWithScoreAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      return [result.selectedIndices, result.selectedScores];
    }
    case "NonMaxSuppressionV4": {
      const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold } = nmsParams(node, tensorMap, context);
      const padToMaxOutputSize = getParamValue("padToMaxOutputSize", node, tensorMap, context);
      const result = await ops.image.nonMaxSuppressionPaddedAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
      return [result.selectedIndices, result.validOutputs];
    }
    case "NonMaxSuppressionV3":
    case "NonMaxSuppressionV2": {
      const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold } = nmsParams(node, tensorMap, context);
      return [await ops.image.nonMaxSuppressionAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold)];
    }
    case "Where": {
      const condition = ops.cast(getParamValue("condition", node, tensorMap, context), "bool");
      const result = [await ops.whereAsync(condition)];
      condition.dispose();
      return result;
    }
    case "ListDiff": {
      return ops.setdiff1dAsync(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context));
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js
var executeOp7 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "LowerBound": {
      const sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      return [ops.lowerBound(sortedSequence, values)];
    }
    case "TopKV2": {
      const x = getParamValue("x", node, tensorMap, context);
      const k = getParamValue("k", node, tensorMap, context);
      const sorted = getParamValue("sorted", node, tensorMap, context);
      const result = ops.topk(x, k, sorted);
      return [result.values, result.indices];
    }
    case "UpperBound": {
      const sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      return [ops.upperBound(sortedSequence, values)];
    }
    case "Unique": {
      const x = getParamValue("x", node, tensorMap, context);
      const result = ops.unique(x);
      return [result.values, result.indices];
    }
    case "UniqueV2": {
      const x = getParamValue("x", node, tensorMap, context);
      const axis = getParamValue("axis", node, tensorMap, context);
      const result = ops.unique(x, axis);
      return [result.values, result.indices];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js
var executeOp8 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Const": {
      return tensorMap[node.name];
    }
    case "PlaceholderWithDefault":
      const def = getParamValue("default", node, tensorMap, context);
      return [getTensor(node.name, tensorMap, context) || def];
    case "Placeholder":
      return [getTensor(node.name, tensorMap, context)];
    case "Identity":
    case "StopGradient":
    case "FakeQuantWithMinMaxVars": {
      const data2 = getParamValue("x", node, tensorMap, context);
      return [cloneTensor(data2)];
    }
    case "IdentityN":
      return getParamValue("x", node, tensorMap, context).map((t2) => cloneTensor(t2));
    case "Snapshot":
      const snapshot = getParamValue("x", node, tensorMap, context);
      return [cloneTensor(snapshot)];
    case "Shape":
      return [ops.tensor1d(getParamValue("x", node, tensorMap, context).shape, "int32")];
    case "ShapeN":
      return getParamValue("x", node, tensorMap, context).map((t2) => ops.tensor1d(t2.shape));
    case "Size":
      return [ops.scalar(getParamValue("x", node, tensorMap, context).size, "int32")];
    case "Rank":
      return [ops.scalar(getParamValue("x", node, tensorMap, context).rank, "int32")];
    case "NoOp":
      return [ops.scalar(1)];
    case "Print":
      const input = getParamValue("x", node, tensorMap, context);
      const data = getParamValue("data", node, tensorMap, context);
      const message = getParamValue("message", node, tensorMap, context);
      const summarize = getParamValue("summarize", node, tensorMap, context);
      console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance.");
      console.log(message);
      for (let i = 0; i < data.length; i++) {
        console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));
      }
      return [input];
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/executor/hash_table.js
var HashTable = class {
  get id() {
    return this.handle.id;
  }
  /**
   * Constructor of HashTable. Creates a hash table.
   *
   * @param keyDType `dtype` of the table keys.
   * @param valueDType `dtype` of the table values.
   */
  constructor(keyDType, valueDType) {
    this.keyDType = keyDType;
    this.valueDType = valueDType;
    this.handle = scalar(0);
    this.tensorMap = /* @__PURE__ */ new Map();
    keep(this.handle);
  }
  /**
   * Dispose the tensors and handle and clear the hashtable.
   */
  clearAndClose() {
    this.tensorMap.forEach((value) => value.dispose());
    this.tensorMap.clear();
    this.handle.dispose();
  }
  /**
   * The number of items in the hash table.
   */
  size() {
    return this.tensorMap.size;
  }
  /**
   * The number of items in the hash table as a rank-0 tensor.
   */
  tensorSize() {
    return scalar(this.size(), "int32");
  }
  /**
   * Replaces the contents of the table with the specified keys and values.
   * @param keys Keys to store in the hashtable.
   * @param values Values to store in the hashtable.
   */
  async import(keys, values) {
    this.checkKeyAndValueTensor(keys, values);
    const $keys = await keys.data();
    this.tensorMap.forEach((value) => value.dispose());
    this.tensorMap.clear();
    return tidy(() => {
      const $values = unstack(values);
      const keysLength = $keys.length;
      const valuesLength = $values.length;
      util_exports.assert(keysLength === valuesLength, () => `The number of elements doesn't match, keys has ${keysLength} elements, the values has ${valuesLength} elements.`);
      for (let i = 0; i < keysLength; i++) {
        const key = $keys[i];
        const value = $values[i];
        keep(value);
        this.tensorMap.set(key, value);
      }
      return this.handle;
    });
  }
  /**
   * Looks up keys in a hash table, outputs the corresponding values.
   *
   * Performs batch lookups, for every element in the key tensor, `find`
   * stacks the corresponding value into the return tensor.
   *
   * If an element is not present in the table, the given `defaultValue` is
   * used.
   *
   * @param keys Keys to look up. Must have the same type as the keys of the
   *     table.
   * @param defaultValue The scalar `defaultValue` is the value output for keys
   *     not present in the table. It must also be of the same type as the
   *     table values.
   */
  async find(keys, defaultValue) {
    this.checkKeyAndValueTensor(keys, defaultValue);
    const $keys = await keys.data();
    return tidy(() => {
      const result = [];
      for (let i = 0; i < $keys.length; i++) {
        const key = $keys[i];
        const value = this.findWithDefault(key, defaultValue);
        result.push(value);
      }
      return stack(result);
    });
  }
  // tslint:disable-next-line: no-any
  findWithDefault(key, defaultValue) {
    const result = this.tensorMap.get(key);
    return result != null ? result : defaultValue;
  }
  checkKeyAndValueTensor(key, value) {
    if (key.dtype !== this.keyDType) {
      throw new Error(`Expect key dtype ${this.keyDType}, but got ${key.dtype}`);
    }
    if (value.dtype !== this.valueDType) {
      throw new Error(`Expect value dtype ${this.valueDType}, but got ${value.dtype}`);
    }
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js
var executeOp9 = async (node, tensorMap, context, resourceManager) => {
  switch (node.op) {
    case "HashTable":
    case "HashTableV2": {
      const existingTableHandle = resourceManager.getHashTableHandleByName(node.name);
      if (existingTableHandle != null) {
        return [existingTableHandle];
      } else {
        const keyDType = getParamValue("keyDType", node, tensorMap, context);
        const valueDType = getParamValue("valueDType", node, tensorMap, context);
        const hashTable = new HashTable(keyDType, valueDType);
        resourceManager.addHashTable(node.name, hashTable);
        return [hashTable.handle];
      }
    }
    case "InitializeTable":
    case "InitializeTableV2":
    case "LookupTableImport":
    case "LookupTableImportV2": {
      const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
      const keys = getParamValue("keys", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      const hashTable = resourceManager.getHashTableById(handle.id);
      return [await hashTable.import(keys, values)];
    }
    case "LookupTableFind":
    case "LookupTableFindV2": {
      const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
      const keys = getParamValue("keys", node, tensorMap, context);
      const defaultValue = getParamValue("defaultValue", node, tensorMap, context);
      const hashTable = resourceManager.getHashTableById(handle.id);
      return [await hashTable.find(keys, defaultValue)];
    }
    case "LookupTableSize":
    case "LookupTableSizeV2": {
      const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
      const hashTable = resourceManager.getHashTableById(handle.id);
      return [hashTable.tensorSize()];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js
var executeOp10 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "ResizeBilinear": {
      const images = getParamValue("images", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      const alignCorners = getParamValue("alignCorners", node, tensorMap, context);
      const halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
      return [ops.image.resizeBilinear(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
    }
    case "ResizeNearestNeighbor": {
      const images = getParamValue("images", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      const alignCorners = getParamValue("alignCorners", node, tensorMap, context);
      const halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
      return [ops.image.resizeNearestNeighbor(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
    }
    case "CropAndResize": {
      const image2 = getParamValue("image", node, tensorMap, context);
      const boxes = getParamValue("boxes", node, tensorMap, context);
      const boxInd = getParamValue("boxInd", node, tensorMap, context);
      const cropSize = getParamValue("cropSize", node, tensorMap, context);
      const method = getParamValue("method", node, tensorMap, context);
      const extrapolationValue = getParamValue("extrapolationValue", node, tensorMap, context);
      return [ops.image.cropAndResize(image2, boxes, boxInd, cropSize, method, extrapolationValue)];
    }
    case "ImageProjectiveTransformV3": {
      const images = getParamValue("images", node, tensorMap, context);
      const transforms = getParamValue("transforms", node, tensorMap, context);
      const outputShape = getParamValue("outputShape", node, tensorMap, context);
      const fillValue = getParamValue("fillValue", node, tensorMap, context);
      const interpolation = getParamValue("interpolation", node, tensorMap, context);
      const fillMode = getParamValue("fillMode", node, tensorMap, context);
      return [ops.image.transform(images, transforms, interpolation.toLowerCase(), fillMode.toLowerCase(), fillValue, outputShape)];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js
var executeOp11 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Equal": {
      return [ops.equal(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "NotEqual": {
      return [ops.notEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Greater": {
      return [ops.greater(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "GreaterEqual": {
      return [ops.greaterEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Less": {
      return [ops.less(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "LessEqual": {
      return [ops.lessEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "LogicalAnd": {
      return [ops.logicalAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "LogicalNot": {
      return [ops.logicalNot(getParamValue("a", node, tensorMap, context))];
    }
    case "LogicalOr": {
      return [ops.logicalOr(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Select":
    case "SelectV2": {
      return [ops.where(getParamValue("condition", node, tensorMap, context), getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "BitwiseAnd": {
      return [ops.bitwiseAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js
var executeOp12 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "BatchMatMul":
    case "BatchMatMulV2":
    case "MatMul":
      return [ops.matMul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context), getParamValue("transposeA", node, tensorMap, context), getParamValue("transposeB", node, tensorMap, context))];
    case "Einsum":
      return [ops.einsum(getParamValue("equation", node, tensorMap, context), ...getParamValue("tensors", node, tensorMap, context))];
    case "Transpose":
      return [ops.transpose(getParamValue("x", node, tensorMap, context), getParamValue("perm", node, tensorMap, context))];
    case "_FusedMatMul":
      const [extraOp, activationFunc] = getParamValue("fusedOps", node, tensorMap, context);
      const isBiasAdd = extraOp === "biasadd";
      const isPrelu = activationFunc === "prelu";
      const numArgs = getParamValue("numArgs", node, tensorMap, context);
      const leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
      if (isBiasAdd) {
        if (isPrelu && numArgs !== 2) {
          throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        }
        if (!isPrelu && numArgs !== 1) {
          throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
        }
      }
      const [biasArg, preluArg] = getParamValue("args", node, tensorMap, context);
      return [ops.fused.matMul({
        a: getParamValue("a", node, tensorMap, context),
        b: getParamValue("b", node, tensorMap, context),
        transposeA: getParamValue("transposeA", node, tensorMap, context),
        transposeB: getParamValue("transposeB", node, tensorMap, context),
        bias: biasArg,
        activation: activationFunc,
        preluActivationWeights: preluArg,
        leakyreluAlpha
      })];
    case "MatrixBandPart":
      return [ops.linalg.bandPart(getParamValue("a", node, tensorMap, context), getParamValue("numLower", node, tensorMap, context), getParamValue("numUpper", node, tensorMap, context))];
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js
var executeOp13 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "EuclideanNorm":
      return [ops.euclideanNorm(getParamValue("x", node, tensorMap, context), getParamValue("axis", node, tensorMap, context), getParamValue("keepDims", node, tensorMap, context))];
    case "FusedBatchNorm":
    case "FusedBatchNormV2": {
      return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
    }
    case "FusedBatchNormV3": {
      return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
    }
    case "LRN": {
      return [ops.localResponseNormalization(getParamValue("x", node, tensorMap, context), getParamValue("radius", node, tensorMap, context), getParamValue("bias", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context), getParamValue("beta", node, tensorMap, context))];
    }
    case "Softmax": {
      return [ops.softmax(getParamValue("x", node, tensorMap, context))];
    }
    case "LogSoftmax": {
      return [ops.logSoftmax(getParamValue("x", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js
var executeOp14 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "RaggedGather": {
      const { outputNestedSplits, outputDenseValues } = ops.raggedGather(getParamValue("paramsNestedSplits", node, tensorMap, context), getParamValue("paramsDenseValues", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("outputRaggedRank", node, tensorMap, context));
      return outputNestedSplits.concat(outputDenseValues);
    }
    case "RaggedRange": {
      const { rtNestedSplits, rtDenseValues } = ops.raggedRange(getParamValue("starts", node, tensorMap, context), getParamValue("limits", node, tensorMap, context), getParamValue("splits", node, tensorMap, context));
      return [rtNestedSplits, rtDenseValues];
    }
    case "RaggedTensorToTensor": {
      return [ops.raggedTensorToTensor(getParamValue("shape", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context), getParamValue("rowPartitionTensors", node, tensorMap, context), getParamValue("rowPartitionTypes", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js
var executeOp15 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Max": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.max(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Mean": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.mean(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Min": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.min(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Sum": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.sum(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "All": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.all(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Any": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.any(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "ArgMax": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [ops.argMax(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "ArgMin": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [ops.argMin(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "Prod": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [ops.prod(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Cumprod": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const exclusive = getParamValue("exclusive", node, tensorMap, context);
      const reverse3 = getParamValue("reverse", node, tensorMap, context);
      return [ops.cumprod(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse3)];
    }
    case "Cumsum": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const exclusive = getParamValue("exclusive", node, tensorMap, context);
      const reverse3 = getParamValue("reverse", node, tensorMap, context);
      return [ops.cumsum(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse3)];
    }
    case "Bincount":
      const x = getParamValue("x", node, tensorMap, context);
      const weights = getParamValue("weights", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      return [ops.bincount(x, weights, size)];
    case "DenseBincount": {
      const x2 = getParamValue("x", node, tensorMap, context);
      const weights2 = getParamValue("weights", node, tensorMap, context);
      const size2 = getParamValue("size", node, tensorMap, context);
      const binaryOutput = getParamValue("binaryOutput", node, tensorMap, context);
      return [ops.denseBincount(x2, weights2, size2, binaryOutput)];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js
var executeOp16 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "ConcatV2":
    case "Concat": {
      const n = getParamValue("n", node, tensorMap, context);
      const axis = getParamValue("axis", node, tensorMap, context);
      let inputs = getParamValue("tensors", node, tensorMap, context);
      inputs = inputs.slice(0, n);
      return [ops.concat(inputs, axis)];
    }
    case "Gather": {
      const input = getParamValue("x", node, tensorMap, context);
      const indices = getParamValue("indices", node, tensorMap, context);
      return [ops.gather(input, ops.cast(indices, "int32"), 0)];
    }
    case "GatherV2": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const batchDims = getParamValue("batchDims", node, tensorMap, context);
      const input = getParamValue("x", node, tensorMap, context);
      const indices = getParamValue("indices", node, tensorMap, context);
      return [ops.gather(input, ops.cast(indices, "int32"), axis, batchDims)];
    }
    case "Reverse": {
      const dims = getParamValue("dims", node, tensorMap, context);
      const axis = [];
      for (let i = 0; i < dims.length; i++) {
        if (dims[i]) {
          axis.push(i);
        }
      }
      const input = getParamValue("x", node, tensorMap, context);
      return [ops.reverse(input, axis)];
    }
    case "ReverseV2": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const input = getParamValue("x", node, tensorMap, context);
      return [ops.reverse(input, axis)];
    }
    case "Slice": {
      const begin = getParamValue("begin", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      return [ops.slice(getParamValue("x", node, tensorMap, context), begin, size)];
    }
    case "StridedSlice": {
      const begin = getParamValue("begin", node, tensorMap, context);
      const end = getParamValue("end", node, tensorMap, context);
      const strides = getParamValue("strides", node, tensorMap, context);
      const beginMask = getParamValue("beginMask", node, tensorMap, context);
      const endMask = getParamValue("endMask", node, tensorMap, context);
      const ellipsisMask = getParamValue("ellipsisMask", node, tensorMap, context);
      const newAxisMask = getParamValue("newAxisMask", node, tensorMap, context);
      const shrinkAxisMask = getParamValue("shrinkAxisMask", node, tensorMap, context);
      const tensor2 = getParamValue("x", node, tensorMap, context);
      return [ops.stridedSlice(tensor2, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask)];
    }
    case "Pack": {
      return tidy(() => {
        const axis = getParamValue("axis", node, tensorMap, context);
        const tensors = getParamValue("tensors", node, tensorMap, context);
        const shape = tensors[0].shape;
        const squeezedShape = ops.squeeze(tensors[0]).shape;
        const mapped = tensors.map((tensor2) => {
          const sameShape = util_exports.arraysEqual(tensor2.shape, shape);
          if (!sameShape && !util_exports.arraysEqual(ops.squeeze(tensor2).shape, squeezedShape)) {
            throw new Error("the input tensors shape does not match");
          }
          return sameShape ? tensor2 : ops.reshape(tensor2, shape);
        });
        return [ops.stack(mapped, axis)];
      });
    }
    case "Unpack": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const tensor2 = getParamValue("tensor", node, tensorMap, context);
      return ops.unstack(tensor2, axis);
    }
    case "Tile": {
      const reps = getParamValue("reps", node, tensorMap, context);
      return [ops.tile(getParamValue("x", node, tensorMap, context), reps)];
    }
    case "Split":
    case "SplitV": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const numOrSizeSplits = getParamValue("numOrSizeSplits", node, tensorMap, context);
      const tensor2 = getParamValue("x", node, tensorMap, context);
      return ops.split(tensor2, numOrSizeSplits, axis);
    }
    case "ScatterNd": {
      const indices = getParamValue("indices", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      const shape = getParamValue("shape", node, tensorMap, context);
      return [ops.scatterND(indices, values, shape)];
    }
    case "GatherNd": {
      const x = getParamValue("x", node, tensorMap, context);
      const indices = getParamValue("indices", node, tensorMap, context);
      return [ops.gatherND(x, indices)];
    }
    case "SparseToDense": {
      const indices = getParamValue("sparseIndices", node, tensorMap, context);
      const shape = getParamValue("outputShape", node, tensorMap, context);
      const sparseValues = getParamValue("sparseValues", node, tensorMap, context);
      const defaultValue = getParamValue("defaultValue", node, tensorMap, context);
      return [ops.sparseToDense(indices, sparseValues, shape, sparseValues.dtype === defaultValue.dtype ? defaultValue : ops.cast(defaultValue, sparseValues.dtype))];
    }
    case "TensorScatterUpdate": {
      const indices = getParamValue("indices", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      const tensor2 = getParamValue("tensor", node, tensorMap, context);
      return [ops.tensorScatterUpdate(tensor2, indices, values)];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js
var executeOp17 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "SparseFillEmptyRows": {
      const { outputIndices, outputValues, emptyRowIndicator, reverseIndexMap } = ops.sparse.sparseFillEmptyRows(getParamValue("indices", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("denseShape", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context));
      return [
        outputIndices,
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    }
    case "SparseReshape": {
      const { outputIndices, outputShape } = ops.sparse.sparseReshape(getParamValue("inputIndices", node, tensorMap, context), getParamValue("inputShape", node, tensorMap, context), getParamValue("newShape", node, tensorMap, context));
      return [outputIndices, outputShape];
    }
    case "SparseSegmentMean": {
      const outputData = ops.sparse.sparseSegmentMean(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
      return [outputData];
    }
    case "SparseSegmentSum": {
      const outputData = ops.sparse.sparseSegmentSum(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
      return [outputData];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js
var executeOp18 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "FFT": {
      return [ops.fft(getParamValue("x", node, tensorMap, context))];
    }
    case "IFFT": {
      return [ops.ifft(getParamValue("x", node, tensorMap, context))];
    }
    case "RFFT": {
      return [ops.rfft(getParamValue("x", node, tensorMap, context))];
    }
    case "IRFFT": {
      return [ops.irfft(getParamValue("x", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js
var executeOp19 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "StaticRegexReplace": {
      return [ops.string.staticRegexReplace(getParamValue("input", node, tensorMap, context), getParamValue("pattern", node, tensorMap, context), getParamValue("rewrite", node, tensorMap, context), getParamValue("replaceGlobal", node, tensorMap, context))];
    }
    case "StringNGrams": {
      const { nGrams, nGramsSplits } = ops.string.stringNGrams(getParamValue("data", node, tensorMap, context), getParamValue("dataSplits", node, tensorMap, context), getParamValue("separator", node, tensorMap, context), getParamValue("nGramWidths", node, tensorMap, context), getParamValue("leftPad", node, tensorMap, context), getParamValue("rightPad", node, tensorMap, context), getParamValue("padWidth", node, tensorMap, context), getParamValue("preserveShortSequences", node, tensorMap, context));
      return [nGrams, nGramsSplits];
    }
    case "StringSplit": {
      const { indices, values, shape } = ops.string.stringSplit(getParamValue("input", node, tensorMap, context), getParamValue("delimiter", node, tensorMap, context), getParamValue("skipEmpty", node, tensorMap, context));
      return [indices, values, shape];
    }
    case "StringToHashBucketFast": {
      const output = ops.string.stringToHashBucketFast(getParamValue("input", node, tensorMap, context), getParamValue("numBuckets", node, tensorMap, context));
      return [output];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js
var executeOp20 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
  switch (node.op) {
    case "Cast": {
      return [ops.cast(getParamValue("x", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "ExpandDims": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [ops.expandDims(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "Squeeze": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [ops.squeeze(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "Reshape": {
      return [ops.reshape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
    }
    case "EnsureShape": {
      return [ops.ensureShape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
    }
    case "MirrorPad": {
      return [ops.mirrorPad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("mode", node, tensorMap, context))];
    }
    case "PadV2":
    case "Pad": {
      return [ops.pad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("constantValue", node, tensorMap, context))];
    }
    case "SpaceToBatchND": {
      const blockShape = getParamValue("blockShape", node, tensorMap, context);
      const paddings = getParamValue("paddings", node, tensorMap, context);
      return [ops.spaceToBatchND(getParamValue("x", node, tensorMap, context), blockShape, paddings)];
    }
    case "BatchToSpaceND": {
      const blockShape = getParamValue("blockShape", node, tensorMap, context);
      const crops = getParamValue("crops", node, tensorMap, context);
      return [ops.batchToSpaceND(getParamValue("x", node, tensorMap, context), blockShape, crops)];
    }
    case "DepthToSpace": {
      const blockSize = getParamValue("blockSize", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      return [ops.depthToSpace(getParamValue("x", node, tensorMap, context), blockSize, dataFormat)];
    }
    case "BroadcastTo": {
      return [ops.broadcastTo(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
    }
    case "BroadcastArgs": {
      return [ops.broadcastArgs(getParamValue("s0", node, tensorMap, context), getParamValue("s1", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/operations/operation_executor.js
function executeOp21(node, tensorMap, context, resourceManager, tidy2 = tidy) {
  const value = ((node2, tensorMap2, context2) => {
    switch (node2.category) {
      case "arithmetic":
        return tidy2(() => executeOp(node2, tensorMap2, context2));
      case "basic_math":
        return tidy2(() => executeOp2(node2, tensorMap2, context2));
      case "control":
        return executeOp3(node2, tensorMap2, context2);
      case "convolution":
        return tidy2(() => executeOp4(node2, tensorMap2, context2));
      case "creation":
        return tidy2(() => executeOp5(node2, tensorMap2, context2));
      case "dynamic":
        return executeOp6(node2, tensorMap2, context2);
      case "evaluation":
        return tidy2(() => executeOp7(node2, tensorMap2, context2));
      case "image":
        return tidy2(() => executeOp10(node2, tensorMap2, context2));
      case "graph":
        return tidy2(() => executeOp8(node2, tensorMap2, context2));
      case "logical":
        return tidy2(() => executeOp11(node2, tensorMap2, context2));
      case "matrices":
        return tidy2(() => executeOp12(node2, tensorMap2, context2));
      case "normalization":
        return tidy2(() => executeOp13(node2, tensorMap2, context2));
      case "ragged":
        return tidy2(() => executeOp14(node2, tensorMap2, context2));
      case "reduction":
        return tidy2(() => executeOp15(node2, tensorMap2, context2));
      case "slice_join":
        return tidy2(() => executeOp16(node2, tensorMap2, context2));
      case "sparse":
        return tidy2(() => executeOp17(node2, tensorMap2, context2));
      case "spectral":
        return tidy2(() => executeOp18(node2, tensorMap2, context2));
      case "string":
        return tidy2(() => executeOp19(node2, tensorMap2, context2));
      case "transformation":
        return tidy2(() => executeOp20(node2, tensorMap2, context2));
      case "hash_table":
        return executeOp9(node2, tensorMap2, context2, resourceManager);
      case "custom":
        const opMapper = getRegisteredOp(node2.op);
        if (opMapper && opMapper.customExecutor) {
          return opMapper.customExecutor(new NodeValueImpl(node2, tensorMap2, context2));
        } else {
          throw TypeError(`Custom op ${node2.op} is not registered.`);
        }
      default:
        throw TypeError(`Unknown op '${node2.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`);
    }
  })(node, tensorMap, context);
  if (util_exports.isPromise(value)) {
    return value.then((data) => [].concat(data));
  }
  return [].concat(value);
}

// node_modules/@tensorflow/tfjs-converter/dist/executor/execution_context.js
var ExecutionContext = class {
  constructor(weightMap = {}, tensorArrayMap = {}, tensorListMap = {}, functionMap = {}, parseNodeNameCache) {
    this.weightMap = weightMap;
    this.tensorArrayMap = tensorArrayMap;
    this.tensorListMap = tensorListMap;
    this.functionMap = functionMap;
    this.parseNodeNameCache = parseNodeNameCache;
    this.rootContext = { id: 0, frameName: "", iterationId: 0 };
    this.contexts = [this.rootContext];
    this.lastId = 0;
    this.generateCurrentContextIds();
  }
  newFrame(id, frameName) {
    return { id, frameName, iterationId: 0 };
  }
  /**
   * Set the current context
   * @param contexts: ExecutionContextInfo[] the current path of execution
   * frames
   */
  set currentContext(contexts) {
    if (this.contexts !== contexts) {
      this.contexts = contexts;
      this.generateCurrentContextIds();
    }
  }
  get currentContext() {
    return this.contexts;
  }
  /**
   * Returns the current context in string format.
   */
  get currentContextId() {
    return this._currentContextIds[0];
  }
  /**
   * Returns the current context and all parent contexts in string format.
   * This allow access to the nodes in the current and parent frames.
   */
  get currentContextIds() {
    return this._currentContextIds;
  }
  generateCurrentContextIds() {
    const names = [];
    for (let i = 0; i < this.contexts.length - 1; i++) {
      const contexts = this.contexts.slice(0, this.contexts.length - i);
      names.push(this.contextIdforContexts(contexts));
    }
    names.push("");
    this._currentContextIds = names;
  }
  contextIdforContexts(contexts) {
    return contexts ? contexts.map((context) => context.id === 0 && context.iterationId === 0 ? "" : `${context.frameName}-${context.iterationId}`).join("/") : "";
  }
  /**
   * Enter a new frame, a new context is pushed on the current context list.
   * @param frameId new frame id
   */
  enterFrame(frameId) {
    if (this.contexts) {
      this.lastId++;
      this.contexts = this.contexts.slice();
      this.contexts.push(this.newFrame(this.lastId, frameId));
      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));
    }
  }
  /**
   * Exit the current frame, the last context is removed from the current
   * context list.
   */
  exitFrame() {
    if (this.contexts && this.contexts.length > 1) {
      this.contexts = this.contexts.slice();
      this.contexts.splice(-1);
      this.currentContextIds.shift();
    } else {
      throw new Error("Cannot exit frame, the context is empty");
    }
  }
  /**
   * Enter the next iteration of a loop, the iteration id of last context is
   * increased.
   */
  nextIteration() {
    if (this.contexts && this.contexts.length > 0) {
      this.contexts = this.contexts.slice();
      this.lastId++;
      const context = Object.assign({}, this.contexts[this.contexts.length - 1]);
      context.iterationId += 1;
      context.id = this.lastId;
      this.contexts.splice(-1, 1, context);
      this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
    } else {
      throw new Error("Cannot increase frame iteration, the context is empty");
    }
  }
  getWeight(name) {
    return this.weightMap[name];
  }
  addTensorArray(tensorArray) {
    this.tensorArrayMap[tensorArray.id] = tensorArray;
  }
  getTensorArray(id) {
    return this.tensorArrayMap[id];
  }
  addTensorList(tensorList) {
    this.tensorListMap[tensorList.id] = tensorList;
  }
  getTensorList(id) {
    return this.tensorListMap[id];
  }
  dispose(keepIds) {
    for (const key in this.tensorArrayMap) {
      this.tensorArrayMap[key].clearAndClose(keepIds);
    }
    for (const key in this.tensorListMap) {
      this.tensorListMap[key].clearAndClose(keepIds);
    }
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/executor/model_analysis.js
function getExecutionSubgraph(inputs, outputs, weightMap, initNodes) {
  const usedNodes = /* @__PURE__ */ new Set();
  const missingInputs = [];
  let dynamicNode = null;
  let syncInputs = null;
  const seen = /* @__PURE__ */ new Set();
  const inputNodeNames = new Set(Object.keys(inputs).map((name) => parseNodeName(name)[0]));
  initNodes = initNodes || [];
  const initNodeNames = new Set(initNodes.map((node) => parseNodeName(node.name)[0]));
  const frontier = [...outputs];
  while (frontier.length > 0) {
    const node = frontier.pop();
    if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {
      if (dynamicNode == null) {
        dynamicNode = node;
        syncInputs = dynamicNode.children.map((child) => child.name).filter((name) => usedNodes.has(name));
      }
    }
    usedNodes.add(node.name);
    if (weightMap[node.name] != null) {
      continue;
    }
    if (inputNodeNames.has(node.name)) {
      continue;
    }
    if (initNodeNames.has(node.name)) {
      continue;
    }
    if (node.inputs.length === 0) {
      missingInputs.push(node.name);
      continue;
    }
    node.inputs.forEach((input) => {
      if (seen.has(input.name)) {
        return;
      }
      seen.add(input.name);
      frontier.push(input);
    });
  }
  return { inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs };
}
function getNodesInTopologicalOrder(graph, executionInfo) {
  const { usedNodes, inputs } = executionInfo;
  const inputNodes = Object.keys(inputs).map((name) => parseNodeName(name)[0]).map((name) => graph.nodes[name]);
  const initNodes = graph.initNodes || [];
  const isUsed = (node) => usedNodes.has(typeof node === "string" ? node : node.name);
  function unique2(nodes) {
    return [...new Map(nodes.map((node) => [node.name, node])).values()];
  }
  const predefinedNodes = unique2([
    ...inputNodes,
    ...graph.weights,
    ...initNodes
  ]).filter(isUsed);
  const allNodes = unique2([
    ...predefinedNodes,
    ...Object.values(graph.nodes)
  ]).filter(isUsed);
  const nameToNode = new Map(allNodes.map((node) => [node.name, node]));
  const inCounts = {};
  for (const node of allNodes) {
    inCounts[node.name] = inCounts[node.name] || 0;
    for (const child of node.children) {
      if (!isUsed(child)) {
        inCounts[child.name] = Number.POSITIVE_INFINITY;
      }
      inCounts[child.name] = (inCounts[child.name] || 0) + 1;
    }
  }
  const frontier = Object.entries(inCounts).filter(([, inCount]) => inCount === 0).map(([name]) => name);
  const orderedNodeNames = [...frontier];
  while (frontier.length > 0) {
    const nodeName = frontier.pop();
    const node = nameToNode.get(nodeName);
    for (const child of node.children.filter(isUsed)) {
      if (--inCounts[child.name] === 0) {
        orderedNodeNames.push(child.name);
        frontier.push(child.name);
      }
    }
  }
  const orderedNodes = orderedNodeNames.map((name) => nameToNode.get(name));
  const filteredOrderedNodes = filterPredefinedReachableNodes(orderedNodes, predefinedNodes);
  validateNodesExecutionOrder(filteredOrderedNodes, predefinedNodes);
  return filteredOrderedNodes;
}
function filterPredefinedReachableNodes(orderedNodes, predefinedNodes) {
  const nameToNode = new Map(orderedNodes.map((node) => [node.name, node]));
  const stack2 = predefinedNodes.map((node) => node.name);
  const predefinedReachableNodeNames = new Set(stack2);
  while (stack2.length > 0) {
    const nodeName = stack2.pop();
    const node = nameToNode.get(nodeName);
    for (const child of node.children) {
      if (!nameToNode.has(child.name) || predefinedReachableNodeNames.has(child.name)) {
        continue;
      }
      predefinedReachableNodeNames.add(child.name);
      stack2.push(child.name);
    }
  }
  const filteredOrderedNodes = orderedNodes.filter((node) => predefinedReachableNodeNames.has(node.name));
  return filteredOrderedNodes;
}
var NodesExecutionOrderError = class extends Error {
  constructor(message) {
    super(`NodesExecutionOrderError: ${message}`);
  }
};
function validateNodesExecutionOrder(orderedNodes, predefinedNodes) {
  const nodeNameToOrder = new Map(orderedNodes.map((node, order) => [node.name, order]));
  const predefinedNodeNames = new Set(predefinedNodes.map((node) => node.name));
  const isPredefined = (node) => predefinedNodeNames.has(typeof node === "string" ? node : node.name);
  const willBeExecutedNodeNames = new Set(orderedNodes.map((node) => node.name));
  const willBeExecuted = (node) => willBeExecutedNodeNames.has(typeof node === "string" ? node : node.name);
  for (const node of orderedNodes) {
    for (const child of node.children.filter(willBeExecuted)) {
      if (!nodeNameToOrder.has(child.name)) {
        throw new NodesExecutionOrderError(`Child ${child.name} of node ${node.name} is unreachable.`);
      }
      if (nodeNameToOrder.get(node.name) > nodeNameToOrder.get(child.name)) {
        throw new NodesExecutionOrderError(`Node ${node.name} is scheduled to run after its child ${child.name}.`);
      }
    }
    if (!isPredefined(node)) {
      for (const input of node.inputs) {
        if (!nodeNameToOrder.has(input.name)) {
          throw new NodesExecutionOrderError(`Input ${input.name} of node ${node.name} is unreachable.`);
        }
        if (nodeNameToOrder.get(input.name) > nodeNameToOrder.get(node.name)) {
          throw new NodesExecutionOrderError(`Node ${node.name} is scheduled to run before its input ${input.name}.`);
        }
      }
    }
  }
}
function getNodeLiveUntilMap(orderedNodes) {
  const nodeNameToOrder = new Map(orderedNodes.map((node, order) => [node.name, order]));
  const INF_LIFE = Number.MAX_SAFE_INTEGER;
  const selfLifespans = orderedNodes.map((node, nodeOrder) => isControlFlow(node) ? INF_LIFE : nodeOrder);
  const getSelfLifeSpan = (node) => {
    const selfLife = selfLifespans[nodeNameToOrder.get(node.name)];
    if (selfLife == null) {
      return -1;
    }
    return selfLife;
  };
  const liveUntilOrders = orderedNodes.map((node, nodeOrder) => {
    return node.children.map(getSelfLifeSpan).reduce((a, b) => Math.max(a, b), selfLifespans[nodeOrder]);
  });
  const liveUntilMap = /* @__PURE__ */ new Map();
  for (let nodeOrder = 0; nodeOrder < orderedNodes.length; ++nodeOrder) {
    const liveUntilOrder = liveUntilOrders[nodeOrder];
    if (liveUntilOrder === INF_LIFE) {
      continue;
    }
    const node = orderedNodes[nodeOrder];
    const liveUntilNode = orderedNodes[liveUntilOrder];
    if (!liveUntilMap.has(liveUntilNode.name)) {
      liveUntilMap.set(liveUntilNode.name, []);
    }
    liveUntilMap.get(liveUntilNode.name).push(node);
  }
  return liveUntilMap;
}
var CONTROL_FLOW_OPS = /* @__PURE__ */ new Set([
  "Switch",
  "Merge",
  "Enter",
  "Exit",
  "NextIteration",
  "StatelessIf",
  "StatelessWhile",
  "if",
  "While"
]);
var DYNAMIC_SHAPE_OPS = /* @__PURE__ */ new Set([
  "NonMaxSuppressionV2",
  "NonMaxSuppressionV3",
  "NonMaxSuppressionV5",
  "Where"
]);
var HASH_TABLE_OPS = /* @__PURE__ */ new Set([
  "HashTable",
  "HashTableV2",
  "LookupTableImport",
  "LookupTableImportV2",
  "LookupTableFind",
  "LookupTableFindV2",
  "LookupTableSize",
  "LookupTableSizeV2"
]);
function isControlFlow(node) {
  return CONTROL_FLOW_OPS.has(node.op);
}
function isDynamicShape(node) {
  return DYNAMIC_SHAPE_OPS.has(node.op);
}
function isHashTable(node) {
  return HASH_TABLE_OPS.has(node.op);
}

// node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js
var GraphExecutor = class _GraphExecutor {
  get weightIds() {
    return this.parent ? this.parent.weightIds : this._weightIds;
  }
  get functionExecutorMap() {
    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
  }
  get weightMap() {
    return this.parent ? this.parent.weightMap : this._weightMap;
  }
  set weightMap(weightMap) {
    const weightIds = Object.keys(weightMap).map((key) => weightMap[key].map((tensor2) => tensor2.id));
    this._weightIds = [].concat(...weightIds);
    this._weightMap = weightMap;
  }
  /**
   * Set `ResourceManager` shared by executors of a model.
   * @param resourceManager: `ResourceManager` of the `GraphModel`.
   */
  set resourceManager(resourceManager) {
    this._resourceManager = resourceManager;
  }
  get inputs() {
    return this._inputs.map((node) => {
      return {
        name: node.name,
        shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
        dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
      };
    });
  }
  get outputs() {
    return this._outputs.map((node) => {
      return {
        name: node.name,
        shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
        dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
      };
    });
  }
  get inputNodes() {
    return this._inputs.map((node) => node.signatureKey || node.name);
  }
  get outputNodes() {
    return this._outputs.map((node) => {
      const name = node.signatureKey || node.name;
      return node.defaultOutput ? `${name}:${node.defaultOutput}` : name;
    });
  }
  get functions() {
    return Object.keys(this._functions).reduce((map, key) => {
      map[key] = this._functions[key].signature;
      return map;
    }, {});
  }
  /**
   *
   * @param graph Graph the model or function graph to be executed.
   * @param parent When building function exector you need to set the parent
   * executor. Since the weights and function executor maps are set at parant
   * level, that function executor can access the function maps and weight maps
   * through the parent.
   */
  constructor(graph, parent) {
    this.graph = graph;
    this.parent = parent;
    this.compiledMap = /* @__PURE__ */ new Map();
    this.parseNodeNameCache = /* @__PURE__ */ new Map();
    this._weightMap = {};
    this.SEPARATOR = ",";
    this._functions = {};
    this._functionExecutorMap = {};
    this.keepIntermediateTensors = false;
    this._outputs = graph.outputs;
    this._inputs = graph.inputs;
    this._initNodes = graph.initNodes;
    this._signature = graph.signature;
    this._functions = graph.functions;
    if (graph.functions != null) {
      Object.keys(graph.functions).forEach((name) => {
        this._functionExecutorMap[name] = new _GraphExecutor(graph.functions[name], this);
      });
    }
  }
  getCompilationKey(inputs, outputs) {
    const sortedInputs = inputs.map((node) => node.name).sort();
    const sortedOutputs = outputs.map((node) => node.name).sort();
    return sortedInputs.join(this.SEPARATOR) + "--" + sortedOutputs.join(this.SEPARATOR);
  }
  /**
   * Compiles the inference graph and returns the minimal set of nodes that are
   * required for execution, in the correct execution order.
   * @returns {Object} compilation The compile result.
   * @returns {Node[]} compilation.orderedNodes Nodes in the correct execution
   *     order.
   * @returns {Map<string, Node[]>} compilation.nodeLiveUntilMap A map from node
   *     to disposable nodes after its execution. That is, for a node `x`,
   *     `nodeLiveUntilMap[x]` indicates all nodes whose intermediate
   *     tensors should be disposed after `x` is executed.
   */
  compile(inputs, outputs) {
    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);
    const { missingInputs, dynamicNode, syncInputs } = executionInfo;
    if (dynamicNode != null) {
      throw new Error(`This execution contains the node '${dynamicNode.name}', which has the dynamic op '${dynamicNode.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${syncInputs}]`);
    }
    if (missingInputs.length > 0) {
      const outNames = outputs.map((n) => n.name);
      const inNames = Object.keys(inputs);
      throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs [${inNames}]. Missing the following inputs: [${missingInputs}]`);
    }
    const orderedNodes = getNodesInTopologicalOrder(this.graph, executionInfo);
    const nodeLiveUntilMap = getNodeLiveUntilMap(orderedNodes);
    return { orderedNodes, nodeLiveUntilMap };
  }
  cloneAndKeepTensor(tensor2) {
    if (tensor2 == null) {
      return null;
    }
    const clone2 = tensor2.clone();
    keep(clone2);
    return clone2;
  }
  cloneTensorList(tensors) {
    if (!tensors) {
      return null;
    }
    const clonedTensor = tensors.map((tensor2) => {
      return this.cloneAndKeepTensor(tensor2);
    });
    return clonedTensor;
  }
  cloneTensorMap(tensorsMap) {
    return Object.fromEntries(Object.entries(tensorsMap).map(([name, tensorsList]) => {
      return [name, this.cloneTensorList(tensorsList)];
    }));
  }
  /**
   * Executes the inference for given input tensors.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs Optional. output node name from the Tensorflow model, if
   * no outputs are specified, the default outputs of the model would be used.
   * You can inspect intermediate nodes of the model by adding them to the
   * outputs array.
   */
  execute(inputs, outputs) {
    this.disposeIntermediateTensors();
    inputs = this.mapInputs(inputs);
    const names = Object.keys(inputs).sort();
    this.checkInputs(inputs);
    this.checkInputShapeAndType(inputs);
    outputs = this.mapOutputs(outputs);
    this.checkOutputs(outputs);
    const inputNodes = names.map((name) => this.graph.nodes[parseNodeName(name)[0]]);
    const outputNodeNames = outputs.map((name) => parseNodeName(name)[0]);
    const outputNodeNameSet = new Set(outputNodeNames);
    let outputNodes = outputNodeNames.map((name) => this.graph.nodes[name]);
    if (outputNodes.length === 0) {
      outputNodes = this._outputs;
    }
    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);
    let compilation = this.compiledMap.get(compilationKey);
    if (compilation == null) {
      compilation = this.compile(inputs, outputNodes);
      this.compiledMap.set(compilationKey, compilation);
    }
    try {
      this.keepIntermediateTensors = env().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (e) {
      this.keepIntermediateTensors = false;
      console.warn(e.message);
    }
    const tensorArrayMap = {};
    const tensorListMap = {};
    return tidy(() => {
      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap, this.parseNodeNameCache);
      const tensorsMap = Object.assign({}, this.weightMap);
      if (this.keepIntermediateTensors) {
        this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);
      }
      Object.keys(inputs).forEach((name) => {
        const [nodeName, index] = parseNodeName(name, context);
        const tensors = [];
        tensors[index] = inputs[name];
        tensorsMap[nodeName] = tensors;
        if (this.keepIntermediateTensors) {
          this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);
        }
      });
      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
      const { orderedNodes, nodeLiveUntilMap } = compilation;
      for (const node of orderedNodes) {
        if (tensorsMap[node.name]) {
          continue;
        }
        const tensors = executeOp21(node, tensorsMap, context, this._resourceManager);
        if (util_exports.isPromise(tensors)) {
          throw new Error(`The execution of the op '${node.op}' returned a promise. Please use model.executeAsync() instead.`);
        }
        tensorsMap[node.name] = tensors;
        if (this.keepIntermediateTensors) {
          this.clonedTensorsMap[node.name] = this.cloneTensorList(tensors);
        }
        this.checkTensorForDisposalWithNodeLiveUntilInfo(node, tensorsMap, context, tensorsToKeep, outputNodeNameSet, nodeLiveUntilMap.get(node.name));
      }
      if (this.parent == null) {
        context.dispose(tensorsToKeep);
      }
      return outputs.map((name) => getTensor(name, tensorsMap, context));
    });
  }
  getFrozenTensorIds(tensorMap) {
    const ids = [].concat.apply([], Object.keys(tensorMap).map((key) => tensorMap[key]).map((tensors) => tensors.map((tensor2) => tensor2.id)));
    return new Set(ids);
  }
  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount) {
    if (isControlFlow(node) || outputNodeNameSet.has(nodeName)) {
      return;
    }
    for (const tensor2 of tensorMap[nodeName]) {
      if (tensor2 == null) {
        continue;
      }
      intermediateTensorConsumerCount[tensor2.id] = (intermediateTensorConsumerCount[tensor2.id] || 0) + node.children.length;
    }
    for (const input of node.inputs) {
      if (isControlFlow(input)) {
        continue;
      }
      const tensors = getTensorsForCurrentContext(input.name, tensorMap, context);
      if (tensors == null) {
        continue;
      }
      for (const tensor2 of tensors) {
        if (!tensor2 || tensor2.kept || tensorsToKeep.has(tensor2.id)) {
          continue;
        }
        const count = intermediateTensorConsumerCount[tensor2.id];
        if (count === 1) {
          tensor2.dispose();
          delete intermediateTensorConsumerCount[tensor2.id];
        } else if (count != null) {
          intermediateTensorConsumerCount[tensor2.id]--;
        }
      }
    }
  }
  checkTensorForDisposalWithNodeLiveUntilInfo(node, tensorMap, context, tensorsToKeep, outputNodeNameSet, liveUntilNodes) {
    function isNonDisposableNode(node2) {
      return isControlFlow(node2) || outputNodeNameSet.has(node2.name);
    }
    if (isControlFlow(node) || liveUntilNodes == null) {
      return;
    }
    for (const nodeToDispose of liveUntilNodes) {
      if (isNonDisposableNode(nodeToDispose)) {
        continue;
      }
      const tensors = getTensorsForCurrentContext(nodeToDispose.name, tensorMap, context);
      for (const tensor2 of tensors) {
        if (!tensor2 || tensor2.kept || tensorsToKeep.has(tensor2.id)) {
          continue;
        }
        tensor2.dispose();
      }
    }
  }
  /**
   * Executes the inference for given input tensors in Async fashion.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs output node name from the Tensorflow model, if no outputs
   * are specified, the default outputs of the model would be used. You can
   * inspect intermediate nodes of the model by adding them to the outputs
   * array.
   */
  async executeAsync(inputs, outputs) {
    return this._executeAsync(inputs, outputs);
  }
  disposeIntermediateTensors() {
    if (!this.clonedTensorsMap) {
      return;
    }
    Object.values(this.clonedTensorsMap).forEach((tensorsList) => {
      for (const tensor2 of tensorsList) {
        if (tensor2 && !tensor2.isDisposed) {
          tensor2.dispose();
        }
      }
    });
    this.clonedTensorsMap = null;
  }
  getIntermediateTensors() {
    return this.clonedTensorsMap;
  }
  /**
   * Executes the inference for given input tensors in Async fashion.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs Optional. output node name from the Tensorflow model,
   * if no outputs are specified, the default outputs of the model would be
   * used. You can inspect intermediate nodes of the model by adding them to
   * the outputs array.
   * @param isFunctionExecution Optional. Flag for executing a function.
   * @param tensorArrayMap Optional, global TensorArray map by id. Used for
   * function execution.
   * @param tensorArrayMap Optional global TensorList map by id. Used for
   * function execution.
   */
  async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {
    this.disposeIntermediateTensors();
    if (!isFunctionExecution) {
      inputs = this.mapInputs(inputs);
      this.checkInputs(inputs);
      this.checkInputShapeAndType(inputs);
      outputs = this.mapOutputs(outputs);
      this.checkOutputs(outputs);
    }
    try {
      this.keepIntermediateTensors = env().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (e) {
      this.keepIntermediateTensors = false;
      console.warn(e.message);
    }
    const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap, this.parseNodeNameCache);
    if (this.keepIntermediateTensors) {
      this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);
    }
    const tensorsMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);
    const results = outputs.map((name) => getTensor(name, tensorsMap, context));
    const outputIds = results.map((t2) => t2.id);
    const inputIds = Object.keys(inputs).map((name) => inputs[name].id);
    const keepIds = /* @__PURE__ */ new Set([...outputIds, ...inputIds, ...this.weightIds]);
    Object.values(tensorsMap).forEach((tensorsList) => {
      tensorsList.forEach((tensor2) => {
        if (tensor2 && !tensor2.isDisposed && !keepIds.has(tensor2.id)) {
          tensor2.dispose();
        }
      });
    });
    if (this.parent == null) {
      context.dispose(keepIds);
    }
    return results;
  }
  async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {
    const mappedInputs = inputs.reduce((map, tensor2, index) => {
      map[this.inputs[index].name] = tensor2;
      return map;
    }, {});
    return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);
  }
  /**
   * When there are control flow nodes in the graph, the graph execution use
   * ExecutionContext to keep track of the frames and loop iterators.
   * @param inputs placeholder tensors for the graph.
   * @param context the execution context object for current execution.
   * @param outputNames Optional. output node name from the Tensorflow model,
   * if no outputs are specified, the default outputs of the model would be
   * used. You can inspect intermediate nodes of the model by adding them to
   * the outputs array.
   * @param isFunctionExecution Flag for executing a function.
   */
  async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {
    const names = Object.keys(inputs);
    const inputNodes = names.map((name) => this.graph.nodes[parseNodeName(name)[0]]);
    const outputNodeNames = outputNames.map((name) => parseNodeName(name)[0]);
    const outputNodeNameSet = new Set(outputNodeNames);
    let outputNodes = outputNodeNames.map((name) => this.graph.nodes[name]);
    if (outputNodes.length === 0) {
      outputNodes = this._outputs;
    }
    const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);
    const stack2 = [
      ...inputNodes,
      ...this.graph.weights,
      ...this._initNodes || []
    ].map((node) => {
      return { node, contexts: context.currentContext };
    });
    const tensorsMap = Object.assign({}, this.weightMap);
    Object.keys(inputs).forEach((name) => {
      const [nodeName, index] = parseNodeName(name);
      const tensors = [];
      tensors[index] = inputs[name];
      tensorsMap[nodeName] = tensors;
    });
    const intermediateTensorConsumerCount = {};
    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
    const added = {};
    while (stack2.length > 0) {
      const promises = this.processStack(inputNodes, stack2, context, tensorsMap, added, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount, usedNodes);
      await Promise.all(promises);
    }
    if (dynamicNode == null && !isFunctionExecution) {
      console.warn(`This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.`);
    }
    const missingOutputs = outputNodes.filter((node) => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map((node) => node.name);
    if (missingOutputs.length > 0) {
      let alternativeMsg = "";
      if (dynamicNode != null) {
        alternativeMsg = `Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${syncInputs}]`;
      }
      throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided inputs [${names}]. Consider providing the following inputs: [${missingInputs}]. ${alternativeMsg}`);
    }
    return tensorsMap;
  }
  processStack(inputNodes, stack2, context, tensorMap, added, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount, usedNodes) {
    const promises = [];
    while (stack2.length > 0) {
      const item = stack2.pop();
      context.currentContext = item.contexts;
      let nodeName = "";
      if (item.node.op === "Enter" && getParamValue("isConstant", item.node, tensorMap, context)) {
        [nodeName] = getNodeNameAndIndex(item.node.name, context);
      }
      if (tensorMap[item.node.name] == null) {
        const tensors = executeOp21(item.node, tensorMap, context, this._resourceManager);
        if (!nodeName) {
          [nodeName] = getNodeNameAndIndex(item.node.name, context);
        }
        const currentContext = context.currentContext;
        if (util_exports.isPromise(tensors)) {
          promises.push(tensors.then((t2) => {
            tensorMap[nodeName] = t2;
            if (this.keepIntermediateTensors) {
              this.clonedTensorsMap[nodeName] = this.cloneTensorList(t2);
            }
            context.currentContext = currentContext;
            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount);
            this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
            return t2;
          }));
        } else {
          tensorMap[nodeName] = tensors;
          if (this.keepIntermediateTensors) {
            this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);
          }
          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount);
          this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
        }
      } else {
        this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
      }
    }
    return promises;
  }
  processChildNodes(node, stack2, context, tensorMap, added, usedNodes) {
    node.children.forEach((childNode) => {
      const [nodeName] = getNodeNameAndIndex(childNode.name, context);
      if (added[nodeName] || !usedNodes.has(childNode.name)) {
        return;
      }
      if (childNode.op === "Merge") {
        if (childNode.inputNames.some((name) => {
          return !!getTensor(name, tensorMap, context);
        })) {
          added[nodeName] = true;
          stack2.push({ contexts: context.currentContext, node: childNode });
        }
      } else if (childNode.inputNames.every((name) => {
        return !!getTensor(name, tensorMap, context);
      })) {
        added[nodeName] = true;
        stack2.push({ contexts: context.currentContext, node: childNode });
      }
    });
  }
  /**
   * Releases the memory used by the weight tensors.
   */
  dispose() {
    Object.keys(this.weightMap).forEach((key) => this.weightMap[key].forEach((tensor2) => tensor2.dispose()));
  }
  checkInputShapeAndType(inputs) {
    Object.keys(inputs).forEach((name) => {
      const input = inputs[name];
      const [nodeName] = parseNodeName(name);
      const node = this.graph.nodes[nodeName];
      if (node.attrParams["shape"] && node.attrParams["shape"].value) {
        const shape = node.attrParams["shape"].value;
        const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);
        util_exports.assert(match, () => `The shape of dict['${node.name}'] provided in model.execute(dict) must be [${shape}], but was [${input.shape}]`);
      }
      if (node.attrParams["dtype"] && node.attrParams["dtype"].value) {
        util_exports.assert(input.dtype === node.attrParams["dtype"].value, () => `The dtype of dict['${node.name}'] provided in model.execute(dict) must be ${node.attrParams["dtype"].value}, but was ${input.dtype}`);
      }
    });
  }
  mapInputs(inputs) {
    var _a, _b;
    const result = {};
    for (const inputName in inputs) {
      const tensor2 = (_b = (_a = this._signature) === null || _a === void 0 ? void 0 : _a.inputs) === null || _b === void 0 ? void 0 : _b[inputName];
      if (tensor2 != null) {
        result[tensor2.name] = inputs[inputName];
      } else {
        result[inputName] = inputs[inputName];
      }
    }
    return result;
  }
  checkInputs(inputs) {
    const notInGraph = Object.keys(inputs).filter((name) => {
      const [nodeName] = parseNodeName(name);
      return this.graph.nodes[nodeName] == null;
    });
    if (notInGraph.length > 0) {
      throw new Error(`The dict provided in model.execute(dict) has keys: [${notInGraph}] that are not part of graph`);
    }
  }
  mapOutputs(outputs) {
    return outputs.map((name) => {
      var _a, _b;
      const tensor2 = (_b = (_a = this._signature) === null || _a === void 0 ? void 0 : _a.outputs) === null || _b === void 0 ? void 0 : _b[name];
      if (tensor2 != null) {
        return tensor2.name;
      }
      return name;
    }, {});
  }
  checkOutputs(outputs) {
    outputs.forEach((name) => {
      const [normalizedName] = parseNodeName(name);
      if (!this.graph.nodes[normalizedName]) {
        throw new Error(`The output '${name}' is not found in the graph`);
      }
    });
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/executor/resource_manager.js
var ResourceManager = class {
  constructor(hashTableNameToHandle = {}, hashTableMap = {}) {
    this.hashTableNameToHandle = hashTableNameToHandle;
    this.hashTableMap = hashTableMap;
  }
  /**
   * Register a `HashTable` in the resource manager.
   *
   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,
   * where id is the table handle tensor's id.
   *
   * @param name Op node name that creates the `HashTable`.
   * @param hashTable The `HashTable` to be added to resource manager.
   */
  addHashTable(name, hashTable) {
    this.hashTableNameToHandle[name] = hashTable.handle;
    this.hashTableMap[hashTable.id] = hashTable;
  }
  /**
   * Get the table handle by node name.
   * @param name Op node name that creates the `HashTable`. This name is also
   *     used in the inputs list of lookup and import `HashTable` ops.
   */
  getHashTableHandleByName(name) {
    return this.hashTableNameToHandle[name];
  }
  /**
   * Get the actual `HashTable` by its handle tensor's id.
   * @param id The id of the handle tensor.
   */
  getHashTableById(id) {
    return this.hashTableMap[id];
  }
  /**
   * Dispose `ResourceManager`, including its hashTables and tensors in them.
   */
  dispose() {
    for (const key in this.hashTableMap) {
      this.hashTableMap[key].clearAndClose();
      delete this.hashTableMap[key];
    }
    for (const name in this.hashTableNameToHandle) {
      this.hashTableNameToHandle[name].dispose();
      delete this.hashTableNameToHandle[name];
    }
  }
};

// node_modules/@tensorflow/tfjs-converter/dist/executor/graph_model.js
var TFHUB_SEARCH_PARAM = "?tfjs-format=file";
var DEFAULT_MODEL_NAME = "model.json";
var GraphModel = class {
  // Returns the version information for the tensorflow model GraphDef.
  get modelVersion() {
    return this.version;
  }
  get inputNodes() {
    return this.executor.inputNodes;
  }
  get outputNodes() {
    return this.executor.outputNodes;
  }
  get inputs() {
    return this.executor.inputs;
  }
  get outputs() {
    return this.executor.outputs;
  }
  get weights() {
    return this.executor.weightMap;
  }
  get metadata() {
    return this.artifacts.userDefinedMetadata;
  }
  get modelSignature() {
    return this.signature;
  }
  get modelStructuredOutputKeys() {
    return this.structuredOutputKeys;
  }
  /**
   * @param modelUrl url for the model, or an `io.IOHandler`.
   * @param weightManifestUrl url for the weight file generated by
   * scripts/convert.py script.
   * @param requestOption options for Request, which allows to send credentials
   * and custom headers.
   * @param onProgress Optional, progress callback function, fired periodically
   * before the load is completed.
   */
  constructor(modelUrl, loadOptions = {}, tfio = io_exports) {
    this.modelUrl = modelUrl;
    this.loadOptions = loadOptions;
    this.version = "n/a";
    this.io = tfio;
    if (loadOptions == null) {
      this.loadOptions = {};
    }
    this.resourceManager = new ResourceManager();
  }
  findIOHandler() {
    const path = this.modelUrl;
    if (path.load != null) {
      this.handler = path;
    } else if (this.loadOptions.requestInit != null) {
      this.handler = this.io.browserHTTPRequest(path, this.loadOptions);
    } else {
      const handlers = this.io.getLoadHandlers(path, this.loadOptions);
      if (handlers.length === 0) {
        handlers.push(this.io.browserHTTPRequest(path, this.loadOptions));
      } else if (handlers.length > 1) {
        throw new Error(`Found more than one (${handlers.length}) load handlers for URL '${[path]}'`);
      }
      this.handler = handlers[0];
    }
  }
  /**
   * Loads the model and weight files, construct the in memory weight map and
   * compile the inference graph.
   */
  load() {
    this.findIOHandler();
    if (this.handler.load == null) {
      throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    }
    const loadResult = this.handler.load();
    if (util_exports.isPromise(loadResult)) {
      return loadResult.then((artifacts) => {
        if (artifacts.getWeightStream == null) {
          return this.loadSync(artifacts);
        }
        return this.loadStreaming(artifacts);
      });
    }
    return this.loadSync(loadResult);
  }
  /**
   * Synchronously construct the in memory weight map and
   * compile the inference graph.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  loadSync(artifacts) {
    const weightMap = this.io.decodeWeights(artifacts.weightData, artifacts.weightSpecs);
    return this.loadWithWeightMap(artifacts, weightMap);
  }
  async loadStreaming(artifacts) {
    if (artifacts.getWeightStream == null) {
      throw new Error("Model artifacts missing streamWeights function");
    }
    const weightMap = await decodeWeightsStream(artifacts.getWeightStream(), artifacts.weightSpecs);
    return this.loadWithWeightMap(artifacts, weightMap);
  }
  loadWithWeightMap(artifacts, weightMap) {
    this.artifacts = artifacts;
    const graph = this.artifacts.modelTopology;
    let signature = this.artifacts.signature;
    if (this.artifacts.userDefinedMetadata != null) {
      const metadata = this.artifacts.userDefinedMetadata;
      if (metadata.signature != null) {
        signature = metadata.signature;
      }
      if (metadata.structuredOutputKeys != null) {
        this.structuredOutputKeys = metadata.structuredOutputKeys;
      }
    }
    this.signature = signature;
    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;
    this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(graph, this.signature));
    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);
    this.executor.resourceManager = this.resourceManager;
    if (artifacts.modelInitializer != null && artifacts.modelInitializer.node != null) {
      const initializer = OperationMapper.Instance.transformGraph(artifacts.modelInitializer);
      this.initializer = new GraphExecutor(initializer);
      this.initializer.weightMap = this.executor.weightMap;
      this.initializer.resourceManager = this.resourceManager;
      this.initializerSignature = artifacts.initializerSignature;
    }
    return true;
  }
  /**
   * Save the configuration and/or weights of the GraphModel.
   *
   * An `IOHandler` is an object that has a `save` method of the proper
   * signature defined. The `save` method manages the storing or
   * transmission of serialized data ("artifacts") that represent the
   * model's topology and weights onto or via a specific medium, such as
   * file downloads, local storage, IndexedDB in the web browser and HTTP
   * requests to a server. TensorFlow.js provides `IOHandler`
   * implementations for a number of frequently used saving mediums, such as
   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
   * for more details.
   *
   * This method also allows you to refer to certain types of `IOHandler`s
   * as URL-like string shortcuts, such as 'localstorage://' and
   * 'indexeddb://'.
   *
   * Example 1: Save `model`'s topology and weights to browser [local
   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
   * then load it back.
   *
   * ```js
   * const modelUrl =
   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';
   * const model = await tf.loadGraphModel(modelUrl);
   * const zeros = tf.zeros([1, 224, 224, 3]);
   * model.predict(zeros).print();
   *
   * const saveResults = await model.save('localstorage://my-model-1');
   *
   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');
   * console.log('Prediction from loaded model:');
   * model.predict(zeros).print();
   * ```
   *
   * @param handlerOrURL An instance of `IOHandler` or a URL-like,
   * scheme-based string shortcut for `IOHandler`.
   * @param config Options for saving the model.
   * @returns A `Promise` of `SaveResult`, which summarizes the result of
   * the saving, such as byte sizes of the saved artifacts for the model's
   *   topology and weight values.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async save(handlerOrURL, config) {
    if (typeof handlerOrURL === "string") {
      const handlers = this.io.getSaveHandlers(handlerOrURL);
      if (handlers.length === 0) {
        throw new Error(`Cannot find any save handlers for URL '${handlerOrURL}'`);
      } else if (handlers.length > 1) {
        throw new Error(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);
      }
      handlerOrURL = handlers[0];
    }
    if (handlerOrURL.save == null) {
      throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    }
    return handlerOrURL.save(this.artifacts);
  }
  addStructuredOutputNames(outputTensors) {
    if (this.structuredOutputKeys) {
      const outputTensorsArray = outputTensors instanceof Tensor ? [outputTensors] : outputTensors;
      const outputTensorMap = {};
      outputTensorsArray.forEach((outputTensor, i) => outputTensorMap[this.structuredOutputKeys[i]] = outputTensor);
      return outputTensorMap;
    }
    return outputTensors;
  }
  /**
   * Execute the inference for the input tensors.
   *
   * @param input The input tensors, when there is single input for the model,
   * inputs param should be a `tf.Tensor`. For models with multiple inputs,
   * inputs params should be in either `tf.Tensor`[] if the input order is
   * fixed, or otherwise NamedTensorMap format.
   *
   * For model with multiple inputs, we recommend you use NamedTensorMap as the
   * input type, if you use `tf.Tensor`[], the order of the array needs to
   * follow the
   * order of inputNodes array. @see {@link GraphModel.inputNodes}
   *
   * You can also feed any intermediate nodes using the NamedTensorMap as the
   * input type. For example, given the graph
   *    InputNode => Intermediate => OutputNode,
   * you can execute the subgraph Intermediate => OutputNode by calling
   *    model.execute('IntermediateNode' : tf.tensor(...));
   *
   * This is useful for models that uses tf.dynamic_rnn, where the intermediate
   * state needs to be fed manually.
   *
   * For batch inference execution, the tensors for each input need to be
   * concatenated together. For example with mobilenet, the required input shape
   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
   * If we are provide a batched data of 100 images, the input tensor should be
   * in the shape of [100, 244, 244, 3].
   *
   * @param config Prediction configuration for specifying the batch size.
   * Currently the batch size option is ignored for graph model.
   *
   * @returns Inference result tensors. If the model is converted and it
   * originally had structured_outputs in tensorflow, then a NamedTensorMap
   * will be returned matching the structured_outputs. If no structured_outputs
   * are present, the output will be single `tf.Tensor` if the model has single
   * output node, otherwise Tensor[].
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(inputs, config) {
    const outputTensors = this.execute(inputs, this.outputNodes);
    return this.addStructuredOutputNames(outputTensors);
  }
  /**
   * Execute the inference for the input tensors in async fashion, use this
   * method when your model contains control flow ops.
   *
   * @param input The input tensors, when there is single input for the model,
   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
   * inputs params should be in either `tf.Tensor`[] if the input order is
   * fixed, or otherwise NamedTensorMap format.
   *
   * For model with multiple inputs, we recommend you use NamedTensorMap as the
   * input type, if you use `tf.Tensor`[], the order of the array needs to
   * follow the
   * order of inputNodes array. @see {@link GraphModel.inputNodes}
   *
   * You can also feed any intermediate nodes using the NamedTensorMap as the
   * input type. For example, given the graph
   *    InputNode => Intermediate => OutputNode,
   * you can execute the subgraph Intermediate => OutputNode by calling
   *    model.execute('IntermediateNode' : tf.tensor(...));
   *
   * This is useful for models that uses tf.dynamic_rnn, where the intermediate
   * state needs to be fed manually.
   *
   * For batch inference execution, the tensors for each input need to be
   * concatenated together. For example with mobilenet, the required input shape
   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
   * If we are provide a batched data of 100 images, the input tensor should be
   * in the shape of [100, 244, 244, 3].
   *
   * @param config Prediction configuration for specifying the batch size.
   * Currently the batch size option is ignored for graph model.
   *
   * @returns A Promise of inference result tensors. If the model is converted
   * and it originally had structured_outputs in tensorflow, then a
   * NamedTensorMap will be returned matching the structured_outputs. If no
   * structured_outputs are present, the output will be single `tf.Tensor` if
   * the model has single output node, otherwise Tensor[].
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async predictAsync(inputs, config) {
    const outputTensors = await this.executeAsync(inputs, this.outputNodes);
    return this.addStructuredOutputNames(outputTensors);
  }
  normalizeInputs(inputs) {
    var _a;
    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {
      const signatureInputs = (_a = this.signature) === null || _a === void 0 ? void 0 : _a.inputs;
      if (signatureInputs != null) {
        for (const input in signatureInputs) {
          const tensor2 = signatureInputs[input];
          if (tensor2.resourceId != null) {
            inputs[input] = this.resourceIdToCapturedInput[tensor2.resourceId];
          }
        }
      }
      return inputs;
    }
    inputs = Array.isArray(inputs) ? inputs : [inputs];
    const numCapturedInputs = Object.keys(this.resourceIdToCapturedInput).length;
    if (inputs.length + numCapturedInputs !== this.inputNodes.length) {
      throw new Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length - numCapturedInputs} non-resource placeholders, while there are ${inputs.length} input tensors provided.`);
    }
    let inputIndex = 0;
    return this.inputNodes.reduce((map, inputName) => {
      var _a2, _b, _c;
      const resourceId = (_c = (_b = (_a2 = this.signature) === null || _a2 === void 0 ? void 0 : _a2.inputs) === null || _b === void 0 ? void 0 : _b[inputName]) === null || _c === void 0 ? void 0 : _c.resourceId;
      if (resourceId != null) {
        map[inputName] = this.resourceIdToCapturedInput[resourceId];
      } else {
        map[inputName] = inputs[inputIndex++];
      }
      return map;
    }, {});
  }
  normalizeOutputs(outputs) {
    outputs = outputs || this.outputNodes;
    return !Array.isArray(outputs) ? [outputs] : outputs;
  }
  executeInitializerGraph() {
    if (this.initializer == null) {
      return [];
    }
    if (this.initializerSignature == null) {
      return this.initializer.execute({}, []);
    } else {
      return this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
    }
  }
  async executeInitializerGraphAsync() {
    if (this.initializer == null) {
      return [];
    }
    if (this.initializerSignature == null) {
      return this.initializer.executeAsync({}, []);
    } else {
      return this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs));
    }
  }
  setResourceIdToCapturedInput(outputs) {
    this.resourceIdToCapturedInput = {};
    if (this.initializerSignature) {
      const signatureOutputs = this.initializerSignature.outputs;
      const outputNames = Object.keys(signatureOutputs);
      for (let i = 0; i < outputNames.length; i++) {
        const outputName = outputNames[i];
        const tensorInfo = signatureOutputs[outputName];
        this.resourceIdToCapturedInput[tensorInfo.resourceId] = outputs[i];
      }
    }
  }
  /**
   * Executes inference for the model for given input tensors.
   * @param inputs tensor, tensor array or tensor map of the inputs for the
   * model, keyed by the input node names.
   * @param outputs output node name from the TensorFlow model, if no
   * outputs are specified, the default outputs of the model would be used.
   * You can inspect intermediate nodes of the model by adding them to the
   * outputs array.
   *
   * @returns A single tensor if provided with a single output or no outputs
   * are provided and there is only one default output, otherwise return a
   * tensor array. The order of the tensor array is the same as the outputs
   * if provided, otherwise the order of outputNodes attribute of the model.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  execute(inputs, outputs) {
    if (this.resourceIdToCapturedInput == null) {
      this.setResourceIdToCapturedInput(this.executeInitializerGraph());
    }
    inputs = this.normalizeInputs(inputs);
    outputs = this.normalizeOutputs(outputs);
    const result = this.executor.execute(inputs, outputs);
    return result.length > 1 ? result : result[0];
  }
  /**
   * Executes inference for the model for given input tensors in async
   * fashion, use this method when your model contains control flow ops.
   * @param inputs tensor, tensor array or tensor map of the inputs for the
   * model, keyed by the input node names.
   * @param outputs output node name from the TensorFlow model, if no outputs
   * are specified, the default outputs of the model would be used. You can
   * inspect intermediate nodes of the model by adding them to the outputs
   * array.
   *
   * @returns A Promise of single tensor if provided with a single output or
   * no outputs are provided and there is only one default output, otherwise
   * return a tensor map.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async executeAsync(inputs, outputs) {
    if (this.resourceIdToCapturedInput == null) {
      this.setResourceIdToCapturedInput(await this.executeInitializerGraphAsync());
    }
    inputs = this.normalizeInputs(inputs);
    outputs = this.normalizeOutputs(outputs);
    const result = await this.executor.executeAsync(inputs, outputs);
    return result.length > 1 ? result : result[0];
  }
  /**
   * Get intermediate tensors for model debugging mode (flag
   * KEEP_INTERMEDIATE_TENSORS is true).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  getIntermediateTensors() {
    return this.executor.getIntermediateTensors();
  }
  /**
   * Dispose intermediate tensors for model debugging mode (flag
   * KEEP_INTERMEDIATE_TENSORS is true).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  disposeIntermediateTensors() {
    this.executor.disposeIntermediateTensors();
  }
  convertTensorMapToTensorsMap(map) {
    return Object.keys(map).reduce((newMap, key) => {
      newMap[key] = [map[key]];
      return newMap;
    }, {});
  }
  /**
   * Releases the memory used by the weight tensors and resourceManager.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  dispose() {
    this.executor.dispose();
    if (this.initializer) {
      this.initializer.dispose();
      if (this.resourceIdToCapturedInput) {
        dispose(this.resourceIdToCapturedInput);
      }
    }
    this.resourceManager.dispose();
  }
};
async function loadGraphModel(modelUrl, options = {}, tfio = io_exports) {
  if (modelUrl == null) {
    throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
  }
  if (options == null) {
    options = {};
  }
  if (options.fromTFHub && typeof modelUrl === "string") {
    modelUrl = getTFHubUrl(modelUrl);
  }
  const model = new GraphModel(modelUrl, options, tfio);
  await model.load();
  return model;
}
function getTFHubUrl(modelUrl) {
  if (!modelUrl.endsWith("/")) {
    modelUrl = modelUrl + "/";
  }
  return `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/flags_webgpu.js
var ENV2 = env();
ENV2.registerFlag("WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE", () => 15);
ENV2.registerFlag("WEBGPU_CPU_FORWARD", () => true);
ENV2.registerFlag("WEBGPU_MATMUL_PROGRAM_TYPE", () => -1);
ENV2.registerFlag("WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE", () => true);
ENV2.registerFlag("WEBGPU_USE_LOW_POWER_GPU", () => false);
ENV2.registerFlag("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e3);
ENV2.registerFlag("WEBGPU_USE_PROFILE_TOOL", () => false);
ENV2.registerFlag("WEBGPU_IMPORT_EXTERNAL_TEXTURE", () => true);
ENV2.registerFlag("WEBGPU_USE_NAIVE_CONV2D_DEBUG", () => false);
ENV2.registerFlag("WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL", () => -1);
ENV2.registerFlag("WEBGPU_CONV_SEPARATE_IM2COL_SHADER", () => false);
ENV2.registerFlag("WEBGPU_PRINT_SHADER", () => "");
ENV2.registerFlag("WEBGPU_ENGINE_COMPILE_ONLY", () => false);

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/adapter_info.js
var AdapterInfo = class {
  constructor(adapterInfo) {
    if (adapterInfo) {
      this.vendor = adapterInfo.vendor;
      this.architecture = adapterInfo.architecture;
      this.intelGPUGeneration = this.getIntelGPUGeneration();
    }
  }
  getIntelGPUGeneration() {
    if (this.isIntel()) {
      if (this.architecture.startsWith("gen")) {
        return Number(this.architecture.match(/\d+/));
      } else if (this.architecture.startsWith("xe")) {
        return 12;
      }
    }
    return 0;
  }
  isIntel() {
    return this.vendor === "intel";
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/buffer_manager.js
var BufferManager = class {
  constructor(device) {
    this.device = device;
    this.numUsedBuffers = 0;
    this.numFreeBuffers = 0;
    this.freeBuffers = /* @__PURE__ */ new Map();
    this.usedBuffers = /* @__PURE__ */ new Map();
    this.numBytesUsed = 0;
    this.numBytesAllocated = 0;
  }
  acquireBuffer(size, usage, mappedAtCreation = false, reuse = true) {
    let buffer2;
    const key = getBufferKey(size, usage);
    if (reuse) {
      if (!this.freeBuffers.has(key)) {
        this.freeBuffers.set(key, []);
      }
      if (this.freeBuffers.get(key).length > 0) {
        buffer2 = this.freeBuffers.get(key).pop();
        this.numFreeBuffers--;
      } else {
        buffer2 = this.device.createBuffer({ size, usage, mappedAtCreation });
        this.numBytesAllocated += size;
      }
    } else {
      buffer2 = this.device.createBuffer({ size, usage, mappedAtCreation });
      this.numBytesAllocated += size;
    }
    if (!this.usedBuffers.has(key)) {
      this.usedBuffers.set(key, []);
    }
    this.usedBuffers.get(key).push(buffer2);
    this.numUsedBuffers++;
    this.numBytesUsed += size;
    return buffer2;
  }
  releaseBuffer(buffer2, reuse = true) {
    if (this.freeBuffers.size === 0) {
      return;
    }
    const size = buffer2.size;
    const usage = buffer2.usage;
    const key = getBufferKey(size, usage);
    const bufferArray = this.usedBuffers.get(key);
    const index = bufferArray.indexOf(buffer2);
    if (index < 0) {
      throw new Error("Cannot find the buffer in buffer manager");
    }
    bufferArray[index] = bufferArray[bufferArray.length - 1];
    bufferArray.pop();
    this.numUsedBuffers--;
    this.numBytesUsed -= size;
    if (reuse) {
      this.freeBuffers.get(key).push(buffer2);
      this.numFreeBuffers++;
    } else {
      buffer2.destroy();
      this.numBytesAllocated -= size;
    }
  }
  getNumUsedBuffers() {
    return this.numUsedBuffers;
  }
  getNumFreeBuffers() {
    return this.numFreeBuffers;
  }
  dispose() {
    this.freeBuffers.forEach((buffers, key) => {
      buffers.forEach((buffer2) => {
        buffer2.destroy();
      });
    });
    this.usedBuffers.forEach((buffers, key) => {
      buffers.forEach((buffer2) => {
        buffer2.destroy();
      });
    });
    this.freeBuffers = /* @__PURE__ */ new Map();
    this.usedBuffers = /* @__PURE__ */ new Map();
    this.numUsedBuffers = 0;
    this.numFreeBuffers = 0;
    this.numBytesUsed = 0;
    this.numBytesAllocated = 0;
  }
};
function getBufferKey(size, usage) {
  return `${size}_${usage}`;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/texture_manager.js
var TextureManager = class {
  constructor(device) {
    this.device = device;
    this.numUsedTextures = 0;
    this.numFreeTextures = 0;
    this.freeTextures = /* @__PURE__ */ new Map();
    this.usedTextures = /* @__PURE__ */ new Map();
    this.numBytesUsed = 0;
    this.numBytesAllocated = 0;
  }
  acquireTexture(width, height, format, usage) {
    const bytesPerElement = getBytesPerElement(format);
    const byteSize = width * height * bytesPerElement;
    const key = getTextureKey(width, height, format, usage);
    if (!this.freeTextures.has(key)) {
      this.freeTextures.set(key, []);
    }
    if (!this.usedTextures.has(key)) {
      this.usedTextures.set(key, []);
    }
    this.numBytesUsed += byteSize;
    this.numUsedTextures++;
    if (this.freeTextures.get(key).length > 0) {
      this.numFreeTextures--;
      const newTexture2 = this.freeTextures.get(key).shift();
      this.usedTextures.get(key).push(newTexture2);
      return newTexture2;
    }
    this.numBytesAllocated += byteSize;
    const newTexture = this.device.createTexture({
      size: [width, height],
      format,
      usage
    });
    this.usedTextures.get(key).push(newTexture);
    return newTexture;
  }
  releaseTexture(texture) {
    if (this.freeTextures.size === 0) {
      return;
    }
    const width = texture.width;
    const height = texture.height;
    const format = texture.format;
    const usage = texture.usage;
    const key = getTextureKey(width, height, format, usage);
    if (!this.freeTextures.has(key)) {
      this.freeTextures.set(key, []);
    }
    this.freeTextures.get(key).push(texture);
    this.numFreeTextures++;
    this.numUsedTextures--;
    const textureList = this.usedTextures.get(key);
    const textureIndex = textureList.indexOf(texture);
    if (textureIndex < 0) {
      throw new Error("Cannot release a texture that was never provided by this texture manager");
    }
    textureList.splice(textureIndex, 1);
    const bytesPerElement = getBytesPerElement(format);
    const byteSize = width * height * bytesPerElement;
    this.numBytesUsed -= byteSize;
  }
  getNumUsedTextures() {
    return this.numUsedTextures;
  }
  getNumFreeTextures() {
    return this.numFreeTextures;
  }
  dispose() {
    this.freeTextures.forEach((textures, key) => {
      textures.forEach((texture) => {
        texture.destroy();
      });
    });
    this.usedTextures.forEach((textures, key) => {
      textures.forEach((texture) => {
        texture.destroy();
      });
    });
    this.freeTextures = /* @__PURE__ */ new Map();
    this.usedTextures = /* @__PURE__ */ new Map();
    this.numUsedTextures = 0;
    this.numFreeTextures = 0;
    this.numBytesUsed = 0;
    this.numBytesAllocated = 0;
  }
};
function getTextureKey(width, height, format, usage) {
  return `${width}_${height}_${format}_${usage}`;
}
function getBytesPerElement(format) {
  if (format === "rgba8unorm") {
    return 16;
  } else {
    throw new Error(`${format} is not supported!`);
  }
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/shader_util.js
function symbolicallyComputeStrides(indicesArr, variableName) {
  if (Math.max(...indicesArr) > 5) {
    throw new Error("Cannot symbolically compute strides for rank > 6 tensor.");
  }
  const numCoords = indicesArr.length;
  const indicesStr = "xyzwuv";
  const shape = indicesArr.map((d) => `${variableName}.${indicesStr[d]}`);
  const strides = new Array(numCoords - 1);
  strides[numCoords - 2] = shape[numCoords - 1];
  for (let i = numCoords - 3; i >= 0; --i) {
    strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;
  }
  return strides;
}
var atomicAddSnippet = (ptr, v, type) => {
  if (type === "int32") {
    return `atomicAdd(${ptr}, bitcast<i32>(${v}));`;
  } else {
    return `
          {
            var oldValue = 0;
            loop {
              let newValueF32 = bitcast<f32>(oldValue) + (${v});
              let newValue = bitcast<i32>(newValueF32);
              let res = atomicCompareExchangeWeak(${ptr}, oldValue, newValue);
              if res.exchanged {
                break;
              }
              oldValue = res.old_value;
            }
          }`;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/webgpu_program.js
var PixelsOpType;
(function(PixelsOpType2) {
  PixelsOpType2[PixelsOpType2["FROM_PIXELS"] = 0] = "FROM_PIXELS";
  PixelsOpType2[PixelsOpType2["DRAW"] = 1] = "DRAW";
})(PixelsOpType || (PixelsOpType = {}));
var compileProgram = (device, program, inputsData, output, parallelCompilation) => {
  const outputData = { dtype: output.dtype, shape: output.shape };
  const source = makeShader(inputsData, outputData, program);
  const module = device.createShaderModule({ code: source, label: program.constructor.name });
  let printShaderString = env().get("WEBGPU_PRINT_SHADER");
  if (printShaderString !== "") {
    printShaderString = printShaderString.toLowerCase();
    const printShaderArray = printShaderString.split(",");
    if (printShaderString === "all" || printShaderArray.some((item) => program.shaderKey.toLowerCase().includes(item))) {
      console.group(program.shaderKey);
      console.debug(source);
      console.groupEnd();
    }
  }
  if (parallelCompilation) {
    return device.createComputePipelineAsync({
      compute: { module, entryPoint: "_start" },
      label: program.constructor.name,
      layout: "auto"
    });
  } else {
    return device.createComputePipeline({
      compute: { module, entryPoint: "_start" },
      label: program.constructor.name,
      layout: "auto"
    });
  }
};
var typeSnippet = (component, type = "f32") => {
  switch (component) {
    case 1:
      return `${type}`;
    case 2:
      return `vec2<${type}>`;
    case 3:
      return `vec3<${type}>`;
    case 4:
      return `vec4<${type}>`;
    default:
      throw new Error(`${component}-component ${type} is not supported.`);
  }
};
function getCoordsDataType(rank) {
  if (rank <= 1) {
    return "i32";
  } else if (rank === 2) {
    return `vec2<i32>`;
  } else if (rank === 3) {
    return `vec3<i32>`;
  } else if (rank === 4) {
    return `vec4<i32>`;
  } else if (rank === 5) {
    return `vec5`;
  } else if (rank === 6) {
    return `vec6`;
  } else {
    throw Error(`GPU for rank ${rank} is not yet supported`);
  }
}
function getCoordsXYZ(index) {
  if (index === 0) {
    return "x";
  } else if (index === 1) {
    return "y";
  } else if (index === 2) {
    return "z";
  } else if (index === 3) {
    return "w";
  } else if (index === 4) {
    return "u";
  } else if (index === 5) {
    return "v";
  } else {
    throw Error(`Index ${index} is not yet supported`);
  }
}
function getMainHeaderString(...params) {
  let snippet;
  switch (params.length) {
    case 0:
      snippet = `
        fn main()
      `;
      break;
    case 1:
      snippet = `
        fn main(${params[0]} : i32)
      `;
      break;
    default:
      throw Error("Unreachable");
  }
  return snippet;
}
function getStartHeaderString(useGlobalIndex, program) {
  let snippet;
  snippet = `
     ${getWorkgroupSizeString(program)}
      fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,
                @builtin(global_invocation_id) GlobalId : vec3<u32>,
                @builtin(local_invocation_index) LocalIndex: u32,
                @builtin(workgroup_id) WorkgroupId : vec3<u32>,
                @builtin(num_workgroups) NumWorkgroups : vec3<u32>) {
        localId = LocalId;
        localIndex = LocalIndex;
        globalId = GlobalId;
        numWorkgroups = NumWorkgroups;
        workgroupId = WorkgroupId;
        ${useGlobalIndex ? `main(getGlobalIndex());` : `main();`};
      }
    `;
  return snippet;
}
function getWorkgroupSizeString(program) {
  return `
  @compute @workgroup_size(${program.workgroupSize[0]}, ${program.workgroupSize[1]}, ${program.workgroupSize[2]})
`;
}
function makeShader(inputInfo, outputData, program) {
  const prefixSnippets = [];
  const flatWorkgroupSize = program.workgroupSize[0] * program.workgroupSize[1] * program.workgroupSize[2];
  program.outputComponent = program.outputComponent ? program.outputComponent : 1;
  prefixSnippets.push(`

      var<private> localId: vec3<u32>;
      var<private> localIndex: u32;
      var<private> globalId: vec3<u32>;
      var<private> numWorkgroups: vec3<u32>;
      var<private> workgroupId: vec3<u32>;

      // Only used when the y/z dimension of workgroup size is 1.
      fn getGlobalIndex() -> i32 {
        ${isFlatDispatch(program) ? `  return i32(globalId.x);` : `  return i32((workgroupId.z * numWorkgroups.x * numWorkgroups.y +
                workgroupId.y * numWorkgroups.x + workgroupId.x) * ${flatWorkgroupSize}u +
                localIndex);
        `}
      }
    `);
  if (program.pixelsOpType != null) {
    const inoutSnippet = program.pixelsOpType === PixelsOpType.FROM_PIXELS ? `@group(0) @binding(0) var<storage, read_write> result: array<${dataTypeToGPUType(outputData.dtype, program.outputComponent)}>;` : `@group(0) @binding(1) var<storage, read> inBuf : array<${dataTypeToGPUType(inputInfo[0].dtype, program.outputComponent)}>;`;
    const outShapeStridesType = outputData.shape.length === 3 ? "vec2<i32>" : "i32";
    prefixSnippets.push(`
        struct Uniform {
          outShapeStrides : ${outShapeStridesType},
          size            : i32,
          numChannels     : i32,
          alpha           : f32,
        };

        ${inoutSnippet}
        @group(0) @binding(2) var<uniform> uniforms: Uniform;
      `);
    const useGlobalIndex2 = isFlatDispatchLayout(program);
    return [
      commonSnippet,
      prefixSnippets.join("\n"),
      getCoordsFromIndexSnippet(outputData.shape),
      program.getUserCode(),
      getStartHeaderString(useGlobalIndex2, program)
    ].join("\n");
  }
  let stridesLength;
  let stridesDataType;
  let uniformDeclaration = "struct Uniforms { NAN : f32, INFINITY : f32, ";
  program.variableNames.forEach((x, i) => {
    const perDataType = getCoordsDataType(inputInfo[i].shape.length);
    uniformDeclaration += `${x.charAt(0).toLowerCase() + x.slice(1)}Shape : ${perDataType}, `;
    stridesLength = inputInfo[i].shape.length - 1;
    stridesDataType = getCoordsDataType(stridesLength);
    uniformDeclaration += `${x.charAt(0).toLowerCase() + x.slice(1)}ShapeStrides: ${stridesDataType}, `;
  });
  const outputDataType = getCoordsDataType(outputData.shape.length);
  uniformDeclaration += `outShape : ${outputDataType}, `;
  stridesLength = outputData.shape.length - 1;
  stridesDataType = getCoordsDataType(stridesLength);
  uniformDeclaration += `
         outShapeStrides: ${stridesDataType}, `;
  if (program.size) {
    uniformDeclaration += "size : i32, ";
  }
  if (program.uniforms) {
    uniformDeclaration += program.uniforms;
  }
  uniformDeclaration += "};";
  uniformDeclaration = insertAlignment(uniformDeclaration);
  prefixSnippets.push(uniformDeclaration);
  if (program.atomic) {
    prefixSnippets.push(`
      @group(0) @binding(0) var<storage, read_write> result: array<atomic<i32>>;
    `);
  } else {
    prefixSnippets.push(`
      @group(0) @binding(0) var<storage, read_write> result: array<${dataTypeToGPUType(outputData.dtype, program.outputComponent)}>;
    `);
  }
  program.variableNames.forEach((x, i) => {
    prefixSnippets.push(`
      @group(0) @binding(${1 + i}) var<storage, read> ${x}: array<${program.variableComponents ? dataTypeToGPUType(inputInfo[i].dtype, program.variableComponents[i]) : dataTypeToGPUType(inputInfo[i].dtype, program.outputComponent)}>;
        `);
  });
  if (uniformDeclaration !== "") {
    prefixSnippets.push(`
      @group(0) @binding(${1 + program.variableNames.length}) var<uniform> uniforms: Uniforms;
      `);
  }
  const coordsSnippet = getOutputCoordsSnippet(outputData.shape, program.dispatchLayout);
  const sources = [
    commonSnippet,
    prefixSnippets.join("\n") + isInfSnippet,
    getCoordsFromIndexSnippet(outputData.shape),
    coordsSnippet,
    getOutputIndexFromCoordsSnippet(outputData.shape.length)
  ];
  if (!program.atomic) {
    sources.push(setOutputSnippet(outputData.shape, outputData.dtype, program.outputComponent));
  }
  program.variableNames.forEach((x, i) => {
    sources.push(`${getCoordsFromIndexSnippet(inputInfo[i].shape, x)}`);
  });
  const inputSnippet = inputInfo.map((x, i) => getInputSnippet(x, outputData.shape, program.variableComponents ? program.variableComponents[i] : program.outputComponent, program.dispatchLayout.x.length === outputData.shape.length)).join("\n");
  sources.push(inputSnippet);
  sources.push(program.getUserCode());
  const useGlobalIndex = isFlatDispatchLayout(program);
  sources.push(getStartHeaderString(useGlobalIndex, program));
  const source = sources.join("\n");
  return source;
}
function makeShaderKey(program, inputsData, output) {
  let key = program.shaderKey;
  if (program.pixelsOpType != null) {
    return key;
  }
  const shapes = [];
  const types = [];
  inputsData.forEach((element) => {
    shapes.push(element.shape);
    types.push(element.dtype);
  });
  shapes.push(output.shape);
  types.push(output.dtype);
  const broadcastDims = inputsData.map((d) => backend_util_exports.getBroadcastDims(d.shape, output.shape));
  const inputShapesEqualsOutShape = inputsData.map((d) => util_exports.arraysEqual(d.shape, output.shape)).join("_");
  const broadcastDimsKey = broadcastDims.map((d) => d.join("_")).join(";");
  const flatDispatchString = isFlatDispatch(program) ? "flatDispatch" : "";
  key += "_" + (program.workgroupSize ? program.workgroupSize.join(",") : "") + shapes.map((shape) => shape.length).join(",") + types.join(",") + program.variableNames.join(",") + broadcastDimsKey + inputShapesEqualsOutShape + flatDispatchString;
  return key;
}
var commonSnippet = `
  struct vec5 {x: i32, y: i32, z: i32, w: i32, u: i32};
  struct vec6 {x: i32, y: i32, z: i32, w: i32, u: i32, v: i32};

  // Checks whether coordinates lie within the bounds of the shape.
  fn coordsInBounds2D(coord : vec2<i32>, shape : vec2<i32>) -> bool {
    return all(coord >= vec2<i32>(0)) && all(coord < shape);
  }
  fn coordsInBounds3D(coord : vec3<i32>, shape : vec3<i32>) -> bool {
    return all(coord >= vec3<i32>(0)) && all(coord < shape);
  }
  fn coordsInBounds4D(coord : vec4<i32>, shape : vec4<i32>) -> bool {
    return all(coord >= vec4<i32>(0)) && all(coord < shape);
  }

  fn getIndexFromCoords1D(coord : i32, shape : i32) -> i32 {
    return coord;
  }
  fn getIndexFromCoords2D(coords : vec2<i32>, shape : vec2<i32>) -> i32 {
    return dot(coords, vec2<i32>(shape.y, 1));
  }
  fn getIndexFromCoords3D(coords : vec3<i32>, shape : vec3<i32>) -> i32 {
    return dot(coords, vec3<i32>(shape.y * shape.z, shape.z, 1));
  }
  fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {
    return dot(coords, vec4<i32>(
        shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));
  }
  fn getIndexFromCoords5D(coords : vec5, shape : vec5) -> i32 {
    let shapeStrides: vec5 = vec5(shape.y * shape.z * shape.w * shape.u, shape.z * shape.w * shape.u, shape.w * shape.u, shape.u, 1);
    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u;
  }
  fn getIndexFromCoords6D(coords : vec6, shape : vec6) -> i32 {
    let shapeStrides: vec6 = vec6(shape.y * shape.z * shape.w * shape.u * shape.v, shape.z * shape.w * shape.u * shape.v, shape.w * shape.u * shape.v, shape.u * shape.v, shape.v, 1);
    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u + coords.v*shapeStrides.v;
  }

  // NaN defination in IEEE 754-1985 is :
  //   - sign = either 0 or 1.
  //   - biased exponent = all 1 bits.
  //   - fraction = anything except all 0 bits (since all 0 bits represents infinity).
  // https://en.wikipedia.org/wiki/IEEE_754-1985#Representation_of_non-numbers
  fn isnan(val: f32) -> bool {
    let floatToUint: u32 = bitcast<u32>(val);
    return (floatToUint & 0x7fffffffu) > 0x7f800000u;
  }
  fn isnanVec4(val : vec4<f32>) -> vec4<bool> {
    let floatToUint: vec4<u32> = bitcast<vec4<u32>>(val);
    return (floatToUint & vec4<u32>(0x7fffffffu)) > vec4<u32>(0x7f800000u);
  }
`;
var isInfSnippet = `
  fn isinf(val: f32) -> bool {
    return abs(val) == uniforms.INFINITY;
  }
`;
function getCoordsFromIndexSnippet(shape, name = "") {
  const rank = shape.length;
  const funcName = name !== "" ? `get${name.charAt(0).toUpperCase() + name.slice(1)}CoordsFromIndex` : "getCoordsFromIndex";
  const stridesName = name !== "" ? `${name.charAt(0).toLowerCase() + name.slice(1)}ShapeStrides` : `outShapeStrides`;
  if (rank <= 1) {
    return `fn ${funcName}(index : i32) -> i32 { return index; }`;
  }
  const strides = util_exports.computeStrides(shape);
  const dtype = getCoordsDataType(rank);
  const coords2 = [];
  for (let i = 0; i < rank; i++) {
    coords2.push(`d${i}`);
  }
  if (strides.length === 1) {
    return `    fn ${funcName}(index : i32) -> vec2<i32> {
      let d0 = index / uniforms.${stridesName}; let d1 = index - d0 * uniforms.${stridesName};
      return vec2<i32>(d0, d1);
    }`;
  }
  let snippet;
  snippet = "var index2 = index;" + strides.map((_, i) => {
    const line1 = `let ${coords2[i]} = index2 / uniforms.${stridesName}.${getCoordsXYZ(i)}`;
    const line2 = i === strides.length - 1 ? `let ${coords2[i + 1]} = index2 - ${coords2[i]} * uniforms.${stridesName}.${getCoordsXYZ(i)}` : `index2 = index2 - ${coords2[i]} * uniforms.${stridesName}.${getCoordsXYZ(i)}`;
    return `${line1}; ${line2};`;
  }).join("");
  return `
    fn ${funcName}(index : i32) -> ${dtype} {
      ${snippet}
      return ${dtype}(${coords2.join(",")});
    }
  `;
}
function getInputAtCoordsSnippet(inputInfo, component) {
  const texName = inputInfo.name;
  const rank = inputInfo.shape.length;
  const type = getCoordsDataType(rank);
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const dims = ["d0", "d1", "d2", "d3", "d4", "d5"].slice(0, rank);
  const inputs = dims.map((d) => `${d} : i32`).join(", ");
  if (rank < 1) {
    return `
      fn ${funcName}() -> ${typeSnippet(component)} {
        return ${typeSnippet(component)}(${texName}[0]);
      }
    `;
  }
  const shapeStr = `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;
  let rankStr = `${rank}D`;
  if (rank === 0) {
    rankStr = "1D";
  }
  return `
    fn ${funcName}(${inputs}) -> ${typeSnippet(component)} {
      return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${type}(${dims.join(",")}),
        ${shapeStr})${component === 1 ? "" : ` / ${component}`}]);
    }
   `;
}
function getInputByOutputSnippet(inputInfo, outShape, component, isFlatDispatchLayout2) {
  const texName = inputInfo.name;
  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
  const funcName = "get" + texFuncSnippet + "ByOutput";
  const inRank = inputInfo.shape.length;
  const outRank = outShape.length;
  const type = getCoordsDataType(outRank);
  if (util_exports.arraysEqual(inputInfo.shape, outShape) && isFlatDispatchLayout2) {
    return `
    fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)} {
      return ${typeSnippet(component)}(${texName}[globalIndex]);
    }

    fn ${funcName}Coords(coords : ${type}) -> ${typeSnippet(component)} {
      return ${typeSnippet(component)}(${texName}[${outRank > 1 ? "getOutputIndexFromCoords(coords)" : "coords"}${component === 1 ? "" : ` / ${component}`}]);
    }
    `;
  }
  const broadcastDims = backend_util_exports.getBroadcastDims(inputInfo.shape, outShape);
  const rankDiff = outRank - inRank;
  let coordsSnippet = "";
  if (inRank === 0) {
    return `
    fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)}{
      return get${texFuncSnippet}();
    }

    fn ${funcName}Coords(coords : ${type}) -> ${typeSnippet(component)}{
      return get${texFuncSnippet}();
    }
  `;
  } else {
    if (outRank < 2 && broadcastDims.length >= 1) {
      coordsSnippet = "coords = 0;";
    } else {
      coordsSnippet = broadcastDims.map((d) => `coords.${getCoordsXYZ(d + rankDiff)} = 0;`).join("\n");
    }
  }
  let unpackedCoordsSnippet = "";
  if (outRank < 2 && inRank > 0) {
    unpackedCoordsSnippet = "coords";
  } else {
    if (outRank > 1) {
      const coordsType = getCoordsDataType(inRank);
      const coordsValues = inputInfo.shape.map((s, i) => `coords.${getCoordsXYZ(i + rankDiff)}`).join(", ");
      unpackedCoordsSnippet = `${coordsType}(${coordsValues})`;
    } else {
      unpackedCoordsSnippet = "coords";
    }
  }
  const shapeStr = `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;
  const rankStr = `${inRank}D`;
  return `
  fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)} {
    var coords = getCoordsFromIndex(globalIndex);
    ${coordsSnippet}
    return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${unpackedCoordsSnippet}, ${shapeStr})${component === 1 ? "" : ` / ${component}`}]);
  }

  fn ${funcName}Coords(coordsIn : ${type}) -> ${typeSnippet(component)} {
    var coords = coordsIn;
    ${coordsSnippet}
    return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${unpackedCoordsSnippet}, ${shapeStr})${component === 1 ? "" : ` / ${component}`}]);
  }
`;
}
function getInputSnippet(inputInfo, outShape, component, isFlatDispatchLayout2) {
  let res = getInputAtCoordsSnippet(inputInfo, component);
  const inShape = inputInfo.shape;
  if (inShape.length <= outShape.length) {
    res += getInputByOutputSnippet(inputInfo, outShape, component, isFlatDispatchLayout2);
  }
  return res;
}
function getOutputCoordsSnippet(outShape, dispatchLayout) {
  const { x, y = [], z = [] } = dispatchLayout;
  const outRank = outShape.length;
  const rank = x.length + y.length + z.length;
  if (rank !== outRank) {
    return "";
  }
  if (x.length === outRank) {
    const dtype2 = getCoordsDataType(outRank);
    const snippet2 = `fn getOutputCoords() -> ${dtype2}{
    let globalIndex = getGlobalIndex();
    return getCoordsFromIndex(globalIndex);
  }
  `;
    return snippet2;
  }
  let gatherDimensionsStr = "";
  const dims = [x, y, z];
  for (let i = 0; i < dims.length; i++) {
    const arr = dims[i];
    if (arr.length === 0) {
      continue;
    }
    if (arr.length === 1) {
      gatherDimensionsStr += `let d${arr[0]} = i32(globalId[${i}]);`;
    } else {
      const strides = symbolicallyComputeStrides(arr, "uniforms.outShape");
      gatherDimensionsStr += `var index${i} = i32(globalId[${i}]);`;
      for (let j2 = 0; j2 < strides.length; j2++) {
        gatherDimensionsStr += `let d${arr[j2]} = index${i} / ${strides[j2]};`;
        if (j2 === strides.length - 1) {
          gatherDimensionsStr += `let d${arr[j2 + 1]} = index${i} - d${arr[j2]} * ${strides[j2]};`;
        } else {
          gatherDimensionsStr += `index${i} = index${i} - d${arr[j2]} * ${strides[j2]};`;
        }
      }
    }
  }
  const dimensions = [];
  for (let i = 0; i < rank; i++) {
    dimensions.push(`d${i}`);
  }
  const dtype = getCoordsDataType(rank);
  let snippet = `fn getOutputCoords() -> ${dtype} {
  ${gatherDimensionsStr}
`;
  if (dimensions.length === 0) {
    snippet += `return ${dtype}(0); }`;
  } else {
    snippet += `return ${dtype}(${dimensions.join(",")}); }`;
  }
  return snippet;
}
function getOutputIndexFromCoordsSnippet(outRank) {
  let snippet = "";
  switch (outRank) {
    case 0:
    case 1:
      snippet += `
        fn getOutputIndexFromCoords(coords : i32) -> i32 {
          return coords;
        }
        `;
      break;
    case 2:
      snippet += `
        fn getOutputIndexFromCoords(coords : vec2<i32>) -> i32 {
          return dot(coords, vec2<i32>(uniforms.outShapeStrides, 1));
        }
        `;
      break;
    case 3:
      snippet += `
        fn getOutputIndexFromCoords(coords : vec3<i32>) -> i32 {
          return dot(coords, vec3<i32>(uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, 1));
        }
        `;
      break;
    case 4:
      snippet += `
        fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {
          return dot(coords, vec4<i32>(
            uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, uniforms.outShapeStrides.z, 1));
        }
        `;
      break;
    case 5:
      snippet += `
        fn getOutputIndexFromCoords(coords : vec5) -> i32 {
          return coords.x * uniforms.outShapeStrides.x +
              coords.y * uniforms.outShapeStrides.y +
              coords.z * uniforms.outShapeStrides.z +
              coords.w * uniforms.outShapeStrides.w +
              coords.u;
        }
        `;
      break;
    case 6:
      snippet += `
        fn getOutputIndexFromCoords(coords : vec6) -> i32 {
          return coords.x * uniforms.outShapeStrides.x +
              coords.y * uniforms.outShapeStrides.y +
              coords.z * uniforms.outShapeStrides.z +
              coords.w * uniforms.outShapeStrides.w +
              coords.u * uniforms.outShapeStrides.u +
              coords.v;
        }
        `;
      break;
    default:
      util_exports.assert(false, () => `Unsupported ${outRank}D shape`);
      break;
  }
  return snippet;
}
function isFlatDispatch(program) {
  return program.dispatch[1] === 1 && program.dispatch[2] === 1;
}
function dataTypeToGPUType(type, component = 1) {
  if (type === "float32") {
    return typeSnippet(component, "f32");
  } else if (type === "int32" || type === "bool") {
    return typeSnippet(component, "i32");
  }
  throw new Error(`type ${type} is not supported.`);
}
function setOutputSnippet(outShape, outBufferType, component) {
  const outRank = outShape.length;
  const gpuType = dataTypeToGPUType(outBufferType, component);
  let snippet = `fn setOutputAtIndex(flatIndex : i32, value : ${typeSnippet(component)}) {
      result[flatIndex] = ${gpuType}(value);
    }

    fn setOutputAtIndexI32(flatIndex : i32, value : ${typeSnippet(component, "i32")}) {
      result[flatIndex] = ${gpuType}(value);
    }
    `;
  if (outRank >= 2) {
    const dims = ["d0", "d1", "d2", "d3", "d4", "d5"].slice(0, outRank);
    const type = getCoordsDataType(outRank);
    snippet += `
      fn setOutputAtCoords(${dims.map((d) => `${d} : i32`).join(", ")}, value : ${typeSnippet(component)}) {
        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(", ")}));
        setOutputAtIndex(flatIndex${component === 1 ? "" : ` / ${component}`}, value);
      }
      fn setOutputAtCoordsI32(${dims.map((d) => `${d} : i32`).join(", ")}, value : ${typeSnippet(component, "i32")}) {
        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(", ")}));
        setOutputAtIndexI32(flatIndex${component === 1 ? "" : ` / ${component}`}, value);
      }
    `;
  }
  return snippet;
}
function insertAlignment(uniformShader) {
  const curInsertRe = /(\w+)\s*:\s*vec(5|6)/g;
  uniformShader = uniformShader.replace(curInsertRe, (match) => {
    return "@align(16) " + match;
  });
  const preInsertRe = /vec(5|6)\s*,\s*(\w+)/g;
  uniformShader = uniformShader.replace(preInsertRe, (_, p1, p2) => {
    return `vec${p1}, @align(16) ${p2}`;
  });
  return uniformShader;
}
function isFlatDispatchLayout(program) {
  if (program.dispatchLayout.hasOwnProperty("y") && program.dispatchLayout.y.length !== 0) {
    return false;
  }
  if (program.dispatchLayout.hasOwnProperty("z") && program.dispatchLayout.z.length !== 0) {
    return false;
  }
  return true;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/webgpu_util.js
var webgpu_util_exports = {};
__export(webgpu_util_exports, {
  GPUBytesPerElement: () => GPUBytesPerElement,
  MatMulProgramType: () => MatMulProgramType,
  assertNotComplex: () => assertNotComplex,
  computeDispatch: () => computeDispatch,
  computeWorkPerThreadForConv2d: () => computeWorkPerThreadForConv2d,
  computeWorkgroupInfoForMatMul: () => computeWorkgroupInfoForMatMul,
  computeWorkgroupSizeForConv2d: () => computeWorkgroupSizeForConv2d,
  flatDispatchLayout: () => flatDispatchLayout,
  isWebGPUSupported: () => isWebGPUSupported,
  tilesFitEvenlyIntoShape: () => tilesFitEvenlyIntoShape
});
var arrayProduct = (arr) => {
  let product = 1;
  for (let i = 0; i < arr.length; i++) {
    product *= arr[i];
  }
  return product;
};
function tilesFitEvenlyIntoShape(tileSize, shape) {
  if (tileSize.length !== shape.length) {
    throw new Error(`Cannot compute whether rank ${tileSize.length} tiles fit evenly into rank ${shape.length} shape - ranks must match.`);
  }
  return shape.every((dim, dimIdx) => dim % tileSize[dimIdx] === 0);
}
function computeDispatch(layout, outputShape, workgroupSize = [1, 1, 1], elementsPerThread = [1, 1, 1]) {
  const [dispatchX, dispatchY, dispatchZ] = [
    Math.ceil(arrayProduct(layout.x.map((d) => outputShape[d])) / (workgroupSize[0] * elementsPerThread[0])),
    layout.y ? Math.ceil(arrayProduct(layout.y.map((d) => outputShape[d])) / (workgroupSize[1] * elementsPerThread[1])) : 1,
    layout.z ? Math.ceil(arrayProduct(layout.z.map((d) => outputShape[d])) / (workgroupSize[2] * elementsPerThread[2])) : 1
  ];
  return [dispatchX, dispatchY, dispatchZ];
}
function computeWorkgroupInfoForMatMul(dimAOuter, dimInner, dimBOuter, transposeA = false) {
  const workgroupSize = [8, 8, 1];
  const elementsPerThread = [4, 4, 1];
  if (!transposeA) {
    if (dimAOuter <= 8) {
      elementsPerThread[1] = 1;
    }
    if (dimInner <= 16 && dimBOuter <= 16) {
      workgroupSize[0] = 4;
    }
  }
  return { workgroupSize, elementsPerThread };
}
function computeWorkgroupSizeForConv2d(layout, outputShape, isVec4 = false) {
  if (isVec4) {
    return [8, 8, 1];
  }
  const dim0 = arrayProduct(layout.x.map((d) => outputShape[d]));
  const dim1 = arrayProduct(layout.y.map((d) => outputShape[d]));
  if (dim0 <= 4) {
    return [4, 16, 1];
  }
  if (dim1 <= 4) {
    return [16, 4, 1];
  }
  return [16, 16, 1];
}
function computeWorkPerThreadForConv2d(layout, outputShape, isVec4 = false) {
  if (isVec4) {
    return [4, 4, 1];
  }
  const dim0 = arrayProduct(layout.x.map((d) => outputShape[d]));
  const dim1 = arrayProduct(layout.y.map((d) => outputShape[d]));
  if (dim0 <= 4) {
    return [1, 2, 1];
  }
  if (dim1 <= 4) {
    return [2, 1, 1];
  }
  return [2, 2, 1];
}
function flatDispatchLayout(shape) {
  return { x: shape.map((d, i) => i) };
}
function GPUBytesPerElement(dtype) {
  if (dtype === "float32" || dtype === "int32" || dtype === "bool" || dtype === "string") {
    return 4;
  } else if (dtype === "complex64") {
    return 8;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function isWebGPUSupported() {
  return !!(typeof globalThis !== "undefined" && globalThis.navigator && globalThis.navigator.gpu);
}
function assertNotComplex(tensor2, opName) {
  if (!Array.isArray(tensor2)) {
    tensor2 = [tensor2];
  }
  tensor2.forEach((t2) => {
    if (t2 != null) {
      util_exports.assert(t2.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the WebGPU backend.`);
    }
  });
}
var MatMulProgramType;
(function(MatMulProgramType2) {
  MatMulProgramType2[MatMulProgramType2["MatMulReduceProgram"] = 0] = "MatMulReduceProgram";
  MatMulProgramType2[MatMulProgramType2["MatMulSplitKProgram"] = 1] = "MatMulSplitKProgram";
  MatMulProgramType2[MatMulProgramType2["MatMulSmallOutputSizeProgram"] = 2] = "MatMulSmallOutputSizeProgram";
  MatMulProgramType2[MatMulProgramType2["MatMulPackedProgram"] = 3] = "MatMulPackedProgram";
  MatMulProgramType2[MatMulProgramType2["MatMulMax"] = 4] = "MatMulMax";
})(MatMulProgramType || (MatMulProgramType = {}));

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/backend_webgpu.js
var CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD");
var reshapeDispatch = (device, program) => {
  const MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE = device.limits.maxComputeWorkgroupsPerDimension;
  const layout = program["dispatchLayout"];
  const dispatch = program["dispatch"];
  if (dispatch.every((d) => d <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE)) {
    return dispatch;
  }
  util_exports.assert(dispatch[0] > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE && layout.y === void 0 && layout.z === void 0, () => "Dispatch size exceeds WebGPU limits in Y or Z dimension.");
  let dispatchAverage = Math.ceil(Math.sqrt(dispatch[0]));
  if (dispatchAverage > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE) {
    dispatchAverage = Math.ceil(Math.cbrt(dispatch[0]));
    util_exports.assert(dispatchAverage <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE, () => "Total dispatch size exceeds WebGPU maximum.");
    return [dispatchAverage, dispatchAverage, dispatchAverage];
  } else {
    return [dispatchAverage, dispatchAverage, 1];
  }
};
var WebGPUBackend = class _WebGPUBackend extends KernelBackend {
  nextDataId() {
    return _WebGPUBackend.nextDataId++;
  }
  constructor(device, adapterInfo) {
    super();
    this.commandQueueOwnedIds = /* @__PURE__ */ new WeakSet();
    this.dispatchCountInPass = 0;
    this.disposed = false;
    this.downloadWaitMs = 0;
    this.tensorDataPendingDisposal = [];
    this.queryResolveBuffer = null;
    this.querySet = null;
    this.querySetCount = 2;
    this.stagingPendingDisposal = [];
    this.uniformPendingDisposal = [];
    this.uploadWaitMs = 0;
    this.hasReadSyncWarned = false;
    this.hasTimestampQueryWarned = false;
    if (!isWebGPUSupported()) {
      throw new Error("WebGPU is not supported on this device");
    }
    this.pipelineCache = {};
    this.device = device;
    this.queue = device.queue;
    this.commandEncoder = null;
    this.computePassEncoder = null;
    this.adapterInfo = new AdapterInfo(adapterInfo);
    this.supportTimestampQuery = this.device.features.has("timestamp-query");
    this.thresholdToIncreaseWorkgroups = this.adapterInfo.intelGPUGeneration >= 12 ? 16 : 8;
    this.bufferManager = new BufferManager(this.device);
    this.textureManager = new TextureManager(this.device);
    this.tensorMap = new DataStorage(this, engine());
    if (env().getBool("WEBGPU_USE_PROFILE_TOOL")) {
      this.dummyCanvas = document.createElement("canvas");
      this.dummyCanvas.width = 1;
      this.dummyCanvas.height = 1;
      this.dummyContext = this.dummyCanvas.getContext("webgpu");
      this.dummyContext.configure({
        device,
        format: "bgra8unorm"
      });
      document.body.appendChild(this.dummyCanvas);
    }
  }
  floatPrecision() {
    return 32;
  }
  /**
   * Dispose the memory if the dataId has 0 refCount. Return true if the memory
   * is released or delayed in this backend, false if there are still
   * references.
   * @param dataId
   * @oaram force Optional, remove the data regardless of refCount
   */
  disposeData(dataId, force = false) {
    if (!this.tensorMap.has(dataId)) {
      return true;
    }
    const tensorData = this.tensorMap.get(dataId);
    if (force) {
      tensorData.refCount = 0;
    } else {
      tensorData.refCount--;
    }
    if (tensorData.refCount > 0) {
      return false;
    }
    if (tensorData.complexTensorInfos != null) {
      this.disposeData(tensorData.complexTensorInfos.real.dataId);
      this.disposeData(tensorData.complexTensorInfos.imag.dataId);
    }
    if (this.commandQueueOwnedIds.has(dataId)) {
      this.tensorDataPendingDisposal.push(dataId);
      return true;
    }
    this.releaseResource(dataId);
    this.tensorMap.delete(dataId);
    return true;
  }
  memory() {
    return {
      numBytesInGPU: this.bufferManager.numBytesUsed,
      numBytesAllocatedInGPU: this.bufferManager.numBytesAllocated,
      unreliable: false
    };
  }
  releaseResource(dataId) {
    const tensorData = this.tensorMap.get(dataId);
    if (!tensorData || !tensorData.resource) {
      return;
    }
    if (tensorData.external) {
      tensorData.resource = null;
      return;
    }
    if (tensorData.resource instanceof GPUBuffer) {
      this.bufferManager.releaseBuffer(tensorData.resource);
    } else if (tensorData.resource instanceof GPUTexture) {
      this.textureManager.releaseTexture(tensorData.resource);
    }
    tensorData.resource = null;
  }
  /** Return refCount of a `TensorData`. */
  refCount(dataId) {
    if (this.tensorMap.has(dataId)) {
      const tensorData = this.tensorMap.get(dataId);
      return tensorData.refCount;
    }
    return 0;
  }
  /** Increase refCount of a `TensorData`. */
  incRef(dataId) {
    const tensorData = this.tensorMap.get(dataId);
    tensorData.refCount++;
  }
  /** Decrease refCount of a `TensorData`. */
  decRef(dataId) {
    if (this.tensorMap.has(dataId)) {
      const tensorData = this.tensorMap.get(dataId);
      tensorData.refCount--;
    }
  }
  write(values, shape, dtype) {
    if (dtype === "complex64" && values != null) {
      throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
    }
    const dataId = { id: this.nextDataId() };
    this.tensorMap.set(dataId, { dtype, shape, values, refCount: 1 });
    return dataId;
  }
  move(dataId, values, shape, dtype, refCount) {
    if (dtype === "complex64") {
      throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
    }
    this.tensorMap.set(dataId, { dtype, shape, values, refCount });
  }
  submitQueue() {
    this.queue.submit([this.commandEncoder.finish()]);
    this.commandEncoder = null;
    this.dispatchCountInPass = 0;
    this.commandQueueOwnedIds = /* @__PURE__ */ new WeakSet();
    this.tensorDataPendingDisposal.forEach((d) => {
      this.releaseResource(d);
      this.tensorMap.delete(d);
    });
    this.uniformPendingDisposal.forEach((b) => this.bufferManager.releaseBuffer(b));
    this.stagingPendingDisposal.forEach((b) => this.bufferManager.releaseBuffer(b, false));
    this.tensorDataPendingDisposal = [];
    this.uniformPendingDisposal = [];
    this.stagingPendingDisposal = [];
  }
  ensureCommandEncoderReady() {
    if (!this.commandEncoder) {
      this.commandEncoder = this.device.createCommandEncoder();
    }
  }
  endComputePassEncoder() {
    if (this.computePassEncoder) {
      this.computePassEncoder.end();
      this.computePassEncoder = null;
    }
  }
  // Check if parallel compilation is done.
  async checkCompileCompletionAsync() {
    let pipelines;
    try {
      pipelines = await Promise.all(Object.values(this.pipelineCache));
    } catch (e) {
      throw new Error(e.message);
    }
    Object.keys(this.pipelineCache).map((key, i) => {
      this.pipelineCache[key] = pipelines[i];
    });
  }
  async getBufferData(buffer2) {
    if (env().getBool("WEBGPU_ENGINE_COMPILE_ONLY")) {
      console.warn("The data may be invalid since WEBGPU_ENGINE_COMPILE_ONLY is true, this can only be called when WEBGPU_ENGINE_COMPILE_ONLY is false");
      return null;
    }
    const size = buffer2.size;
    const stagingBuffer = this.bufferManager.acquireBuffer(size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);
    this.ensureCommandEncoderReady();
    this.endComputePassEncoder();
    this.commandEncoder.copyBufferToBuffer(buffer2, 0, stagingBuffer, 0, size);
    this.submitQueue();
    await stagingBuffer.mapAsync(GPUMapMode.READ);
    const values = stagingBuffer.getMappedRange().slice(0);
    stagingBuffer.unmap();
    if (stagingBuffer != null) {
      this.bufferManager.releaseBuffer(stagingBuffer);
    }
    if (env().getBool("WEBGPU_USE_PROFILE_TOOL")) {
      util_exports.assert(this.dummyContext !== void 0, () => `Fail to get context for profiling tool`);
      this.dummyContext.getCurrentTexture();
    }
    return values;
  }
  convertAndCacheOnCPU(dataId, data) {
    const tensorData = this.tensorMap.get(dataId);
    tensorData.values = data;
    return tensorData.values;
  }
  readSync(dataId) {
    const tensorData = this.tensorMap.get(dataId);
    const { values, complexTensorInfos } = tensorData;
    if (values != null || tensorData.dtype === "string") {
      return values;
    }
    if (tensorData.dtype === "complex64") {
      const realValues = this.readSync(complexTensorInfos.real.dataId);
      const imagValues = this.readSync(complexTensorInfos.imag.dataId);
      const complexVals = util_exports.convertBackendValuesAndArrayBuffer(backend_util_exports.mergeRealAndImagArrays(realValues, imagValues).buffer, "float32");
      this.convertAndCacheOnCPU(dataId, complexVals);
      return complexVals;
    }
    if (!this.hasReadSyncWarned) {
      this.hasReadSyncWarned = true;
      console.warn(`The performance of synchronously reading data from GPU to CPU is poor on the webgpu backend, please use asynchronous APIs instead.`);
    }
    const alphaModes = ["opaque", "premultiplied"];
    const buffer2 = tensorData.resource;
    const bufferSize = buffer2.size;
    util_exports.assert(bufferSize % 4 === 0, () => "Because there is 4 bytes for one pixel, buffer size must be multiple of 4.");
    const pixelsSize = bufferSize / 4;
    const valsGPU = new ArrayBuffer(bufferSize);
    const canvasWidth = 256, canvasHeight = 256;
    const stagingDeviceStorage = alphaModes.map((_) => new OffscreenCanvas(canvasWidth, canvasHeight));
    const stagingHostStorage = new OffscreenCanvas(canvasWidth, canvasHeight);
    this.endComputePassEncoder();
    stagingDeviceStorage.map((storage, index) => {
      const context = storage.getContext("webgpu");
      context.configure({
        device: this.device,
        format: "bgra8unorm",
        usage: GPUTextureUsage.COPY_DST,
        alphaMode: alphaModes[index]
      });
      return context.getCurrentTexture();
    }).map((texture, index) => {
      const bytesPerRow = canvasWidth * 4;
      const readDataGPUToCPU = (width2, height2, offset2) => {
        this.ensureCommandEncoderReady();
        this.commandEncoder.copyBufferToTexture({
          buffer: buffer2,
          bytesPerRow,
          offset: offset2
        }, {
          texture
        }, {
          width: width2,
          height: height2
        });
        this.submitQueue();
        const context = stagingHostStorage.getContext("2d", {
          willReadFrequently: true
        });
        context.clearRect(0, 0, width2, height2);
        context.drawImage(stagingDeviceStorage[index], 0, 0);
        const stagingValues = context.getImageData(0, 0, width2, height2).data;
        const alphaMode = alphaModes[index];
        const span = new Uint8ClampedArray(valsGPU, offset2, width2 * height2 * 4);
        for (let k = 0; k < span.length; k += 4) {
          if (alphaMode === "premultiplied") {
            span[k + 3] = stagingValues[k + 3];
          } else {
            const value = stagingValues[k];
            span[k] = stagingValues[k + 2];
            span[k + 1] = stagingValues[k + 1];
            span[k + 2] = value;
          }
        }
      };
      const fullyReadCount = Math.floor(pixelsSize / (canvasWidth * canvasHeight));
      let width = canvasWidth, height = canvasHeight, offset = 0;
      for (let i = 0; i < fullyReadCount; i++) {
        readDataGPUToCPU(width, height, offset);
        offset += canvasWidth * canvasHeight * 4;
      }
      const remainSize = pixelsSize % (canvasWidth * canvasHeight);
      height = Math.floor(remainSize / canvasWidth);
      if (height > 0) {
        readDataGPUToCPU(width, height, offset);
        offset += height * (canvasWidth * 4);
      }
      width = remainSize % canvasWidth;
      if (width > 0) {
        readDataGPUToCPU(width, 1, offset);
      }
    });
    const vals = util_exports.convertBackendValuesAndArrayBuffer(valsGPU, tensorData.dtype);
    this.convertAndCacheOnCPU(dataId, vals);
    return vals;
  }
  async read(dataId) {
    if (!this.tensorMap.has(dataId)) {
      throw new Error(`Tensor ${dataId} was not registered!`);
    }
    const tensorData = this.tensorMap.get(dataId);
    const { values } = tensorData;
    if (values != null) {
      return values;
    }
    let vals;
    if (tensorData.dtype === "complex64") {
      const ps = await Promise.all([
        this.read(tensorData.complexTensorInfos.real.dataId),
        this.read(tensorData.complexTensorInfos.imag.dataId)
      ]);
      const realValues = ps[0];
      const imagValues = ps[1];
      vals = backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
    } else {
      const data = await this.getBufferData(tensorData.resource);
      vals = util_exports.convertBackendValuesAndArrayBuffer(data, tensorData.dtype);
    }
    this.convertAndCacheOnCPU(dataId, vals);
    return vals;
  }
  // The source GPUBuffer and destination GPUBuffer have the same size and
  // usage.
  copyBuffer(srcBuffer) {
    const size = srcBuffer.size;
    const usage = srcBuffer.usage;
    const dstBuffer = this.bufferManager.acquireBuffer(size, usage);
    this.ensureCommandEncoderReady();
    this.endComputePassEncoder();
    this.commandEncoder.copyBufferToBuffer(srcBuffer, 0, dstBuffer, 0, size);
    this.submitQueue();
    return dstBuffer;
  }
  /**
   * Create a TF.js tensor out of an existing WebGPU buffer.
   */
  createTensorFromGPUData(webGPUData, shape, dtype) {
    let buffer2 = webGPUData.buffer;
    if (dtype === "complex64") {
      throw new Error(`Cannot write to a complex64 dtype. `);
    }
    const dataId = { id: this.nextDataId() };
    this.tensorMap.set(dataId, {
      dtype,
      shape,
      values: null,
      refCount: 1,
      external: webGPUData.zeroCopy
    });
    const tensorData = this.tensorMap.get(dataId);
    const size = GPUBytesPerElement(tensorData.dtype) * util_exports.sizeFromShape(tensorData.shape);
    if (webGPUData.buffer.size < size) {
      throw new Error(`GPUBuffer size(${webGPUData.buffer.size}) is smaller than tensor size(${size})!`);
    } else if ((webGPUData.buffer.usage & (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) !== (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) {
      throw new Error("GPUBuffer.usage should include GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC!");
    }
    if (webGPUData.zeroCopy !== true) {
      buffer2 = this.copyBuffer(buffer2);
    }
    tensorData.resource = buffer2;
    return engine().makeTensorFromDataId(dataId, shape, dtype, this);
  }
  /**
   * Read tensor to a new GPUBuffer.
   * @param dataId The source tensor.
   */
  readToGPU(dataId) {
    const srcTensorData = this.tensorMap.get(dataId);
    const { values, dtype, shape, resource } = srcTensorData;
    if (dtype === "complex64") {
      throw new Error("Does not support reading buffer for complex64 dtype.");
    }
    if (resource == null) {
      if (values != null) {
        throw new Error("Data is not on GPU but on CPU.");
      } else {
        throw new Error("There is no data on GPU or CPU.");
      }
    }
    const srcBuffer = resource;
    const size = srcBuffer.size;
    const usage = srcBuffer.usage;
    const buffer2 = this.bufferManager.acquireBuffer(size, usage);
    this.ensureCommandEncoderReady();
    this.endComputePassEncoder();
    this.commandEncoder.copyBufferToBuffer(resource, 0, buffer2, 0, size);
    this.submitQueue();
    const tensorInfo = this.makeTensorInfo(shape, dtype);
    const tensorRef = engine().makeTensorFromTensorInfo(tensorInfo);
    const tensorData = this.tensorMap.get(tensorInfo.dataId);
    tensorData.resource = buffer2;
    return { tensorRef, buffer: buffer2 };
  }
  bufferSync(t2) {
    const data = this.readSync(t2.dataId);
    if (t2.dtype === "string") {
      try {
        const strings = data.map((d) => util_exports.decodeString(d));
        return buffer(t2.shape, t2.dtype, strings);
      } catch (_a) {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    }
    return buffer(t2.shape, t2.dtype, data);
  }
  async time(f) {
    if (!this.supportTimestampQuery && !this.hasTimestampQueryWarned) {
      console.warn(`This device doesn't support timestamp-query extension. Start Chrome browser with flag --enable-dawn-features=allow_unsafe_apis to try it again. Otherwise, zero will be shown for the kernel time when profiling mode is enabled.`);
      this.hasTimestampQueryWarned = true;
    }
    const oldActiveTimers = this.activeTimers;
    const newActiveTimers = [];
    let outerMostTime = false;
    if (this.programTimersStack == null) {
      this.programTimersStack = newActiveTimers;
      outerMostTime = true;
    } else {
      this.activeTimers.push(newActiveTimers);
    }
    this.activeTimers = newActiveTimers;
    f();
    const flattenedActiveTimerQueries = util_exports.flatten(this.activeTimers.map((d) => d.query)).filter((d) => d != null);
    const flattenedActiveTimerNames = util_exports.flatten(this.activeTimers.map((d) => d.name)).filter((d) => d != null);
    this.activeTimers = oldActiveTimers;
    if (outerMostTime) {
      this.programTimersStack = null;
    }
    const res = {
      uploadWaitMs: this.uploadWaitMs,
      downloadWaitMs: this.downloadWaitMs,
      kernelMs: null,
      wallMs: null
    };
    const kernelMs = await Promise.all(flattenedActiveTimerQueries);
    res["kernelMs"] = util_exports.sum(kernelMs);
    res["getExtraProfileInfo"] = () => kernelMs.map((d, i) => ({ name: flattenedActiveTimerNames[i], ms: d })).map((d) => `${d.name}: ${d.ms}`).join(", ");
    this.uploadWaitMs = 0;
    this.downloadWaitMs = 0;
    return res;
  }
  makeTensorInfo(shape, dtype, values) {
    if (dtype === "string" && values != null && values.length > 0 && util_exports.isString(values[0])) {
      values = values.map((d) => util_exports.encodeString(d));
    }
    const dataId = this.write(values, shape, dtype);
    return { dataId, shape, dtype };
  }
  tensorToBinding(tensor2) {
    if (!tensor2) {
      return null;
    }
    const tensorData = this.tensorMap.get(tensor2.dataId);
    const resource = tensorData.resource;
    if (resource instanceof GPUBuffer) {
      return { buffer: resource };
    }
    if (resource instanceof GPUTexture) {
      return resource.createView();
    }
    return resource;
  }
  uploadToGPU(dataId) {
    const tensorData = this.tensorMap.get(dataId);
    if (tensorData.resource != null) {
      return;
    }
    const size = GPUBytesPerElement(tensorData.dtype) * util_exports.sizeFromShape(tensorData.shape);
    let buffer2;
    const usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST;
    if (tensorData.values) {
      buffer2 = this.bufferManager.acquireBuffer(size, usage, true);
      if (buffer2.mapState === "unmapped") {
        const stagingBuffer = this.bufferManager.acquireBuffer(size, GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC, true, false);
        const arrayBuffer = stagingBuffer.getMappedRange();
        if (tensorData.dtype === "int32" || tensorData.dtype === "bool") {
          new Int32Array(arrayBuffer).set(tensorData.values);
        } else {
          new Float32Array(arrayBuffer).set(tensorData.values);
        }
        stagingBuffer.unmap();
        this.ensureCommandEncoderReady();
        this.endComputePassEncoder();
        this.commandEncoder.copyBufferToBuffer(stagingBuffer, 0, buffer2, 0, size);
        this.stagingPendingDisposal.push(stagingBuffer);
      } else {
        const arrayBuffer = buffer2.getMappedRange();
        if (tensorData.dtype === "int32" || tensorData.dtype === "bool") {
          new Int32Array(arrayBuffer).set(tensorData.values);
        } else {
          new Float32Array(arrayBuffer).set(tensorData.values);
        }
        buffer2.unmap();
      }
      tensorData.values = null;
    } else {
      buffer2 = this.bufferManager.acquireBuffer(size, usage);
    }
    tensorData.resource = buffer2;
  }
  makeUniforms(programUniform) {
    let currentOffset = 0;
    let preLength = 0;
    const offsets = [];
    let maxAlignmentOfField = 1;
    programUniform.forEach((d) => {
      if (d.data.length === 0) {
        d.data = [1];
      }
      let baseAlignment;
      switch (d.data.length) {
        case 1:
          baseAlignment = 4;
          break;
        case 2:
          baseAlignment = 8;
          break;
        case 3:
          baseAlignment = 16;
          break;
        case 4:
          baseAlignment = 16;
          break;
        case 5:
          baseAlignment = 16;
          break;
        case 6:
          baseAlignment = 16;
          break;
        default:
          util_exports.assert(false, () => `Unsupported ${d.data.length}D shape`);
      }
      if (preLength === 5 || preLength === 6) {
        baseAlignment = 16;
      }
      if (baseAlignment > maxAlignmentOfField) {
        maxAlignmentOfField = baseAlignment;
      }
      currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;
      preLength = d.data.length;
      offsets.push(currentOffset);
      currentOffset += d.data.length * 4;
    });
    currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;
    const arrayBuffer = new ArrayBuffer(currentOffset);
    programUniform.forEach((d, i) => {
      const offset = offsets[i];
      if (d.type === "int32") {
        new Int32Array(arrayBuffer, offset, d.data.length).set(d.data);
      } else if (d.type === "uint32") {
        new Uint32Array(arrayBuffer, offset, d.data.length).set(d.data);
      } else {
        new Float32Array(arrayBuffer, offset, d.data.length).set(d.data);
      }
    });
    const uniformBuffer = this.bufferManager.acquireBuffer(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);
    this.queue.writeBuffer(uniformBuffer, 0, arrayBuffer, 0, currentOffset);
    this.uniformPendingDisposal.push(uniformBuffer);
    return { offset: 0, size: currentOffset, buffer: uniformBuffer };
  }
  runWebGPUProgram(program, inputs, outputDtype, programDefinedUniform, output) {
    if (!output) {
      output = this.makeTensorInfo(program.outputShape, outputDtype);
    }
    if (util_exports.sizeFromShape(output.shape) === 0) {
      this.tensorMap.get(output.dataId).values = util_exports.getTypedArrayFromDType(output.dtype, 0);
      return output;
    }
    this.uploadToGPU(output.dataId);
    program.dispatch = reshapeDispatch(this.device, program);
    const inputsData = inputs.map((input, i) => {
      if (input.dtype === "complex64") {
        throw new Error(`GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.`);
      }
      this.uploadToGPU(input.dataId);
      return {
        // Returning dtype from tensorMap because it reflects dtype
        // of underlying buffer, rather than abstract dtype.
        dtype: this.tensorMap.get(input.dataId).dtype,
        shape: input.shape,
        name: program.variableNames[i]
      };
    });
    program.shaderKey = makeShaderKey(program, inputsData, output);
    const parallelCompilation = env().getBool("WEBGPU_ENGINE_COMPILE_ONLY");
    if (!(program.shaderKey in this.pipelineCache)) {
      this.pipelineCache[program.shaderKey] = compileProgram(this.device, program, inputsData, output, parallelCompilation);
    }
    program.pipeline = this.pipelineCache[program.shaderKey];
    if (!parallelCompilation) {
      this.recordAndSubmit(program, output, inputs, programDefinedUniform);
    }
    return output;
  }
  recordAndSubmit(program, output, inputs, programDefinedUniform) {
    if (program.pipeline instanceof Promise) {
      throw new Error("Please call checkCompileCompletionAsync to ensure parallel compilation is done!");
    }
    let programUniform = [];
    let bufferShapes = [];
    const uniformsType = "int32";
    if (program.pixelsOpType == null) {
      programUniform.push({ type: "float32", data: [NaN] }, { type: "float32", data: [Infinity] });
      bufferShapes = inputs.concat(output).map((d) => d.shape);
      const uniformsType2 = "int32";
      bufferShapes.map((d) => {
        programUniform.push({ type: uniformsType2, data: d });
        const strides = util_exports.computeStrides(d);
        programUniform.push({ type: uniformsType2, data: strides });
      });
    } else {
      const strides = util_exports.computeStrides(output.shape);
      programUniform.push({ type: uniformsType, data: strides });
    }
    if (program.size) {
      const size = util_exports.sizeFromShape(program.outputShape);
      programUniform.push({
        type: uniformsType,
        data: [program.outputComponent ? size / program.outputComponent : size]
      });
    }
    if (programDefinedUniform) {
      programUniform = [...programUniform, ...programDefinedUniform];
    }
    const bindings = [
      this.tensorToBinding(output),
      ...inputs.map((t2) => this.tensorToBinding(t2)),
      this.makeUniforms(programUniform)
    ];
    inputs.forEach((input) => {
      this.commandQueueOwnedIds.add(input.dataId);
    });
    this.commandQueueOwnedIds.add(output.dataId);
    const bindGroup = this.device.createBindGroup({
      layout: program.pipeline.getBindGroupLayout(0),
      entries: bindings.map((b, i) => ({ binding: i, resource: b }))
    });
    const shouldTimeProgram = this.activeTimers != null;
    this.ensureCommandEncoderReady();
    const computePassDescriptor = {};
    if (shouldTimeProgram && this.supportTimestampQuery) {
      this.endComputePassEncoder();
      if (this.querySet == null) {
        this.querySet = this.device.createQuerySet({
          type: "timestamp",
          count: this.querySetCount
        });
      }
      computePassDescriptor.timestampWrites = {
        querySet: this.querySet,
        beginningOfPassWriteIndex: 0,
        endOfPassWriteIndex: 1
      };
      this.computePassEncoder = this.commandEncoder.beginComputePass(computePassDescriptor);
    } else if (!this.computePassEncoder) {
      this.computePassEncoder = this.commandEncoder.beginComputePass(computePassDescriptor);
    }
    this.computePassEncoder.setPipeline(program.pipeline);
    this.computePassEncoder.setBindGroup(0, bindGroup);
    this.computePassEncoder.dispatchWorkgroups(program.dispatch[0], program.dispatch[1], program.dispatch[2]);
    this.dispatchCountInPass++;
    if (shouldTimeProgram || env().get("WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE") <= this.dispatchCountInPass || program.pixelsOpType === PixelsOpType.DRAW) {
      this.endComputePassEncoder();
      if (shouldTimeProgram) {
        this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime() });
      } else {
        this.submitQueue();
      }
    }
  }
  async getQueryTime() {
    if (!this.supportTimestampQuery) {
      return 0;
    }
    if (this.queryResolveBuffer == null) {
      this.queryResolveBuffer = this.bufferManager.acquireBuffer(this.querySetCount * 8, GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST | GPUBufferUsage.QUERY_RESOLVE);
    }
    this.commandEncoder.resolveQuerySet(this.querySet, 0, this.querySetCount, this.queryResolveBuffer, 0);
    const queryStagingBuffer = this.bufferManager.acquireBuffer(this.querySetCount * 8, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);
    this.commandEncoder.copyBufferToBuffer(this.queryResolveBuffer, 0, queryStagingBuffer, 0, this.querySetCount * 8);
    this.submitQueue();
    await queryStagingBuffer.mapAsync(GPUMapMode.READ);
    const arrayBuffer = new BigUint64Array(queryStagingBuffer.getMappedRange());
    const time = Number(arrayBuffer[1] - arrayBuffer[0]) / 1e6;
    queryStagingBuffer.unmap();
    this.bufferManager.releaseBuffer(queryStagingBuffer);
    return time;
  }
  shouldExecuteOnCPU(inputs, sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD) {
    return env().getBool("WEBGPU_CPU_FORWARD") && inputs.every((input) => this.tensorMap.get(input.dataId).resource == null && util_exports.sizeFromShape(input.shape) < sizeThreshold);
  }
  numDataIds() {
    return this.tensorMap.numDataIds() - this.tensorDataPendingDisposal.length;
  }
  dispose() {
    if (this.disposed) {
      return;
    }
    if (this.querySet != null) {
      this.querySet.destroy();
    }
    this.bufferManager.dispose();
    this.textureManager.dispose();
    this.disposed = true;
  }
};
WebGPUBackend.nextDataId = 0;

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/base.js
if (isWebGPUSupported()) {
  registerBackend(
    "webgpu",
    async () => {
      const gpuDescriptor = {
        powerPreference: env().get("WEBGPU_USE_LOW_POWER_GPU") ? "low-power" : "high-performance"
      };
      const adapter = await navigator.gpu.requestAdapter(gpuDescriptor);
      const deviceDescriptor = {};
      const requiredFeatures = [];
      if (adapter.features.has("timestamp-query")) {
        requiredFeatures.push("timestamp-query");
      }
      if (adapter.features.has("bgra8unorm-storage")) {
        requiredFeatures.push(["bgra8unorm-storage"]);
      }
      deviceDescriptor.requiredFeatures = requiredFeatures;
      const adapterLimits = adapter.limits;
      deviceDescriptor.requiredLimits = {
        "maxComputeWorkgroupStorageSize": adapterLimits.maxComputeWorkgroupStorageSize,
        "maxComputeWorkgroupsPerDimension": adapterLimits.maxComputeWorkgroupsPerDimension,
        "maxStorageBufferBindingSize": adapterLimits.maxStorageBufferBindingSize,
        "maxBufferSize": adapterLimits.maxBufferSize,
        "maxComputeWorkgroupSizeX": adapterLimits.maxComputeWorkgroupSizeX,
        "maxComputeInvocationsPerWorkgroup": adapterLimits.maxComputeInvocationsPerWorkgroup
      };
      const device = await adapter.requestDevice(deviceDescriptor);
      const adapterInfo = "info" in adapter ? adapter.info : "requestAdapterInfo" in adapter ? await adapter.requestAdapterInfo() : void 0;
      return new WebGPUBackend(device, adapterInfo);
    },
    3
    /*priority*/
  );
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/binary_op_util.js
var BinaryOpType;
(function(BinaryOpType2) {
  BinaryOpType2[BinaryOpType2["ADD"] = 0] = "ADD";
  BinaryOpType2[BinaryOpType2["ATAN2"] = 1] = "ATAN2";
  BinaryOpType2[BinaryOpType2["COMPLEX_MULTIPLY_IMAG"] = 2] = "COMPLEX_MULTIPLY_IMAG";
  BinaryOpType2[BinaryOpType2["COMPLEX_MULTIPLY_REAL"] = 3] = "COMPLEX_MULTIPLY_REAL";
  BinaryOpType2[BinaryOpType2["DIV"] = 4] = "DIV";
  BinaryOpType2[BinaryOpType2["ELU_DER"] = 5] = "ELU_DER";
  BinaryOpType2[BinaryOpType2["EQUAL"] = 6] = "EQUAL";
  BinaryOpType2[BinaryOpType2["FLOOR_DIV"] = 7] = "FLOOR_DIV";
  BinaryOpType2[BinaryOpType2["GREATER"] = 8] = "GREATER";
  BinaryOpType2[BinaryOpType2["GREATER_EQUAL"] = 9] = "GREATER_EQUAL";
  BinaryOpType2[BinaryOpType2["LESS"] = 10] = "LESS";
  BinaryOpType2[BinaryOpType2["LESS_EQUAL"] = 11] = "LESS_EQUAL";
  BinaryOpType2[BinaryOpType2["LOGICAL_AND"] = 12] = "LOGICAL_AND";
  BinaryOpType2[BinaryOpType2["LOGICAL_OR"] = 13] = "LOGICAL_OR";
  BinaryOpType2[BinaryOpType2["MAX"] = 14] = "MAX";
  BinaryOpType2[BinaryOpType2["MIN"] = 15] = "MIN";
  BinaryOpType2[BinaryOpType2["MOD"] = 16] = "MOD";
  BinaryOpType2[BinaryOpType2["MUL"] = 17] = "MUL";
  BinaryOpType2[BinaryOpType2["NOT_EQUAL"] = 18] = "NOT_EQUAL";
  BinaryOpType2[BinaryOpType2["POW"] = 19] = "POW";
  BinaryOpType2[BinaryOpType2["PRELU"] = 20] = "PRELU";
  BinaryOpType2[BinaryOpType2["SQUARED_DIFFERENCE"] = 21] = "SQUARED_DIFFERENCE";
  BinaryOpType2[BinaryOpType2["SUB"] = 22] = "SUB";
})(BinaryOpType || (BinaryOpType = {}));
var ADD = "let resultTemp = a + b;";
var ATAN2 = "let resultTemp = atan2(a, b);";
var COMPLEX_MULTIPLY_REAL = "let resultTemp = areal * breal - aimag * bimag;";
var COMPLEX_MULTIPLY_IMAG = "let resultTemp = areal * bimag + aimag * breal;";
var DIV = "let resultTemp = a / b;";
var ELU_DER = "let resultTemp = select(a * (b + 1.0), a, b >= b - b);";
var EQUAL = `
  let zero = sign(a) * 0 + 0;
  let one = sign(b) * 0 + 1;
  let resultTemp = select(zero, one, a == b);
`;
var FLOOR_DIV = `
  let remainder =
      select(a % b, round(a % b), (round(a) == a) & (round(b) == b));
  let quotient = (a - remainder) / b;
  let resultTemp =
      round(select(quotient, quotient - 1, sign(remainder) == -sign(b)));
`;
var GREATER = `
  let zero = sign(a) * 0 + 0;
  let one = sign(b) * 0 + 1;
  let resultTemp = select(zero, one, a > b);
`;
var GREATER_EQUAL = `
  let zero = sign(a) * 0 + 0;
  let one = sign(b) * 0 + 1;
  let resultTemp = select(zero, one, a >= b);
`;
var LESS = `
  let zero = sign(a) * 0 + 0;
  let one = sign(b) * 0 + 1;
  let resultTemp = select(zero, one, a < b);
`;
var LESS_EQUAL = `
  let zero = sign(a) * 0 + 0;
  let one = sign(b) * 0 + 1;
  let resultTemp = select(zero, one, a <= b);
`;
var LOGICAL_AND = "return f32(a >= 1.0 && b >= 1.0);";
var LOGICAL_AND_VEC4 = `return (vec4<f32>(a >= vec4<f32>(1.0)) *
  vec4<f32>(b >= vec4<f32>(1.0)));`;
var LOGICAL_OR = "return f32(a >= 1.0 || b >= 1.0);";
var LOGICAL_OR_VEC4 = `return min(vec4<f32>(a >= vec4<f32>(1.0)) +
  vec4<f32>(b >= vec4<f32>(1.0)), vec4<f32>(1.0));`;
var MAX = "let resultTemp = max(a, b);";
var MIN = "let resultTemp = min(a, b);";
var MOD = `
  let isNaN = b == 0.;
  var resultTemp = a % b;
  resultTemp = select((resultTemp + b) % b, resultTemp,
      (a < 0. && b < 0.) || (a >= 0. && b > 0.));
`;
var MOD_VEC4 = `
  let isNaN = !vec4<bool>(b);
  var resultTemp = vec4<f32>(a % b);
  if (!((a[0] < 0. && b[0] < 0.) || (a[0] >= 0. && b[0] > 0.))) {
    resultTemp[0] = (resultTemp[0] + b[0]) % b[0];
  }
  if (!((a[1] < 0. && b[1] < 0.) || (a[1] >= 0. && b[1] > 0.))) {
    resultTemp[1] = (resultTemp[1] + b[1]) % b[1];
  }
  if (!((a[2] < 0. && b[2] < 0.) || (a[2] >= 0. && b[2] > 0.))) {
    resultTemp[2] = (resultTemp[2] + b[2]) % b[2];
  }
  if (!((a[3] < 0. && b[3] < 0.) || (a[3] >= 0. && b[3] > 0.))) {
    resultTemp[3] = (resultTemp[3] + b[3]) % b[3];
  }
`;
var MUL = "let resultTemp = a * b;";
var NOT_EQUAL = `
  var resultTemp = f32(a != b);
  let valueForNaN = 1.0;
`;
var NOT_EQUAL_VEC4 = `
  var resultTemp = vec4<f32>(a != b);
  let valueForNaN = 1.0;
`;
var POW = `
  let isNaN = a < 0.0 && floor(b) < b;
  if (b == 0.0) {
    return 1.0;
  }
  var resultTemp = select(sign(a) * pow(abs(a), b), pow(abs(a), b),
      round(abs(b) % 2.0) != 1.0);
`;
var POW_VEC4 = `
  let isModRound1Bool = vec4<i32>(round(abs(b) % vec4<f32>(2.0))) == vec4<i32>(1);
  let isModRound1 = vec4<f32>(isModRound1Bool);
  let multiplier = sign(a) * isModRound1 + (vec4<f32>(1.0) - isModRound1);
  var resultTemp = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  let isExpZero = b == vec4<f32>(0.0);
  if (isExpZero.r) {
    resultTemp.r = 1.0;
  }
  if (isExpZero.g) {
    resultTemp.g = 1.0;
  }
  if (isExpZero.b) {
    resultTemp.b = 1.0;
  }
  if (isExpZero.a) {
    resultTemp.a = 1.0;
  }
  let isNaN = (a < vec4<f32>(0.0)) & (floor(b) < b);
`;
var PRELU = `if (a < 0.0) { return b * a; }  return a;`;
var PRELU_VEC4 = `
  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));
  return (aLessThanZero * (b * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);
`;
var SQUARED_DIFFERENCE = "let resultTemp = (a - b) * (a - b);";
var SUB = "let resultTemp = a - b;";
function getBinaryOpString(type, useVec4) {
  let doOpSnippet;
  do {
    switch (type) {
      case BinaryOpType.ATAN2:
        doOpSnippet = ATAN2;
        break;
      case BinaryOpType.MAX:
        doOpSnippet = MAX;
        break;
      case BinaryOpType.MIN:
        doOpSnippet = MIN;
        break;
      case BinaryOpType.MOD:
        doOpSnippet = useVec4 ? MOD_VEC4 : MOD;
        break;
      case BinaryOpType.NOT_EQUAL:
        doOpSnippet = useVec4 ? NOT_EQUAL_VEC4 : NOT_EQUAL;
        break;
      case BinaryOpType.POW:
        doOpSnippet = useVec4 ? POW_VEC4 : POW;
        break;
      default:
        continue;
    }
    let isNaN4;
    let dTypeN;
    let boolN;
    if (useVec4) {
      isNaN4 = "isnanVec4";
      dTypeN = "vec4<f32>";
      boolN = "vec4<bool>";
    } else {
      isNaN4 = "isnan";
      dTypeN = "f32";
      boolN = "bool";
    }
    return `
      let aIsNaN = ${isNaN4}(a);
      let aPostLegalization = select(a, ${dTypeN}(42), aIsNaN);
      let bIsNaN = ${isNaN4}(b);
      let bPostLegalization = select(b, ${dTypeN}(42), bIsNaN);
      let isNaN = false;
      let valueForNaN = uniforms.NAN;
      {
        let a = aPostLegalization;
        let b = bPostLegalization;
        ${doOpSnippet}
        return select(
            resultTemp, ${dTypeN}(valueForNaN),
            ${boolN}(isNaN) | aIsNaN | bIsNaN);
      }
    `;
  } while (false);
  switch (type) {
    case BinaryOpType.ADD:
      doOpSnippet = ADD;
      break;
    case BinaryOpType.COMPLEX_MULTIPLY_IMAG:
      doOpSnippet = COMPLEX_MULTIPLY_IMAG;
      break;
    case BinaryOpType.COMPLEX_MULTIPLY_REAL:
      doOpSnippet = COMPLEX_MULTIPLY_REAL;
      break;
    case BinaryOpType.DIV:
      doOpSnippet = DIV;
      break;
    case BinaryOpType.ELU_DER:
      doOpSnippet = ELU_DER;
      break;
    case BinaryOpType.EQUAL:
      doOpSnippet = EQUAL;
      break;
    case BinaryOpType.FLOOR_DIV:
      doOpSnippet = FLOOR_DIV;
      break;
    case BinaryOpType.GREATER:
      doOpSnippet = GREATER;
      break;
    case BinaryOpType.GREATER_EQUAL:
      doOpSnippet = GREATER_EQUAL;
      break;
    case BinaryOpType.LESS:
      doOpSnippet = LESS;
      break;
    case BinaryOpType.LESS_EQUAL:
      doOpSnippet = LESS_EQUAL;
      break;
    case BinaryOpType.LOGICAL_AND:
      return useVec4 ? LOGICAL_AND_VEC4 : LOGICAL_AND;
    case BinaryOpType.LOGICAL_OR:
      return useVec4 ? LOGICAL_OR_VEC4 : LOGICAL_OR;
    case BinaryOpType.MUL:
      doOpSnippet = MUL;
      break;
    case BinaryOpType.PRELU:
      return useVec4 ? PRELU_VEC4 : PRELU;
    case BinaryOpType.SQUARED_DIFFERENCE:
      doOpSnippet = SQUARED_DIFFERENCE;
      break;
    case BinaryOpType.SUB:
      doOpSnippet = SUB;
      break;
    default:
  }
  return `
    ${doOpSnippet}
    return resultTemp;
  `;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/unary_op_util.js
var UnaryOpType;
(function(UnaryOpType2) {
  UnaryOpType2[UnaryOpType2["ABS"] = 0] = "ABS";
  UnaryOpType2[UnaryOpType2["ACOS"] = 1] = "ACOS";
  UnaryOpType2[UnaryOpType2["ACOSH"] = 2] = "ACOSH";
  UnaryOpType2[UnaryOpType2["ASIN"] = 3] = "ASIN";
  UnaryOpType2[UnaryOpType2["ASINH"] = 4] = "ASINH";
  UnaryOpType2[UnaryOpType2["ATAN"] = 5] = "ATAN";
  UnaryOpType2[UnaryOpType2["ATANH"] = 6] = "ATANH";
  UnaryOpType2[UnaryOpType2["CEIL"] = 7] = "CEIL";
  UnaryOpType2[UnaryOpType2["COS"] = 8] = "COS";
  UnaryOpType2[UnaryOpType2["COSH"] = 9] = "COSH";
  UnaryOpType2[UnaryOpType2["ELU"] = 10] = "ELU";
  UnaryOpType2[UnaryOpType2["ERF"] = 11] = "ERF";
  UnaryOpType2[UnaryOpType2["EXP"] = 12] = "EXP";
  UnaryOpType2[UnaryOpType2["EXPM1"] = 13] = "EXPM1";
  UnaryOpType2[UnaryOpType2["FLOOR"] = 14] = "FLOOR";
  UnaryOpType2[UnaryOpType2["IS_FINITE"] = 15] = "IS_FINITE";
  UnaryOpType2[UnaryOpType2["IS_INF"] = 16] = "IS_INF";
  UnaryOpType2[UnaryOpType2["IS_NAN"] = 17] = "IS_NAN";
  UnaryOpType2[UnaryOpType2["LINEAR"] = 18] = "LINEAR";
  UnaryOpType2[UnaryOpType2["LOG"] = 19] = "LOG";
  UnaryOpType2[UnaryOpType2["LOG1P"] = 20] = "LOG1P";
  UnaryOpType2[UnaryOpType2["LOGICAL_NOT"] = 21] = "LOGICAL_NOT";
  UnaryOpType2[UnaryOpType2["NEG"] = 22] = "NEG";
  UnaryOpType2[UnaryOpType2["RELU"] = 23] = "RELU";
  UnaryOpType2[UnaryOpType2["RELU6"] = 24] = "RELU6";
  UnaryOpType2[UnaryOpType2["LEAKYRELU"] = 25] = "LEAKYRELU";
  UnaryOpType2[UnaryOpType2["RECIPROCAL"] = 26] = "RECIPROCAL";
  UnaryOpType2[UnaryOpType2["ROUND"] = 27] = "ROUND";
  UnaryOpType2[UnaryOpType2["RSQRT"] = 28] = "RSQRT";
  UnaryOpType2[UnaryOpType2["SELU"] = 29] = "SELU";
  UnaryOpType2[UnaryOpType2["SIGMOID"] = 30] = "SIGMOID";
  UnaryOpType2[UnaryOpType2["SIGN"] = 31] = "SIGN";
  UnaryOpType2[UnaryOpType2["SIN"] = 32] = "SIN";
  UnaryOpType2[UnaryOpType2["SINH"] = 33] = "SINH";
  UnaryOpType2[UnaryOpType2["SOFTPLUS"] = 34] = "SOFTPLUS";
  UnaryOpType2[UnaryOpType2["SQRT"] = 35] = "SQRT";
  UnaryOpType2[UnaryOpType2["SQUARE"] = 36] = "SQUARE";
  UnaryOpType2[UnaryOpType2["STEP"] = 37] = "STEP";
  UnaryOpType2[UnaryOpType2["TAN"] = 38] = "TAN";
  UnaryOpType2[UnaryOpType2["TANH"] = 39] = "TANH";
  UnaryOpType2[UnaryOpType2["TO_INT"] = 40] = "TO_INT";
})(UnaryOpType || (UnaryOpType = {}));
var ABS = `return abs(a);`;
var ACOS = `
  if (abs(a) > 1.) {
    return uniforms.NAN;
  }
  return acos(a);
`;
var ACOSH = `
  if (a < 1.) {
    return uniforms.NAN;
  }
  return acosh(a);
`;
var ASIN = `
  if (abs(a) > 1.) {
    return uniforms.NAN;
  }
  return asin(a);
`;
var ASINH = `return asinh(a);`;
var ATAN = `
  if (isnan(a)) {
    return uniforms.NAN;
  }
  return atan(a);
`;
var ATANH = `
  if (abs(a) > 1.) {
    return uniforms.NAN;
  }
  if (a == 1.) {
    return uniforms.INFINITY;
  }
  if (a == -1.) {
    return -uniforms.INFINITY;
  }
  return atanh(a);
`;
var CEIL = `return ceil(a);`;
var COS = `return cos(a);`;
var COSH = `
  let e2x = exp(-a);
  return (e2x + 1.0 / e2x) / 2.0;
`;
var EXPM1 = `return exp(a) - 1.0;`;
var ELU = `if (a >= 0.0) { return a; }  return (exp(a) - 1.0);`;
var ELU_VEC4 = `
  var resFloat = exp(a) - vec4<f32>(1.0);
  if (a.r >= 0.0) {
    resFloat.r = a.r;
  }
  if (a.g >= 0.0) {
    resFloat.g = a.g;
  }
  if (a.b >= 0.0) {
    resFloat.b = a.b;
  }
  if (a.a >= 0.0) {
    resFloat.a = a.a;
  }
  return resFloat;
`;
var ERF = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  let p = ${backend_util_exports.ERF_P};
  let a1 = ${backend_util_exports.ERF_A1};
  let a2 = ${backend_util_exports.ERF_A2};
  let a3 = ${backend_util_exports.ERF_A3};
  let a4 = ${backend_util_exports.ERF_A4};
  let a5 = ${backend_util_exports.ERF_A5};

  let sign = sign(a);
  let absA = abs(a);
  let t = 1.0 / (1.0 + p * absA);
  return sign * (1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * exp(-absA * absA));
`;
var EXP = `return exp(a);`;
var FLOOR = `return floor(a);`;
var IS_FINITE = `return f32(!isnan(a) && !isinf(a));`;
var IS_INF = `return f32(isinf(a));`;
var IS_NAN = `return f32(isnan(a));`;
var LINEAR = `return a;`;
var LOG = `if (a < 0.0) { return uniforms.NAN; }
  return log(a);`;
var LOG1P = `
  if (isnan(a)) { return a; }
  return log(1.0 + a);
`;
var LOGICAL_NOT = `return f32(!(a >= 1.0));`;
var NEG = `return -a;`;
var LEAKYRELU = `if (a < 0.0) { return uniforms.alpha * a; } return a;`;
var LEAKYRELU_VEC4 = `
  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));
  return (aLessThanZero * (uniforms.alpha * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);
`;
var RECIPROCAL = `return 1.0 / a;`;
var RELU = `return select(a, 0.0, a < 0.0);`;
var RELU6 = "return clamp(a, 0.0, 6.0);";
var RELU6_VEC4 = "return clamp(a, vec4<f32>(0.0, 0.0, 0.0, 0.0), vec4<f32>(6.0, 6.0, 6.0, 6.0));";
var RELU_VEC4 = `
  return select(a, vec4<f32>(0.0), a < vec4<f32>(0.0));
`;
var ROUND = `return round(a);`;
var RSQRT = `return inverseSqrt(a);`;
var SELU = `
  if (a >= 0.0) {
    return ${backend_util_exports.SELU_SCALE} * a;
  } else {
    return ${backend_util_exports.SELU_SCALEALPHA} * (exp(a) - 1.0);
  }
`;
var SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * a));`;
var SIGN = `return sign(a);`;
var SIN = `return sin(a);`;
var SINH = `
  let e2x = exp(a);
  return (e2x - 1.0 / e2x) / 2.0;
`;
var SOFTPLUS = `
  let epsilon = 1.1920928955078125e-7;
  let threshold = log(epsilon) + 2.0;

  let too_large = a > -threshold;
  let too_small = a < threshold;
  let exp_a = exp(a);

  if (too_large) {
    return a;
  } else if (too_small) {
    return exp_a;
  } else {
    return log(exp_a + 1.0);
  }
`;
var SQRT = `return sqrt(a);`;
var SQUARE = `return a * a;`;
var STEP = `
  if (isnan(a)) {
    return a;
  }

  return select(uniforms.stepAlpha, 1.0, a > 0.0);
`;
var TAN = `return tan(a);`;
var TANH = `
  let e2x = exp(-2.0 * abs(a));
  return sign(a) * (1.0 - e2x) / (1.0 + e2x);
`;
var TO_INT = `return f32(i32((a)));`;
function getUnaryOpString(type, useVec4) {
  switch (type) {
    case UnaryOpType.ABS:
      return ABS;
    case UnaryOpType.ACOS:
      return ACOS;
    case UnaryOpType.ACOSH:
      return ACOSH;
    case UnaryOpType.ASIN:
      return ASIN;
    case UnaryOpType.ASINH:
      return ASINH;
    case UnaryOpType.ATAN:
      return ATAN;
    case UnaryOpType.ATANH:
      return ATANH;
    case UnaryOpType.COS:
      return COS;
    case UnaryOpType.COSH:
      return COSH;
    case UnaryOpType.CEIL:
      return CEIL;
    case UnaryOpType.ELU:
      return useVec4 ? ELU_VEC4 : ELU;
    case UnaryOpType.ERF:
      return ERF;
    case UnaryOpType.EXP:
      return EXP;
    case UnaryOpType.EXPM1:
      return EXPM1;
    case UnaryOpType.FLOOR:
      return FLOOR;
    case UnaryOpType.IS_FINITE:
      return IS_FINITE;
    case UnaryOpType.IS_INF:
      return IS_INF;
    case UnaryOpType.IS_NAN:
      return IS_NAN;
    case UnaryOpType.LINEAR:
      return LINEAR;
    case UnaryOpType.LOG:
      return LOG;
    case UnaryOpType.LOG1P:
      return LOG1P;
    case UnaryOpType.LOGICAL_NOT:
      return LOGICAL_NOT;
    case UnaryOpType.NEG:
      return NEG;
    case UnaryOpType.LEAKYRELU:
      return useVec4 ? LEAKYRELU_VEC4 : LEAKYRELU;
    case UnaryOpType.RECIPROCAL:
      return RECIPROCAL;
    case UnaryOpType.RELU:
      return useVec4 ? RELU_VEC4 : RELU;
    case UnaryOpType.RELU6:
      return useVec4 ? RELU6_VEC4 : RELU6;
    case UnaryOpType.ROUND:
      return ROUND;
    case UnaryOpType.RSQRT:
      return RSQRT;
    case UnaryOpType.SELU:
      return SELU;
    case UnaryOpType.SIGMOID:
      return SIGMOID;
    case UnaryOpType.SIGN:
      return SIGN;
    case UnaryOpType.SIN:
      return SIN;
    case UnaryOpType.SINH:
      return SINH;
    case UnaryOpType.SOFTPLUS:
      return SOFTPLUS;
    case UnaryOpType.SQRT:
      return SQRT;
    case UnaryOpType.SQUARE:
      return SQUARE;
    case UnaryOpType.STEP:
      return STEP;
    case UnaryOpType.TAN:
      return TAN;
    case UnaryOpType.TANH:
      return TANH;
    case UnaryOpType.TO_INT:
      return TO_INT;
    default:
      throw new Error(`BinaryType ${type} is not implemented!`);
  }
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/activation_util.js
function activationFnSnippet(activation, hasPreluActivationWeights = false, packed = false, coordsLength = 3) {
  if (activation === null) {
    return "";
  }
  let activationOpSnippet = "";
  if (activation === "linear") {
    activationOpSnippet = getUnaryOpString(UnaryOpType.LINEAR);
  } else if (activation === "relu") {
    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU, packed);
  } else if (activation === "elu") {
    activationOpSnippet = getUnaryOpString(UnaryOpType.ELU, packed);
  } else if (activation === "relu6") {
    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU6, packed);
  } else if (activation === "prelu") {
    activationOpSnippet = getBinaryOpString(BinaryOpType.PRELU, packed);
  } else if (activation === "sigmoid") {
    activationOpSnippet = getUnaryOpString(UnaryOpType.SIGMOID, packed);
  } else if (activation === "leakyrelu") {
    activationOpSnippet = getUnaryOpString(UnaryOpType.LEAKYRELU, packed);
  } else {
    throw new Error(`Activation ${activation} has not been implemented for the WebGPU backend.`);
  }
  const elementSize = packed ? 4 : 1;
  const dataType = typeSnippet(elementSize);
  let activationFnSnippet2 = "";
  if (hasPreluActivationWeights) {
    activationFnSnippet2 = `
      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${dataType} {
        let b = getPreluActivationWeightsByOutputCoords(coords);
        ${activationOpSnippet}
      }`;
  } else {
    activationFnSnippet2 = `
      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${dataType} {
        ${activationOpSnippet}
      }`;
  }
  return activationFnSnippet2;
}
function biasActivationSnippet(hasBias, activation) {
  return `
      ${hasBias ? "value = value + getBiasByOutputCoords(coords);" : ""}
      ${activation ? "value = activation(value, coords);" : ""}
      `;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/matmul_packed_webgpu.js
function matMulReadFnSource(transposeA, transposeB, fitAOuter = false, fitBOuter = false, fitInner = false, component = 1) {
  util_exports.assert(transposeA && component === 1 || !transposeA, () => `transposeA ${transposeA} is not compatible with component size ${component}`);
  const sampleA = `
      ${transposeA ? `value = getA(batch, col, row);` : `value = getA(batch, row, col);`}

    `;
  const sampleB = transposeB ? `value = getB(batch, col, row);` : `value = getB(batch, row, col);`;
  return `
  fn mm_readA(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {
    var value = ${typeSnippet(component)}(0.0);
    ${fitAOuter && fitInner ? sampleA : `
    ${transposeA ? `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` : `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}
    {
      ${sampleA}
    }
    `}
    return value;
  }

  fn mm_readB(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {
    var value = ${typeSnippet(component)}(0.0);
    ${sampleB}
    return value;
  }
  `;
}
function matMulReadWriteFnSource(hasBias, activation, transposeA, transposeB, fitAOuter = false, fitBOuter = false, fitInner = false, component = 1) {
  return `
  ${matMulReadFnSource(transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}
  fn mm_write(batch: i32, row: i32, col: i32, valueIn: ${typeSnippet(component)}) {
    ${fitAOuter && fitBOuter ? "" : "if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)"}
    {
      var value = valueIn;
      let coords = vec3<i32>(batch, row, col);
      ${biasActivationSnippet(hasBias, activation)}
      setOutputAtCoords(coords[0], coords[1], coords[2], value);
    }
  }
  `;
}
var writeDataToSubAVec4Snippet = (transpose3, innerElementSize) => {
  if (transpose3) {
    return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          kStart + inputRow,
          globalRowStart + inputCol * ${innerElementSize});
        `;
  } else {
    return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          globalRow + innerRow,
          kStart + inputCol * ${innerElementSize});
        `;
  }
};
var calculateResultSnippet = (transposeA, innerElementSize, rowPerThread, tileInner) => {
  if (transposeA) {
    return `
      for (var k = 0; k < ${tileInner}; k++) {
        let BCached0 = mm_Bsub[k][tileCol];
        let ACached0 = mm_Asub[k][localRow];
        for (var i = 0; i < ${rowPerThread}; i++) {
          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);
        }
      }`;
  } else {
    let bCachedStr = "";
    let accStr = "";
    for (let i = 0; i < innerElementSize; i++) {
      bCachedStr += `let BCached${i} = mm_Bsub[k * ${innerElementSize} + ${i}][tileCol];`;
      accStr += `acc[i] = fma(BCached${i}, vec4<f32>(ACached[${i}]), acc[i]);`;
    }
    return `
      for (var k = 0; k < ${tileInner / innerElementSize}; k++) {
        ${bCachedStr}
        for (var i = 0; i < ${rowPerThread}; i++) {
          let ACached = mm_Asub[tileRow + i][k];
          ${accStr}
        }
      }`;
  }
};
function makeMatMulPackedVec4Source(workPerThread, workgroupSize, transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32, broadcastBatch = false) {
  const tileAOuter = workgroupSize[1] * workPerThread[1];
  const tileBOuter = workgroupSize[0] * workPerThread[0];
  const tileAWidth = transposeA ? tileAOuter : tileInner;
  const tileAHight = transposeA ? tileInner : tileAOuter;
  const innerElementSize = tileAWidth / workgroupSize[0];
  const rowPerThreadB = tileInner / workgroupSize[1];
  const rowPerThread = workPerThread[1];
  const colPerThread = workPerThread[0];
  util_exports.assert((transposeA && innerElementSize === 4 && workPerThread[1] === 4 || !transposeA && (innerElementSize === 3 || innerElementSize === 4)) && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4, () => `If transposeA ${transposeA} is true, innerElementSize ${innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.
          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.
      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);
  return `
  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;
  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;

  ${getMainHeaderString()} {
    let localRow = i32(localId.y);
    let tileRow = localRow * ${rowPerThread};
    let tileCol = i32(localId.x);

    let globalRow = i32(globalId.y) * ${rowPerThread};
    let globalCol = i32(globalId.x) * ${colPerThread};
    let batch = ${splitK ? "0" : "i32(globalId.z)"};
    let batchA = ${splitK || !broadcastBatch ? "batch" : "batch % uniforms.aShape[0]"};
    let batchB = ${splitK || !broadcastBatch ? "batch" : "batch % uniforms.bShape[0]"};
    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};

    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : `(uniforms.dimInner - 1) / ${tileInner} + 1`};
    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : "0"};

    var acc: array<vec4<f32>, ${rowPerThread}>;

    // Loop over shared dimension.
    let tileRowB = localRow * ${rowPerThreadB};
    for (var t = 0; t < numTiles; t++) {
        // Load one tile of A into local memory.
        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
            let inputRow = tileRow + innerRow;
            let inputCol = tileCol;
            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}
        }

        // Load one tile of B into local memory.
        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {
            let inputRow = tileRowB + innerRow;
            let inputCol = tileCol;
            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);
        }
        kStart = kStart + ${tileInner};
        workgroupBarrier();

        // Compute acc values for a single thread.
        ${calculateResultSnippet(transposeA, innerElementSize, rowPerThread, tileInner)}
        workgroupBarrier();
    }

    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);
    }
  }`;
}
var writeDataToSubASnippet = (transpose3) => {
  if (transpose3) {
    return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          kStart + inputRow,
          globalRowStart + inputCol);
        `;
  } else {
    return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          globalRowStart + inputRow,
          kStart + inputCol);
        `;
  }
};
var readDataFromSubASnippet = (transposeA) => {
  return transposeA ? "let ACached = mm_Asub[k][tileRow + innerRow];" : "let ACached = mm_Asub[tileRow + innerRow][k];";
};
function makeMatMulPackedSource(workPerThread, workgroupSize, transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32, sequentialAccessByThreads = false, broadcastBatch = false) {
  const tileAOuter = workPerThread[1] * workgroupSize[1];
  const tileBOuter = workPerThread[0] * workgroupSize[0];
  const tileAWidth = transposeA ? tileAOuter : tileInner;
  const tileAHight = transposeA ? tileInner : tileAOuter;
  util_exports.assert(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0, () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);
  const rowPerThreadA = tileAHight / workgroupSize[1];
  const colPerThreadA = tileAWidth / workgroupSize[0];
  const rowPerThreadB = tileInner / workgroupSize[1];
  const rowPerThread = workPerThread[1];
  const colPerThread = workPerThread[0];
  const matmulSnippet = sequentialAccessByThreads ? `
      let localRow = i32(localId.y);
      let localCol = i32(localId.x);
      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};
      let globalColStart = i32(workgroupId.x) * ${tileBOuter};

      // Loop over shared dimension.
      for (var t = 0; t < numTiles; t++) {
        // Load one tile of A into local memory.
        for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {
          for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {
            ${writeDataToSubASnippet(transposeA)}
          }
        }
        // Load one tile of B into local memory.
        for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {
              for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {
            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,
              kStart + inputRow,
              globalColStart + inputCol);
          }
        }
        kStart = kStart + ${tileInner};
        workgroupBarrier();

        // Compute acc values for a single thread.
        var BCached : array<f32, ${colPerThread}>;
        for (var k = 0; k < ${tileInner}; k++) {
          for (var inner = 0; inner < ${colPerThread}; inner++) {
            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];
          }
          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
            let ACached = ${transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` : `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}
            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
              acc[innerRow][innerCol] =
                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);
            }
          }
        }
        workgroupBarrier();
      }
      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};
        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};
          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);
        }
      }
      ` : `
  let tileRow = i32(localId.y) * ${rowPerThread};
  let tileCol = i32(localId.x) * ${colPerThread};

  let globalRow = i32(globalId.y) * ${rowPerThread};
  let globalCol = i32(globalId.x) * ${colPerThread};
  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};

  let tileRowA = i32(localId.y) * ${rowPerThreadA};
  let tileColA = i32(localId.x) * ${colPerThreadA};
  let tileRowB = i32(localId.y) * ${rowPerThreadB};
  // Loop over shared dimension.
  for (var t = 0; t < numTiles; t++) {
    // Load one tile of A into local memory.
    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {
      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {
        let inputRow = tileRowA + innerRow;
        let inputCol = tileColA + innerCol;
        ${writeDataToSubASnippet(transposeA)}
      }
    }

    // Load one tile of B into local memory.
    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {
      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
        let inputRow = tileRowB + innerRow;
        let inputCol = tileCol + innerCol;
        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,
          kStart + inputRow,
          globalCol + innerCol);
      }
    }
    kStart = kStart + ${tileInner};
    workgroupBarrier();

    // Compute acc values for a single thread.
    var BCached : array<f32, ${colPerThread}>;
    for (var k = 0; k < ${tileInner}; k++) {
      for (var inner = 0; inner < ${colPerThread}; inner++) {
        BCached[inner] = mm_Bsub[k][tileCol + inner];
      }

      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        ${readDataFromSubASnippet(transposeA)}
        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
          acc[innerRow][innerCol] =
              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);
        }
      }
    }

    workgroupBarrier();
  }

  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
      mm_write(batch, globalRow + innerRow, globalCol + innerCol,
          acc[innerRow][innerCol]);
    }
  }
  `;
  return `
    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;
    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;

    ${getMainHeaderString()} {
      let batch = ${splitK ? "0" : "i32(globalId.z)"};
      let batchA = ${splitK || !broadcastBatch ? "batch" : "batch % uniforms.aShape[0]"};
      let batchB = ${splitK || !broadcastBatch ? "batch" : "batch % uniforms.bShape[0]"};
      let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : `(uniforms.dimInner - 1) / ${tileInner} + 1`};
      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : "0"};

      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;

      // Without this initialization strange values show up in acc.
      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
          acc[innerRow][innerCol] = 0.0;
        }
      }
      ${matmulSnippet}
    }
  `;
}
var readVectorASnippet = (transpose3) => {
  return transpose3 ? `
      mm_readA(batchA, colA, globalRow),
      mm_readA(batchA, colA + 1, globalRow),
      mm_readA(batchA, colA + 2, globalRow),
      mm_readA(batchA, colA + 3, globalRow)
  ` : `
      mm_readA(batchA, globalRow, colA),
      mm_readA(batchA, globalRow, colA + 1),
      mm_readA(batchA, globalRow, colA + 2),
      mm_readA(batchA, globalRow, colA + 3)
  `;
};
function makeVectorMatrixProductSource(workgroupSize, transposeA = false) {
  util_exports.assert(workgroupSize[1] === 1 && workgroupSize[2] === 1, () => `A linear work group size is required. But got ${workgroupSize}.`);
  const tileSize = workgroupSize[0] * 4;
  return `
    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;

    ${getMainHeaderString()} {
      let tileCol = i32(localId.x);
      let globalCol = i32(globalId.x);
      let globalRow = i32(globalId.y);

      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;
      let batch = i32(globalId.z);
      let batchA = batch % uniforms.aShape[0];
      let batchB = batch % uniforms.bShape[0];
      // Without this initialization strange values show up in acc.
      var acc = 0.0;

      // Loop over shared dimension.
      for (var t = 0; t < numTiles; t++) {
        // Load one tile of A into local memory.
        let colA = t * ${tileSize} + tileCol * 4;
        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});
        workgroupBarrier();

        // Compute acc values for a single thread.
        for (var k = 0; k < ${tileSize / 4}; k++) {
          let rowB = t * ${tileSize} + k * 4;
          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),
                              mm_readB(batchB, rowB + 1, globalCol),
                              mm_readB(batchB, rowB + 2, globalCol),
                              mm_readB(batchB, rowB + 3, globalCol));

          let ACached = mm_Asub[k];
          acc = acc + dot(ACached, BCached);
        }

        workgroupBarrier();
      }

      mm_write(batch, globalRow, globalCol, acc);
    }
  `;
}
var MatMulPackedProgram = class {
  constructor(aShape, outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null, sequentialAccessByThreads = false) {
    this.variableNames = ["A", "B"];
    this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
    this.outputShape = outputShape;
    this.dispatchLayout = { x: [2], y: [1], z: [0] };
    const dimInner = transposeA ? aShape[1] : aShape[2];
    this.isVec4 = (dimInner % 4 === 0 && !transposeA || outputShape[1] % 4 === 0 && transposeA) && outputShape[2] % 4 === 0 && !transposeB;
    this.outputComponent = this.isVec4 ? 4 : 1;
    this.isVectorA = outputShape[1] === 1 && !transposeA;
    if (!this.isVec4 && this.isVectorA) {
      this.elementsPerThread = [1, 1, 1];
      this.workgroupSize = [32, 1, 1];
    } else {
      const workgroupInfo = computeWorkgroupInfoForMatMul(outputShape[1], dimInner, outputShape[2], transposeA);
      this.workgroupSize = workgroupInfo.workgroupSize;
      this.elementsPerThread = workgroupInfo.elementsPerThread;
    }
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);
    const addBias = bias != null;
    const hasPreluActivationWeights = preluActivationWeights != null;
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivationWeights) {
      this.variableNames.push("preluActivationWeights");
    }
    this.sequentialAccessByThreads = sequentialAccessByThreads;
    this.transposeA = transposeA;
    this.transposeB = transposeB;
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivationWeights = hasPreluActivationWeights;
    [this.fitAOuter, this.fitBOuter, this.fitInner] = this.getShapeFit(outputShape[1], outputShape[2], dimInner);
    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${this.isVectorA}_${this.sequentialAccessByThreads}`;
  }
  getShapeFit(dimAOuter, dimBOuter, dimInner) {
    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];
    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];
    if (!this.isVec4 && this.isVectorA) {
      this.tileInner = this.workgroupSize[0] * 4;
    } else {
      this.tileInner = tileBOuter;
    }
    const fitAOuter = dimAOuter % tileAOuter === 0;
    const fitBOuter = dimBOuter % tileBOuter === 0;
    const fitInner = dimInner % this.tileInner === 0;
    return [fitAOuter, fitBOuter, fitInner];
  }
  getUserCode() {
    const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights, this.isVec4)}
      ${matMulReadWriteFnSource(this.addBias, this.activation, false, this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner, this.isVec4 ? 4 : 1)}
      ${this.isVec4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, true) : this.isVectorA ? makeVectorMatrixProductSource(this.workgroupSize, this.transposeA) : makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, this.sequentialAccessByThreads, true)}
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/matmul_reduce_webgpu.js
function makeMatMulReduceSource(workgroupSizeX) {
  return `
    var<workgroup> sumValues : array<f32, ${workgroupSizeX}>;
    ${getMainHeaderString()} {
      let coords = getOutputCoords();
      let batch = coords[0];
      let batchA = batch % uniforms.aShape[0];
      let batchB = batch % uniforms.bShape[0];
      let row = coords[1];
      let col = coords[2];
      var sum = 0.0;
      let Length = uniforms.dimInner;
      for (var k = i32(localId.x); k < Length; k = k + ${workgroupSizeX}) {
        let dataA = mm_readA(batchA, row, k);
        let dataB = mm_readB(batchB, k, col);
        sum = sum + dataA * dataB;
      }
      sumValues[localId.x] = sum;
      workgroupBarrier();

      for(var currentSize = ${workgroupSizeX / 2}u; currentSize > 1u;
          currentSize = currentSize / 2u) {
        if (localId.x < currentSize)
        {
          sumValues[localId.x] = sumValues[localId.x] + sumValues[localId.x + currentSize];
        }
        workgroupBarrier();
      }

      if (localId.x == 0u) {
        sum = sumValues[0] + sumValues[1];
        mm_write(batch, row, col, sum);
      }
    }
  `;
}
var MatMulReduceProgram = class {
  constructor(outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null) {
    this.variableNames = ["A", "B"];
    this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
    this.workgroupSize = [256, 1, 1];
    this.outputShape = outputShape;
    this.dispatchLayout = { x: [], y: [1, 2], z: [0] };
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    const addBias = bias != null;
    const hasPreluActivationWeights = preluActivationWeights != null;
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivationWeights) {
      this.variableNames.push("preluActivationWeights");
    }
    this.transposeA = transposeA;
    this.transposeB = transposeB;
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivationWeights = hasPreluActivationWeights;
    this.shaderKey = `matMulReduce_${this.activation}_${transposeA}_${transposeB}`;
  }
  getUserCode() {
    const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}
      ${matMulReadWriteFnSource(this.addBias, this.activation, this.transposeA, this.transposeB)}
      ${makeMatMulReduceSource(this.workgroupSize[0])}
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/matmul_small_output_size_webgpu.js
function makeMatMulSmallOutputSizeSource(workgroupSize) {
  const tileAOuter = workgroupSize[1];
  const tileBOuter = workgroupSize[0];
  const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;
  return `
  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;
  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;

  // If the output size is small for matrix multiplication, avoid to use vec4
  // and handle some elements per thread to optimally utilize the ALU.
  // Read data from global memory to registers firstly, then store them into
  // shared memory, so it is instruction-Level parallelism for arithmetic
  // operations and others handle IO operations between barrier api, makes ALU
  // and load/store units work simultaneously, could improves the performance.
  ${getMainHeaderString()} {
    let tileRow = i32(localId.y);
    let tileCol = i32(localId.x);
    let globalRow = i32(globalId.y);
    let globalCol = i32(globalId.x);
    let batch = i32(globalId.z);
    let batchA = batch % uniforms.aShape[0];
    let batchB = batch % uniforms.bShape[0];

    // uniforms.dimInner should be greater than 0.
    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;
    var acc = 0.0;

    var globalColA = tileCol;
    var globalRowB = 0;
    var regA = mm_readA(batchA, globalRow, globalColA);
    var regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);
    var regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);
    globalColA = globalColA + ${tileInner};
    globalRowB = globalRowB + ${tileInner};

    for (var t = 0; t < numTiles; t = t + 1) {
      mm_Asub[tileRow][tileCol] = regA;
      mm_Bsub[2 * tileRow][tileCol] = regB0;
      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;

      workgroupBarrier();

      regA = mm_readA(batchA, globalRow, globalColA);
      regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);
      regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);
      globalColA = globalColA + ${tileInner};
      globalRowB = globalRowB + ${tileInner};

      for (var k = 0; k < ${tileInner}; k = k + 1) {
        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];
      }
      workgroupBarrier();
    }

    mm_write(batch, globalRow, globalCol, acc);
  }
  `;
}
var MatMulSmallOutputSizeProgram = class {
  constructor(aShape, bShape, outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null) {
    this.variableNames = ["A", "B"];
    this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
    this.workgroupSize = [16, 8, 1];
    this.outputShape = outputShape;
    this.dispatchLayout = { x: [2], y: [1], z: [0] };
    this.dispatch = [
      Math.ceil(outputShape[2] / this.workgroupSize[0]),
      Math.ceil(outputShape[1] / this.workgroupSize[1]),
      outputShape[0]
    ];
    const addBias = bias != null;
    if (addBias) {
      this.variableNames.push("bias");
    }
    const hasPreluActivationWeights = preluActivationWeights != null;
    if (hasPreluActivationWeights) {
      this.variableNames.push("preluActivationWeights");
    }
    this.transposeA = transposeA;
    this.transposeB = transposeB;
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivationWeights = hasPreluActivationWeights;
    this.shaderKey = `matMulSmallOutputSize_${this.activation}_${transposeA}_${transposeB}`;
  }
  getUserCode() {
    const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}
      ${matMulReadWriteFnSource(this.addBias, this.activation, this.transposeA, this.transposeB)}
      ${makeMatMulSmallOutputSizeSource(this.workgroupSize)}
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/matmul_splitK_webgpu.js
var MatMulSplitKProgram = class {
  constructor(outputShape, dimInner, transposeA = false, transposeB = false) {
    this.variableNames = ["A", "B"];
    this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
    this.workgroupSize = [8, 8, 1];
    this.atomic = true;
    this.splitedDimInner = 128;
    util_exports.assert(outputShape[0] === 1, () => "MatMulSplitKProgram only supports batch = 1.");
    this.outputShape = outputShape;
    this.dispatchLayout = { x: [2], y: [1], z: [0, 3] };
    const isVec4 = (transposeA && this.outputShape[1] % 4 === 0 || !transposeA && dimInner % 4 === 0) && this.outputShape[2] % 4 === 0;
    this.elementsPerThread = [4, 4, this.splitedDimInner];
    this.outputComponent = isVec4 ? 4 : 1;
    if (!isVec4) {
      if (this.outputShape[1] < 16) {
        this.elementsPerThread[1] = 1;
      }
      if (this.outputShape[2] < 16) {
        this.elementsPerThread[0] = 1;
      }
    }
    this.dispatch = computeDispatch(this.dispatchLayout, [
      this.outputShape[0],
      this.outputShape[1],
      this.outputShape[2],
      dimInner
    ], this.workgroupSize, this.elementsPerThread);
    this.transposeA = transposeA;
    this.transposeB = transposeB;
    this.shaderKey = `matMulSplitK_${transposeA}_${transposeB}_${this.elementsPerThread}_${this.outputComponent}`;
  }
  getUserCode() {
    const component = this.outputComponent;
    const userCode = `
      ${matMulReadFnSource(false, this.transposeB, false, false, false, component)}
      fn mm_write(batch: i32, row : i32, col : i32, value : ${typeSnippet(component)}) {
        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {
          let coords = vec3<i32>(batch, row, col);
          let flatIndex = getOutputIndexFromCoords(coords);
          // The problem is that we should initialize output to zero before using.
          // Otherwise, the original value will be added to the result.
          for (var i = 0; i < ${component}; i = i + 1) {
            ${atomicAddSnippet("&result[flatIndex + i]", `${component > 1 ? "value[i]" : "value"}`, "float32")}
          }
        }
      }
      ${component === 4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, this.transposeA, 32, true, this.splitedDimInner) : makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, this.transposeA, 32, true, this.splitedDimInner)}
    `;
    return userCode;
  }
};
var BiasActivationProgram = class {
  constructor(outputShape, bias = null, activation = null, preluActivationWeights = null) {
    this.uniforms = "";
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.addBias = bias != null;
    this.hasPreluActivationWeights = preluActivationWeights != null;
    this.activation = activation;
    if (this.addBias) {
      this.variableNames.push("bias");
    }
    if (this.hasPreluActivationWeights) {
      this.variableNames.push("preluActivationWeights");
    }
    this.shaderKey = `biasActivation_${activation}`;
  }
  getUserCode() {
    return `
    ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        var value = getXByOutputIndex(index);
        ${biasActivationSnippet(this.addBias, this.activation)}
        setOutputAtIndex(index, value);
      }
    }
    `;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/fill_webgpu.js
var FillProgram = class {
  constructor(shape) {
    this.variableNames = [];
    this.outputShape = [];
    this.uniforms = "value : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "fill";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        setOutputAtIndex(index, uniforms.value);
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Fill.js
function fill2(args) {
  const { backend: backend2, attrs } = args;
  const { shape, value } = attrs;
  let { dtype } = attrs;
  dtype = dtype || util_exports.inferDtype(value);
  if (dtype === "string") {
    const values = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(shape));
    values.fill(value);
    return backend2.makeTensorInfo(shape, dtype, values);
  } else {
    const program = new FillProgram(shape);
    const uniformData = [{ type: "float32", data: [value] }];
    return backend2.runWebGPUProgram(program, [], dtype, uniformData);
  }
}
var fillConfig = {
  kernelName: Fill,
  backendName: "webgpu",
  kernelFunc: fill2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Reshape.js
function reshape2(args) {
  const { inputs, attrs } = args;
  const { x } = inputs;
  const { shape } = attrs;
  const xSize = util_exports.sizeFromShape(x.shape);
  const $shape = util_exports.inferFromImplicitShape(shape, xSize);
  const $xSize = util_exports.sizeFromShape($shape);
  util_exports.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
  args.backend.incRef(x.dataId);
  return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
}
var reshapeConfig = {
  kernelName: Reshape,
  backendName: "webgpu",
  kernelFunc: reshape2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/BatchMatMul_impl.js
function batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const aRank = a.shape.length;
  const bRank = b.shape.length;
  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
  const outerDimsA = a.shape.slice(0, -2);
  const outerDimsB = b.shape.slice(0, -2);
  const batchDimA = util_exports.sizeFromShape(outerDimsA);
  const batchDimB = util_exports.sizeFromShape(outerDimsB);
  const outShapeOuterDims = broadcast_util_exports.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  util_exports.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
  const a3d = reshape2({ inputs: { x: a }, backend: backend2, attrs: { shape: a3dShape } });
  const b3d = reshape2({ inputs: { x: b }, backend: backend2, attrs: { shape: b3dShape } });
  const intermediates = [a3d, b3d];
  const batchDim = Math.max(batchDimA, batchDimB);
  const inputs = [a3d, b3d];
  const dimensions = [
    { type: "int32", data: [outerShapeA] },
    { type: "int32", data: [outerShapeB] },
    { type: "int32", data: [innerShapeA] }
  ];
  let program;
  let out;
  const outputShape = [batchDim, outerShapeA, outerShapeB];
  let matmulProgramType = env().get("WEBGPU_MATMUL_PROGRAM_TYPE");
  if (matmulProgramType < 0) {
    const thresholdFlagValue = env().getNumber("WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL");
    const thresholdToIncreaseWorkgroups = thresholdFlagValue > 0 ? thresholdFlagValue : backend2.thresholdToIncreaseWorkgroups;
    const workgroupsBy32x32 = batchDim * Math.ceil(outerShapeA / 32) * Math.ceil(outerShapeB / 32);
    const hasFewWorkgroups = workgroupsBy32x32 <= thresholdToIncreaseWorkgroups || outerShapeA <= 8 && workgroupsBy32x32 <= thresholdToIncreaseWorkgroups * 2;
    if (hasFewWorkgroups) {
      if (batchDim * outerShapeA * outerShapeB <= 128) {
        matmulProgramType = MatMulProgramType.MatMulReduceProgram;
      } else if (batchDim === 1 && innerShapeB >= 2e3) {
        matmulProgramType = MatMulProgramType.MatMulSplitKProgram;
      } else {
        matmulProgramType = MatMulProgramType.MatMulSmallOutputSizeProgram;
      }
    } else {
      matmulProgramType = MatMulProgramType.MatMulPackedProgram;
    }
  }
  switch (matmulProgramType) {
    case MatMulProgramType.MatMulReduceProgram:
      program = new MatMulReduceProgram(outputShape, transposeA, transposeB, bias, activation, preluActivationWeights);
      break;
    case MatMulProgramType.MatMulSplitKProgram: {
      out = fill2({ backend: backend2, attrs: { shape: outputShape, value: 0, dtype: a.dtype } });
      program = new MatMulSplitKProgram(outputShape, innerShapeB, transposeA, transposeB);
      if (bias || activation) {
        out = backend2.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);
        const biasActivationProgram = new BiasActivationProgram(out.shape, bias, activation, preluActivationWeights);
        let uniformData = null;
        const activationInputs = [out];
        if (bias) {
          activationInputs.push(bias);
        }
        if (preluActivationWeights) {
          activationInputs.push(preluActivationWeights);
        }
        if (activation === "leakyrelu") {
          uniformData = [{ type: "float32", data: [leakyreluAlpha] }];
          biasActivationProgram.uniforms += " alpha : f32,";
        }
        const outActivated = backend2.runWebGPUProgram(biasActivationProgram, activationInputs, out.dtype, uniformData);
        intermediates.push(out);
        const outReshaped2 = reshape2({ inputs: { x: outActivated }, backend: backend2, attrs: { shape: outShape } });
        intermediates.push(outActivated);
        for (const i of intermediates) {
          backend2.disposeData(i.dataId);
        }
        return outReshaped2;
      }
      break;
    }
    case MatMulProgramType.MatMulSmallOutputSizeProgram:
      program = new MatMulSmallOutputSizeProgram(a3dShape, b3dShape, outputShape, transposeA, transposeB, bias, activation, preluActivationWeights);
      break;
    case MatMulProgramType.MatMulPackedProgram:
      const sequentialAccessByThreads = backend2.adapterInfo.isIntel();
      program = new MatMulPackedProgram(a3dShape, outputShape, transposeA, transposeB, bias, activation, preluActivationWeights, sequentialAccessByThreads);
      break;
    default:
      throw new Error(`Unsupported MatMulProgramType ${matmulProgramType}.`);
  }
  if (bias) {
    inputs.push(bias);
  }
  if (preluActivationWeights) {
    inputs.push(preluActivationWeights);
  }
  if (activation === "leakyrelu") {
    dimensions.push({ type: "float32", data: [leakyreluAlpha] });
    program.uniforms += " alpha : f32,";
  }
  out = backend2.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);
  const outReshaped = reshape2({ inputs: { x: out }, backend: backend2, attrs: { shape: outShape } });
  intermediates.push(out);
  for (const i of intermediates) {
    backend2.disposeData(i.dataId);
  }
  return outReshaped;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/_FusedMatMul.js
function _fusedMatMul(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { a, b, bias, preluActivationWeights } = inputs;
  const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
  return batchMatMulImpl({
    a,
    b,
    transposeA,
    transposeB,
    backend: backend2,
    bias,
    preluActivationWeights,
    leakyreluAlpha,
    activation
  });
}
var _fusedMatMulConfig = {
  kernelName: _FusedMatMul,
  backendName: "webgpu",
  kernelFunc: _fusedMatMul
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/binary_op_complex_webgpu.js
var BinaryOpComplexProgram = class {
  constructor(op2, aShape, bShape) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"];
    this.workgroupSize = [128, 1, 1];
    this.size = true;
    this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `binaryOpComplex_${op2}`;
    this.op = op2;
  }
  getUserCode() {
    const opStr = getBinaryOpString(this.op, false);
    const userCode = `
      fn binaryOpComplex(
          areal : f32, aimag : f32, breal : f32, bimag : f32) -> f32 {
        ${opStr}
      }

      ${getMainHeaderString("index")} {
        if(index < uniforms.size) {
          let areal = getARealByOutputIndex(index);
          let aimag = getAImagByOutputIndex(index);
          let breal = getBRealByOutputIndex(index);
          let bimag = getBImagByOutputIndex(index);
          setOutputAtIndex(index, binaryOpComplex(areal, aimag, breal, bimag));
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/binary_op_webgpu.js
var BinaryOpProgram = class {
  constructor(op2, aShape, bShape) {
    this.size = true;
    this.variableNames = ["A", "B"];
    this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.op = op2;
    this.useSharedMemoryWithA = aShape.length <= 1 && bShape.length > 1 && aShape[0] < 128;
    this.useSharedMemoryWithB = bShape.length <= 1 && aShape.length > 1 && bShape[0] < 128;
    if (this.useSharedMemoryWithA || this.useSharedMemoryWithB) {
      this.outputComponent = 1;
      this.variableComponents = [1, 1];
      this.lastDimensionSize = this.useSharedMemoryWithB ? bShape[0] : aShape[0];
      this.shaderKey = `binary_${op2}_${this.lastDimensionSize}`;
      this.type = "shared";
      this.workgroupSize = [256, 1, 1];
    } else {
      const aDivisibleBy4 = aShape.length > 0 && aShape[aShape.length - 1] % 4 === 0;
      const bDivisibleBy4 = bShape.length > 0 && bShape[bShape.length - 1] % 4 === 0;
      if (aDivisibleBy4 && bDivisibleBy4) {
        this.outputComponent = 4;
        this.variableComponents = [4, 4];
      } else if (aDivisibleBy4 && (util_exports.isScalarShape(bShape) || bShape[bShape.length - 1] === 1) || bDivisibleBy4 && (util_exports.isScalarShape(aShape) || aShape[aShape.length - 1] === 1)) {
        this.outputComponent = 4;
        this.variableComponents = aDivisibleBy4 ? [4, 1] : [1, 4];
      } else {
        this.outputComponent = 1;
        this.variableComponents = [1, 1];
      }
      this.type = "nonshared";
      this.shaderKey = `binary_${op2}_${this.variableComponents}`;
      this.workgroupSize = [128, 1, 1];
    }
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.outputComponent, 1, 1]);
  }
  getUserCode() {
    let userCode;
    const dType = this.outputComponent === 4 ? "vec4<f32>" : "f32";
    const opFnStr = `
    fn binaryOperation(a : ${dType}, b : ${dType}) -> ${dType} {
      ${getBinaryOpString(this.op, this.outputComponent === 4)}
    };
    `;
    if (this.type === "shared") {
      const sharedIndexSnippet = this.lastDimensionSize > 1 ? `coords[${this.outputShape.length - 1}]` : "0";
      const accessDataSnippet = this.useSharedMemoryWithB ? `let a = getAByOutputIndex(index);
          let b = sharedBuf[${sharedIndexSnippet}];` : `let a = sharedBuf[${sharedIndexSnippet}];
          let b = getBByOutputIndex(index);`;
      userCode = `
        ${opFnStr}
        var<workgroup> sharedBuf : array<f32, ${this.lastDimensionSize}>;
        ${getMainHeaderString("index")} {
          // Fill in the shared memory buffer.
          let localIndex = i32(localId.x);
          if(localIndex < ${this.lastDimensionSize}) {
            sharedBuf[localIndex] = f32(${this.useSharedMemoryWithB ? "B" : "A"}[localIndex]);
          }
          workgroupBarrier();

          if(index < uniforms.size) {
            let coords = getCoordsFromIndex(index);
            ${accessDataSnippet}
            setOutputAtIndex(index, binaryOperation(a, b));
          }
        }
        `;
    } else {
      userCode = `
       ${opFnStr}
       ${getMainHeaderString("index")} {
         if (index < uniforms.size) {
           let coords = getCoordsFromIndex(index * ${this.outputComponent});
           let a = ${dType}(getAByOutputCoords(coords));
           let b = ${dType}(getBByOutputCoords(coords));
           setOutputAtIndex(index, binaryOperation(a, b));
         }
       }
       `;
    }
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Identity.js
function identity(args) {
  const { inputs } = args;
  const { x } = inputs;
  args.backend.incRef(x.dataId);
  return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
}
var identityConfig = {
  kernelName: Identity,
  backendName: "webgpu",
  kernelFunc: identity
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Complex.js
function complex2(args) {
  const { inputs, backend: backend2 } = args;
  const { real: real3, imag: imag3 } = inputs;
  const complexInfo = backend2.makeTensorInfo(real3.shape, "complex64");
  const complex3 = backend2.tensorMap.get(complexInfo.dataId);
  const realTensorInfo = identity({ inputs: { x: real3 }, backend: backend2 });
  const imagTensorInfo = identity({ inputs: { x: imag3 }, backend: backend2 });
  complex3.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };
  return complexInfo;
}
var complexConfig = {
  kernelName: Complex,
  backendName: "webgpu",
  kernelFunc: complex2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/unary_op_webgpu.js
var UnaryOpProgram = class {
  constructor(outputShape, op2, uniforms = "") {
    this.variableNames = ["A"];
    this.size = true;
    const workgroupSizeX = 128;
    this.workgroupSize = [workgroupSizeX, 1, 1];
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.op = op2;
    if (uniforms !== "") {
      this.uniforms = uniforms;
    }
    this.shaderKey = `unary_${op2}`;
  }
  getUserCode() {
    return `
      fn unaryOperation(a : f32) -> f32 {
        ${getUnaryOpString(this.op, false)}
      }
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let a = getAByOutputIndex(index);
          setOutputAtIndex(index, unaryOperation(a));
        }
      }
      `;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/kernel_funcs_utils.js
function unaryKernelFunc({ opType, cpuKernelImpl, dtype }) {
  return ({ inputs, backend: backend2 }) => {
    const { x } = inputs;
    const webgpuBackend = backend2;
    const $dtype = dtype || x.dtype;
    if (webgpuBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {
      const xData = webgpuBackend.tensorMap.get(x.dataId);
      const outValues = cpuKernelImpl(xData.values, $dtype);
      return webgpuBackend.makeTensorInfo(x.shape, $dtype, outValues);
    }
    const program = new UnaryOpProgram(x.shape, opType);
    return webgpuBackend.runWebGPUProgram(program, [x], $dtype);
  };
}
function binaryKernelFunc({ opType, cpuKernelImpl, supportsComplex = false, dtype }) {
  return ({ inputs, backend: backend2 }) => {
    const { a, b } = inputs;
    const webgpuBackend = backend2;
    if (supportsComplex && a.dtype === "complex64") {
      const aData = webgpuBackend.tensorMap.get(a.dataId);
      const bData = webgpuBackend.tensorMap.get(b.dataId);
      let real3, imag3;
      if (opType !== BinaryOpType.MUL) {
        [real3, imag3] = [
          [aData.complexTensorInfos.real, bData.complexTensorInfos.real],
          [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]
        ].map((complexParts) => {
          const [aPart, bPart] = complexParts;
          const aHandle = {
            dataId: aPart.dataId,
            dtype: aPart.dtype,
            shape: a.shape
          };
          const bHandle = {
            dataId: bPart.dataId,
            dtype: bPart.dtype,
            shape: b.shape
          };
          const program2 = new BinaryOpProgram(opType, a.shape, b.shape);
          return webgpuBackend.runWebGPUProgram(program2, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));
        });
      } else {
        const realProgram = new BinaryOpComplexProgram(BinaryOpType.COMPLEX_MULTIPLY_REAL, a.shape, b.shape);
        const imagProgram = new BinaryOpComplexProgram(BinaryOpType.COMPLEX_MULTIPLY_IMAG, a.shape, b.shape);
        const inputs2 = [
          {
            dataId: aData.complexTensorInfos.real.dataId,
            dtype: aData.complexTensorInfos.real.dtype,
            shape: a.shape
          },
          {
            dataId: aData.complexTensorInfos.imag.dataId,
            dtype: aData.complexTensorInfos.imag.dtype,
            shape: a.shape
          },
          {
            dataId: bData.complexTensorInfos.real.dataId,
            dtype: bData.complexTensorInfos.real.dtype,
            shape: b.shape
          },
          {
            dataId: bData.complexTensorInfos.imag.dataId,
            dtype: bData.complexTensorInfos.imag.dtype,
            shape: b.shape
          }
        ];
        real3 = webgpuBackend.runWebGPUProgram(realProgram, inputs2, "float32");
        imag3 = webgpuBackend.runWebGPUProgram(imagProgram, inputs2, "float32");
      }
      const complexOutput = complex2({ inputs: { real: real3, imag: imag3 }, backend: webgpuBackend });
      webgpuBackend.disposeData(real3.dataId);
      webgpuBackend.disposeData(imag3.dataId);
      return complexOutput;
    }
    const $dtype = dtype || upcastType(a.dtype, b.dtype);
    if ((a.dtype === "string" || b.dtype === "string" || webgpuBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {
      const aData = webgpuBackend.tensorMap.get(a.dataId).values;
      const bData = webgpuBackend.tensorMap.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(aData)
      ) : aData;
      const decodedBVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(bData)
      ) : bData;
      const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      return webgpuBackend.makeTensorInfo(outShape, $dtype, outValues);
    }
    const program = new BinaryOpProgram(opType, a.shape, b.shape);
    return webgpuBackend.runWebGPUProgram(program, [a, b], $dtype);
  };
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/shared.js
var { addImpl: addImplCPU, castImpl: castImplCPU, ceilImpl: ceilImplCPU, concatImpl: concatImplCPU, equalImpl: equalImplCPU, expImpl: expImplCPU, expm1Impl: expm1ImplCPU, floorImpl: floorImplCPU, floorDivImpl: floorDivImplCPU, gatherNdImpl: gatherNdImplCPU, gatherV2Impl: gatherV2ImplCPU, greaterEqualImpl: greaterEqualImplCPU, greaterImpl: greaterImplCPU, lessEqualImpl: lessEqualImplCPU, lessImpl: lessImplCPU, logImpl: logImplCPU, maxImpl: maxImplCPU, maximumImpl: maximumImplCPU, minimumImpl: minimumImplCPU, multiplyImpl: multiplyImplCPU, negImpl: negImplCPU, notEqualImpl: notEqualImplCPU, prodImpl: prodImplCPU, rangeImpl: rangeImplCPU, rsqrtImpl: rsqrtImplCPU, scatterImpl: scatterImplCPU, simpleAbsImpl: simpleAbsImplCPU, sliceImpl: sliceImplCPU, stridedSliceImpl: stridedSliceImplCPU, stringNGramsImpl: stringNGramsImplCPU, subImpl: subImplCPU, tileImpl: tileImplCPU, topKImpl: topKImplCPU, transposeImpl: transposeImplCPU, uniqueImpl: uniqueImplCPU } = shared_exports;

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Abs.js
var abs2 = unaryKernelFunc({ opType: UnaryOpType.ABS, cpuKernelImpl: simpleAbsImplCPU });
var absConfig = {
  kernelName: Abs,
  backendName: "webgpu",
  kernelFunc: abs2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Acos.js
var acos2 = unaryKernelFunc({ opType: UnaryOpType.ACOS });
var acosConfig = {
  kernelName: Acos,
  backendName: "webgpu",
  kernelFunc: acos2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Acosh.js
var acosh2 = unaryKernelFunc({ opType: UnaryOpType.ACOSH });
var acoshConfig = {
  kernelName: Acosh,
  backendName: "webgpu",
  kernelFunc: acosh2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Add.js
var addKernelFunc = binaryKernelFunc({ opType: BinaryOpType.ADD, cpuKernelImpl: addImplCPU, supportsComplex: true });
var addConfig = {
  kernelName: Add,
  backendName: "webgpu",
  kernelFunc: addKernelFunc
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/addn_packed_webgpu.js
var AddNPackedProgram = class {
  constructor(shapes) {
    this.workPerThread = 1;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = shapes[0];
    this.variableNames = shapes.map((_, i) => `T${i}`);
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
    this.shaderKey = "addN";
  }
  getUserCode() {
    const snippets = [];
    this.variableNames.forEach((variable2) => {
      snippets.push(`let v${variable2} = get${variable2}ByOutputCoords(coords);`);
    });
    const operation = this.variableNames.map((variable2) => {
      return `v${variable2}`;
    }).join(" + ");
    const userCode = `
      ${getMainHeaderString("index")} {
        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let flatIndex = index * ${this.workPerThread} + i;
          if (flatIndex < uniforms.size) {
            let coords = getCoordsFromIndex(flatIndex);
            ${snippets.join("\n        ")}
            setOutputAtIndex(flatIndex, ${operation});
          }
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/AddN.js
function addN2(args) {
  const { inputs, backend: backend2 } = args;
  const tensors = inputs;
  if (tensors.length === 1) {
    return identity({ inputs: { x: tensors[0] }, backend: backend2 });
  }
  const dtype = tensors.map((t2) => t2.dtype).reduce((d1, d2) => upcastType(d1, d2));
  const shapes = tensors.map((t2) => t2.shape);
  const program = new AddNPackedProgram(shapes);
  return backend2.runWebGPUProgram(program, tensors, dtype);
}
var addNConfig = {
  kernelName: AddN,
  backendName: "webgpu",
  kernelFunc: addN2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/transpose_shared_webgpu.js
var TransposeSharedProgram = class {
  constructor(aShape, newDim) {
    this.variableNames = ["A"];
    this.workgroupSize = [16, 16, 1];
    const outputShape = new Array(aShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = aShape[newDim[i]];
    }
    this.outputShape = outputShape;
    this.dispatchLayout = { x: [0], y: [1] };
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [1, 1, 1]);
    this.shaderKey = "transposeShared";
  }
  getUserCode() {
    util_exports.assert(this.workgroupSize[0] === this.workgroupSize[1], () => `Must be a square tile, current tile shape is ${this.workgroupSize[0]} x ${this.workgroupSize[1]}`);
    const tileSize = this.workgroupSize[0];
    const userCode = `
      var<workgroup> tile : array<array<f32, ${this.workgroupSize[0] + 1}>, ${this.workgroupSize[0]}>;
      ${getMainHeaderString()} {
        var x = i32(workgroupId.x) * ${tileSize} + i32(localId.x);
        var y = i32(workgroupId.y) * ${tileSize} + i32(localId.y);
        let width = uniforms.outShape[0];
        let height = uniforms.outShape[1];
        if (x < width && y < height) {
          tile[localId.y][localId.x] = f32(A[y * width + x]);
        }
        workgroupBarrier();

        x = i32(workgroupId.y) * ${tileSize} + i32(localId.x);
        y = i32(workgroupId.x) * ${tileSize} + i32(localId.y);
        if (x < height && y < width) {
          setOutputAtIndex((y * height + x), tile[localId.x]
            [localId.y]);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/transpose_webgpu.js
var TransposeProgram = class {
  constructor(aShape, newDim) {
    this.variableNames = ["A"];
    this.workPerThread = 1;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    const outputShape = new Array(aShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = aShape[newDim[i]];
    }
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
    this.newDim = newDim;
    this.shaderKey = `transpose_${newDim}`;
  }
  getUserCode() {
    const dtype = getCoordsDataType(this.outputShape.length);
    const switched = getSwitchedCoords(this.newDim);
    const userCode = `
      ${getMainHeaderString("index")} {
        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let flatIndex = index * ${this.workPerThread} + i;
          if(flatIndex < uniforms.size) {
            let coords = getCoordsFromIndex(flatIndex);
            setOutputAtIndex(flatIndex, A[getIndexFromCoords${this.outputShape.length}D(
              ${dtype}(${switched}), uniforms.aShape)]);
          }
        }
      }
    `;
    return userCode;
  }
};
function getSwitchedCoords(newDim) {
  const rank = newDim.length;
  if (rank > 6) {
    throw Error(`Transpose for rank ${rank} is not yet supported`);
  }
  const switchedCoords = new Array(rank);
  for (let i = 0; i < newDim.length; i++) {
    switchedCoords[newDim[i]] = `coords.${getCoordsXYZ(i)}`;
  }
  return switchedCoords.join();
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Transpose.js
function transpose2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { perm } = attrs;
  const webgpuBackend = backend2;
  const xRank = x.shape.length;
  const newShape = new Array(xRank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[perm[i]];
  }
  if (backend2.shouldExecuteOnCPU([x])) {
    const xData = webgpuBackend.tensorMap.get(x.dataId);
    const values = xData.values;
    const outValues = transposeImplCPU(values, x.shape, x.dtype, perm, newShape);
    return backend2.makeTensorInfo(newShape, x.dtype, outValues);
  }
  if (x.shape.length === 2 && util_exports.arraysEqual(perm, [1, 0])) {
    const program2 = new TransposeSharedProgram(x.shape, perm);
    return webgpuBackend.runWebGPUProgram(program2, [x], x.dtype);
  }
  const program = new TransposeProgram(x.shape, perm);
  return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);
}
var transposeConfig = {
  kernelName: Transpose,
  backendName: "webgpu",
  kernelFunc: transpose2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/reduce_webgpu.js
var ReduceProgram = class {
  constructor(reduceInfo, reduceType, maxComputeWorkgroupSizeX) {
    this.variableNames = ["x"];
    this.uniforms = "reduceSize : i32,";
    this.size = true;
    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];
    const [outputShape] = backend_util_exports.computeOutAndReduceShapes(this.inputShape, [1]);
    this.outputShape = outputShape.length === 0 ? [1] : outputShape;
    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {
      this.workgroupSize = [512, 1, 1];
    } else if (reduceInfo.inSize >= 4096) {
      this.workgroupSize = [256, 1, 1];
    } else {
      this.workgroupSize = [64, 1, 1];
    }
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);
    this.reduceType = reduceType;
    this.shaderKey = `reduce_${reduceType}`;
  }
  getUserCode() {
    let reduceOp = ``;
    let initValue = "0.0";
    const workgroupSizeX = this.workgroupSize[0];
    if (this.reduceType === "min" || this.reduceType === "max") {
      reduceOp = `
         if (isnan(candidate)) {
          bestValue = uniforms.NAN;
         } else if (!isnan(bestValue) && candidate ${this.reduceType === "min" ? "<" : ">"} bestValue)
           {  bestValue = candidate; }`;
      initValue = "f32(x[offset])";
    } else if (this.reduceType === "sum" || this.reduceType === "mean") {
      reduceOp = " bestValue = bestValue + candidate; ";
    } else if (this.reduceType === "prod") {
      reduceOp = " bestValue = bestValue * candidate; ";
      initValue = "1.0";
    } else if (this.reduceType === "all") {
      reduceOp = " bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ";
      initValue = "1.0";
    } else if (this.reduceType === "any") {
      reduceOp = " bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ";
      initValue = "0.0";
    }
    const outputSnippet = this.reduceType === "mean" ? (
      // tslint:disable-next-line:max-line-length
      `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));`
    ) : `setOutputAtIndex(outputIndex, bestValue);`;
    const sharedMemorySnippet = `
         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;
       `;
    const userCode = `
       fn DIV_CEIL(a : u32, b : u32) -> u32 {
        return ((a - 1u) / b + 1u);
       }

       ${sharedMemorySnippet}
       fn getOffset(outputIndex : i32) -> i32 {
         let outputCoords = getCoordsFromIndex(outputIndex);
         let offset = ${this.outputShape.length === 1 ? "outputCoords" : "outputCoords[0]"} * uniforms.reduceSize;
          return offset;
       }
       ${getMainHeaderString("index")} {
         let outputIndex = index / ${workgroupSizeX};
         let offset = getOffset(outputIndex);
         var bestValue = ${initValue};
         let Length = uniforms.reduceSize;
         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);
         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;
             k = k + ${workgroupSizeX}) {
           let candidate = f32(x[offset + k]);
           ${reduceOp}
         }
         xBestValues[localId.x] = bestValue;
         workgroupBarrier();

         var reduceSize = min(u32(Length), ${workgroupSizeX}u);
         for (var currentSize = reduceSize / 2u; reduceSize > 1u;
             currentSize = reduceSize / 2u) {
           let interval = DIV_CEIL(reduceSize, 2u);
           if (localId.x < currentSize) {
            let candidate = xBestValues[localId.x + interval];
            ${reduceOp}
            xBestValues[localId.x] = bestValue;
           }
           reduceSize = interval;
           workgroupBarrier();
         }

         if (localId.x == 0u && outputIndex < uniforms.size) {
          ${outputSnippet}
        }
       }
     `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/reduce.js
var RETURN_TYPES = {
  "mean": "float32",
  "all": "bool",
  "any": "bool"
};
function reduce(x, axis, keepDims, reduceType, backend2) {
  const xRank = x.shape.length;
  const toDispose = [];
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  let input = x;
  if (permutedAxes != null) {
    input = transpose2({ inputs: { x }, attrs: { perm: permutedAxes }, backend: backend2 });
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    toDispose.push(input);
  }
  backend_util_exports.assertAxesAreInnerMostDims(reduceType, axes, xRank);
  const [reduceOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(input.shape, axes);
  let resOutShape = reduceOutShape;
  if (keepDims) {
    resOutShape = backend_util_exports.expandShapeToKeepDim(reduceOutShape, origAxes);
  }
  let res;
  if ((reduceType === "max" || reduceType === "prod") && backend2.shouldExecuteOnCPU([input])) {
    const xVals = backend2.tensorMap.get(input.dataId).values;
    switch (reduceType) {
      case "max":
        const outValues = maxImplCPU(xVals, util_exports.sizeFromShape(reduceShape), resOutShape, x.dtype);
        res = backend2.makeTensorInfo(resOutShape, x.dtype, outValues);
        break;
      case "prod":
        const { outVals, outShape, outDtype } = prodImplCPU(input.shape, input.dtype, xVals, axes);
        res = backend2.makeTensorInfo(outShape, outDtype, outVals);
        break;
      default:
        throw new Error(`${reduceType} CPU implementation is not yet supported.`);
    }
  } else {
    const inSize = util_exports.sizeFromShape(reduceShape);
    const xSize = util_exports.sizeFromShape(input.shape);
    const batchSize = xSize / inSize;
    const reduceInfo = { windowSize: inSize, inSize, batchSize, outSize: 1 };
    const dtype = RETURN_TYPES[reduceType] || sumOutType(x.dtype);
    const uniformData = [
      { type: "int32", data: [inSize] }
    ];
    const program = new ReduceProgram(reduceInfo, reduceType, backend2.device.limits.maxComputeWorkgroupSizeX);
    const reduced = backend2.runWebGPUProgram(program, [input], dtype, uniformData);
    toDispose.push(reduced);
    res = reshape2({ inputs: { x: reduced }, attrs: { shape: resOutShape }, backend: backend2 });
  }
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return res;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/All.js
function all2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { keepDims, axis } = attrs;
  return reduce(x, axis, keepDims, "all", backend2);
}
var allConfig = {
  kernelName: All,
  backendName: "webgpu",
  kernelFunc: all2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Any.js
function any2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { keepDims, axis } = attrs;
  return reduce(x, axis, keepDims, "any", backend2);
}
var anyConfig = {
  kernelName: Any,
  backendName: "webgpu",
  kernelFunc: any2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/argminmax_webgpu.js
var ArgMinMaxProgram = class {
  constructor(inputShape, axis, reduceType) {
    this.workgroupSize = [64, 1, 1];
    this.variableNames = ["x"];
    this.uniforms = "infinityValue : f32,";
    this.size = true;
    const axes = [axis];
    this.op = reduceType === "min" ? "<" : ">";
    const [outputShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(inputShape, axes);
    this.outputShape = outputShape.length === 0 ? [1] : outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    if (util_exports.sizeFromShape(reduceShape) < 32) {
      this.type = "plain";
      this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    } else {
      this.type = "shared";
      this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);
    }
    this.inputShape = inputShape;
    this.shaderKey = `argMinMax_${this.op}_${this.type}`;
  }
  getUserCode() {
    const workgroupSizeX = this.workgroupSize[0];
    const getInputShapeLastDim = () => {
      if (this.inputShape.length === 1) {
        return "uniforms.xShape";
      } else {
        return `uniforms.xShape.${getCoordsXYZ(this.inputShape.length - 1)}`;
      }
    };
    const splitOutputCoords = () => {
      let snippet = "";
      if (this.outputShape.length === 1) {
        if (this.inputShape.length !== 1) {
          snippet += "outputCoords,";
        }
      } else {
        for (let i = 0; i < this.outputShape.length; i++) {
          snippet += `outputCoords.${getCoordsXYZ(i)},`;
        }
      }
      return snippet;
    };
    if (this.type === "shared") {
      const sharedMemorySnippet = `
      var<workgroup> xBestIndices : array<i32, ${workgroupSizeX}>;
      var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;
    `;
      const userCode = `
      fn DIV_CEIL(a : u32, b : u32) -> u32 {
        return ((a - 1u) / b + 1u);
      }

      ${sharedMemorySnippet}

      ${getMainHeaderString("index")} {
        let outputIndex = index / ${workgroupSizeX};
        let reduceLength = ${getInputShapeLastDim()};

        var bestIndex = i32(localId.x);
        var bestValue = uniforms.infinityValue;
        let outputCoords = getCoordsFromIndex(outputIndex);
        for (var k = i32(localId.x); k < reduceLength && outputIndex < uniforms.size;
            k = k + ${workgroupSizeX}) {
          let candidate = getX(${splitOutputCoords()} k);
          if (!isnan(candidate) && candidate ${this.op} bestValue) {
            bestValue = candidate;
            bestIndex = k;
          }
        }
        xBestValues[localId.x] = bestValue;
        xBestIndices[localId.x] = bestIndex;
        workgroupBarrier();

        var reduceSize = min(u32(reduceLength), ${workgroupSizeX}u);
        for (var currentSize = reduceSize / 2u; reduceSize > 1u;
            currentSize = reduceSize / 2u) {
          let interval = DIV_CEIL(reduceSize, 2u);
          if (localId.x < currentSize) {
            let candidate = xBestValues[localId.x + interval];
            if (candidate ${this.op} bestValue) {
              bestValue = candidate;
              xBestValues[localId.x] = bestValue;
              xBestIndices[localId.x] = xBestIndices[localId.x + interval];
            }
          }
          reduceSize = interval;
          workgroupBarrier();
        }

        if (localId.x == 0u && outputIndex < uniforms.size) {
          setOutputAtIndexI32(outputIndex, xBestIndices[localId.x]);
        }
      }
    `;
      return userCode;
    } else {
      const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let outputCoords = getCoordsFromIndex(index);
          var bestIndex = 0;
          var bestValue = getX(${splitOutputCoords()} 0);
          let reduceLength = ${getInputShapeLastDim()};
          for (var i = 1; i < reduceLength; i++) {
            let candidate = getX(${splitOutputCoords()} i);
            if (candidate ${this.op} bestValue) {
              bestValue = candidate;
              bestIndex = i;
            }
          }
          setOutputAtIndexI32(index, bestIndex);
        }
      }
      `;
      return userCode;
    }
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ArgMax.js
function argMax2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  let axes = util_exports.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("argMax", [axes[0]], $x.shape.length);
  const program = new ArgMinMaxProgram($x.shape, axes[0], "max");
  const uniformData = [{ type: "float32", data: [Number.NEGATIVE_INFINITY] }];
  const out = backend2.runWebGPUProgram(program, [$x], "int32", uniformData);
  intermediateTensorInfos.forEach((t2) => backend2.disposeData(t2.dataId));
  return out;
}
var argMaxConfig = {
  kernelName: ArgMax,
  backendName: "webgpu",
  kernelFunc: argMax2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ArgMin.js
function argMin2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  let axes = util_exports.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("argMin", [axes[0]], $x.shape.length);
  const program = new ArgMinMaxProgram($x.shape, axes[0], "min");
  const uniformData = [{ type: "float32", data: [Number.POSITIVE_INFINITY] }];
  const out = backend2.runWebGPUProgram(program, [$x], "int32", uniformData);
  intermediateTensorInfos.forEach((t2) => backend2.disposeData(t2.dataId));
  return out;
}
var argMinConfig = {
  kernelName: ArgMin,
  backendName: "webgpu",
  kernelFunc: argMin2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Asin.js
var asin2 = unaryKernelFunc({ opType: UnaryOpType.ASIN });
var asinConfig = {
  kernelName: Asin,
  backendName: "webgpu",
  kernelFunc: asin2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Asinh.js
var asinh2 = unaryKernelFunc({ opType: UnaryOpType.ASINH });
var asinhConfig = {
  kernelName: Asinh,
  backendName: "webgpu",
  kernelFunc: asinh2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Atan.js
var atan3 = unaryKernelFunc({ opType: UnaryOpType.ATAN });
var atanConfig = {
  kernelName: Atan,
  backendName: "webgpu",
  kernelFunc: atan3
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Atan2.js
var atan22 = binaryKernelFunc({ opType: BinaryOpType.ATAN2 });
var atan2Config = {
  kernelName: Atan2,
  backendName: "webgpu",
  kernelFunc: atan22
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Atanh.js
var atanh2 = unaryKernelFunc({ opType: UnaryOpType.ATANH });
var atanhConfig = {
  kernelName: Atanh,
  backendName: "webgpu",
  kernelFunc: atanh2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/pool_filtersizeone_webgpu.js
var PoolWithFilterSizeEqualsOneProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x"];
    this.uniforms = `strides : vec2<i32>,`;
    this.workgroupSize = [256, 1, 1];
    this.size = true;
    this.outputShape = convInfo.outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "poolWithFilterSizeEqualsOne";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let batch = coords[0];
          let d = coords[3];

          let xRCCorner = coords.yz * uniforms.strides;
          let xRCorner = xRCCorner.x;
          let xCCorner = xRCCorner.y;

          let value = getX(batch, xRCorner, xCCorner, d);
          setOutputAtIndex(index, value);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/pool_webgpu.js
var Pool2DProgram = class {
  constructor(convInfo, poolType, computePositions = false, flattenPositions = false, includeBatchIndex = false) {
    this.variableNames = ["x"];
    this.uniforms = `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, convDims : vec2<i32>, filterDims : vec2<i32>,`;
    this.workgroupSize = [128, 1, 1];
    this.size = true;
    if (poolType === "avg" && computePositions) {
      throw new Error("Cannot compute positions for average pool.");
    }
    this.outputShape = convInfo.outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.poolType = poolType;
    this.computePositions = computePositions;
    this.flattenPositions = flattenPositions;
    this.includeBatchIndex = includeBatchIndex;
    this.shaderKey = `pool2D_${poolType}_${computePositions}_${flattenPositions}_${includeBatchIndex}`;
  }
  getUserCode() {
    let updateSnippet;
    if (this.poolType === "avg") {
      updateSnippet = `resultValue = resultValue + value; count = count + 1.0;`;
    } else if (this.computePositions) {
      const positionStr = this.flattenPositions ? this.includeBatchIndex ? `((batch * uniforms.xShape[1] + xR) * uniforms.xShape[2] + xC) * uniforms.xShape[3] + d` : `(xR * uniforms.xShape[2] + xC) * uniforms.xShape[3] + d` : `wR * uniforms.filterDims.y + wC`;
      updateSnippet = `let currMaxValue = mix(value, maxValue, maxValueFound);
      if (value >= currMaxValue) {
        maxValue = value;
        maxValueFound = 1.0;
        maxPosition = ${positionStr};
      }`;
    } else {
      updateSnippet = `resultValue = max(value, resultValue);`;
    }
    let returnValue = `resultValue`;
    if (this.poolType === "avg") {
      returnValue = `resultValue / max(count, 1.0)`;
    }
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
          let batch = coords[0];
          let d = coords[3];
          let xRCCorner = vec2<i32>(coords.yz) * uniforms.strides - uniforms.pads;
          let xRCorner = xRCCorner.x;
          let xCCorner = xRCCorner.y;

          ${this.computePositions ? `var maxValue = 0.0;
            var maxValueFound = 0.0;
            var maxPosition = 0;` : `var resultValue = ${this.poolType === "avg" ? "0.0" : "-1.0 / pow(10.0, -20.0)"};`}

          var count = 0.0;
          for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + uniforms.dilations.x) {
            let xR = xRCorner + wR;

            if (xR < 0 || xR >= uniforms.convDims.x) {
              continue;
            }

            for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + uniforms.dilations.y) {
              let xC = xCCorner + wC;
              if (xC < 0 || xC >= uniforms.convDims.y) {
                continue;
              }

              let value = getX(batch, xR, xC, d);
              ${updateSnippet}
            }
          }

          ${this.computePositions ? `setOutputAtIndexI32(index, maxPosition);` : `setOutputAtIndex(index, ${returnValue});`}
        }
      }
    `;
    return userCode;
  }
};
var Pool3DProgram = class {
  constructor(convInfo, poolType, computePositions = false, flattenPositions = false, includeBatchIndex = false) {
    this.variableNames = ["x"];
    this.uniforms = `strides : vec3<i32>, pads : vec3<i32>, convDims : vec3<i32>, filterDims : vec3<i32>,`;
    this.workgroupSize = [128, 1, 1];
    this.size = true;
    if (poolType === "avg" && computePositions) {
      throw new Error("Cannot compute positions for average pool.");
    }
    this.outputShape = convInfo.outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.poolType = poolType;
    this.computePositions = computePositions;
    this.flattenPositions = flattenPositions;
    this.includeBatchIndex = includeBatchIndex;
    this.shaderKey = `pool3D_${poolType}_${computePositions}_${flattenPositions}_${includeBatchIndex}`;
  }
  getUserCode() {
    let updateSnippet;
    if (this.poolType === "avg") {
      updateSnippet = `resultValue += value; count += 1.0;`;
    } else if (this.computePositions) {
      const positionStr = this.flattenPositions ? this.includeBatchIndex ? `(((batch * uniforms.xShape.y + xD) * uniforms.xShape.z + xR) * uniforms.xShape.w + xC) * uniforms.xShape.u + ch` : `((xD * uniforms.xShape.z + xR) * uniforms.xShape.w + xC) * uniforms.xShape.u + ch` : `wD * uniforms.filterDims.y * uniforms.filterDims.y + wR * uniforms.filterDims.z + wC`;
      updateSnippet = `let currMaxValue = mix(value, maxValue, maxValueFound);
      if (value >= currMaxValue) {
        maxValue = value;
        maxValueFound = 1.0;
        maxPosition = ${positionStr};
      }`;
    } else {
      updateSnippet = `resultValue = max(value, resultValue);`;
    }
    let returnValue = `resultValue`;
    if (this.poolType === "avg") {
      returnValue = `resultValue / max(count, 1.0)`;
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let batch = coords.x;
          let ch = coords.u;

          let xCorner = vec3<i32>(coords.y, coords.z, coords.w) * uniforms.strides - uniforms.pads;
          let xDCorner = xCorner.x;
          let xRCorner = xCorner.y;
          let xCCorner = xCorner.z;

          ${this.computePositions ? `var maxValue = 0.0;
            var maxValueFound = 0.0;
            var maxPosition = 0;` : `var resultValue = ${this.poolType === "avg" ? "0.0" : "-1.0 / pow(10.0, -20.0)"};`}

          var count = 0.0;
          for (var wD = 0; wD < uniforms.filterDims.x; wD++) {
            let xD = xDCorner + wD;
            if (xD < 0 || xD >= uniforms.convDims.x) {
              continue;
            }

            for (var wR = 0; wR < uniforms.filterDims.y; wR++) {
              let xR = xRCorner + wR;
              if (xR < 0 || xR >= uniforms.convDims.y) {
                continue;
              }

              for (var wC = 0; wC < uniforms.filterDims.z; wC++) {
                let xC = xCCorner + wC;
                if (xC < 0 || xC >= uniforms.convDims.z) {
                  continue;
                }

                let value = getX(batch, xD, xR, xC, ch);
                ${updateSnippet}
              }
            }
          }

          ${this.computePositions ? `setOutputAtIndexI32(index, maxPosition);` : `setOutputAtIndex(index, ${returnValue});`}
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Max.js
function max2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { reductionIndices, keepDims } = attrs;
  return reduce(x, reductionIndices, keepDims, "max", backend2);
}
var maxConfig = {
  kernelName: Max,
  backendName: "webgpu",
  kernelFunc: max2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Mean.js
function mean2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { keepDims, axis } = attrs;
  return reduce(x, axis, keepDims, "mean", backend2);
}
var meanConfig = {
  kernelName: Mean,
  backendName: "webgpu",
  kernelFunc: mean2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Pool_impl.js
function poolImpl(x, convInfo, poolType, backend2) {
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    return identity({ inputs: { x }, backend: backend2 });
  }
  if (convInfo.filterWidth === convInfo.inWidth && convInfo.filterHeight === convInfo.inHeight && convInfo.batchSize === 1 && convInfo.padInfo.type === "VALID") {
    const length = x.shape.length;
    const reshapeX = reshape2({
      inputs: { x },
      backend: backend2,
      attrs: {
        shape: [
          x.shape[length - 3] * x.shape[length - 2],
          x.shape[length - 1]
          /* channel */
        ]
      }
    });
    let reduceX;
    if (poolType === "avg") {
      reduceX = mean2({ inputs: { x: reshapeX }, backend: backend2, attrs: { axis: 0, keepDims: false } });
    } else {
      util_exports.assert(poolType === "max", () => `Invalid pool type ${poolType}`);
      reduceX = max2({
        inputs: { x: reshapeX },
        backend: backend2,
        attrs: { reductionIndices: 0, keepDims: false }
      });
    }
    const result = reshape2({ inputs: { x: reduceX }, backend: backend2, attrs: { shape: convInfo.outShape } });
    backend2.disposeData(reshapeX.dataId);
    backend2.disposeData(reduceX.dataId);
    return result;
  }
  let program;
  const dimensions = [{ type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] }];
  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1) {
    program = new PoolWithFilterSizeEqualsOneProgram(convInfo);
  } else {
    if (poolType === "avg") {
      program = new Pool2DProgram(convInfo, "avg");
    } else {
      util_exports.assert(poolType === "max", () => `Invalid pool type ${poolType}`);
      program = new Pool2DProgram(convInfo, "max");
    }
    dimensions.push({ type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] }, {
      type: "int32",
      data: [convInfo.dilationHeight, convInfo.dilationWidth]
    }, { type: "int32", data: [convInfo.inHeight, convInfo.inWidth] }, {
      type: "int32",
      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
    });
  }
  return backend2.runWebGPUProgram(program, [x], x.dtype, dimensions);
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPool.js
function avgPool2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = 1;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  return poolImpl(x, convInfo, "avg", backend2);
}
var avgPoolConfig = {
  kernelName: AvgPool,
  backendName: "webgpu",
  kernelFunc: avgPool2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPool3D.js
function avgPool3D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode, dataFormat);
  const avgPoolProgram = new Pool3DProgram(convInfo, "avg");
  const dimensions = [
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    {
      type: "int32",
      data: [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]
    },
    {
      type: "int32",
      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth
      ]
    }
  ];
  return backend2.runWebGPUProgram(avgPoolProgram, [x], x.dtype, dimensions);
}
var avgPool3DConfig = {
  kernelName: AvgPool3D,
  backendName: "webgpu",
  kernelFunc: avgPool3D
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/avg_pool_backprop_webgpu.js
var AvgPool2DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy"];
    this.uniforms = `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, filterDims : vec2<i32>,
       outHeight : i32, outWidth : i32, avgMultiplier : f32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `avgPool2DBackprop`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords[0];
        let d = coords[3];

        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;
        let dyRCorner = dyRCCorner.x;
        let dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var wR = 0; wR < uniforms.filterDims[0]; wR = wR + uniforms.dilations[0]) {
          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);

          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
            continue;
          }
          let idyR = i32(dyR);

          for (var wC = 0; wC < uniforms.filterDims[1]; wC = wC + uniforms.dilations[1]) {
            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);

            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
              continue;
            }
            let idyC = i32(dyC);

            let dyValue = getDy(batch, idyR, idyC, d);

            dotProd = dotProd + dyValue * uniforms.avgMultiplier;
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
    `;
    return userCode;
  }
};
var AvgPool3DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy"];
    this.uniforms = `strides : vec3<i32>, pads : vec3<i32>, filterDims : vec3<i32>,
       outDepth : i32, outHeight : i32, outWidth : i32, avgMultiplier : f32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `avgPool3DBackprop`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords.x;
        let ch = coords.u;

        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;
        let dyDCorner = dyCorner.x;
        let dyRCorner = dyCorner.y;
        let dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var wD = 0; wD < uniforms.filterDims[0]; wD++) {
          let dyD = f32(dyDCorner + wD) / f32(uniforms.strides[0]);

          if (dyD < 0.0 || dyD >= f32(uniforms.outDepth) || fract(dyD) > 0.0) {
            continue;
          }
          let idyD = i32(dyD);

          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {
            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);

            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
              continue;
            }
            let idyR = i32(dyR);

            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {
              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);

              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
                continue;
              }
              let idyC = i32(dyC);

              let dyValue = getDy(batch, idyD, idyR, idyC, ch);
              dotProd += dyValue * uniforms.avgMultiplier;
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPool3DGrad.js
function avgPool3DGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input } = inputs;
  const x = input;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
  const program = new AvgPool3DBackpropProgram(convInfo);
  const avgMultiplier = 1 / (convInfo.filterDepth * convInfo.filterHeight * convInfo.filterWidth);
  const uniformData = [
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth - 1 - convInfo.padInfo.front,
        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,
        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left
      ]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth
      ]
    },
    { type: "int32", data: [convInfo.outDepth] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "float32", data: [avgMultiplier] }
  ];
  return backend2.runWebGPUProgram(program, [dy], x.dtype, uniformData);
}
var avgPool3DGradConfig = {
  kernelName: AvgPool3DGrad,
  backendName: "webgpu",
  kernelFunc: avgPool3DGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPoolGrad.js
function avgPoolGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input } = inputs;
  const x = input;
  assertNotComplex([dy, input], "avgPoolGrad");
  const { filterSize, strides, pad: pad2 } = attrs;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2);
  const program = new AvgPool2DBackpropProgram(convInfo);
  const avgMultiplier = 1 / (convInfo.filterHeight * convInfo.filterWidth);
  const uniformData = [
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,
        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left
      ]
    },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] },
    {
      type: "int32",
      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
    },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "float32", data: [avgMultiplier] }
  ];
  return backend2.runWebGPUProgram(program, [dy], x.dtype, uniformData);
}
var avgPoolGradConfig = {
  kernelName: AvgPoolGrad,
  backendName: "webgpu",
  kernelFunc: avgPoolGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/BatchMatMul.js
function batchMatMul(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { a, b } = inputs;
  const { transposeA, transposeB } = attrs;
  return batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend2 });
}
var batchMatMulConfig = {
  kernelName: BatchMatMul,
  backendName: "webgpu",
  kernelFunc: batchMatMul
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/slice_webgpu.js
var SliceProgram = class {
  constructor(start, destSize) {
    this.variableNames = ["source"];
    this.workPerThread = 1;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = destSize;
    this.rank = destSize.length;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
    this.start = start;
    this.uniforms = `start : ${getCoordsDataType(start.length)}, `;
    this.shaderKey = "slice";
  }
  getUserCode() {
    const dtype = getCoordsDataType(this.rank);
    const sourceCoords = getCoords(this.rank);
    let coordSum;
    if (this.start.length === 1) {
      coordSum = this.outputShape.map((_, i) => {
        return `sourceLoc = uniforms.start + coords;`;
      });
    } else {
      coordSum = this.outputShape.map((_, i) => {
        return `sourceLoc.${coords[i]} = uniforms.start.${getCoordsXYZ(i)} + coords.${coords[i]};`;
      });
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          var sourceLoc : ${dtype};
          let coords = getCoordsFromIndex(index);
          ${coordSum.join("\n")}
          setOutputAtIndex(index, getSource(${sourceCoords}));
        }
      }
    `;
    return userCode;
  }
};
var coords = ["x", "y", "z", "w", "u", "v"];
function getCoords(rank) {
  if (rank === 1) {
    return "sourceLoc";
  } else if (rank <= 6) {
    return coords.slice(0, rank).map((coord) => `sourceLoc.${coord}`).join(",");
  } else {
    throw Error(`Slicing for rank ${rank} is not yet supported`);
  }
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Slice.js
function slice2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { begin, size } = attrs;
  const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size);
  slice_util_exports.assertParamsValid(x, $begin, $size);
  if (backend2.shouldExecuteOnCPU([x]) || x.dtype === "string") {
    const xTensorData = backend2.tensorMap.get(x.dataId);
    const outValues = sliceImplCPU(xTensorData.values, $begin, $size, x.shape, x.dtype);
    return backend2.makeTensorInfo($size, x.dtype, outValues);
  }
  if (util_exports.sizeFromShape($size) === 0) {
    return backend2.makeTensorInfo($size, x.dtype, []);
  }
  const program = new SliceProgram($begin, $size);
  const uniformData = [{ type: "int32", data: $begin }];
  return backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
}
var sliceConfig = {
  kernelName: Slice,
  backendName: "webgpu",
  kernelFunc: slice2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/BatchToSpaceND.js
var batchToSpaceND2 = (args) => {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockShape, crops } = attrs;
  util_exports.assert(x.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGPU backend not implemented yet");
  const prod3 = blockShape.reduce((a, b) => a * b);
  const reshaped = backend_util_exports.getReshaped(x.shape, blockShape, prod3);
  const permuted = backend_util_exports.getPermuted(reshaped.length, blockShape.length);
  const reshapedPermuted = backend_util_exports.getReshapedPermuted(x.shape, blockShape, prod3);
  const sliceBeginCoords = backend_util_exports.getSliceBeginCoords(crops, blockShape.length);
  const sliceSize = backend_util_exports.getSliceSize(reshapedPermuted, crops, blockShape.length);
  const toDispose = [];
  const reshapedIntermediate = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: reshaped } });
  const transposedIntermediate = transpose2({ inputs: { x: reshapedIntermediate }, backend: backend2, attrs: { perm: permuted } });
  const reshapedIntermediate2 = reshape2({
    inputs: { x: transposedIntermediate },
    backend: backend2,
    attrs: { shape: reshapedPermuted }
  });
  const sliced = slice2({
    inputs: { x: reshapedIntermediate2 },
    backend: backend2,
    attrs: { begin: sliceBeginCoords, size: sliceSize }
  });
  toDispose.push(reshapedIntermediate);
  toDispose.push(transposedIntermediate);
  toDispose.push(reshapedIntermediate2);
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return sliced;
};
var batchToSpaceNDConfig = {
  kernelName: BatchToSpaceND,
  backendName: "webgpu",
  kernelFunc: batchToSpaceND2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/bincount_webgpu.js
var writeSnippet = `
  fn bincount_write(index: i32, value: f32) {
    ${atomicAddSnippet("&result[index]", "value", "float32")}
  }
`;
var binaryWriteSnippet = `
  fn bincount_write(index: i32, value: f32) {
    atomicStore(&result[index], bitcast<i32>(value));
  }
`;
var BincountProgram = class {
  constructor(shape, hasWeights, binaryOutput = false) {
    this.outputShape = [];
    this.variableNames = ["x"];
    this.uniforms = "binCountSize : i32,";
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.hasWeights = true;
    this.binaryOutput = false;
    this.outputShape = shape;
    this.rank = shape.length;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.binaryOutput = binaryOutput;
    if (binaryOutput) {
      this.atomic = false;
    }
    this.hasWeights = hasWeights;
    if (this.hasWeights) {
      this.variableNames.push("w");
    }
    this.shaderKey = `bincount_${this.hasWeights}_${this.binaryOutput}_${this.rank}`;
  }
  getUserCode() {
    const userCode = `
    ${this.binaryOutput ? binaryWriteSnippet : writeSnippet}
  ${getMainHeaderString("index")} {
    ${this.rank === 1 ? `if (index < uniforms.xShape) {
      let indexVal = i32(getX(index));
      if (indexVal < uniforms.binCountSize) {
        let value = ${this.binaryOutput ? 1 : this.hasWeights ? "getW(index)" : "1."};
        bincount_write(indexVal, value);
      }
    }` : `let coord = getCoordsFromIndex(index);
    if (coordsInBounds2D(coord, uniforms.xShape)) {
      let indexVal = i32(getX(coord[0], coord[1]));
      if (indexVal < uniforms.binCountSize) {
        let value = ${this.binaryOutput ? 1 : this.hasWeights ? "getW(coord[0], coord[1])" : "1."};
        bincount_write(coord.x * uniforms.binCountSize + indexVal, value);
      }
    }`}
  }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Bincount.js
function bincount2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, weights } = inputs;
  const { size } = attrs;
  const xSize = util_exports.sizeFromShape(x.shape);
  const weightsSize = util_exports.sizeFromShape(weights.shape);
  const hasWeights = weightsSize > 0;
  const outputSize = [size];
  const dtype = weights.dtype;
  const output = fill2({ backend: backend2, attrs: { shape: outputSize, value: 0, dtype } });
  const program = new BincountProgram([xSize], hasWeights);
  const uniformData = [{ type: "int32", data: [size] }];
  const bincountInputs = hasWeights ? [x, weights] : [x];
  const res = backend2.runWebGPUProgram(program, bincountInputs, dtype, uniformData, output);
  return res;
}
var bincountConfig = {
  kernelName: Bincount,
  backendName: "webgpu",
  kernelFunc: bincount2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/broadcast_args_webgpu.js
var BroadcastArgsProgram = class {
  constructor(shape) {
    this.outputShape = [];
    this.variableNames = ["s0", "s1"];
    this.uniforms = "s0Size : i32, s1Size : i32, ";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [shape];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "broadcastArgs";
  }
  getUserCode() {
    const userCode = `
  ${getMainHeaderString("index")} {
    if (index < uniforms.size) {
      var s0 = 1.0;
      var s1 = 1.0;
      let indexS0 = index - uniforms.size + uniforms.s0Size;
      let indexS1 = index - uniforms.size + uniforms.s1Size;
      if (indexS0 >= 0) {
        s0 = getS0(indexS0);
      }
      if (indexS1 >= 0) {
        s1 = getS1(indexS1);
      }

      if (s0 == 1.0) {
        setOutputAtIndex(index, s1);
      } else if (s1 == 1.0) {
        setOutputAtIndex(index, s0);
      } else if (s0 != s1) {
        setOutputAtIndex(index, uniforms.NAN);
      } else {
        setOutputAtIndex(index, s0);
      }
    }
  }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/BroadcastArgs.js
function broadcastArgs2(args) {
  const { inputs, backend: backend2 } = args;
  const { s0, s1 } = inputs;
  if (backend2.shouldExecuteOnCPU([s0, s1])) {
    const s0TensorInfo = backend2.tensorMap.get(s0.dataId);
    const s1TensorInfo = backend2.tensorMap.get(s1.dataId);
    const s0Vals = s0TensorInfo.values;
    const s1Vals = s1TensorInfo.values;
    const broadcastShape = backend_util_exports.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
    return backend2.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
  }
  const s0Size = util_exports.sizeFromShape(s0.shape);
  const s1Size = util_exports.sizeFromShape(s1.shape);
  const outputSize = Math.max(s0Size, s1Size);
  const program = new BroadcastArgsProgram(outputSize);
  const uniformData = [{ type: "int32", data: [s0Size] }, { type: "int32", data: [s1Size] }];
  return backend2.runWebGPUProgram(program, [s0, s1], "int32", uniformData);
}
var broadcastArgsConfig = {
  kernelName: BroadcastArgs,
  backendName: "webgpu",
  kernelFunc: broadcastArgs2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/NotEqual.js
var notEqual2 = binaryKernelFunc({
  opType: BinaryOpType.NOT_EQUAL,
  dtype: "bool",
  cpuKernelImpl: notEqualImplCPU
});
var notEqualConfig = {
  kernelName: NotEqual,
  backendName: "webgpu",
  kernelFunc: notEqual2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Real.js
function real2(args) {
  const { inputs, backend: backend2 } = args;
  const { input } = inputs;
  const inputData = backend2.tensorMap.get(input.dataId);
  return identity({ inputs: { x: inputData.complexTensorInfos.real }, backend: backend2 });
}
var realConfig = {
  kernelName: Real,
  backendName: "webgpu",
  kernelFunc: real2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/int.js
function int(input, backend2) {
  const program = new UnaryOpProgram(input.shape, UnaryOpType.TO_INT);
  const output = backend2.runWebGPUProgram(program, [input], "int32");
  return { dataId: output.dataId, shape: output.shape, dtype: output.dtype };
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Cast.js
function cast2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { dtype } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity({ inputs: { x }, backend: backend2 });
    }
    const zerosTensor = zeros(x.shape);
    const floatX = cast2({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
    const result = complex2({ inputs: { real: floatX, imag: zerosTensor }, backend: backend2 });
    zerosTensor.dispose();
    backend2.disposeData(floatX.dataId);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real2({ inputs: { input: x }, backend: backend2 });
    const result = cast2({ inputs: { x: realPart }, backend: backend2, attrs: { dtype } });
    backend2.disposeData(realPart.dataId);
    return result;
  }
  if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity({ inputs: { x }, backend: backend2 });
    return { dataId: result.dataId, shape: result.shape, dtype };
  }
  if (backend2.shouldExecuteOnCPU([x])) {
    const values = backend2.tensorMap.get(x.dataId).values;
    const [resultShape, resultType, resultData] = castImplCPU(values, x.shape, x.dtype, dtype);
    return backend2.makeTensorInfo(resultShape, resultType, resultData);
  }
  if (dtype === "int32") {
    return int(x, backend2);
  }
  if (dtype === "bool") {
    const zerosTensorInfo = backend2.makeTensorInfo([], "bool", util_exports.getTypedArrayFromDType("bool", 1));
    const binaryInputs = { a: x, b: zerosTensorInfo };
    const result = notEqual2({ inputs: binaryInputs, backend: backend2 });
    backend2.disposeData(zerosTensorInfo.dataId);
    return result;
  }
  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
}
var castConfig = {
  kernelName: Cast,
  backendName: "webgpu",
  kernelFunc: cast2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Ceil.js
var ceil2 = unaryKernelFunc({ opType: UnaryOpType.CEIL, cpuKernelImpl: ceilImplCPU });
var ceilConfig = {
  kernelName: Ceil,
  backendName: "webgpu",
  kernelFunc: ceil2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/clip_vec4_webgpu.js
var ClipVec4Program = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.uniforms = "minVal : f32, maxVal : f32,";
    this.workPerThread = 4;
    this.workgroupSize = [64, 1, 1];
    this.outputComponent = 4;
    this.size = true;
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
    this.shaderKey = "clipVec4";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if(index < uniforms.size) {
          let value = getAByOutputIndex(index);
          var clampedValue = clamp(
              value, vec4<f32>(uniforms.minVal), vec4<f32>(uniforms.maxVal));
          clampedValue = select(clampedValue, value, isnanVec4(value));
          setOutputAtIndex(index, clampedValue);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/clip_webgpu.js
var ClipProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.uniforms = "minVal : f32, maxVal : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "clip";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if(index < uniforms.size) {
          let value = getAByOutputIndex(index);
          if (isnan(value)) {
            setOutputAtIndex(index, value);
            return;
          }
          setOutputAtIndex(index, clamp(value, uniforms.minVal, uniforms.maxVal));
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ClipByValue.js
function clipByValue2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { clipValueMin, clipValueMax } = attrs;
  let program;
  const uniformData = [
    { type: "float32", data: [clipValueMin] },
    { type: "float32", data: [clipValueMax] }
  ];
  if (util_exports.sizeFromShape(x.shape) % 4 === 0) {
    program = new ClipVec4Program(x.shape);
  } else {
    program = new ClipProgram(x.shape);
  }
  return backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
}
var clipByValueConfig = {
  kernelName: ClipByValue,
  backendName: "webgpu",
  kernelFunc: clipByValue2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/complex_abs_webgpu.js
var ComplexAbsProgram = class {
  constructor(shape) {
    this.outputShape = [];
    this.variableNames = ["real", "imag"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "complexAbs";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let re = abs(getRealByOutputIndex(index));
        let im = abs(getImagByOutputIndex(index));
        let mx = max(re, im);

        // The length function in wgsl may be not underflow-safe on some GPUs.
        // So the safe solution is to ensure underflow-safety in all cases.
        setOutputAtIndex(index, select(mx * length(vec2<f32>(1, min(re, im)/mx)), 0.0, mx == 0.0));
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ComplexAbs.js
function makeComplexComponentTensorInfo(complexTensor, complexPart) {
  return {
    dataId: complexPart.dataId,
    dtype: complexPart.dtype,
    shape: complexTensor.shape
  };
}
function complexAbs(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  const xData = backend2.tensorMap.get(x.dataId);
  const program = new ComplexAbsProgram(x.shape);
  const programInputs = [
    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),
    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag)
  ];
  return backend2.runWebGPUProgram(program, programInputs, programInputs[0].dtype);
}
var complexAbsConfig = {
  kernelName: ComplexAbs,
  backendName: "webgpu",
  kernelFunc: complexAbs
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/concat_webgpu.js
var ConcatProgram = class {
  constructor(shapes) {
    this.uniforms = "";
    this.workPerThread = 1;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = backend_util_exports.computeOutShape(
      shapes,
      1
      /* axis */
    );
    this.variableNames = shapes.map((_, i) => `T${i}`);
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
    this.offsetLength = shapes.length - 1;
    for (let i = 0; i < this.offsetLength; i++) {
      this.uniforms += `offset${i} : i32,`;
    }
    this.shaderKey = "concat";
  }
  getUserCode() {
    const snippets = [];
    if (this.offsetLength > 0) {
      snippets.push(`if (yC < uniforms.offset0){ setOutputAtCoords(coords.x, coords.y, getT0(yR, yC)); }`);
      for (let i = 1; i < this.offsetLength; i++) {
        snippets.push(`else if (yC < uniforms.offset${[i]}){ setOutputAtCoords(coords.x, coords.y, getT${i}(yR, yC - uniforms.offset${i - 1})); }`);
      }
      const lastIndex = this.offsetLength;
      const lastShiftIndex = this.offsetLength - 1;
      snippets.push(`else { setOutputAtCoords(coords.x, coords.y, getT${lastIndex}(yR, yC - uniforms.offset${lastShiftIndex})); }`);
    } else {
      snippets.push(`setOutputAtCoords(coords.x, coords.y, getT0(yR, yC));`);
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let flatIndex = index * ${this.workPerThread} + i;
          if(flatIndex < uniforms.size) {
            let coords = getCoordsFromIndex(flatIndex);
            let yR = coords.x;
            let yC = coords.y;

            ${snippets.join("\n        ")}
          }
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Imag.js
function imag2(args) {
  const { inputs, backend: backend2 } = args;
  const { input } = inputs;
  const inputData = backend2.tensorMap.get(input.dataId);
  return identity({ inputs: { x: inputData.complexTensorInfos.imag }, backend: backend2 });
}
var imagConfig = {
  kernelName: Imag,
  backendName: "webgpu",
  kernelFunc: imag2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Concat_impl.js
function concatImpl(inputs, axis, backend2) {
  const dtype = inputs[0].dtype;
  if (dtype === "complex64") {
    const reals = inputs.map((t2) => real2({ inputs: { input: t2 }, backend: backend2 }));
    const imags = inputs.map((t2) => imag2({ inputs: { input: t2 }, backend: backend2 }));
    const realConcated = concatImpl(reals, axis, backend2);
    const imagConcated = concatImpl(imags, axis, backend2);
    const result = complex2({ inputs: { real: realConcated, imag: imagConcated }, backend: backend2 });
    reals.forEach((r) => backend2.disposeData(r.dataId));
    imags.forEach((i) => backend2.disposeData(i.dataId));
    backend2.disposeData(realConcated.dataId);
    backend2.disposeData(imagConcated.dataId);
    return result;
  }
  let runOnCpu = backend2.shouldExecuteOnCPU(inputs);
  if (dtype === "string") {
    runOnCpu = true;
  }
  if (runOnCpu) {
    const tensors2D2 = inputs.map((t2) => {
      const innerSize = util_exports.sizeFromShape(t2.shape.slice(axis));
      const shape = [-1, innerSize];
      return reshape2({ inputs: { x: t2 }, backend: backend2, attrs: { shape } });
    });
    const inputsValShapes = tensors2D2.map((t2) => {
      return { vals: backend2.readSync(t2.dataId), shape: t2.shape };
    });
    const outShape2 = backend_util_exports.computeOutShape(
      tensors2D2.map((t2) => t2.shape),
      1
      /* axis */
    );
    const simplyConcat = tensors2D2[0].shape[0] === 1;
    const outVals = concatImplCPU(inputsValShapes, outShape2, dtype, simplyConcat);
    const finalOutShape = backend_util_exports.computeOutShape(inputs.map((t2) => t2.shape), axis);
    const outInfo = backend2.makeTensorInfo(finalOutShape, dtype, outVals);
    tensors2D2.forEach((t2) => backend2.disposeData(t2.dataId));
    return outInfo;
  }
  const maxInputNum = backend2.device.limits.maxStorageBuffersPerShaderStage - 1;
  if (inputs.length > maxInputNum) {
    const reducedInputs = [];
    for (let i = 0; i < inputs.length; i += maxInputNum) {
      const subArray = inputs.slice(i, i + maxInputNum);
      reducedInputs.push(concatImpl(subArray, axis, backend2));
    }
    const result = concatImpl(reducedInputs, axis, backend2);
    for (const i of reducedInputs) {
      backend2.disposeData(i.dataId);
    }
    return result;
  }
  const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend2);
  const shapes = tensors2D.map((t2) => t2.shape);
  const program = new ConcatProgram(shapes);
  const uniformData = [];
  const offsets = new Array(shapes.length - 1);
  if (offsets.length > 0) {
    offsets[0] = shapes[0][1];
    uniformData.push({ type: "int32", data: [offsets[0]] });
    for (let i = 1; i < offsets.length; i++) {
      offsets[i] = offsets[i - 1] + shapes[i][1];
      uniformData.push({ type: "int32", data: [offsets[i]] });
    }
  }
  const res = backend2.runWebGPUProgram(program, tensors2D, tensors2D[0].dtype, uniformData);
  tensors2D.forEach((r) => backend2.disposeData(r.dataId));
  const reshapedResult = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape: outShape } });
  backend2.disposeData(res.dataId);
  return reshapedResult;
}
function computeTensors2D(inputs, axis, backend2) {
  const outShape = backend_util_exports.computeOutShape(inputs.map((t2) => t2.shape), axis);
  const tensors2D = inputs.map((t2) => reshape2({
    inputs: { x: t2 },
    backend: backend2,
    attrs: {
      shape: [
        util_exports.sizeFromShape(t2.shape.slice(0, axis)),
        util_exports.sizeFromShape(t2.shape.slice(axis))
      ]
    }
  }));
  return { tensors2D, outShape };
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Concat.js
function concat2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { axis } = attrs;
  const $axis = util_exports.parseAxisParam(axis, inputs[0].shape)[0];
  const shapes = inputs.map((t2) => t2.shape);
  backend_util_exports.assertParamsConsistent(shapes, $axis);
  const outShape = backend_util_exports.computeOutShape(inputs.map((t2) => t2.shape), $axis);
  if (util_exports.sizeFromShape(outShape) === 0) {
    return backend2.makeTensorInfo(outShape, inputs[0].dtype, []);
  }
  const $inputs = inputs.filter((t2) => util_exports.sizeFromShape(t2.shape) > 0);
  if ($inputs.length === 1) {
    return identity({ inputs: { x: $inputs[0] }, backend: backend2 });
  }
  return concatImpl($inputs, $axis, backend2);
}
var concatConfig = {
  kernelName: Concat,
  backendName: "webgpu",
  kernelFunc: concat2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/conv2d_mm_webgpu.js
function conv2dCommonSnippet(isChannelsLast, fitAOuter, fitBOuter, fitInner, addBias = false, activation = null, hasPreluActivationWeights = false, innerElementSizeX = 4, innerElementSizeW = 4, innerElementSize = 4) {
  const getXSnippet = (innerElementSize2) => {
    switch (innerElementSize2) {
      case 1:
        return "resData = f32(x[xIndex]);";
      case 3:
        return "resData = vec3<f32>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);";
      case 4:
        return "resData = vec4<f32>(x[xIndex / 4]);";
      default:
        throw new Error(`innerElementSize ${innerElementSize2} is not supported.`);
    }
  };
  const getWSnippet = (innerElementSize2) => {
    switch (innerElementSize2) {
      case 1:
        return "return f32(W[row * uniforms.wShape[3] + col]);";
      case 4:
        return "return vec4<f32>(W[(row * uniforms.wShape[3] + col) / 4]);";
      default:
        throw new Error(`innerElementSize ${innerElementSize2} is not supported.`);
    }
  };
  const coordASnippet = isChannelsLast ? `
      let coord = vec4<i32>(batch, xRow, xCol, xCh);
      ` : `
      let coord = vec4<i32>(batch, xCh, xRow, xCol);
      `;
  const coordResSnippet = isChannelsLast ? `
      let coords = vec4<i32>(
        batch,
        row / outWidth,
        row % outWidth,
        col);
      ` : `
      let coords = vec4<i32>(
        batch,
        row,
        col / outWidth,
        col % outWidth);
      `;
  const xHight = isChannelsLast ? "uniforms.xShape[1]" : "uniforms.xShape[2]";
  const xWidth = isChannelsLast ? "uniforms.xShape[2]" : "uniforms.xShape[3]";
  const row = isChannelsLast ? "row" : "col";
  const col = isChannelsLast ? "col" : "row";
  const readXSnippet = `
      let inChannels = uniforms.wShape[2];
      let outWidth = ${isChannelsLast ? "uniforms.outShape[2]" : "uniforms.outShape[3]"};
      let outRow = ${row} / outWidth;
      let outCol = ${row} % outWidth;

      let WRow = ${col} / (uniforms.filterDims[1] * inChannels);
      let WCol = ${col} / inChannels % uniforms.filterDims[1];
      let xRow = outRow * uniforms.strides[0] + uniforms.dilations[0] * WRow - uniforms.pads[0];
      let xCol = outCol * uniforms.strides[1] + uniforms.dilations[1] * WCol - uniforms.pads[1];
      let xCh = ${col} % inChannels;
      var resData = ${typeSnippet(innerElementSizeX)}(0.0);
      // The bounds checking is always needed since we use it to pad zero for
      // the 'same' padding type.
      if (xRow >= 0 && xRow < ${xHight} && xCol >= 0 && xCol < ${xWidth}) {
        ${coordASnippet}
        let xIndex = getIndexFromCoords4D(coord, uniforms.xShape);
        ${getXSnippet(innerElementSizeX)}
      }
      return resData;`;
  const sampleX = isChannelsLast ? fitAOuter && fitInner ? `
      ${readXSnippet}` : `
      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {
        ${readXSnippet}
      }
      return ${typeSnippet(innerElementSizeX)}(0.0);` : fitInner && fitBOuter ? `
      ${readXSnippet}` : `
      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {
        ${readXSnippet}
      }
      return ${typeSnippet(innerElementSizeX)}(0.0);`;
  const sampleW = `${getWSnippet(innerElementSizeW)}`;
  const resType = typeSnippet(innerElementSize);
  const aType = isChannelsLast ? typeSnippet(innerElementSizeX) : typeSnippet(innerElementSizeW);
  const bType = isChannelsLast ? typeSnippet(innerElementSizeW) : typeSnippet(innerElementSizeX);
  const userCode = `
      ${activationFnSnippet(activation, hasPreluActivationWeights, innerElementSize === 4, 4)}
      fn mm_readA(batch: i32, row : i32, col : i32) -> ${aType} {
        ${isChannelsLast ? sampleX : sampleW}
      }

      fn mm_readB(batch: i32, row : i32, col : i32) -> ${bType} {
        ${isChannelsLast ? sampleW : sampleX}
      }

      fn mm_write(batch: i32, row : i32, col : i32, valueIn : ${resType}) {
        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)
        {
        var value = valueIn;
        let outWidth = ${isChannelsLast ? "uniforms.outShape[2]" : "uniforms.outShape[3]"};
        ${coordResSnippet}
        ${biasActivationSnippet(addBias, activation)}
        setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
        }
      }`;
  return userCode;
}
var Conv2DMMProgram = class {
  constructor(convInfo, dimAOuter, dimBOuter, dimInner, addBias = false, activation = null, hasPreluActivationWeights = false, sequentialAccessByThreads = false) {
    this.variableNames = ["x", "W"];
    this.uniforms = `filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, dilations : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
    this.outputShape = convInfo.outShape;
    this.isChannelsLast = convInfo.dataFormat === "channelsLast";
    this.isVec4 = ((convInfo.inChannels % 4 === 0 || convInfo.inChannels % 3 === 0) && this.isChannelsLast || convInfo.outWidth % 4 === 0 && !this.isChannelsLast) && convInfo.outChannels % 4 === 0;
    this.dispatchLayout = this.isChannelsLast ? { x: [3], y: [1, 2], z: [0] } : { x: [2, 3], y: [1], z: [0] };
    this.workgroupSize = computeWorkgroupSizeForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
    this.elementsPerThread = computeWorkPerThreadForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);
    if (this.isVec4) {
      this.outputComponent = 4;
      if (this.isChannelsLast && convInfo.inChannels % 4 !== 0) {
        this.innerElementSize = 3;
        this.variableComponents = [1, 4];
      } else {
        this.innerElementSize = 4;
        this.variableComponents = [4, 4];
      }
      if (addBias) {
        this.variableNames.push("bias");
        this.variableComponents.push(4);
      }
      if (hasPreluActivationWeights) {
        this.variableNames.push("preluActivationWeights");
        this.variableComponents.push(4);
      }
    } else {
      this.innerElementSize = this.elementsPerThread[0];
      if (addBias) {
        this.variableNames.push("bias");
      }
      if (hasPreluActivationWeights) {
        this.variableNames.push("preluActivationWeights");
      }
    }
    this.sequentialAccessByThreads = sequentialAccessByThreads;
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivationWeights = hasPreluActivationWeights;
    this.tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];
    this.tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];
    this.tileInner = Math.max(this.workgroupSize[0] * this.innerElementSize, this.workgroupSize[1]);
    this.fitAOuter = dimAOuter % this.tileAOuter === 0;
    this.fitBOuter = dimBOuter % this.tileBOuter === 0;
    this.fitInner = dimInner % this.tileInner === 0;
    this.shaderKey = `conv2DMM_${this.elementsPerThread}_${this.activation}}_${this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${this.innerElementSize}_${this.isChannelsLast}_${this.sequentialAccessByThreads}`;
  }
  getUserCode() {
    const matMulSource = this.isVec4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, !this.isChannelsLast, this.tileInner) : makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, !this.isChannelsLast, this.tileInner, false, null, this.sequentialAccessByThreads);
    const elementsSize = this.isVec4 ? [this.innerElementSize, 4, 4] : [1, 1, 1];
    const userCode = `
    ${conv2dCommonSnippet(this.isChannelsLast, this.fitAOuter, this.fitBOuter, this.fitInner, this.addBias, this.activation, this.hasPreluActivationWeights, elementsSize[0], elementsSize[1], elementsSize[2])}
    ${matMulSource}
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/conv2d_naive_webgpu.js
var Conv2DNaiveProgram = class {
  constructor(convInfo, addBias = false, activation = null, hasPreluActivationWeights = false) {
    this.variableNames = ["x", "W"];
    this.uniforms = "filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>,";
    this.workgroupSize = [4, 4, 8];
    this.outputShape = convInfo.outShape;
    this.isChannelsLast = convInfo.dataFormat === "channelsLast";
    this.dispatchLayout = this.isChannelsLast ? { x: [2], y: [1], z: [0, 3] } : { x: [3], y: [2], z: [0, 1] };
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivationWeights = hasPreluActivationWeights;
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivationWeights) {
      this.variableNames.push("preluActivationWeights");
    }
    this.shaderKey = `conv2dnaive_${this.activation}_${this.isChannelsLast}`;
  }
  getUserCode() {
    const userCode = `
       ${activationFnSnippet(this.activation, this.hasPreluActivationWeights, false, 4)}
       fn readInp(batch : i32, row : i32, col : i32, chan : i32) -> f32{
         let coords = vec4<i32>(batch, row, col, chan);
         if (coordsInBounds4D(coords, uniforms.xShape)) {
           return  getX(batch, row, col, chan);
         } else {
          return 0.0;
         }
       }
       fn readFilt(row : i32, col : i32, xChannel : i32, outChannel : i32) -> f32{
         let coords = vec4<i32>(row, col, xChannel, outChannel);
         if(coordsInBounds4D(coords, uniforms.wShape)) {
           return getW(row, col, xChannel, outChannel);
          } else {
            return 0.0;
          }
       }
       fn writeResult(batch : i32, row : i32, col : i32, chan : i32, valueIn : f32) {
         let coords = ${this.isChannelsLast ? `vec4<i32>(batch, row, col, chan);` : `vec4<i32>(batch, chan, row, col);`}
         if (coordsInBounds4D(coords, uniforms.outShape)) {
           var value = valueIn;
           ${biasActivationSnippet(this.addBias, this.activation)}
           setOutputAtCoords(coords.x, coords.y, coords.z, coords.w, value);
         }
       }
       ${getMainHeaderString("index")} {
         let coords = getOutputCoords();
         let batch = coords[0];
         let outChannel = ${this.isChannelsLast ? `coords[3];` : `coords[1];`}
         let outRow = ${this.isChannelsLast ? `coords[1];` : `coords[2];`}
         let outCol = ${this.isChannelsLast ? `coords[2];` : `coords[3];`}
         var acc : f32 = 0.0;
         for (var row = 0; row < uniforms.filterDims[0]; row = row + 1) {
           for (var col = 0; col < uniforms.filterDims[1]; col = col + 1) {
             let xRow = outRow * uniforms.strides[0] + uniforms.dilations[0] * row - uniforms.pads[0];
             let xCol = outCol * uniforms.strides[1] + uniforms.dilations[1] * col - uniforms.pads[1];
             for (var xChannel = 0; xChannel < ${this.isChannelsLast ? `uniforms.xShape[3];` : `uniforms.xShape[1];`} xChannel = xChannel + 1) {
               ${this.isChannelsLast ? `let v = readInp(batch, xRow, xCol, xChannel);` : `let v = readInp(batch, xChannel, xRow, xCol);`}
               let f = readFilt(row, col, xChannel, outChannel);
               acc = acc + v * f;
             }
           }
         }
         writeResult(batch, outRow, outCol, outChannel, acc);
       }
     `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/im2col_webgpu.js
var Im2ColProgram = class {
  constructor(outputShape, isChannelsLast) {
    this.variableNames = ["x"];
    this.uniforms = `pads : vec2<i32>, strides : vec2<i32>, dilations : vec2<i32>, outWidth : i32, itemsPerBlockRow : i32,
       inChannels : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.isChannelsLast = isChannelsLast;
    this.shaderKey = `im2col_${this.isChannelsLast}`;
  }
  getUserCode() {
    const rowDim = this.isChannelsLast ? 1 : 2;
    const colDim = this.isChannelsLast ? 2 : 3;
    const row = this.isChannelsLast ? "coords[1]" : "coords[2]";
    const col = this.isChannelsLast ? "coords[2]" : "coords[1]";
    const getXSnippet = this.isChannelsLast ? "getX(batch, xRow, xCol, ch)" : "getX(batch, ch, xRow, xCol)";
    const userCode = `
    ${getMainHeaderString("index")} {
      let coords = getCoordsFromIndex(index);
      if(index < uniforms.size) {
        let batch = coords[0];
        let row = ${row};
        let col = ${col};
        let offsetY = (row / uniforms.outWidth) * uniforms.strides[0] - uniforms.pads[0];
        let xRow = offsetY + uniforms.dilations[0] * (col / uniforms.itemsPerBlockRow);
        var value = 0.0;
        if(xRow < uniforms.xShape[${rowDim}] && xRow >= 0) {
          let offsetX = (row % uniforms.outWidth) * uniforms.strides[1] -
              uniforms.pads[1];
          let xCol = offsetX + uniforms.dilations[1] * ((col %
              uniforms.itemsPerBlockRow) / uniforms.inChannels);
          let ch = col % uniforms.inChannels;
          if(xCol < uniforms.xShape[${colDim}] && xCol >= 0) {
            value = ${getXSnippet};
          }
        }
        setOutputAtIndex(index, value);
      }
    }
   `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2D_impl.js
function getShapeForBatchMatMul(shape, isChannelsLast) {
  const length = shape.length;
  if (length >= 3) {
    return isChannelsLast ? [
      ...shape.slice(0, -3),
      shape[length - 3] * shape[length - 2],
      shape[length - 1]
      /* channel */
    ] : [
      ...shape.slice(0, -3),
      shape[length - 3],
      shape[length - 2] * shape[length - 1]
      /* height * width */
    ];
  } else if (!isChannelsLast && length === 1 && shape[0] > 1) {
    return [shape[0], 1];
  } else {
    return null;
  }
}
function conv2dByMatMul({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const transposeA = isChannelsLast ? false : true;
  const transposeB = false;
  const sameSize = isChannelsLast && convInfo.filterHeight === convInfo.inHeight && convInfo.filterWidth === convInfo.inWidth && convInfo.padInfo.type === "VALID";
  const intermediates = [];
  let xReshaped;
  let filterReshaped;
  if (sameSize) {
    const sharedDim = convInfo.inHeight * convInfo.inWidth * convInfo.inChannels;
    xReshaped = reshape2({
      inputs: { x },
      backend: backend2,
      attrs: { shape: [1, convInfo.batchSize, sharedDim] }
    });
    filterReshaped = reshape2({
      inputs: { x: filter },
      backend: backend2,
      attrs: { shape: [1, sharedDim, convInfo.outChannels] }
    });
  } else {
    xReshaped = reshape2({
      inputs: { x },
      backend: backend2,
      attrs: {
        shape: isChannelsLast ? [
          convInfo.batchSize,
          convInfo.inHeight * convInfo.inWidth,
          convInfo.inChannels
        ] : [
          convInfo.batchSize,
          convInfo.inChannels,
          convInfo.inHeight * convInfo.inWidth
        ]
      }
    });
    filterReshaped = reshape2({
      inputs: { x: filter },
      backend: backend2,
      attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
    });
  }
  intermediates.push(xReshaped);
  intermediates.push(filterReshaped);
  if (preluActivationWeights != null) {
    const targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
    if (targetShape != null) {
      preluActivationWeights = reshape2({
        inputs: { x: preluActivationWeights },
        backend: backend2,
        attrs: { shape: targetShape }
      });
      intermediates.push(preluActivationWeights);
    }
  }
  if (bias != null) {
    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
    if (targetShape != null) {
      bias = reshape2({ inputs: { x: bias }, backend: backend2, attrs: { shape: targetShape } });
      intermediates.push(bias);
    }
  }
  const result = batchMatMulImpl({
    a: isChannelsLast ? xReshaped : filterReshaped,
    b: isChannelsLast ? filterReshaped : xReshaped,
    transposeA,
    transposeB,
    backend: backend2,
    bias,
    activation,
    preluActivationWeights,
    leakyreluAlpha
  });
  const out = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: convInfo.outShape } });
  intermediates.push(result);
  for (const i of intermediates) {
    backend2.disposeData(i.dataId);
  }
  return out;
}
function conv2dWithIm2Col({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const { filterWidth, filterHeight, inChannels, strideWidth, strideHeight, padInfo, outWidth, outHeight, dilationWidth, dilationHeight, dataFormat } = convInfo;
  const isChannelsLast = dataFormat === "channelsLast";
  const sharedDim = filterWidth * filterHeight * inChannels;
  const numCols = outHeight * outWidth;
  const x2ColShape = isChannelsLast ? [convInfo.batchSize, numCols, sharedDim] : [convInfo.batchSize, sharedDim, numCols];
  const im2ColProgram = new Im2ColProgram(x2ColShape, isChannelsLast);
  const dimensions = [
    { type: "int32", data: [padInfo.top, padInfo.left] },
    { type: "int32", data: [strideHeight, strideWidth] },
    { type: "int32", data: [dilationHeight, dilationWidth] },
    { type: "int32", data: [outWidth] },
    { type: "int32", data: [inChannels * filterWidth] },
    { type: "int32", data: [inChannels] }
  ];
  const x2Col = backend2.runWebGPUProgram(im2ColProgram, [x], x.dtype, dimensions);
  const intermediates = [];
  intermediates.push(x2Col);
  const filterReshaped = reshape2({ inputs: { x: filter }, backend: backend2, attrs: { shape: [1, sharedDim, -1] } });
  intermediates.push(filterReshaped);
  if (preluActivationWeights != null) {
    const targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
    if (targetShape != null) {
      preluActivationWeights = reshape2({
        inputs: { x: preluActivationWeights },
        backend: backend2,
        attrs: { shape: targetShape }
      });
      intermediates.push(preluActivationWeights);
    }
  }
  if (bias != null) {
    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
    if (targetShape != null) {
      bias = reshape2({ inputs: { x: bias }, backend: backend2, attrs: { shape: targetShape } });
      intermediates.push(bias);
    }
  }
  const transposeA = isChannelsLast ? false : true;
  const transposeB = false;
  const result = batchMatMulImpl({
    a: isChannelsLast ? x2Col : filterReshaped,
    b: isChannelsLast ? filterReshaped : x2Col,
    transposeA,
    transposeB,
    backend: backend2,
    bias,
    activation,
    preluActivationWeights,
    leakyreluAlpha
  });
  const out = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: convInfo.outShape } });
  intermediates.push(result);
  for (const i of intermediates) {
    backend2.disposeData(i.dataId);
  }
  return out;
}
function conv2DImpl({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const sameSize = isChannelsLast && convInfo.filterHeight === convInfo.inHeight && convInfo.filterWidth === convInfo.inWidth && convInfo.padInfo.type === "VALID";
  const useNaiveConv2d = env().getBool("WEBGPU_USE_NAIVE_CONV2D_DEBUG");
  if (!useNaiveConv2d && (sameSize || convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID"))) {
    return conv2dByMatMul({
      x,
      filter,
      convInfo,
      backend: backend2,
      bias,
      activation,
      preluActivationWeights,
      leakyreluAlpha
    });
  }
  const thresholdFlagValue = env().getNumber("WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL");
  const thresholdToIncreaseWorkgroups = thresholdFlagValue > -1 ? thresholdFlagValue : backend2.thresholdToIncreaseWorkgroups;
  const workgroupsBy32x32 = convInfo.batchSize * Math.ceil(convInfo.outHeight * convInfo.outWidth / 32) * Math.ceil(convInfo.outChannels / 32);
  if (env().getBool("WEBGPU_CONV_SEPARATE_IM2COL_SHADER") || workgroupsBy32x32 <= thresholdToIncreaseWorkgroups) {
    return conv2dWithIm2Col({
      x,
      filter,
      convInfo,
      backend: backend2,
      bias,
      preluActivationWeights,
      leakyreluAlpha,
      activation
    });
  }
  let program;
  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];
  const dimensions = [
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    { type: "int32", data: [...padInfo] },
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] }
  ];
  if (useNaiveConv2d) {
    program = new Conv2DNaiveProgram(convInfo, hasBias, activation, hasPreluActivationWeights);
  } else {
    const dimAOuter = isChannelsLast ? convInfo.outHeight * convInfo.outWidth : convInfo.outChannels;
    const dimBOuter = isChannelsLast ? convInfo.outChannels : convInfo.outHeight * convInfo.outWidth;
    const dimInner = convInfo.filterHeight * convInfo.filterWidth * convInfo.inChannels;
    dimensions.push({ type: "int32", data: [dimAOuter] }, { type: "int32", data: [dimBOuter] }, { type: "int32", data: [dimInner] });
    const sequentialAccessByThreads = backend2.adapterInfo.isIntel();
    program = new Conv2DMMProgram(convInfo, dimAOuter, dimBOuter, dimInner, hasBias, activation, hasPreluActivationWeights, sequentialAccessByThreads);
  }
  const intermediates = [];
  const inputVar = [x, filter];
  if (hasBias) {
    if (!isChannelsLast && bias.shape.length === 1) {
      bias = reshape2({ inputs: { x: bias }, backend: backend2, attrs: { shape: [bias.shape[0], 1, 1] } });
      intermediates.push(bias);
    }
    inputVar.push(bias);
  }
  if (hasPreluActivationWeights) {
    if (!isChannelsLast && preluActivationWeights.shape.length === 1) {
      preluActivationWeights = reshape2({
        inputs: { x: preluActivationWeights },
        backend: backend2,
        attrs: { shape: [preluActivationWeights.shape[0], 1, 1] }
      });
      intermediates.push(preluActivationWeights);
    }
    inputVar.push(preluActivationWeights);
  }
  if (activation === "leakyrelu") {
    dimensions.push({ type: "float32", data: [leakyreluAlpha] });
    program.uniforms += " alpha : f32,";
  }
  const out = backend2.runWebGPUProgram(program, inputVar, x.dtype, dimensions);
  for (const i of intermediates) {
    backend2.disposeData(i.dataId);
  }
  return out;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2D.js
function conv2d2(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
  return conv2DImpl({ x, filter, convInfo, backend: backend2 });
}
var conv2DConfig = {
  kernelName: Conv2D,
  backendName: "webgpu",
  kernelFunc: conv2d2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/conv_backprop_webgpu.js
var Conv2DDerInputProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "W"];
    this.uniforms = "filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, outBackprop : vec4<i32>,";
    this.workgroupSize = [64, 1, 1];
    this.size = false;
    this.isVec4 = false;
    this.workPerThread = 1;
    this.outputShape = convInfo.inShape;
    this.isChannelsLast = convInfo.dataFormat === "channelsLast";
    this.isVec4 = this.isChannelsLast && convInfo.outChannels % 4 === 0 && convInfo.inChannels % 4 === 0;
    if (this.isVec4) {
      this.workPerThread = 2;
      this.outputComponent = 4;
      this.workgroupSize = [4, 4, 4];
      this.dispatchLayout = { x: [3], y: [2], z: [0, 1] };
      this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [4, this.workPerThread, 1]);
    } else {
      this.size = true;
      this.workPerThread = 1;
      this.workgroupSize = [64, 1, 1];
      this.dispatchLayout = flatDispatchLayout(this.outputShape);
      this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    }
    this.shaderKey = `conv2DDerInput_${this.isChannelsLast}_${this.isVec4}_${this.workPerThread}`;
  }
  getUserCode() {
    const rowDim = this.isChannelsLast ? 1 : 2;
    const colDim = this.isChannelsLast ? 2 : 3;
    const channelDim = this.isChannelsLast ? 3 : 1;
    const vec4Snippet = `
    ${getMainHeaderString()} {
      let batch = i32(globalId.z) / uniforms.outShape[1];
      let r = i32(globalId.z) % uniforms.outShape[1];
      let c = i32(globalId.y) * ${this.workPerThread};
      let d1 = i32(globalId.x) * 4;

      let dyCorner = vec2<i32>(r, c) - uniforms.pads;

      // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
      // ? = to be determined. : = across all values in that axis.
      var dotProd: array<vec4<f32>, ${this.workPerThread}>;
      for (var i = 0; i < ${this.workPerThread}; i++) {
        dotProd[i] = vec4<f32>(0.0);
      }
      for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {
        let dyR = f32(dyCorner.x + wR) / f32(uniforms.strides.x);
        let wRPerm = uniforms.filterDims.x - 1 - wR;
        if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) ||
            fract(dyR) > 0.0) {
          continue;
        }
        let idyR = i32(dyR);

        for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {
          let dyC = f32(dyCorner.y + wC) / f32(uniforms.strides.y);
          let dyC2 = f32(dyCorner.y + 1 + wC) / f32(uniforms.strides.y);
          let wCPerm = uniforms.filterDims.y - 1 - wC;
          var bDyCVal = true;
          var bDyCVal2 = true;
          if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||
              fract(dyC) > 0.0) {
            bDyCVal = false;
          }
          if (dyC2 < 0.0 || dyC2 >= f32(uniforms.outBackprop[2]) ||
              fract(dyC2) > 0.0) {
            bDyCVal2 = false;
          }

          let idyC = i32(dyC);
          let idyC2 = i32(dyC2);
          if (bDyCVal && bDyCVal2) {
            let d2Length = uniforms.outBackprop[3];
            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {
              let wValue0 = getW(wRPerm, wCPerm, d1, d2);
              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);
              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);
              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);
              var xValue =  getDy(batch, idyR, idyC, d2);
              let tmpval = vec4<f32>(dot(xValue, wValue0),
                                     dot(xValue, wValue1),
                                     dot(xValue, wValue2),
                                     dot(xValue, wValue3));
              dotProd[0] = dotProd[0] + tmpval;
              xValue = getDy(batch, idyR, idyC2, d2);
              dotProd[1] = dotProd[1] + vec4<f32>(dot(xValue, wValue0),
                                                  dot(xValue, wValue1),
                                                  dot(xValue, wValue2),
                                                  dot(xValue, wValue3));
            }
          } else if (bDyCVal) {
            let d2Length = uniforms.outBackprop[3];
            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {
              let wValue0 = getW(wRPerm, wCPerm, d1, d2);
              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);
              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);
              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);
              var xValue =  getDy(batch, idyR, idyC, d2);
              let tmpval = vec4<f32>(dot(xValue, wValue0),
                                     dot(xValue, wValue1),
                                     dot(xValue, wValue2),
                                     dot(xValue, wValue3));
              dotProd[0] = dotProd[0] + tmpval;
            }
          } else if (bDyCVal2) {
            let d2Length = uniforms.outBackprop[3];
            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {
              let wValue0 = getW(wRPerm, wCPerm, d1, d2);
              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);
              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);
              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);
              var xValue =  getDy(batch, idyR, idyC2, d2);
              let tmpval = vec4<f32>(dot(xValue, wValue0),
                                     dot(xValue, wValue1),
                                     dot(xValue, wValue2),
                                     dot(xValue, wValue3));
              dotProd[1] = dotProd[1] + tmpval;
            }
          }
        }
      }

      for (var i = 0; i < ${this.workPerThread}; i = i + 1) {
        let coords = vec4<i32>(batch, r, c + i, d1);
        if (coordsInBounds4D(coords, uniforms.outShape)) {
          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], dotProd[i]);
        }
      }
    }
    `;
    return this.isVec4 ? `
    ${vec4Snippet}
    ` : `
    ${getMainHeaderString("index")} {
      if(index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords[0];
        let d1 = coords[${channelDim}];

        let dyCorner = vec2<i32>(coords[${rowDim}], coords[${colDim}]) - uniforms.pads;
        let dyRCorner = dyCorner.x;
        let dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {
          let dyR = (f32(dyRCorner) + f32(wR)) / f32(uniforms.strides.x);
          let wRPerm = uniforms.filterDims.x - 1 - wR;
          if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) || fract(dyR) > 0.0 ||
              wRPerm < 0) {
            continue;
          }
          let idyR = i32(dyR);

          for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {
            let dyC = (f32(dyCCorner) + f32(wC)) / f32(uniforms.strides.y);
            let wCPerm = uniforms.filterDims.y - 1 - wC;
            if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||
                fract(dyC) > 0.0 || wCPerm < 0) {
              continue;
            }
            let idyC = i32(dyC);

            for (var d2 = 0; d2 < uniforms.outBackprop[3]; d2 = d2 + 1) {
              let xValue = ${this.isChannelsLast ? "getDy(batch, idyR, idyC, d2)" : "getDy(batch, d2, idyR, idyC)"};
              let wValue = getW(wRPerm, wCPerm, d1, d2);
              dotProd = dotProd + xValue * wValue;
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
  `;
  }
};
var Conv2DDerFilterProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "dy"];
    this.uniforms = "pads : vec2<i32>, strides : vec2<i32>, batchSize : i32, outHeight : i32, outWidth : i32, inHeight : i32, inWidth : i32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.filterShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.isChannelsLast = convInfo.dataFormat === "channelsLast";
    this.shaderKey = `conv2DDerFilter_${this.isChannelsLast}`;
  }
  getUserCode() {
    return `
    ${getMainHeaderString("index")} {
      if(index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let wR = coords[0];
        let wC = coords[1];
        let d1 = coords[2];
        let d2 = coords[3];

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var b = 0; b < uniforms.batchSize; b = b + 1) {
          for (var yR = 0; yR < uniforms.outHeight; yR = yR + 1) {
            let xR = wR + yR * uniforms.strides[0] - uniforms.pads[0];
            if (xR < 0 || xR >= uniforms.inHeight) {
              continue;
            }

            for (var yC = 0; yC < uniforms.outWidth; yC = yC + 1) {
              let xC = wC + yC * uniforms.strides[1] - uniforms.pads[1];

              if (xC < 0 || xC >= uniforms.inWidth) {
                continue;
              }

              if (${this.isChannelsLast}) {
                let dyValue = getDy(b, yR, yC, d2);
                let xValue = getX(b, xR, xC, d1);
                dotProd = dotProd + xValue * dyValue;
              } else {
                let dyValue = getDy(b, d2, yR, yC);
                let xValue = getX(b, d1, xR, xC);
                dotProd = dotProd + xValue * dyValue;
              }
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
  `;
  }
};
var Conv3DDerFilterProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "dy"];
    this.uniforms = `pads : vec3<i32>, strides : vec3<i32>, batchSize : i32, outDepth : i32,
       outHeight : i32, outWidth : i32, inDepth : i32, inHeight : i32, inWidth : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.filterShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `conv3DDerFilter`;
  }
  getUserCode() {
    return `
    ${getMainHeaderString("index")} {
      if(index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let wF = coords.x;
        let wR = coords.y;
        let wC = coords.z;
        let d1 = coords.w;
        let d2 = coords.u;

        var dotProd = 0.0;
        for (var b = 0; b < uniforms.batchSize; b++) {
          for (var yF = 0; yF < uniforms.outDepth; yF++) {
            let xF = wF + yF * uniforms.strides[0] - uniforms.pads[0];
            if (xF < 0 || xF >= uniforms.inDepth) {
              continue;
            }

            for (var yR = 0; yR < uniforms.outHeight; yR++) {
              let xR = wR + yR * uniforms.strides[1] - uniforms.pads[1];
              if (xR < 0 || xR >= uniforms.inHeight) {
                continue;
              }

              for (var yC = 0; yC < uniforms.outWidth; yC++) {
                let xC = wC + yC * uniforms.strides[2] - uniforms.pads[2];
                if (xC < 0 || xC >= uniforms.inWidth) {
                  continue;
                }

                let dyValue = getDy(b, yF, yR, yC, d2);
                let xValue = getX(b, xF, xR, xC, d1);
                dotProd += xValue * dyValue;
              }
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
  `;
  }
};
var Conv3DDerInputProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "W"];
    this.uniforms = `filterDims : vec3<i32>, pads : vec3<i32>, strides : vec3<i32>,
      outDepth : i32, outHeight : i32, outWidth : i32, outChannels : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `conv3DDerInput`;
  }
  getUserCode() {
    return `
    ${getMainHeaderString("index")} {
      if(index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords.x;
        let d1 = coords.u;

        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;
        let dyFCorner = dyCorner.x;
        let dyRCorner = dyCorner.y;
        let dyCCorner = dyCorner.z;

        var dotProd = 0.0;
        for (var wF = 0; wF < uniforms.filterDims[0]; wF++) {
          let dyF = f32(dyFCorner + wF) / f32(uniforms.strides[0]);
          if (dyF < 0.0 || dyF >= f32(uniforms.outDepth) || fract(dyF) > 0.0) {
            continue;
          }
          let idyF = i32(dyF);

          let wFPerm = uniforms.filterDims[0] - 1 - wF;

          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {
            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);

            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
              continue;
            }
            let idyR = i32(dyR);

            let wRPerm = uniforms.filterDims[1] - 1 - wR;

            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {
              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);

              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
                continue;
              }
              let idyC = i32(dyC);

              let wCPerm = uniforms.filterDims[2] - 1 - wC;

              for (var d2 = 0; d2 < uniforms.outChannels; d2++) {
                let xValue = getDy(batch, idyF, idyR, idyC, d2);
                let wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
  `;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2DBackpropFilter.js
function conv2DBackpropFilter(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
  const program = new Conv2DDerFilterProgram(convInfo);
  const uniformData = [
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.batchSize] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "int32", data: [convInfo.inHeight] },
    { type: "int32", data: [convInfo.inWidth] }
  ];
  return backend2.runWebGPUProgram(program, [x, dy], x.dtype, uniformData);
}
var conv2DBackpropFilterConfig = {
  kernelName: Conv2DBackpropFilter,
  backendName: "webgpu",
  kernelFunc: conv2DBackpropFilter
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/conv_backprop_mm_webgpu.js
function conv2dTransposeCommonSnippet(innerElementSize = 4) {
  const getWSnippet = (innerElementSize2) => {
    switch (innerElementSize2) {
      case 1:
        return "return W[getIndexFromCoords4D(coord, uniforms.wShape)];";
      case 4:
        return `
            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);
            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);
            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);
            let v0 = W[getIndexFromCoords4D(coord, uniforms.wShape)];
            let v1 = W[getIndexFromCoords4D(coord1, uniforms.wShape)];
            let v2 = W[getIndexFromCoords4D(coord2, uniforms.wShape)];
            let v3 = W[getIndexFromCoords4D(coord3, uniforms.wShape)];
            return vec4<f32>(v0, v1, v2, v3);
            `;
      default:
        throw new Error(`innerElementSize ${innerElementSize2} is not supported.`);
    }
  };
  const readASnippet = `
      let outRow = row / uniforms.outShape[2];
      let outCol = row % uniforms.outShape[2];

      let WRow = col / (uniforms.filterDims[1] * uniforms.outBackprop[3]);
      let WCol = col / uniforms.outBackprop[3] % uniforms.filterDims[1];
      let xR = f32(outRow - uniforms.pads[0] + WRow) / f32(uniforms.strides[0]);
      let xC = f32(outCol - uniforms.pads[1] + WCol) / f32(uniforms.strides[1]);
      if (xR < 0.0 || xR >= f32(uniforms.outBackprop[1]) || fract(xR) > 0.0) {
        return ${typeSnippet(innerElementSize)}(0.0);
      }
      if (xC < 0.0 || xC >= f32(uniforms.outBackprop[2]) || fract(xC) > 0.0) {
        return ${typeSnippet(innerElementSize)}(0.0);
      }
      let coord = vec4<i32>(
          batch,
          i32(xR),
          i32(xC),
          col % uniforms.outBackprop[3]);
      return x[getIndexFromCoords4D(coord, uniforms.xShape)/${innerElementSize}];`;
  const sampleA = `if (row < uniforms.dimAOuter && col < uniforms.dimInner) {
        ${readASnippet}
      }
      return ${typeSnippet(innerElementSize)}(0.0);`;
  const userCode = `
  fn mm_readA(batch: i32, row : i32, col : i32) -> ${typeSnippet(innerElementSize)} {
    ${sampleA}
  }

  fn mm_readB(batch: i32, row : i32, col : i32) -> ${typeSnippet(innerElementSize)} {
    let coordX = uniforms.filterDims.x - 1 -
        row / (uniforms.filterDims[1] * uniforms.outBackprop[3]);
    let coordY = uniforms.filterDims.y - 1 -
        (row / uniforms.outBackprop[3]) % uniforms.filterDims[1];
    if (row < uniforms.dimInner && col < uniforms.dimBOuter &&
        coordX >= 0 && coordY >= 0) {
      let rowInner = row % uniforms.outBackprop[3];
      let coord = vec4<i32>(coordX, coordY, col, rowInner);
      ${getWSnippet(innerElementSize)}
    }
    return ${typeSnippet(innerElementSize)}(0.0);
  }

  fn mm_write(batch: i32, row : i32, col : i32, valueInput : ${typeSnippet(innerElementSize)}) {
    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {
      var value = valueInput;
      let outCoord = vec4<i32>(
          batch,
          row / uniforms.outShape[2],
          row % uniforms.outShape[2],
          col);
      result[getIndexFromCoords4D(outCoord, uniforms.outShape)/${innerElementSize}] = value;
    }
  }`;
  return userCode;
}
var Conv2DDerInputMMProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "W"];
    this.uniforms = "filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, outBackprop : vec4<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,";
    this.outputShape = convInfo.inShape;
    util_exports.assert(convInfo.dataFormat === "channelsLast", () => "TODO: NCHW is unimplemented");
    this.isVec4 = convInfo.inChannels % 4 === 0 && convInfo.outChannels % 4 === 0;
    this.dispatchLayout = { x: [3], y: [1, 2], z: [0] };
    this.workgroupSize = computeWorkgroupSizeForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
    this.elementsPerThread = computeWorkPerThreadForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);
    if (this.isVec4) {
      this.outputComponent = 4;
      this.variableComponents = [4, 1];
    }
    this.shaderKey = `conv2DDerInputMM_${this.isVec4}_${this.elementsPerThread}`;
  }
  getUserCode() {
    const matMulSource = this.isVec4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize) : makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize);
    const userCode = `
    ${conv2dTransposeCommonSnippet(this.isVec4 ? 4 : 1)}
    ${matMulSource}
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2DBackpropInput.js
function conv2DBackpropInput(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { inputShape, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
  const dimensions = [
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    {
      type: "int32",
      data: [
        convInfo.filterHeight - 1 - convInfo.padInfo.top,
        convInfo.filterWidth - 1 - convInfo.padInfo.left
      ]
    },
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    {
      type: "int32",
      data: [
        convInfo.batchSize,
        convInfo.outHeight,
        convInfo.outWidth,
        convInfo.outChannels
      ]
    }
  ];
  let program;
  if (env().getBool("WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE") || convInfo.dataFormat !== "channelsLast") {
    program = new Conv2DDerInputProgram(convInfo);
  } else {
    program = new Conv2DDerInputMMProgram(convInfo);
    const dimAOuter = convInfo.inHeight * convInfo.inWidth;
    const dimBOuter = convInfo.inChannels;
    const dimInner = convInfo.filterHeight * convInfo.filterWidth * convInfo.outChannels;
    dimensions.push({ type: "uint32", data: [dimAOuter] }, { type: "uint32", data: [dimBOuter] }, { type: "uint32", data: [dimInner] });
  }
  return backend2.runWebGPUProgram(program, [dy, filter], "float32", dimensions);
}
var conv2DBackpropInputConfig = {
  kernelName: Conv2DBackpropInput,
  backendName: "webgpu",
  kernelFunc: conv2DBackpropInput
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/conv3d_naive_webgpu.js
var Conv3DNaiveProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "W"];
    this.uniforms = "filterDims: vec3<i32>, pads: vec3<i32>, strides: vec3<i32>, dilations: vec3<i32>,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `conv3dnaive`;
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        let batch = coords.x;
        let d2 = coords.u;

        let xFRCCorner = vec3<i32>(coords.y, coords.z, coords.w) * uniforms.strides - uniforms.pads;
        let xFCorner = xFRCCorner.x;
        let xRCorner = xFRCCorner.y;
        let xCCorner = xFRCCorner.z;

        let inputDepthNearestVec4 = (uniforms.xShape.u / 4) * 4;
        let inputDepthVec4Remainder = uniforms.xShape.u % 4;

        var dotProd = 0.0;
        for (var wF = 0; wF < uniforms.filterDims[0]; wF++) {
          let xF = xFCorner + wF * uniforms.dilations[0];
          if (xF < 0 || xF >= uniforms.xShape.y) {
            continue;
          }

          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {
            let xR = xRCorner + wR * uniforms.dilations[1];
            if (xR < 0 || xR >= uniforms.xShape.z) {
              continue;
            }

            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {
              let xC = xCCorner + wC * uniforms.dilations[2];
              if (xC < 0 || xC >= uniforms.xShape.w) {
                continue;
              }

              for (var d1 = 0; d1 < inputDepthNearestVec4; d1 += 4) {
                let xValues = vec4<f32>(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                let wValues = vec4<f32>(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (inputDepthVec4Remainder == 1) {
                dotProd += getX(batch, xF, xR, xC, inputDepthNearestVec4) *
                  getW(wF, wR, wC, inputDepthNearestVec4, d2);
              } else if (inputDepthVec4Remainder == 2) {
                let xValues = vec2<f32>(
                  getX(batch, xF, xR, xC, inputDepthNearestVec4),
                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1)
                );
                let wValues = vec2<f32>(
                  getW(wF, wR, wC, inputDepthNearestVec4, d2),
                  getW(wF, wR, wC, inputDepthNearestVec4 + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (inputDepthVec4Remainder == 3) {
                let xValues = vec3<f32>(
                  getX(batch, xF, xR, xC, inputDepthNearestVec4),
                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),
                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2)
                );
                let wValues = vec3<f32>(
                  getW(wF, wR, wC, inputDepthNearestVec4, d2),
                  getW(wF, wR, wC, inputDepthNearestVec4 + 1, d2),
                  getW(wF, wR, wC, inputDepthNearestVec4 + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }`;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv3D.js
function conv3D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
  const padInfo = [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left];
  const dimensions = [
    {
      type: "int32",
      data: [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth]
    },
    { type: "int32", data: [...padInfo] },
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.dilationDepth,
        convInfo.dilationHeight,
        convInfo.dilationWidth
      ]
    }
  ];
  const program = new Conv3DNaiveProgram(convInfo);
  const dtype = upcastType(x.dtype, filter.dtype);
  return backend2.runWebGPUProgram(program, [x, filter], dtype, dimensions);
}
var conv3DConfig = {
  kernelName: Conv3D,
  backendName: "webgpu",
  kernelFunc: conv3D
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv3DBackpropFilterV2.js
function conv3DBackpropFilterV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad2, filterShape } = attrs;
  const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filterShape, strides, 1, pad2);
  const program = new Conv3DDerFilterProgram(convInfo);
  const uniformData = [
    {
      type: "int32",
      data: [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]
    },
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    { type: "int32", data: [convInfo.batchSize] },
    { type: "int32", data: [convInfo.outDepth] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "int32", data: [convInfo.inDepth] },
    { type: "int32", data: [convInfo.inHeight] },
    { type: "int32", data: [convInfo.inWidth] }
  ];
  return backend2.runWebGPUProgram(program, [x, dy], dy.dtype, uniformData);
}
var conv3DBackpropFilterV2Config = {
  kernelName: Conv3DBackpropFilterV2,
  backendName: "webgpu",
  kernelFunc: conv3DBackpropFilterV2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv3DBackpropInputV2.js
function conv3DBackpropInputV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, pad: pad2, inputShape } = attrs;
  const convInfo = backend_util_exports.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad2);
  const program = new Conv3DDerInputProgram(convInfo);
  const uniformData = [
    {
      type: "int32",
      data: [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.filterDepth - 1 - convInfo.padInfo.front,
        convInfo.filterHeight - 1 - convInfo.padInfo.top,
        convInfo.filterWidth - 1 - convInfo.padInfo.left
      ]
    },
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    { type: "int32", data: [convInfo.outDepth] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "int32", data: [convInfo.outChannels] }
  ];
  return backend2.runWebGPUProgram(program, [dy, filter], dy.dtype, uniformData);
}
var conv3DBackpropInputV2Config = {
  kernelName: Conv3DBackpropInputV2,
  backendName: "webgpu",
  kernelFunc: conv3DBackpropInputV2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Cos.js
var cos2 = unaryKernelFunc({ opType: UnaryOpType.COS });
var cosConfig = {
  kernelName: Cos,
  backendName: "webgpu",
  kernelFunc: cos2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Cosh.js
var cosh2 = unaryKernelFunc({ opType: UnaryOpType.COSH });
var coshConfig = {
  kernelName: Cosh,
  backendName: "webgpu",
  kernelFunc: cosh2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/crop_and_resize_webgpu.js
var CropAndResizeProgram = class {
  constructor(channnel, boxShape, cropSize, method) {
    this.variableNames = ["Image", "Boxes", "BoxInd"];
    this.uniforms = "extrapolationValue : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    const [numBoxes] = boxShape;
    this.outputShape = [numBoxes, cropSize[0], cropSize[1], channnel];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.methodId = method === "bilinear" ? 1 : 0;
    this.cropHeightBiggerThan1 = this.outputShape[1] > 1;
    this.cropWidthBiggerThan1 = this.outputShape[2] > 1;
    this.shaderKey = `cropAndResize_${this.methodId}_${this.cropHeightBiggerThan1}_${this.cropWidthBiggerThan1}`;
  }
  getUserCode() {
    const [inputHeightFloat, inputWidthFloat] = [`f32(uniforms.imageShape[1] - 1)`, `f32(uniforms.imageShape[2] - 1)`];
    const [heightRatio, heightScale, inY] = this.cropHeightBiggerThan1 ? [
      `(${inputHeightFloat} / f32(uniforms.outShape[1] - 1))`,
      "(y2-y1) * height_ratio",
      `y1*${inputHeightFloat} + f32(y)*(height_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (y1+y2) * ${inputHeightFloat}`
    ];
    const [widthRatio, widthScale, inX] = this.cropWidthBiggerThan1 ? [
      `(${inputWidthFloat} / f32(uniforms.outShape[2] - 1))`,
      "(x2-x1) * width_ratio",
      `x1*${inputWidthFloat} + f32(x)*(width_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (x1+x2) * ${inputWidthFloat}`
    ];
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let height_ratio = f32(${heightRatio});
        let width_ratio = f32(${widthRatio});
        let b = coords[0];
        let y = coords[1];
        let x = coords[2];
        let d = coords[3];
        // get box vals
        let y1 = getBoxes(b, 0);
        let x1 = getBoxes(b, 1);
        let y2 = getBoxes(b, 2);
        let x2 = getBoxes(b, 3);
        // get image in batch index
        let bInd = i32(round(getBoxInd(b)));
        if(bInd < 0 || bInd >= uniforms.outShape[0]) {
          return;
        }
        let height_scale = ${heightScale};
        let width_scale = ${widthScale};
        let in_y = ${inY};
        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {
          setOutputAtIndex(index, uniforms.extrapolationValue);
          return;
        }
        let in_x = ${inX};
        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {
          setOutputAtIndex(index, uniforms.extrapolationValue);
          return;
        }
        let sourceFracIndexCR = vec2<f32>(in_x,in_y);
        if(${this.methodId} == 1) {
          // Compute the four integer indices.
          let sourceFloorCR = vec2<i32>(sourceFracIndexCR);
          let sourceCeilCR = vec2<i32>(ceil(sourceFracIndexCR));
          let topLeft = getImage(bInd, sourceFloorCR.y, sourceFloorCR.x, d);
          let bottomLeft = getImage(bInd, sourceCeilCR.y, sourceFloorCR.x, d);
          let topRight = getImage(bInd, sourceFloorCR.y, sourceCeilCR.x, d);
          let bottomRight = getImage(bInd, sourceCeilCR.y, sourceCeilCR.x, d);
          let fracCR = sourceFracIndexCR - vec2<f32>(sourceFloorCR);
          let top = topLeft + (topRight - topLeft) * fracCR.x;
          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          let newValue = top + (bottom - top) * fracCR.y;
          setOutputAtIndex(index, newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          let sourceNearestCR = vec2<i32>(floor(
            sourceFracIndexCR + vec2<f32>(0.5,0.5)));
          let newValue = getImage(
            bInd, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutputAtIndex(index, newValue);
        }
      }
    }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/CropAndResize.js
var cropAndResize = (args) => {
  const { inputs, backend: backend2, attrs } = args;
  const { image: image2, boxes, boxInd } = inputs;
  const { cropSize, method, extrapolationValue } = attrs;
  const program = new CropAndResizeProgram(image2.shape[3], boxes.shape, cropSize, method);
  const uniformData = [{ type: "float32", data: [extrapolationValue] }];
  return backend2.runWebGPUProgram(program, [image2, boxes, boxInd], "float32", uniformData);
};
var cropAndResizeConfig = {
  kernelName: CropAndResize,
  backendName: "webgpu",
  kernelFunc: cropAndResize
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/cum_webgpu.js
var CumOpType;
(function(CumOpType2) {
  CumOpType2["Prod"] = "*";
  CumOpType2["Sum"] = "+";
})(CumOpType || (CumOpType = {}));
var CumProgram = class {
  constructor(op2, shape, exclusive, reverse3) {
    this.variableNames = ["x"];
    this.uniforms = "index : f32,";
    this.size = true;
    this.workgroupSize = [128, 1, 1];
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.exclusive = exclusive;
    this.reverse = reverse3;
    this.op = op2;
    this.shaderKey = `cum_${this.op}_${this.exclusive}_${this.reverse}`;
  }
  getUserCode() {
    const rank = this.outputShape.length;
    const initVal = this.op === CumOpType.Prod ? "1.0" : "0.0";
    const val = this.exclusive ? initVal : `getX(${getCoords2(rank, "coords", this.op)})`;
    const length = this.outputShape[this.outputShape.length - 1];
    let condition = "";
    let idxString = "";
    if (this.exclusive) {
      condition = this.reverse ? `end != ${length - 1}` : "end != 0";
      idxString = this.reverse ? "end + 1" : "end - 1";
    } else {
      condition = this.reverse ? `end + pow2 < ${length}` : "end >= pow2";
      idxString = this.reverse ? "end + pow2" : "end - pow2";
    }
    return `
      ${getMainHeaderString("index")} {
       if (index < uniforms.size) {
         var coords = getCoordsFromIndex(index);

         let end = ${getFinalCoord(rank, "coords", this.op)};
         var val = ${val};
         let pow2 = i32(pow(2.0, uniforms.index));
         if (${condition}) {
           let idx = ${idxString};
           ${getFinalCoord(rank, "coords", this.op)} = idx;
           val ${this.op}= getX(${getCoords2(rank, "coords", this.op)});
         }
         setOutputAtIndex(index, val);
       }
      }
    `;
  }
};
function getCoords2(rank, name, op2) {
  if (rank === 1) {
    return `${name}`;
  } else if (rank === 2) {
    return `${name}.x, ${name}.y`;
  } else if (rank === 3) {
    return `${name}.x, ${name}.y, ${name}.z`;
  } else if (rank === 4) {
    return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;
  } else {
    throw Error(`Cumulative ${op2} for rank ${rank} is not yet supported`);
  }
}
function getFinalCoord(rank, name, op2) {
  if (rank === 1) {
    return `${name}`;
  } else if (rank === 2) {
    return `${name}.y`;
  } else if (rank === 3) {
    return `${name}.z`;
  } else if (rank === 4) {
    return `${name}.w`;
  } else {
    throw Error(`Cumulative ${op2} for rank ${rank} is not yet supported`);
  }
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Cum_impl.js
function cumImpl(op2, x, backend2, axis, exclusive, reverse3) {
  const xRank = x.shape.length;
  const permutation = backend_util_exports.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation != null) {
    permutedX = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
  }
  const permutedAxis = backend_util_exports.getInnerMostAxes(1, xRank)[0];
  if (permutedAxis !== xRank - 1) {
    throw new Error(`WebGPU cumprod shader expects an inner-most axis=${x.shape.length - 1} but got axis=${axis}`);
  }
  const size = permutedX.shape[permutedAxis];
  let result = identity({ inputs: { x: permutedX }, backend: backend2 });
  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {
    const program = new CumProgram(op2, permutedX.shape, false, reverse3);
    const prevResult = result;
    const uniformData = [{ type: "float32", data: [i] }];
    result = backend2.runWebGPUProgram(program, [result], result.dtype, uniformData);
    backend2.disposeData(prevResult.dataId);
  }
  if (exclusive) {
    const program = new CumProgram(op2, permutedX.shape, exclusive, reverse3);
    const prevResult = result;
    const uniformData = [{ type: "float32", data: [0] }];
    result = backend2.runWebGPUProgram(program, [result], result.dtype, uniformData);
    backend2.disposeData(prevResult.dataId);
  }
  if (permutation != null) {
    const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
    const reverseTransposedResult = transpose2({ inputs: { x: result }, backend: backend2, attrs: { perm: reversePermutation } });
    backend2.disposeData(result.dataId);
    backend2.disposeData(permutedX.dataId);
    return reverseTransposedResult;
  }
  return result;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Cumprod.js
function cumprod2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse3 } = attrs;
  return cumImpl(CumOpType.Prod, x, backend2, axis, exclusive, reverse3);
}
var cumprodConfig = {
  kernelName: Cumprod,
  backendName: "webgpu",
  kernelFunc: cumprod2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Cumsum.js
function cumsum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse3 } = attrs;
  return cumImpl(CumOpType.Sum, x, backend2, axis, exclusive, reverse3);
}
var cumsumConfig = {
  kernelName: Cumsum,
  backendName: "webgpu",
  kernelFunc: cumsum2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/DenseBincount.js
function denseBincount2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, weights } = inputs;
  const { size, binaryOutput } = attrs;
  const xRankOne = x.shape.length === 1;
  const weightsSize = util_exports.sizeFromShape(weights.shape);
  const hasWeights = weightsSize > 0;
  const dtype = weights.dtype;
  const xSize = xRankOne ? [x.shape[0]] : [x.shape[0], x.shape[1]];
  const outputSize = xRankOne ? [size] : [x.shape[0], size];
  const output = fill2({ backend: backend2, attrs: { shape: outputSize, value: 0, dtype } });
  const program = new BincountProgram(xSize, hasWeights, binaryOutput);
  const uniformData = [{ type: "int32", data: [size] }];
  const bincountInputs = hasWeights ? [x, weights] : [x];
  const res = backend2.runWebGPUProgram(program, bincountInputs, dtype, uniformData, output);
  return res;
}
var denseBincountConfig = {
  kernelName: DenseBincount,
  backendName: "webgpu",
  kernelFunc: denseBincount2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/depth_to_space_webgpu.js
var DepthToSpaceProgram = class {
  constructor(outputShape, dataFormat) {
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.uniforms = "blockSize : i32,";
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `depthToSpace_${dataFormat}`;
    this.dataFormat = dataFormat;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let b = coords[0];
          let h = ${this.getHeightCoordString()};
          let w = ${this.getWidthCoordString()};
          let d = ${this.getDepthCoordString()};

          let in_h = h / uniforms.blockSize;
          let offset_h = h % uniforms.blockSize;
          let in_w = w / uniforms.blockSize;
          let offset_w = w % uniforms.blockSize;
          let offset_d = (offset_h * uniforms.blockSize + offset_w) *
            ${this.getOutputDepthSize()};
          let in_d = d + offset_d;

          let rlt = ${this.getInputSamplingString()};
          setOutputAtIndex(index, rlt);
        }
      }`;
    return userCode;
  }
  getHeightCoordString() {
    if (this.dataFormat === "NHWC") {
      return `coords[1]`;
    } else {
      return `coords[2]`;
    }
  }
  getWidthCoordString() {
    if (this.dataFormat === "NHWC") {
      return `coords[2]`;
    } else {
      return `coords[3]`;
    }
  }
  getDepthCoordString() {
    if (this.dataFormat === "NHWC") {
      return `coords[3]`;
    } else {
      return `coords[1]`;
    }
  }
  getOutputDepthSize() {
    if (this.dataFormat === "NHWC") {
      return `uniforms.outShape[3]`;
    } else {
      return `uniforms.outShape[1]`;
    }
  }
  getInputSamplingString() {
    if (this.dataFormat === "NHWC") {
      return `getX(b, in_h, in_w, in_d)`;
    } else {
      return `getX(b, in_d, in_h, in_w)`;
    }
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthToSpace.js
function depthToSpace2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockSize, dataFormat } = attrs;
  const batchSize = x.shape[0];
  const inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
  const outputHeight = inputHeight * blockSize;
  const outputWidth = inputWidth * blockSize;
  const outputDepth = inputDepth / (blockSize * blockSize);
  const outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
  const uniformData = [
    { type: "int32", data: [blockSize] }
  ];
  const program = new DepthToSpaceProgram(outputShape, dataFormat);
  return backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
}
var depthToSpaceConfig = {
  kernelName: DepthToSpace,
  backendName: "webgpu",
  kernelFunc: depthToSpace2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/depthwise_conv2d_nchw_shared_webgpu.js
var DepthwiseConv2DNCHWSharedProgram = class {
  constructor(outputShape, filterHeight, filterWidth, addBias = false, activation = null, hasPreluActivation = false) {
    this.variableNames = ["x", "W"];
    this.uniforms = `pads : vec2<i32>, inDims : vec2<i32>,`;
    this.workgroupSize = [16, 16, 1];
    this.outputShape = outputShape;
    this.dispatchLayout = { x: [3], y: [2], z: [0, 1] };
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivation) {
      this.variableNames.push("preluActivationWeights");
    }
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivation = hasPreluActivation;
    this.filterHeight = filterHeight;
    this.filterWidth = filterWidth;
    this.shaderKey = `depthwiseNCHW_${this.activation}_${this.filterHeight}_${this.filterWidth}`;
  }
  getUserCode() {
    const filterSize = this.filterWidth * this.filterHeight;
    const flatWorkgroupSize = this.workgroupSize[0] * this.workgroupSize[1] * this.workgroupSize[2];
    const tileAHeight = this.workgroupSize[1] + this.filterHeight - 1;
    const tileAWidth = this.workgroupSize[0] + this.filterWidth - 1;
    const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}

      var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHeight}>;
      var<workgroup> mm_Bsub : array<array<f32, ${this.filterWidth}>, ${this.filterHeight}>;
      fn readX(batch : i32, channel : i32, row : i32, col : i32) -> f32 {
        var value = 0.0;
        if (row >=0 && row < uniforms.inDims[0] && col >=0 && col < uniforms.inDims[1])
        {
          value = getX(batch, channel, row, col);
        }
        return value;
      }

      ${getMainHeaderString()} {
        let coords = getOutputCoords();
        let batch = coords[0];
        let xRCCorner = vec2<i32>(coords.zw) - uniforms.pads;
        let channelMul = uniforms.wShape[3];
        let d1 = coords[1] / channelMul;
        let q = coords[1] % channelMul;

        let inputRowStart = xRCCorner.x;
        let inputColStart = xRCCorner.y;

        let localRow = i32(localId.y);
        let localCol = i32(localId.x);

        // Load one tile of X into local memory.
        for (var inputRow = localRow; inputRow < ${tileAHeight}; inputRow = inputRow + ${this.workgroupSize[1]}) {
          for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${this.workgroupSize[0]}) {
            let rowOffset = inputRow - localRow;
            let colOffset = inputCol - localCol;
            mm_Asub[inputRow][inputCol] = readX(batch, d1, inputRowStart + rowOffset, inputColStart + colOffset);
          }
        }

        // Load one tile of W into local memory.
        var wIndex = i32(localIndex);
        ${filterSize < flatWorkgroupSize ? `if (wIndex < ${filterSize})` : `for(; wIndex < ${filterSize}; wIndex = wIndex + ${flatWorkgroupSize})`}

        {
          let wRow = wIndex / ${this.filterWidth};
          let wCol = wIndex % ${this.filterWidth};
          mm_Bsub[wRow][wCol] = getW(wRow, wCol, d1, q);
        }

        workgroupBarrier();

        var value = 0.0;
        for (var wR = 0; wR < ${this.filterHeight}; wR = wR + 1) {
          for (var wC = 0; wC < ${this.filterWidth}; wC = wC + 1) {
            let xVal = mm_Asub[localRow + wR][localCol + wC];
            let wVal = mm_Bsub[wR][wC];
            value = fma(xVal, wVal, value);
          }
        }
        ${biasActivationSnippet(this.addBias, this.activation)}
        if (coordsInBounds4D(coords, uniforms.outShape)) {
          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/depthwise_conv2d_vec4_webgpu.js
var DepthwiseConv2DVec4Program = class {
  constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false) {
    this.variableNames = ["x", "W"];
    this.uniforms = "pads : vec2<i32>, inDims : vec2<i32>, virtualWidth : i32,";
    this.workgroupSize = [64, 1, 1];
    this.workPerThread = 4;
    this.outputComponent = 4;
    this.outputShape = convInfo.outShape;
    this.virtualWidth = Math.ceil(this.outputShape[2] / this.workPerThread) * this.workPerThread;
    const virtualOutputShape = [
      this.outputShape[0],
      this.outputShape[1],
      this.virtualWidth,
      this.outputShape[3]
    ];
    this.dispatchLayout = flatDispatchLayout(virtualOutputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, virtualOutputShape, this.workgroupSize, [this.outputComponent * this.workPerThread, 1, 1]);
    util_exports.assert(convInfo.dataFormat === "channelsLast", () => "TODO: NCHW is unimplemented");
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivation) {
      this.variableNames.push("preluActivationWeights");
    }
    this.convInfo = convInfo;
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivation = hasPreluActivation;
    this.shaderKey = `depthwiseVec4_${activation}_${this.convInfo.filterHeight}_${this.convInfo.filterWidth}_${this.convInfo.strideHeight}_${this.convInfo.strideWidth}_${this.workPerThread}`;
  }
  getUserCode() {
    const xNumber = (this.workPerThread - 1) * this.convInfo.strideWidth + this.convInfo.filterWidth;
    const strideHeight = this.convInfo.strideHeight;
    const strideWidth = this.convInfo.strideWidth;
    const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivation, true, 4)}
      fn readX(batch : i32, row : i32, col : i32, channel : i32) -> vec4<f32> {
        var value = vec4<f32>(0.0);
        if (col >=0 && col < uniforms.inDims[1]) {
          value = getX(batch, row, col, channel);
        }
        return value;
      }

      ${getMainHeaderString("index")} {
        let width0 = uniforms.outShape[3] / ${this.outputComponent};
        let d1 = (index % width0) * ${this.outputComponent};
        var index1 = index / width0;
        let width1 = uniforms.virtualWidth / ${this.workPerThread};
        let c = (index1 % width1) * ${this.workPerThread};
        index1 = index1 / width1;
        let r = index1 % uniforms.outShape[1];
        let batch = index1 / uniforms.outShape[1];

        let xRCCorner = vec2<i32>(r, c) * vec2<i32>(${strideHeight}, ${strideWidth}) - uniforms.pads;

        let xRCorner = xRCCorner.x;
        let xCCorner = xRCCorner.y;
        var xVals : array<vec4<f32>, ${xNumber}>;
        var dotProd : array<vec4<f32>, ${this.workPerThread}>;
        for (var i = 0; i < ${this.workPerThread}; i++) {
          dotProd[i] = vec4<f32>(0.0);
        }

        // Use constant instead of uniform can give better performance.
        for (var wR = 0; wR < ${this.convInfo.filterHeight}; wR = wR + 1) {
          let xR = xRCorner + wR;
          if (xR >=0 && xR < uniforms.inDims[0]) {
            for (var i = 0; i < ${xNumber}; i++) {
              xVals[i] = readX(batch, xR, xCCorner + i, d1);
            }
            for (var wC = 0; wC < ${this.convInfo.filterWidth}; wC = wC + 1) {
              let wValue = getW(wR, wC, d1, 0);
              for (var i = 0; i < ${this.workPerThread}; i++) {
                dotProd[i] = fma(xVals[i * ${strideWidth} + wC], wValue, dotProd[i]);
              }
            }
          }
        }

        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let coords = vec4<i32>(batch, r, c + i, d1);
          if (coordsInBounds4D(coords, uniforms.outShape)) {
            var value = dotProd[i];
            ${biasActivationSnippet(this.addBias, this.activation)}
            setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
          }
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/depthwise_conv2d_webgpu.js
var DepthwiseConv2DProgram = class {
  constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false) {
    this.variableNames = ["x", "W"];
    this.uniforms = `pads : vec2<i32>, inDims : vec2<i32>, filterHeight : i32,
      filterWidth : i32, strides : vec2<i32>, dilations : vec2<i32>,`;
    this.workgroupSize = [256, 1, 1];
    this.size = true;
    this.outputShape = convInfo.outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.isChannelsLast = convInfo.dataFormat === "channelsLast";
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivation) {
      this.variableNames.push("preluActivationWeights");
    }
    this.convInfo = convInfo;
    this.addBias = addBias;
    this.activation = activation;
    this.hasPreluActivation = hasPreluActivation;
    this.shaderKey = `depthwise_${this.activation}_${this.isChannelsLast}`;
  }
  getUserCode() {
    const getXSnippet = this.isChannelsLast ? "getX(batch, xR, xC, d1);" : "getX(batch, d1, xR, xC);";
    const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}

      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getOutputCoords();
          let batch = coords[0];
          let xRCCorner = vec2<i32>(coords.${this.isChannelsLast ? "yz" : "zw"}) * uniforms.strides - uniforms.pads;
          let d2 = coords[${this.isChannelsLast ? 3 : 1}];
          let channelMul = uniforms.wShape[3];
          let d1 = d2 / channelMul;
          let q = d2 % channelMul;

          let inputRowStart = xRCCorner.x;
          let inputColStart = xRCCorner.y;
          let inputRowEnd = inputRowStart + uniforms.filterHeight *
              uniforms.dilations[0];
          let inputColEnd = inputColStart + uniforms.filterWidth *
              uniforms.dilations[1];

          // Convolve x(?, ?, d1)|x(d1, ?, ?) with w(:, :, d1, q) to get
          // y(yR, yC, d2)|y(d2, yR, yC). ? = to be determined. : = across all
          // values in that axis. x(?, ?, d1) and y(yR, yC, d2) is for NHWC.
          // x(d1, ?, ?) and y(d2, yR, yC) is for NCHW.
          var value = 0.0;

          // Extract if checking out of for loop for performance.
          if (inputRowStart >= 0 && inputColStart >= 0 &&
            inputRowEnd < uniforms.inDims[0] &&
                inputColEnd < uniforms.inDims[1]) {
              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {
                let xR = inputRowStart + wR * uniforms.dilations[0];

                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {
                  let xC = inputColStart + wC * uniforms.dilations[1];

                  let xVal = ${getXSnippet};
                  let wVal = getW(wR, wC, d1, q);
                  value = value + xVal * wVal;
                }
              }
            } else {
              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {
                let xR = inputRowStart + wR * uniforms.dilations[0];

                if (xR < 0 || xR >= uniforms.inDims[0]) {
                  continue;
                }

                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {
                  let xC = inputColStart + wC * uniforms.dilations[1];

                  if (xC < 0 || xC >= uniforms.inDims[1]) {
                    continue;
                  }

                  let xVal = ${getXSnippet};
                  let wVal = getW(wR, wC, d1, q);
                  value = value + xVal * wVal;
                }
              }
            }
            ${biasActivationSnippet(this.addBias, this.activation)}
          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthwiseConv2dNative.js
function depthwiseConv2dNative(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad2, dimRoundingMode, true, $dataFormat);
  const dimensions = [
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.inHeight, convInfo.inWidth] }
  ];
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  let program;
  if (!isChannelsLast && convInfo.inHeight > 16 && convInfo.inWidth > 16 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && convInfo.dilationWidth === 1 && convInfo.dilationHeight === 1 && convInfo.inChannels === convInfo.outChannels) {
    program = new DepthwiseConv2DNCHWSharedProgram(convInfo.outShape, convInfo.filterHeight, convInfo.filterWidth);
  } else if (isChannelsLast && convInfo.outHeight > 4 && convInfo.outWidth > 4 && convInfo.strideWidth <= 2 && convInfo.inChannels === convInfo.outChannels && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.inChannels % 4 === 0) {
    program = new DepthwiseConv2DVec4Program(convInfo);
    dimensions.push({ type: "int32", data: [program.virtualWidth] });
  } else {
    program = new DepthwiseConv2DProgram(convInfo);
    dimensions.push({ type: "int32", data: [convInfo.filterHeight] }, { type: "int32", data: [convInfo.filterWidth] }, { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] }, {
      type: "int32",
      data: [convInfo.dilationHeight, convInfo.dilationWidth]
    });
  }
  return backend2.runWebGPUProgram(program, [x, filter], x.dtype, dimensions);
}
var depthwiseConv2dNativeConfig = {
  kernelName: DepthwiseConv2dNative,
  backendName: "webgpu",
  kernelFunc: depthwiseConv2dNative
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/conv_backprop_depthwise_webgpu.js
var DepthwiseConv2DDerFilterProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "dy"];
    this.uniforms = `strides : vec2<i32>, pads : vec2<i32>, filterDims : vec2<i32>, outHeight : i32,
      outWidth : i32, inHeight : i32, inWidth : i32, batchSize : i32, channelMul : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.filterShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `depthwise_conv2d_backprop_filter`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let wR = coords[0];
        let wC = coords[1];
        let d1 = coords[2];
        let dm = coords[3];
        let d2 = d1 * uniforms.channelMul + dm;

        var dotProd = 0.0;
        for (var b = 0; b < uniforms.batchSize; b++) {
          for (var yR = 0; yR < uniforms.outHeight; yR++) {
            let xR = wR + yR * uniforms.strides[0] - uniforms.pads[0];

            if (xR < 0 || xR >= uniforms.inHeight) {
              continue;
            }

            for (var yC = 0; yC < uniforms.outWidth; yC++) {
              let xC = wC + yC * uniforms.strides[1] - uniforms.pads[1];

              if (xC < 0 || xC >= uniforms.inWidth) {
                continue;
              }

              let dyValue = getDy(b, yR, yC, d2);
              let xValue = getX(b, xR, xC, d1);
              dotProd += xValue * dyValue;
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
    `;
    return userCode;
  }
};
var DepthwiseConv2DDerInputProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "W"];
    this.uniforms = `strides : vec2<i32>, pads : vec2<i32>, filterDims : vec2<i32>,
       outHeight : i32, outWidth : i32, channelMul : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `depthwise_conv2d_backprop_input`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords[0];
        let d1 = coords[3];
        let dyCorner = coords.yz - uniforms.pads;
        let dyRCorner = dyCorner.x;
        let dyCCorner = dyCorner.y;

        var dotProd = 0.0;
        for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {
          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);

          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
            continue;
          }

          let idyR = i32(dyR);
          let wRPerm = uniforms.filterDims[0] - 1 - wR;

          for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {
            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);

            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
              continue;
            }

            let idyC = i32(dyC);
            let wCPerm = uniforms.filterDims[1] - 1 - wC;

            for (var dm = 0; dm < uniforms.channelMul; dm++) {
              let d2 = d1 * uniforms.channelMul + dm;
              let xValue = getDy(batch, idyR, idyC, d2);
              let wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js
function depthwiseConv2dNativeBackpropFilter(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, dilations, pad: pad2, dimRoundingMode, filterShape } = attrs;
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filterShape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const program = new DepthwiseConv2DDerFilterProgram(convInfo);
  const uniformData = [
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "int32", data: [convInfo.inHeight] },
    { type: "int32", data: [convInfo.inWidth] },
    { type: "int32", data: [convInfo.batchSize] },
    { type: "int32", data: [convInfo.outChannels / convInfo.inChannels] }
  ];
  return backend2.runWebGPUProgram(program, [x, dy], "float32", uniformData);
}
var depthwiseConv2dNativeBackpropFilterConfig = {
  kernelName: DepthwiseConv2dNativeBackpropFilter,
  backendName: "webgpu",
  kernelFunc: depthwiseConv2dNativeBackpropFilter
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js
function depthwiseConv2dNativeBackpropInput(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, dilations, pad: pad2, dimRoundingMode, inputShape } = attrs;
  const convInfo = backend_util_exports.computeConv2DInfo(
    inputShape,
    filter.shape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const program = new DepthwiseConv2DDerInputProgram(convInfo);
  const uniformData = [
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    {
      type: "int32",
      data: [
        convInfo.filterHeight - 1 - convInfo.padInfo.top,
        convInfo.filterWidth - 1 - convInfo.padInfo.left
      ]
    },
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] },
    { type: "int32", data: [convInfo.outChannels / convInfo.inChannels] }
  ];
  return backend2.runWebGPUProgram(program, [dy, filter], dy.dtype, uniformData);
}
var depthwiseConv2dNativeBackpropInputConfig = {
  kernelName: DepthwiseConv2dNativeBackpropInput,
  backendName: "webgpu",
  kernelFunc: depthwiseConv2dNativeBackpropInput
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/diag_webgpu.js
var DiagProgram = class {
  constructor(size) {
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [size, size];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "diag";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getOutputCoords();
          let value = select(0.0, getX(coords[0]), coords[0] == coords[1]);
          setOutputAtIndex(index, value);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Diag.js
function diag2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  const outShape = [...x.shape, ...x.shape];
  const xSize = util_exports.sizeFromShape(x.shape);
  const flat = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: [xSize] } });
  const program = new DiagProgram(xSize);
  const res = backend2.runWebGPUProgram(program, [flat], flat.dtype);
  const out = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape: outShape } });
  backend2.disposeData(flat.dataId);
  backend2.disposeData(res.dataId);
  return out;
}
var diagConfig = {
  kernelName: Diag,
  backendName: "webgpu",
  kernelFunc: diag2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/dilation_webgpu.js
var Dilation2DProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "w"];
    this.uniforms = "filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "dilation2d";
  }
  getUserCode() {
    const userCode = `
       ${getMainHeaderString("index")} {
         if (index < uniforms.size) {
           let neg_infinity = -3.4e38;
           let coords = getOutputCoords();
           let batch = coords.x;
           let d1 = coords.w;
           let outTopLeftCorner = coords.yz * uniforms.strides - uniforms.pads;
           let hBeg = outTopLeftCorner.x;
           let wBeg = outTopLeftCorner.y;

           var curVal = neg_infinity;
           for (var h = 0; h < uniforms.filterDims[0]; h = h + 1) {
             let hIn = hBeg + h * uniforms.dilations[0];

             if (hIn >= 0 && hIn < uniforms.xShape[1]) {
               for (var w = 0; w < uniforms.filterDims[1]; w = w + 1) {
                 let wIn = wBeg + w * uniforms.dilations[1];

                 if (wIn >= 0 && wIn < uniforms.xShape[2]) {
                   let val = getX(batch, hIn, wIn, d1) + getW(h, w, d1);
                   if (val > curVal) {
                     curVal = val;
                   }
                 }
               }
             }
           }

           setOutputAtIndex(index, curVal);
         }
       }
     `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Dilation2D.js
function dilation2D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  const convInfo = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];
  const uniformData = [
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    { type: "int32", data: [...padInfo] },
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] }
  ];
  const program = new Dilation2DProgram(convInfo);
  const out = backend2.runWebGPUProgram(program, [x, filter], x.dtype, uniformData);
  return out;
}
var dilation2DConfig = {
  kernelName: Dilation2D,
  backendName: "webgpu",
  kernelFunc: dilation2D
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/dilation_backprop_webgpu.js
var Dilation2DBackpropInputProgram = class {
  constructor(convInfo, outputDtype) {
    this.variableNames = ["x", "w", "dy"];
    this.uniforms = "filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,";
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);
    this.dispatch = computeDispatch(this.dispatchLayout, convInfo.outShape, this.workgroupSize);
    if (outputDtype !== "float32" && outputDtype !== "int32") {
      throw new Error(`Dilation2DBackpropInput only supports float32 and int32
          types, does not support ${outputDtype} type.`);
    }
    this.type = outputDtype;
    this.shaderKey = "dilation2DBackpropInput";
  }
  getUserCode() {
    const userCode = `
       ${getMainHeaderString("index")} {
         if (index < uniforms.dySize) {
           let coords = getDyCoordsFromIndex(index);
           let b = coords[0];
           let r = coords[1];
           let c = coords[2];
           let d = coords[3];

           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;
           var curVal = -3.4e38;  // neg_infinity
           var xRMax = 0;
           var xCMax = 0;

           // In the case of multiple argmax branches, we only back-propagate
           // along the last branch, i.e., the one with largest value of
           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling
           // backward routines.
           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {
             let xR = dyCorner.x + wR * uniforms.dilations[0];

             if (xR >= 0 && xR < uniforms.xShape[1]) {
               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {
                 let xC = dyCorner.y + wC * uniforms.dilations[1];

                 if (xC >= 0 && xC < uniforms.xShape[2]) {
                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);
                   if (val > curVal) {
                     curVal = val;
                     xRMax = xR;
                     xCMax = xC;
                   }
                 }
               }
             }
           }

           let flatIndexIn = d + uniforms.xShape[3] *
               (xCMax + uniforms.xShape[2] * (xRMax + uniforms.xShape[1] * b));
           let value = getDy(b, r, c, d);
           ${atomicAddSnippet("&result[flatIndexIn]", "value", this.type)}
         }
       }
     `;
    return userCode;
  }
};
var Dilation2DBackpropFilterProgram = class {
  constructor(convInfo, shape, outputDtype) {
    this.variableNames = ["x", "w", "dy"];
    this.uniforms = "filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,";
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.outputShape = convInfo.filterShape;
    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);
    this.dispatch = computeDispatch(this.dispatchLayout, convInfo.outShape, this.workgroupSize);
    if (outputDtype !== "float32" && outputDtype !== "int32") {
      throw new Error(`Dilation2DBackpropFilter only supports float32 and int32
          types, does not support ${outputDtype} type.`);
    }
    this.type = outputDtype;
    this.shaderKey = "dilation2DBackpropFilter";
  }
  getUserCode() {
    const userCode = `
       ${getMainHeaderString("index")} {
         if (index < uniforms.dySize) {
           let coords = getDyCoordsFromIndex(index);
           let b = coords[0];
           let r = coords[1];
           let c = coords[2];
           let d = coords[3];

           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;
           var curVal = -3.4e38;  // neg_infinity
           var wRMax = 0;
           var wCMax = 0;

           // In the case of multiple argmax branches, we only back-propagate
           // along the last branch, i.e., the one with largest value of
           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling
           // backward routines.
           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {
             let xR = dyCorner.x + wR * uniforms.dilations[0];

             if (xR >= 0 && xR < uniforms.xShape[1]) {
               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {
                 let xC = dyCorner.y + wC * uniforms.dilations[1];

                 if (xC >= 0 && xC < uniforms.xShape[2]) {
                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);
                   if (val > curVal) {
                     curVal = val;
                     wRMax = wR;
                     wCMax = wC;
                   }
                 }
               }
             }
           }

           let flatIndexIn = d + uniforms.wShape[2] * (wCMax + wRMax * uniforms.wShape[1]);
           let value = getDy(b, r, c, d);
           ${atomicAddSnippet("&result[flatIndexIn]", "value", this.type)}
         }
       }
     `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Dilation2DBackpropFilter.js
function dilation2DBackpropFilter(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, dy } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  const convInfo = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
  const dtype = filter.dtype;
  const program = new Dilation2DBackpropFilterProgram(convInfo, filter.shape, dtype);
  const uniformData = [
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] },
    { type: "int32", data: [util_exports.sizeFromShape(convInfo.outShape)] }
  ];
  const output = fill2({ backend: backend2, attrs: { shape: filter.shape, value: 0, dtype } });
  return backend2.runWebGPUProgram(program, [x, filter, dy], dtype, uniformData, output);
}
var dilation2DBackpropFilterConfig = {
  kernelName: Dilation2DBackpropFilter,
  backendName: "webgpu",
  kernelFunc: dilation2DBackpropFilter
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Dilation2DBackpropInput.js
function dilation2DBackpropInput(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, dy } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  const convInfo = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
  const dtype = x.dtype;
  const program = new Dilation2DBackpropInputProgram(convInfo, dtype);
  const uniformData = [
    { type: "int32", data: [convInfo.filterHeight, convInfo.filterWidth] },
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] },
    { type: "int32", data: [util_exports.sizeFromShape(convInfo.outShape)] }
  ];
  const output = fill2({ backend: backend2, attrs: { shape: convInfo.inShape, value: 0, dtype } });
  return backend2.runWebGPUProgram(program, [x, filter, dy], dtype, uniformData, output);
}
var dilation2DBackpropInputConfig = {
  kernelName: Dilation2DBackpropInput,
  backendName: "webgpu",
  kernelFunc: dilation2DBackpropInput
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/draw_webgpu.js
var DrawProgram = class {
  constructor(outShape, type, textureFormat) {
    this.variableNames = ["Image"];
    this.uniforms = "alpha: f32,";
    this.workgroupSize = [64, 1, 1];
    this.pixelsOpType = PixelsOpType.DRAW;
    this.size = true;
    this.outputShape = outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.type = type;
    this.textureFormat = textureFormat;
    this.shaderKey = `draw_${type}_${textureFormat}`;
  }
  getUserCode() {
    let calculateResult;
    const value = this.type === "float32" ? "value" : "value / 255.0";
    calculateResult = `
      if (uniforms.numChannels == 1) {
        rgba[0] = ${value};
        rgba[1] = ${value};
        rgba[2] = ${value};
      } else {
        rgba[d] = ${value};
      }`;
    const userCode = `
       @group(0) @binding(0) var outImage : texture_storage_2d<${this.textureFormat}, write>;
       ${getMainHeaderString("index")} {
         if (index < uniforms.size) {
           var rgba = vec4<f32>(0.0, 0.0, 0.0, uniforms.alpha);
           for (var d = 0; d < uniforms.numChannels; d = d + 1) {
             let value = f32(inBuf[index * uniforms.numChannels + d]);
             ${calculateResult}
           }
           rgba.x = rgba.x * rgba.w;
           rgba.y = rgba.y * rgba.w;
           rgba.z = rgba.z * rgba.w;
           let coords = getCoordsFromIndex(index);
           textureStore(outImage, vec2<i32>(coords.yx), rgba);
         }
       }
      `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Draw.js
function draw(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { image: image2 } = inputs;
  const { canvas, options } = attrs;
  const [height, width] = image2.shape.slice(0, 2);
  const { imageOptions } = options || {};
  const alpha = (imageOptions === null || imageOptions === void 0 ? void 0 : imageOptions.alpha) || 1;
  const format = backend2.device.features.has("bgra8unorm-storage") ? "bgra8unorm" : "rgba8unorm";
  const outShape = [height, width];
  const program = new DrawProgram(outShape, image2.dtype, format);
  canvas.width = width;
  canvas.height = height;
  const backendName = "webgpu";
  let gpuContext = canvas.getContext(backendName);
  let canvasWebGPU;
  if (!gpuContext) {
    canvasWebGPU = new OffscreenCanvas(width, height);
    gpuContext = canvasWebGPU.getContext(backendName);
  }
  const numChannels = image2.shape.length === 3 ? image2.shape[2] : 1;
  gpuContext.configure({
    device: backend2.device,
    format,
    usage: GPUTextureUsage.STORAGE_BINDING,
    alphaMode: "premultiplied"
  });
  const outputDtype = "int32";
  const output = backend2.makeTensorInfo(outShape, outputDtype);
  const info = backend2.tensorMap.get(output.dataId);
  info.resource = gpuContext.getCurrentTexture();
  info.external = true;
  const uniformData = [{ type: "uint32", data: [numChannels] }, { type: "float32", data: [alpha] }];
  backend2.runWebGPUProgram(program, [image2], outputDtype, uniformData, output);
  if (canvasWebGPU) {
    const canvas2dContext = canvas.getContext("2d");
    if (!canvas2dContext) {
      throw new Error(`Please make sure this canvas has only been used for 2d or webgpu context!`);
    }
    canvas2dContext.drawImage(canvasWebGPU, 0, 0);
  }
  backend2.disposeData(output.dataId);
  return image2;
}
var drawConfig = {
  kernelName: Draw,
  backendName: "webgpu",
  kernelFunc: draw
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Multiply.js
var multiplyKernelFunc = binaryKernelFunc({
  opType: BinaryOpType.MUL,
  cpuKernelImpl: multiplyImplCPU,
  supportsComplex: true
});
var multiplyConfig = {
  kernelName: Multiply,
  backendName: "webgpu",
  kernelFunc: multiplyKernelFunc
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sum.js
function sum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  return reduce(x, axis, keepDims, "sum", backend2);
}
var sumConfig = {
  kernelName: Sum,
  backendName: "webgpu",
  kernelFunc: sum2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Einsum.js
function einsum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { equation } = attrs;
  const tensors = inputs;
  const { allDims, summedDims, idDims } = backend_util_exports.decodeEinsumEquation(equation, tensors.length);
  backend_util_exports.checkEinsumDimSizes(allDims.length, idDims, tensors);
  const { path, steps } = backend_util_exports.getEinsumComputePath(summedDims, idDims);
  const nSteps = steps.length;
  let out = null;
  let numDimsRemaining = allDims.length;
  const tensorsToDispose = [];
  for (let i = 0; i < nSteps; ++i) {
    for (const idTerm of steps[i]) {
      const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
      let x;
      if (backend_util_exports.isIdentityPermutation(perm)) {
        x = tensors[idTerm];
      } else {
        x = transpose2({ inputs: { x: tensors[idTerm] }, backend: backend2, attrs: { perm } });
        tensorsToDispose.push(x);
      }
      const targetShape = x.shape.slice();
      for (let k = 0; k < dimsToExpand.length; ++k) {
        targetShape.splice(dimsToExpand[k], 0, 1);
      }
      if (!util_exports.arraysEqual(x.shape, targetShape)) {
        x = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: targetShape } });
        tensorsToDispose.push(x);
      }
      if (out === null) {
        out = x;
      } else {
        out = multiplyKernelFunc({ inputs: { a: x, b: out }, backend: backend2 });
        tensorsToDispose.push(out);
      }
    }
    if (i < nSteps - 1) {
      if (path[i] >= 0) {
        out = sum2({
          inputs: { x: out },
          backend: backend2,
          attrs: {
            axis: path[i] - (allDims.length - numDimsRemaining),
            keepDims: false
          }
        });
        tensorsToDispose.push(out);
      }
      numDimsRemaining--;
    }
  }
  for (const tensorInfo of tensorsToDispose) {
    if (tensorInfo === out) {
      continue;
    }
    backend2.disposeData(tensorInfo.dataId);
  }
  return out;
}
var einsumConfig = {
  kernelName: Einsum,
  backendName: "webgpu",
  kernelFunc: einsum2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Elu.js
var elu2 = unaryKernelFunc({ opType: UnaryOpType.ELU });
var eluConfig = {
  kernelName: Elu,
  backendName: "webgpu",
  kernelFunc: elu2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/EluGrad.js
var eluGrad = (args) => {
  const { inputs, backend: backend2 } = args;
  const { dy, y } = inputs;
  const program = new BinaryOpProgram(BinaryOpType.ELU_DER, dy.shape, y.shape);
  return backend2.runWebGPUProgram(program, [dy, y], dy.dtype);
};
var eluGradConfig = {
  kernelName: EluGrad,
  backendName: "webgpu",
  kernelFunc: eluGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Equal.js
var equal2 = binaryKernelFunc({ opType: BinaryOpType.EQUAL, dtype: "bool", cpuKernelImpl: equalImplCPU });
var equalConfig = {
  kernelName: Equal,
  backendName: "webgpu",
  kernelFunc: equal2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Erf.js
var erf2 = unaryKernelFunc({ opType: UnaryOpType.ERF });
var erfConfig = {
  kernelName: Erf,
  backendName: "webgpu",
  kernelFunc: erf2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Exp.js
var exp2 = unaryKernelFunc({
  opType: UnaryOpType.EXP,
  cpuKernelImpl: expImplCPU,
  dtype: "float32"
});
var expConfig = {
  kernelName: Exp,
  backendName: "webgpu",
  kernelFunc: exp2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ExpandDims.js
function expandDims2(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { dim } = attrs;
  const { input } = inputs;
  const inputRank = input.shape.length;
  const newShape = input.shape.slice();
  let $dim = dim;
  if (dim < 0) {
    util_exports.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
    $dim = inputRank + dim + 1;
  }
  newShape.splice($dim, 0, 1);
  return reshape2({ inputs: { x: input }, backend: backend2, attrs: { shape: newShape } });
}
var expandDimsConfig = {
  kernelName: ExpandDims,
  backendName: "webgpu",
  kernelFunc: expandDims2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Expm1.js
var expm12 = unaryKernelFunc({ opType: UnaryOpType.EXPM1, cpuKernelImpl: expm1ImplCPU });
var expm1Config = {
  kernelName: Expm1,
  backendName: "webgpu",
  kernelFunc: expm12
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/fft_webgpu.js
var FFTProgram = class {
  constructor(component, shape) {
    this.variableNames = ["real", "imag"];
    this.outputShape = [];
    this.uniforms = "exponentMultiplier : f32, denominator: f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.component = component;
    this.shaderKey = `fft_${component}`;
  }
  getUserCode() {
    const opString = this.component === "real" ? "return real * expR - imag * expI;" : "return real * expI + imag * expR;";
    const userCode = `
    fn unaryOpComplex(real: f32, expR: f32, imag: f32, expI: f32) -> f32 {
      ${opString}
    }

    fn mulMatDFT(batch: i32, index: i32) -> f32 {
      let indexRatio = f32(index) / f32(uniforms.realShape[1]);
      let exponentMultiplierTimesIndexRatio =
          uniforms.exponentMultiplier * indexRatio;

      var result = 0.0;

      for (var i = 0; i < uniforms.realShape[1]; i = i + 1) {
        // x = (-2|2 * PI / N) * index * i;
        let x = exponentMultiplierTimesIndexRatio * f32(i);
        let expR = cos(x);
        let expI = sin(x);
        let real = getReal(batch, i);
        let imag = getImag(batch, i);

        result = result +
            unaryOpComplex(real, expR, imag, expI) / uniforms.denominator;
      }

      return result;
    }

    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        setOutputAtIndex(index, mulMatDFT(coords[0], coords[1]));
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FFT_impl.js
function fftImpl(x, inverse, backend2) {
  const xData = backend2.tensorMap.get(x.dataId);
  const inputSize = util_exports.sizeFromShape(x.shape);
  const innerDimensionSize = x.shape[x.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const toDispose = [];
  const input2D = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: [batch, innerDimensionSize] } });
  toDispose.push(input2D);
  const xShape = input2D.shape;
  const realProgram = new FFTProgram("real", xShape);
  const imagProgram = new FFTProgram("imag", xShape);
  const inputs = [
    {
      dataId: xData.complexTensorInfos.real.dataId,
      dtype: xData.complexTensorInfos.real.dtype,
      shape: xShape
    },
    {
      dataId: xData.complexTensorInfos.imag.dataId,
      dtype: xData.complexTensorInfos.imag.dtype,
      shape: xShape
    }
  ];
  const exponentMultiplier = inverse ? 2 * Math.PI : -2 * Math.PI;
  const denominator = inverse ? xShape[1] : 1;
  const uniformData = [
    { type: "float32", data: [exponentMultiplier] },
    { type: "float32", data: [denominator] }
  ];
  const realPart = backend2.runWebGPUProgram(realProgram, inputs, "float32", uniformData);
  toDispose.push(realPart);
  const imagPart = backend2.runWebGPUProgram(imagProgram, inputs, "float32", uniformData);
  toDispose.push(imagPart);
  const complexOutput = complex2({ inputs: { real: realPart, imag: imagPart }, backend: backend2 });
  toDispose.push(complexOutput);
  const complexOutputReshaped = reshape2({ inputs: { x: complexOutput }, backend: backend2, attrs: { shape: x.shape } });
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return complexOutputReshaped;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FFT.js
function fft2(args) {
  const { inputs, backend: backend2 } = args;
  const { input } = inputs;
  return fftImpl(input, false, backend2);
}
var fftConfig = {
  kernelName: FFT,
  backendName: "webgpu",
  kernelFunc: fft2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/flip_left_right_webgpu.js
var FlipLeftRightProgram = class {
  constructor(imageShape) {
    this.outputShape = [];
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = imageShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "flipLeftRight";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let coordX = uniforms.xShape[2] - coords[2] - 1;
          let outputValue = getX(coords[0], coords[1], coordX, coords[3]);
          setOutputAtIndex(index, outputValue);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FlipLeftRight.js
var flipLeftRightConfig = {
  kernelName: FlipLeftRight,
  backendName: "webgpu",
  kernelFunc: ({ inputs, backend: backend2 }) => {
    const { image: image2 } = inputs;
    const webgpuBackend = backend2;
    const program = new FlipLeftRightProgram(image2.shape);
    const output = webgpuBackend.runWebGPUProgram(program, [image2], image2.dtype);
    return output;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Floor.js
var floor2 = unaryKernelFunc({ opType: UnaryOpType.FLOOR, cpuKernelImpl: floorImplCPU });
var floorConfig = {
  kernelName: Floor,
  backendName: "webgpu",
  kernelFunc: floor2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FloorDiv.js
var floorDiv2 = binaryKernelFunc({
  opType: BinaryOpType.FLOOR_DIV,
  cpuKernelImpl: floorDivImplCPU,
  dtype: "int32"
});
var floorDivConfig = {
  kernelName: FloorDiv,
  backendName: "webgpu",
  kernelFunc: floorDiv2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/from_pixels_webgpu.js
var FromPixelsProgram = class {
  constructor(outputShape, numChannels, importVideo = false) {
    this.pixelsOpType = PixelsOpType.FROM_PIXELS;
    this.outputShape = [0];
    this.variableNames = [];
    this.workgroupSize = [256, 1, 1];
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [numChannels, 1, 1]);
    this.importVideo = importVideo;
    this.shaderKey = `fromPixels_${this.importVideo}`;
  }
  getUserCode() {
    const textureLoad = this.importVideo ? "textureLoad(src, vec2<i32>(coords.yx));" : "textureLoad(src, vec2<i32>(coords.yx), 0)";
    const textureType = this.importVideo ? "texture_external" : "texture_2d<f32>";
    return `
      @binding(1) @group(0) var src: ${textureType};
      ${getMainHeaderString("index")} {
        let flatIndex = index * uniforms.numChannels;
        if (flatIndex < uniforms.size) {
          let coords = getCoordsFromIndex(flatIndex);
          let values = ${textureLoad};
          for (var i = 0; i < uniforms.numChannels; i = i + 1) {
            result[flatIndex + i] = i32(floor(255.0 * values[i]));
          }
        }
      }
  `;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FromPixels.js
var fromPixelsConfig = {
  kernelName: FromPixels,
  backendName: "webgpu",
  kernelFunc: fromPixels
};
var fromPixels2DContext;
var willReadFrequently = env().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
function fromPixels(args) {
  const { inputs, backend: backend2, attrs } = args;
  let { pixels } = inputs;
  const { numChannels } = attrs;
  if (pixels == null) {
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  }
  const isVideo = typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement;
  const isImage = typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement;
  const isCanvas = typeof HTMLCanvasElement !== "undefined" && pixels instanceof HTMLCanvasElement || typeof OffscreenCanvas !== "undefined" && pixels instanceof OffscreenCanvas;
  const isImageBitmap = typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap;
  const [width, height] = isVideo ? [
    pixels.videoWidth,
    pixels.videoHeight
  ] : [pixels.width, pixels.height];
  const outputShape = [height, width, numChannels];
  const importVideo = env().getBool("WEBGPU_IMPORT_EXTERNAL_TEXTURE") && isVideo;
  const isVideoOrImage = isVideo || isImage;
  if (isImageBitmap || isCanvas || isVideoOrImage) {
    let resource;
    if (importVideo) {
      resource = backend2.device.importExternalTexture({ source: pixels });
    } else {
      if (isVideoOrImage) {
        const newWillReadFrequently = env().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
        if (fromPixels2DContext == null || newWillReadFrequently !== willReadFrequently) {
          willReadFrequently = newWillReadFrequently;
          fromPixels2DContext = document.createElement("canvas").getContext("2d", { willReadFrequently });
        }
        fromPixels2DContext.canvas.width = width;
        fromPixels2DContext.canvas.height = height;
        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
        pixels = fromPixels2DContext.canvas;
      }
      const usage = GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING;
      const format = "rgba8unorm";
      const texture = backend2.textureManager.acquireTexture(outputShape[1], outputShape[0], format, usage);
      backend2.queue.copyExternalImageToTexture({ source: pixels }, { texture }, [outputShape[1], outputShape[0]]);
      resource = texture;
    }
    const size = util_exports.sizeFromShape(outputShape);
    const strides = util_exports.computeStrides(outputShape);
    const program = new FromPixelsProgram(outputShape, numChannels, importVideo);
    const uniformData = [
      { type: "uint32", data: [size] },
      { type: "uint32", data: [numChannels] },
      { type: "uint32", data: [...strides] }
    ];
    const input = backend2.makeTensorInfo([height, width], "int32");
    const info = backend2.tensorMap.get(input.dataId);
    info.resource = resource;
    const result = backend2.runWebGPUProgram(program, [input], "int32", uniformData);
    backend2.disposeData(input.dataId);
    return result;
  }
  const imageData = pixels.data;
  let pixelArray = imageData;
  if (numChannels != null && numChannels !== 4) {
    pixelArray = new Uint8Array(pixels.width * pixels.height * numChannels);
    const dataLength = imageData.length;
    let j2 = 0;
    for (let i = 0; i < dataLength; i++) {
      if (i % 4 < numChannels) {
        pixelArray[j2++] = imageData[i];
      }
    }
  }
  const output = backend2.makeTensorInfo(outputShape, "int32", new Int32Array(pixelArray));
  backend2.uploadToGPU(output.dataId);
  return output;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/batchnorm_webgpu.js
var BatchNormProgram = class {
  constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape) {
    this.uniforms = "varianceEpsilon : f32,";
    this.workgroupSize = [128, 1, 1];
    this.size = true;
    this.variableNames = ["x", "mean", "variance"];
    backend_util_exports.assertAndGetBroadcastShape(xShape, meanShape);
    backend_util_exports.assertAndGetBroadcastShape(xShape, varianceShape);
    this.outputShape = xShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    if (offsetShape != null) {
      backend_util_exports.assertAndGetBroadcastShape(xShape, offsetShape);
      this.variableNames.push("offset");
    }
    if (scaleShape != null) {
      backend_util_exports.assertAndGetBroadcastShape(xShape, scaleShape);
      this.variableNames.push("scale");
    }
    this.offsetShape = offsetShape;
    this.scaleShape = scaleShape;
    this.shaderKey = "batchNorm";
  }
  getUserCode() {
    let offsetSnippet = "0.0";
    if (this.offsetShape != null) {
      offsetSnippet = "getOffsetByOutputIndex(index)";
    }
    let scaleSnippet = "1.0";
    if (this.scaleShape != null) {
      scaleSnippet = "getScaleByOutputIndex(index)";
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size)
        {
          let xValue = getXByOutputIndex(index);
          let meanValue = getMeanByOutputIndex(index);
          let varianValue = getVarianceByOutputIndex(index);
          let offsetValue = ${offsetSnippet};
          let scaleValue = ${scaleSnippet};
          let inv = scaleValue * inverseSqrt(varianValue + f32(uniforms.varianceEpsilon));
          setOutputAtIndex(index,dot(vec3<f32>(xValue, -meanValue, offsetValue), vec3<f32>(inv, inv, 1.0)));
        }
      }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FusedBatchNorm.js
var fusedBatchNormConfig = {
  kernelName: FusedBatchNorm,
  backendName: "webgpu",
  kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
    const { x, scale, offset, mean: mean3, variance } = inputs;
    const { varianceEpsilon } = attrs;
    const webGPUBackend = backend2;
    const batchNormInputs = [x, mean3, variance];
    let offsetShape = null;
    if (offset != null) {
      offsetShape = offset.shape;
      batchNormInputs.push(offset);
    }
    let scaleShape = null;
    if (scale != null) {
      scaleShape = scale.shape;
      batchNormInputs.push(scale);
    }
    const program = new BatchNormProgram(x.shape, mean3.shape, variance.shape, offsetShape, scaleShape);
    const uniformData = [{ type: "float32", data: [varianceEpsilon] }];
    return webGPUBackend.runWebGPUProgram(program, batchNormInputs, x.dtype, uniformData);
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FusedConv2D.js
function fusedConv2d(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
  return conv2DImpl({
    x,
    filter,
    convInfo,
    backend: backend2,
    bias,
    preluActivationWeights,
    leakyreluAlpha,
    activation
  });
}
var fusedConv2DConfig = {
  kernelName: FusedConv2D,
  backendName: "webgpu",
  kernelFunc: fusedConv2d
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/FusedDepthwiseConv2D.js
function fusedDepthwiseConv2D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad2, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filter.shape,
    strides,
    $dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const programInputs = [x, filter];
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  if (hasBias) {
    programInputs.push(bias);
  }
  if (hasPreluActivationWeights) {
    programInputs.push(preluActivationWeights);
  }
  const dimensions = [
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.inHeight, convInfo.inWidth] }
  ];
  let program;
  if (convInfo.outHeight > 4 && convInfo.outWidth > 4 && convInfo.strideWidth <= 2 && convInfo.inChannels === convInfo.outChannels && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.inChannels % 4 === 0) {
    program = new DepthwiseConv2DVec4Program(convInfo, hasBias, activation, hasPreluActivationWeights);
    dimensions.push({ type: "int32", data: [program.virtualWidth] });
  } else {
    program = new DepthwiseConv2DProgram(convInfo, hasBias, activation, hasPreluActivationWeights);
    dimensions.push({ type: "int32", data: [convInfo.filterHeight] }, { type: "int32", data: [convInfo.filterWidth] }, { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] }, {
      type: "int32",
      data: [convInfo.dilationHeight, convInfo.dilationWidth]
    });
  }
  if (activation === "leakyrelu") {
    dimensions.push({ type: "float32", data: [leakyreluAlpha] });
    program.uniforms += " alpha : f32,";
  }
  const result = backend2.runWebGPUProgram(program, programInputs, "float32", dimensions);
  return result;
}
var fusedDepthwiseConv2DConfig = {
  kernelName: FusedDepthwiseConv2D,
  backendName: "webgpu",
  kernelFunc: fusedDepthwiseConv2D
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/gather_nd_webgpu.js
var GatherNDProgram = class {
  constructor(sliceDim, shape) {
    this.variableNames = ["A", "indices"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `gathernd_${sliceDim}`;
    this.sliceDim = sliceDim;
    this.uniforms = `sliceDim : i32, strides : ${getCoordsDataType(sliceDim)},`;
  }
  getUserCode() {
    let strideString;
    if (this.sliceDim > 1) {
      strideString = "uniforms.strides[j]";
    } else {
      strideString = "uniforms.strides";
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          var flattenIndex = 0;
          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {
            let indexTemp = i32(round(getIndices(coords[0], j)));
            let strideNum = ${strideString};
            flattenIndex = flattenIndex + indexTemp * strideNum;
          }

          setOutputAtIndex(index, getA(flattenIndex, coords[1]));
        }
      }
      `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/GatherNd.js
function gatherNd(args) {
  const { inputs, backend: backend2 } = args;
  const { params, indices } = inputs;
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  const paramsSize = util_exports.sizeFromShape(params.shape);
  const [resultShape, numSlices, sliceSize, strides] = backend_util_exports.prepareAndValidate(params, indices);
  const flattenIndices = reshape2({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numSlices, sliceRank] } });
  const flattenX = reshape2({
    inputs: { x: params },
    backend: backend2,
    attrs: { shape: [util_exports.sizeFromShape(params.shape) / sliceSize, sliceSize] }
  });
  if (backend2.shouldExecuteOnCPU([params, indices]) || params.dtype === "string") {
    const indicesData = backend2.readSync(indices.dataId);
    const paramsBuf = backend2.bufferSync(params);
    const outValue = gatherNdImplCPU(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
    return backend2.makeTensorInfo(resultShape, params.dtype, outValue.values);
  }
  const program = new GatherNDProgram(sliceRank, [numSlices, sliceSize]);
  const uniformData = [{ type: "int32", data: [sliceRank] }, { type: "int32", data: strides }];
  const res = backend2.runWebGPUProgram(program, [flattenX, flattenIndices], flattenX.dtype, uniformData);
  const reshaped = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape: resultShape } });
  backend2.disposeData(flattenIndices.dataId);
  backend2.disposeData(flattenX.dataId);
  backend2.disposeData(res.dataId);
  return reshaped;
}
var gatherNdConfig = {
  kernelName: GatherNd,
  backendName: "webgpu",
  kernelFunc: gatherNd
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/gather_webgpu.js
var GatherProgram = class {
  constructor(aShape, outputShape) {
    this.variableNames = ["A", "indices"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = aShape.slice();
    this.aShape = aShape;
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `gather`;
  }
  getUserCode() {
    const sourceCoords = getSourceCoords(this.aShape);
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let resRC = getCoordsFromIndex(index);
          let indexZ = i32(getIndices(resRC.x, resRC.z));
          let inBounds = select(0.0, 1.0, indexZ >= 0 && indexZ < uniforms.aShape[2]);
          setOutputAtIndex(index, inBounds * getA(${sourceCoords}));
        }
      }
    `;
    return userCode;
  }
};
function getSourceCoords(aShape) {
  const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
  const sourceCoords = [];
  for (let i = 0; i < aShape.length; i++) {
    if (i === 2) {
      sourceCoords.push("indexZ");
    } else {
      sourceCoords.push(`${currentCoords[i]}`);
    }
  }
  return sourceCoords.join();
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/GatherV2.js
function gatherV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, indices } = inputs;
  const { axis, batchDims } = attrs;
  const parsedAxis = util_exports.parseAxisParam(axis, x.shape)[0];
  const shapeInfo = backend_util_exports.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
  const indicesSize = util_exports.sizeFromShape(indices.shape);
  const toDispose = [];
  const flattenX = reshape2({
    inputs: { x },
    backend: backend2,
    attrs: {
      shape: [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        shapeInfo.dimSize,
        shapeInfo.sliceSize
      ]
    }
  });
  const flattenIndex = reshape2({
    inputs: { x: indices },
    backend: backend2,
    attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
  });
  toDispose.push(flattenX);
  toDispose.push(flattenIndex);
  const flattenOutputShape = [
    shapeInfo.batchSize,
    shapeInfo.outerSize,
    indicesSize / shapeInfo.batchSize,
    shapeInfo.sliceSize
  ];
  if (backend2.shouldExecuteOnCPU([x, indices])) {
    const indicesTensorData = backend2.tensorMap.get(flattenIndex.dataId);
    const indicesValues = indicesTensorData.values;
    const indicesBuffer = buffer(flattenIndex.shape, flattenIndex.dtype, indicesValues);
    const flattenXTensorData = backend2.tensorMap.get(flattenX.dataId);
    const xValues = flattenXTensorData.values;
    const xBuffer = buffer(flattenX.shape, flattenX.dtype, xValues);
    const outBuf = gatherV2ImplCPU(xBuffer, indicesBuffer, flattenOutputShape);
    toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
    return backend2.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
  }
  const program = new GatherProgram(flattenX.shape, flattenOutputShape);
  const res = backend2.runWebGPUProgram(program, [flattenX, flattenIndex], flattenX.dtype);
  toDispose.push(res);
  const reshaped = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape: shapeInfo.outputShape } });
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return reshaped;
}
var gatherV2Config = {
  kernelName: GatherV2,
  backendName: "webgpu",
  kernelFunc: gatherV2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Greater.js
var greater2 = binaryKernelFunc({
  opType: BinaryOpType.GREATER,
  cpuKernelImpl: greaterImplCPU,
  dtype: "bool"
});
var greaterConfig = {
  kernelName: Greater,
  backendName: "webgpu",
  kernelFunc: greater2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/GreaterEqual.js
var greaterEqual2 = binaryKernelFunc({
  opType: BinaryOpType.GREATER_EQUAL,
  dtype: "bool",
  cpuKernelImpl: greaterEqualImplCPU
});
var greaterEqualConfig = {
  kernelName: GreaterEqual,
  backendName: "webgpu",
  kernelFunc: greaterEqual2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/IFFT.js
function ifft2(args) {
  const { inputs, backend: backend2 } = args;
  const { input } = inputs;
  return fftImpl(input, true, backend2);
}
var ifftConfig = {
  kernelName: IFFT,
  backendName: "webgpu",
  kernelFunc: ifft2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/IsFinite.js
var isFinite3 = unaryKernelFunc({ opType: UnaryOpType.IS_FINITE, dtype: "bool" });
var isFiniteConfig = {
  kernelName: IsFinite,
  backendName: "webgpu",
  kernelFunc: isFinite3
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/IsInf.js
var isInf2 = unaryKernelFunc({ opType: UnaryOpType.IS_INF, dtype: "bool" });
var isInfConfig = {
  kernelName: IsInf,
  backendName: "webgpu",
  kernelFunc: isInf2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/IsNaN.js
var isNaN3 = unaryKernelFunc({ opType: UnaryOpType.IS_NAN, dtype: "bool" });
var isNaNConfig = {
  kernelName: IsNan,
  backendName: "webgpu",
  kernelFunc: isNaN3
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LeakyRelu.js
function leakyRelu2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { alpha } = attrs;
  const uniformData = [{ type: "float32", data: [alpha] }];
  const program = new UnaryOpProgram(x.shape, UnaryOpType.LEAKYRELU, "alpha : f32,");
  return backend2.runWebGPUProgram(program, [x], "float32", uniformData);
}
var leakyReluConfig = {
  kernelName: LeakyRelu,
  backendName: "webgpu",
  kernelFunc: leakyRelu2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Less.js
var less2 = binaryKernelFunc({ opType: BinaryOpType.LESS, dtype: "bool", cpuKernelImpl: lessImplCPU });
var lessConfig = {
  kernelName: Less,
  backendName: "webgpu",
  kernelFunc: less2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LessEqual.js
var lessEqual2 = binaryKernelFunc({
  opType: BinaryOpType.LESS_EQUAL,
  dtype: "bool",
  cpuKernelImpl: lessEqualImplCPU
});
var lessEqualConfig = {
  kernelName: LessEqual,
  backendName: "webgpu",
  kernelFunc: lessEqual2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/lin_space_webgpu.js
var LinSpaceProgram = class {
  constructor(shape) {
    this.variableNames = [];
    this.outputShape = [];
    this.uniforms = "start : f32, step : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [shape];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "linSpace";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          setOutputAtIndex(index, uniforms.start + f32(index) * uniforms.step);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LinSpace.js
function linSpace(args) {
  const { backend: backend2, attrs } = args;
  const { start, stop, num } = attrs;
  const step3 = (stop - start) / (num - 1);
  const program = new LinSpaceProgram(num);
  const uniformData = [{ type: "float32", data: [start] }, { type: "float32", data: [step3] }];
  return backend2.runWebGPUProgram(program, [], "float32", uniformData);
}
var linSpaceConfig = {
  kernelName: LinSpace,
  backendName: "webgpu",
  kernelFunc: linSpace
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Log.js
var log2 = unaryKernelFunc({ opType: UnaryOpType.LOG, cpuKernelImpl: logImplCPU });
var logConfig = {
  kernelName: Log,
  backendName: "webgpu",
  kernelFunc: log2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Log1p.js
var log1p2 = unaryKernelFunc({ opType: UnaryOpType.LOG1P });
var log1pConfig = {
  kernelName: Log1p,
  backendName: "webgpu",
  kernelFunc: log1p2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LogicalAnd.js
var logicalAnd2 = binaryKernelFunc({ opType: BinaryOpType.LOGICAL_AND, dtype: "bool" });
var logicalAndConfig = {
  kernelName: LogicalAnd,
  backendName: "webgpu",
  kernelFunc: logicalAnd2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LogicalNot.js
var logicalNot2 = unaryKernelFunc({ opType: UnaryOpType.LOGICAL_NOT });
var logicalNotConfig = {
  kernelName: LogicalNot,
  backendName: "webgpu",
  kernelFunc: logicalNot2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LogicalOr.js
var logicalOr2 = binaryKernelFunc({ opType: BinaryOpType.LOGICAL_OR });
var logicalOrConfig = {
  kernelName: LogicalOr,
  backendName: "webgpu",
  kernelFunc: logicalOr2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/lrn_webgpu.js
var powOperatorSnippet = `
  var powValue = 0.0;
  let basis = uniforms.bias + uniforms.alpha * sum;
  if (uniforms.beta == 0.5) {
    powValue = inverseSqrt(basis);
  } else if (uniforms.beta == 1.0) {
    powValue = 1.0 / basis;
  } else {
    powValue = exp(log(basis) * (-uniforms.beta));
  }
`;
var LRNProgram = class {
  constructor(xShape) {
    this.outputShape = [];
    this.variableNames = ["x"];
    this.uniforms = "radius : i32, bias : f32, alpha : f32, beta : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = xShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "lrn";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        let b = coords[0];
        let r = coords[1];
        let c = coords[2];
        let d = coords[3];

        let x = getX(b, r, c, d);
        var sum = 0.0;
        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {
          let idx = d + i;
          if (idx >= 0 && idx < uniforms.xShape[3]) {
            let z = getX(b, r, c, idx);
            sum = sum + z * z;
          }
        }
        ${powOperatorSnippet}

        setOutputAtIndex(index, x * powValue);
      }
    }
  `;
    return userCode;
  }
};
var LRNSharedProgram = class {
  constructor(xShape, radius) {
    this.outputShape = [];
    this.variableNames = ["x"];
    this.uniforms = "radius : i32, bias : f32, alpha : f32, beta : f32,";
    this.workgroupSize = [256, 1, 1];
    this.maxAllowRadius = 16;
    util_exports.assert(radius <= this.maxAllowRadius, () => `Radius must be less than or equal to ${this.maxAllowRadius}, current radius is ${radius}`);
    this.outputShape = xShape;
    this.elementsPerWorkgroup = this.workgroupSize[0] - 2 * this.maxAllowRadius;
    this.dispatchLayout = { x: [3], y: [2], z: [0, 1] };
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [
      this.elementsPerWorkgroup,
      this.workgroupSize[1],
      this.workgroupSize[2]
    ]);
    this.shaderKey = "lrn_shared";
  }
  getUserCode() {
    const userCode = `
    var <workgroup>lrnSub: array<f32, ${this.workgroupSize[0]}>;
    const elementsPerWorkgroup = ${this.elementsPerWorkgroup};
    const maxAllowRadius = ${this.maxAllowRadius};

    ${getMainHeaderString()} {
      let localDepth = i32(localId.x);
      let workgroupDepth = i32(workgroupId.x) * elementsPerWorkgroup;
      let xDepth = workgroupDepth + localDepth - maxAllowRadius;
      let b = i32(globalId.z) / uniforms.xShape[1];
      let r = i32(globalId.z) - b * uniforms.xShape[1];
      let c = i32(globalId.y);
      let d = workgroupDepth + localDepth;

      var x = 0.0;
      if (xDepth >= 0 && xDepth < uniforms.xShape[3]) {
        x = getX(b, r, c, xDepth);
      }
      lrnSub[localDepth] = x;
      workgroupBarrier();

      if (localDepth < elementsPerWorkgroup && d < uniforms.outShape[3]) {
        var sum = 0.0;
        let index = localDepth + maxAllowRadius;
        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {
          let z = lrnSub[index + i];
          sum = sum + z * z;
        }
        ${powOperatorSnippet}

        setOutputAtCoords(b, r, c, d, lrnSub[index] * powValue);
      }
    } `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LRN.js
function lrn(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  let program;
  if (depthRadius > 16) {
    program = new LRNProgram(x.shape);
  } else {
    program = new LRNSharedProgram(x.shape, depthRadius);
  }
  const uniformData = [
    { type: "int32", data: [depthRadius] },
    { type: "float32", data: [bias] },
    { type: "float32", data: [alpha] },
    { type: "float32", data: [beta] }
  ];
  const res = backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
  return res;
}
var lrnConfig = {
  kernelName: LRN,
  backendName: "webgpu",
  kernelFunc: lrn
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/lrn_grad_webgpu.js
var LRNGradProgram = class {
  constructor(inputShape) {
    this.outputShape = [];
    this.variableNames = ["inputImage", "outputImage", "dy"];
    this.uniforms = "depthRadius : i32, bias : f32, alpha : f32, beta : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = inputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "lrn_grad";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        let b = coords[0];
        let r = coords[1];
        let c = coords[2];

        let MIN_DEPTH_BEGIN = 0;
        let MAX_DEPTH_END = uniforms.outShape[3];
        var result = 0.0;
        for (var d = MIN_DEPTH_BEGIN; d < MAX_DEPTH_END; d++) {
          let depthBegin = max(MIN_DEPTH_BEGIN, d - uniforms.depthRadius);
          let depthEnd = min(MAX_DEPTH_END, d + uniforms.depthRadius + 1);

          var norm = 0.0;
          for (var k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; k++) {
            if (k < depthBegin) {
              continue;
            } else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            } else {
              break;
            }
          }

          norm = uniforms.alpha * norm + uniforms.bias;

          for (var k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; k++) {
            if (k < depthBegin) {
              continue;
            } else if (k >= depthBegin && k < depthEnd) {
              var dyi = -2.0 * uniforms.alpha * uniforms.beta
                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d) / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * uniforms.beta);
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            } else {
              break;
            }
          }
        }

        setOutputAtIndex(index, result);
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/LRNGrad.js
function lrnGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, y, dy } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  const program = new LRNGradProgram(x.shape);
  const uniformData = [
    { type: "int32", data: [depthRadius] },
    { type: "float32", data: [bias] },
    { type: "float32", data: [alpha] },
    { type: "float32", data: [beta] }
  ];
  const res = backend2.runWebGPUProgram(program, [x, y, dy], x.dtype, uniformData);
  return res;
}
var lrnGradConfig = {
  kernelName: LRNGrad,
  backendName: "webgpu",
  kernelFunc: lrnGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Maximum.js
var maximum2 = binaryKernelFunc({
  opType: BinaryOpType.MAX,
  cpuKernelImpl: maximumImplCPU
});
var maximumConfig = {
  kernelName: Maximum,
  backendName: "webgpu",
  kernelFunc: maximum2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPool.js
function maxPool2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = 1;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  return poolImpl(x, convInfo, "max", backend2);
}
var maxPoolConfig = {
  kernelName: MaxPool,
  backendName: "webgpu",
  kernelFunc: maxPool2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPool3D.js
function maxPool3d2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode, dataFormat);
  const maxPoolProgram = new Pool3DProgram(convInfo, "max");
  const dimensions = [
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    {
      type: "int32",
      data: [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]
    },
    {
      type: "int32",
      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth
      ]
    }
  ];
  return backend2.runWebGPUProgram(maxPoolProgram, [x], x.dtype, dimensions);
}
var maxPool3DConfig = {
  kernelName: MaxPool3D,
  backendName: "webgpu",
  kernelFunc: maxPool3d2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/max_pool_backprop_webgpu.js
var MaxPool2DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "maxPos"];
    this.uniforms = `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, filterDims : vec2<i32>,
       outHeight : i32, outWidth : i32`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "maxPool2DBackprop";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords[0];
        let d = coords[3];

        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;
        let dyRCorner = dyRCCorner.x;
        let dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        let lastIndex = uniforms.filterDims[0] * uniforms.filterDims[1] - 1;
        for (var wR = 0; wR < uniforms.filterDims[0]; wR += uniforms.dilations[0]) {
          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);

          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
            continue;
          }
          let idyR = i32(dyR);

          for (var wC = 0; wC < uniforms.filterDims[1]; wC += uniforms.dilations[1]) {
            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);

            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
              continue;
            }
            let idyC = i32(dyC);

            let dyValue = getDy(batch, idyR, idyC, d);
            let maxPosValue = lastIndex - i32(getMaxPos(batch, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            let curPosValue = wR * uniforms.filterDims[1] + wC;
            let mask = select(0.0, 1.0, maxPosValue == curPosValue);
            dotProd += dyValue * mask;
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
    `;
    return userCode;
  }
};
var MaxPool3DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "maxPos"];
    this.uniforms = `strides : vec3<i32>, pads : vec3<i32>, filterDims : vec3<i32>,
      outDepth : i32, outHeight : i32, outWidth : i32`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = convInfo.inShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "maxPool3DBackprop";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords.x;
        let ch = coords.u;

        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;
        let dyDCorner = dyCorner.x;
        let dyRCorner = dyCorner.y;
        let dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        let lastIndex = uniforms.filterDims[0] * uniforms.filterDims[1] * uniforms.filterDims[2] - 1;

        for (var wD = 0; wD < uniforms.filterDims[0]; wD++) {
          let dyD = f32(dyDCorner + wD) / f32(uniforms.strides[0]);

          if (dyD < 0.0 || dyD >= f32(uniforms.outDepth) || fract(dyD) > 0.0) {
            continue;
          }
          let idyD = i32(dyD);

          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {
            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);

            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
              continue;
            }
            let idyR = i32(dyR);

            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {
              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);

              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
                continue;
              }
              let idyC = i32(dyC);

              let dyValue = getDy(batch, idyD, idyR, idyC, ch);
              let maxPosValue = lastIndex - i32(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              let curPosValue = wD * uniforms.filterDims[1] * uniforms.filterDims[2] + wR * uniforms.filterDims[2] + wC;
              let mask = select(0.0, 1.0, maxPosValue == curPosValue);
              dotProd += dyValue * mask;
            }
          }
        }

        setOutputAtIndex(index, dotProd);
      }
    }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPool3DGrad.js
function maxPool3DGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input } = inputs;
  const x = input;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  const maxPool3dPositionsProgram = new Pool3DProgram(
    convInfo,
    "max",
    true
    /* get positions */
  );
  let uniformData = [
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    {
      type: "int32",
      data: [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]
    },
    {
      type: "int32",
      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth
      ]
    }
  ];
  const maxPool3dPositions = backend2.runWebGPUProgram(maxPool3dPositionsProgram, [x], "int32", uniformData);
  const maxPool3dBackpropProgram = new MaxPool3DBackpropProgram(convInfo);
  uniformData = [
    {
      type: "int32",
      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth - 1 - convInfo.padInfo.front,
        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,
        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left
      ]
    },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth
      ]
    },
    { type: "int32", data: [convInfo.outDepth] },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] }
  ];
  const result = backend2.runWebGPUProgram(maxPool3dBackpropProgram, [dy, maxPool3dPositions], x.dtype, uniformData);
  backend2.disposeData(maxPool3dPositions.dataId);
  return result;
}
var maxPool3DGradConfig = {
  kernelName: MaxPool3DGrad,
  backendName: "webgpu",
  kernelFunc: maxPool3DGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPoolGrad.js
function maxPoolGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input, output } = inputs;
  const x = input;
  assertNotComplex([input, output], "maxPoolGrad");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
  const maxPoolPositionsProgram = new Pool2DProgram(convInfo, "max", true);
  let uniformData = [
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] },
    { type: "int32", data: [convInfo.inHeight, convInfo.inWidth] },
    {
      type: "int32",
      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
    }
  ];
  const maxPoolPositions = backend2.runWebGPUProgram(maxPoolPositionsProgram, [x], "int32", uniformData);
  const maxPoolBackpropProgram = new MaxPool2DBackpropProgram(convInfo);
  uniformData = [
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    {
      type: "int32",
      data: [
        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,
        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left
      ]
    },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] },
    {
      type: "int32",
      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
    },
    { type: "int32", data: [convInfo.outHeight] },
    { type: "int32", data: [convInfo.outWidth] }
  ];
  const result = backend2.runWebGPUProgram(maxPoolBackpropProgram, [dy, maxPoolPositions], x.dtype, uniformData);
  backend2.disposeData(maxPoolPositions.dataId);
  return result;
}
var maxPoolGradConfig = {
  kernelName: MaxPoolGrad,
  backendName: "webgpu",
  kernelFunc: maxPoolGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPoolWithArgmax.js
function maxPoolWithArgmax2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { filterSize, strides, pad: pad2, includeBatchInIndex } = attrs;
  const { x } = inputs;
  util_exports.assert(x.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`);
  const dilations = [1, 1];
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2);
  const uniformData = [
    { type: "int32", data: [convInfo.strideHeight, convInfo.strideWidth] },
    { type: "int32", data: [convInfo.padInfo.top, convInfo.padInfo.left] },
    { type: "int32", data: [convInfo.dilationHeight, convInfo.dilationWidth] },
    { type: "int32", data: [convInfo.inHeight, convInfo.inWidth] },
    {
      type: "int32",
      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
    }
  ];
  let program = new Pool2DProgram(convInfo, "max", false);
  const poolOutput = backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
  program = new Pool2DProgram(convInfo, "max", true, true, includeBatchInIndex);
  const indexOutput = backend2.runWebGPUProgram(program, [x], "int32", uniformData);
  return [poolOutput, indexOutput];
}
var maxPoolWithArgmaxConfig = {
  kernelName: MaxPoolWithArgmax,
  backendName: "webgpu",
  kernelFunc: maxPoolWithArgmax2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Min.js
function min2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  return reduce(x, axis, keepDims, "min", backend2);
}
var minConfig = {
  kernelName: Min,
  backendName: "webgpu",
  kernelFunc: min2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Minimum.js
var minimum2 = binaryKernelFunc({
  opType: BinaryOpType.MIN,
  cpuKernelImpl: minimumImplCPU
});
var minimumConfig = {
  kernelName: Minimum,
  backendName: "webgpu",
  kernelFunc: minimum2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/mirror_pad_webgpu.js
var MirrorPadProgram = class {
  constructor(xShape, paddings, mode) {
    this.uniforms = "";
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = paddings.map(
      (p, i) => p[0] + xShape[i] + p[1]
      /* afterPad */
    );
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.xShape = xShape;
    paddings.map((_, i) => {
      this.uniforms += ` pad${i} : vec2<i32>,`;
    });
    this.offset = mode === "reflect" ? 0 : 1;
    this.shaderKey = `mirrorPad_${mode}`;
  }
  getUserCode() {
    const rank = this.xShape.length;
    const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(",");
    const end = this.xShape.map((_, i) => `uniforms.pad${i}[0] + uniforms.xShape${rank > 1 ? `[${i}]` : ""}`).join(",");
    const shaderStart = rank === 1 ? "start" : "start[i]";
    const shaderEnd = rank === 1 ? "end" : "end[i]";
    const shaderOutC = rank === 1 ? "outC" : "outC[i]";
    const dtype = getCoordsDataType(rank);
    const unpackedCoords = rank > 1 ? ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank) : "coords";
    return `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let start = ${dtype}(${start});
          let end = ${dtype}(${end});
          var outC = getCoordsFromIndex(index);
          for (var i = 0; i < ${rank}; i = i + 1) {
            if (${shaderOutC} < ${shaderStart}) {
              ${shaderOutC} = ${shaderStart} * 2 - ${shaderOutC} - ${this.offset};
            } else if(${shaderOutC} >= ${shaderEnd}) {
              ${shaderOutC} = (${shaderEnd} - 1) * 2 - ${shaderOutC} + ${this.offset};
            }
          }
          let coords = outC - start;
          setOutputAtIndex(index, getX(${unpackedCoords}));
        }
      }
    `;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/MirrorPad.js
var mirrorPadConfig = {
  kernelName: MirrorPad,
  backendName: "webgpu",
  kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
    const { x } = inputs;
    const { paddings, mode } = attrs;
    const webGPUBackend = backend2;
    const uniformData = paddings.map((p) => {
      return { type: "int32", data: [p[0], p[1]] };
    });
    const program = new MirrorPadProgram(x.shape, paddings, mode);
    const output = webGPUBackend.runWebGPUProgram(program, [x], x.dtype, uniformData);
    return output;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Mod.js
var mod2 = binaryKernelFunc({ opType: BinaryOpType.MOD });
var modConfig = {
  kernelName: Mod,
  backendName: "webgpu",
  kernelFunc: mod2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/multinomial_webgpu.js
var MultinomialProgram = class {
  constructor(batchSize, numSamples) {
    this.variableNames = ["probs"];
    this.outputShape = [];
    this.uniforms = "seed : f32, numOutcomes: i32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [batchSize, numSamples];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "multinomial";
  }
  getUserCode() {
    const userCode = `
    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    fn random (seed : f32, resultUV : vec2<f32>) -> f32 {
      let HASHSCALE1 = 443.8975;
      let p = resultUV * seed;
      var p3  = fract(vec3<f32>(p.xyx) * HASHSCALE1);
      p3 = p3 + dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        let batch = coords[0];

        let resUV = vec2<f32>(f32(coords[1]) / f32(uniforms.outShape[1]),
            f32(coords[0]) / f32(uniforms.outShape[0]));
        let r = random(uniforms.seed, resUV);
        var cdf = 0.0;
        for (var i = 0; i < uniforms.numOutcomes - 1; i = i + 1) {
          cdf = cdf + getProbs(batch, i);

          if (r < cdf) {
            setOutputAtIndexI32(index, i);
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutputAtIndexI32(index, uniforms.numOutcomes - 1);
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/softmax_webgpu.js
var SoftmaxProgram = class {
  constructor(outputShape) {
    this.variableNames = ["logits"];
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = [this.outputShape[0], 1, 1];
    if (this.outputShape[1] >= 4096) {
      this.workgroupSize = [256, 1, 1];
    } else {
      this.workgroupSize = [64, 1, 1];
    }
    this.shaderKey = "softmax";
  }
  getUserCode() {
    const userCode = `
    var<workgroup> buf : array<f32, ${this.workgroupSize[0]}>;
    var<workgroup> rowMaxShared : f32;
    var<workgroup> rowSumShared : f32;
    const blockSize = ${this.workgroupSize[0]};
    ${getMainHeaderString("index")} {
      let row = index / blockSize;
      let tid = i32(localId.x);
      let cols = uniforms.outShape[1];

      var threadMax = -3.402823e+38f;
      for (var col = tid; col < cols; col += blockSize) {
        let value = getLogits(row, col);
        threadMax = max(threadMax, value);
      }
      if (tid < cols) {
        buf[tid] = threadMax;
      }
      workgroupBarrier();

      var reduceSize = min(cols, blockSize);
      for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {
        reduceSize = currSize + (reduceSize & 1);
        if (tid < currSize) {
          buf[tid] = max(buf[tid], buf[tid + reduceSize]);
        }
        workgroupBarrier();
      }

      if (tid == 0) {
        rowMaxShared = buf[0];
      }
      workgroupBarrier();

      var threadSum = 0.0;
      for (var col = tid; col < cols; col += blockSize) {
        let subExp = exp(getLogits(row, col) - rowMaxShared);
        threadSum += subExp;
      }
      buf[tid] = threadSum;
      workgroupBarrier();

      for (var currSize = blockSize >> 1;  currSize > 0; currSize = currSize >> 1) {
        if (tid < currSize) {
          buf[tid] = buf[tid] + buf[tid + currSize];
        }
        workgroupBarrier();
      }

      if (tid == 0) {
        rowSumShared = buf[0];
      }
      workgroupBarrier();

      for (var col = tid; col < cols; col += blockSize) {
        let value = exp(getLogits(row, col) - rowMaxShared) / rowSumShared;
        setOutputAtCoords(row, col, value);
      }
  }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Softmax.js
function softmax2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { logits } = inputs;
  const { dim } = attrs;
  const logitsReshaped = reshape2({
    inputs: { x: logits },
    backend: backend2,
    attrs: {
      shape: [
        util_exports.sizeFromShape(logits.shape) / logits.shape[dim],
        logits.shape[dim]
      ]
    }
  });
  const program = new SoftmaxProgram(logitsReshaped.shape);
  const res = backend2.runWebGPUProgram(program, [logitsReshaped], logits.dtype);
  const resReshaped = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape: logits.shape } });
  backend2.disposeData(logitsReshaped.dataId);
  backend2.disposeData(res.dataId);
  return resReshaped;
}
var softmaxConfig = {
  kernelName: Softmax,
  backendName: "webgpu",
  kernelFunc: softmax2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Multinomial.js
function multinomial2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { logits } = inputs;
  const { numSamples, seed, normalized } = attrs;
  const probs = normalized ? logits : softmax2({ inputs: { logits }, backend: backend2, attrs: { dim: logits.shape.length - 1 } });
  const batchSize = probs.shape[0];
  const numOutcomes = probs.shape[1];
  const program = new MultinomialProgram(batchSize, numSamples);
  const uniformData = [{ type: "float32", data: [seed] }, { type: "int32", data: [numOutcomes] }];
  const res = backend2.runWebGPUProgram(program, [probs], "int32", uniformData);
  if (!normalized) {
    backend2.disposeData(probs.dataId);
  }
  return res;
}
var multinomialConfig = {
  kernelName: Multinomial,
  backendName: "webgpu",
  kernelFunc: multinomial2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Neg.js
function neg2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (backend2.shouldExecuteOnCPU([x])) {
    const xData = backend2.tensorMap.get(x.dataId);
    const [outValues, newShape] = negImplCPU(xData.values, x.shape, x.dtype);
    return backend2.makeTensorInfo(newShape, x.dtype, outValues);
  }
  const program = new UnaryOpProgram(x.shape, UnaryOpType.NEG);
  return backend2.runWebGPUProgram(program, [x], x.dtype);
}
var negConfig = {
  kernelName: Neg,
  backendName: "webgpu",
  kernelFunc: neg2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/NonMaxSuppressionV3.js
function nonMaxSuppressionV3(args) {
  console.warn("tf.nonMaxSuppression() in webgpu locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
  const boxesVals = backend2.readSync(boxes.dataId);
  const scoresVals = backend2.readSync(scores.dataId);
  const { selectedIndices } = kernel_impls_exports.nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  return backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
}
var nonMaxSuppressionV3Config = {
  kernelName: NonMaxSuppressionV3,
  backendName: "webgpu",
  kernelFunc: nonMaxSuppressionV3
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/NonMaxSuppressionV5.js
function nonMaxSuppressionV5(args) {
  console.warn("tf.nonMaxSuppression() in webgpu locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
  const boxesVals = backend2.readSync(boxes.dataId);
  const scoresVals = backend2.readSync(scores.dataId);
  const maxOutputSizeVal = maxOutputSize;
  const iouThresholdVal = iouThreshold;
  const scoreThresholdVal = scoreThreshold;
  const softNmsSigmaVal = softNmsSigma;
  const { selectedIndices, selectedScores } = kernel_impls_exports.nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
  return [
    backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend2.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
  ];
}
var nonMaxSuppressionV5Config = {
  kernelName: NonMaxSuppressionV5,
  backendName: "webgpu",
  kernelFunc: nonMaxSuppressionV5
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/onehot_webgpu.js
var OneHotProgram = class {
  constructor(numIndices, depth) {
    this.variableNames = ["x"];
    this.uniforms = "onValue : f32, offValue : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [numIndices, depth];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "onehot";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if(index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          setOutputAtIndex(index, mix(uniforms.offValue, uniforms.onValue,
                                      f32(i32(round(getX(coords.x))) == coords.y)));
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/OneHot.js
function oneHot2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { indices } = inputs;
  const { dtype, depth, onValue, offValue } = attrs;
  const indicesSize = util_exports.sizeFromShape(indices.shape);
  const program = new OneHotProgram(indicesSize, depth);
  const reshaped = reshape2({ inputs: { x: indices }, backend: backend2, attrs: { shape: [indicesSize] } });
  const uniformData = [{ type: "float32", data: [onValue] }, { type: "float32", data: [offValue] }];
  const result = backend2.runWebGPUProgram(program, [reshaped], dtype, uniformData);
  backend2.disposeData(reshaped.dataId);
  const outShape = [...indices.shape, depth];
  const out = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: outShape } });
  backend2.disposeData(result.dataId);
  return out;
}
var oneHotConfig = {
  kernelName: OneHot,
  backendName: "webgpu",
  kernelFunc: oneHot2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ZerosLike.js
function zerosLike2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (x.dtype === "complex64") {
    const realPart = real2({ inputs: { input: x }, backend: backend2 });
    const r = zerosLike2({ inputs: { x: realPart }, backend: backend2 });
    const imagPart = imag2({ inputs: { input: x }, backend: backend2 });
    const i = zerosLike2({ inputs: { x: imagPart }, backend: backend2 });
    const result = complex2({ inputs: { real: r, imag: i }, backend: backend2 });
    backend2.disposeData(realPart.dataId);
    backend2.disposeData(r.dataId);
    backend2.disposeData(imagPart.dataId);
    backend2.disposeData(i.dataId);
    return result;
  } else {
    return fill2({
      attrs: {
        shape: x.shape,
        dtype: x.dtype,
        value: x.dtype === "string" ? "" : 0
      },
      backend: backend2
    });
  }
}
var zerosLikeConfig = {
  kernelName: ZerosLike,
  backendName: "webgpu",
  kernelFunc: zerosLike2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/OnesLike.js
function onesLike2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("onesLike is not supported under string dtype");
  } else if (x.dtype === "complex64") {
    const realPart = real2({ inputs: { input: x }, backend: backend2 });
    const r = onesLike2({ inputs: { x: realPart }, backend: backend2 });
    const imagPart = imag2({ inputs: { input: x }, backend: backend2 });
    const i = zerosLike2({ inputs: { x: imagPart }, backend: backend2 });
    const result = complex2({ inputs: { real: r, imag: i }, backend: backend2 });
    backend2.disposeData(realPart.dataId);
    backend2.disposeData(r.dataId);
    backend2.disposeData(imagPart.dataId);
    backend2.disposeData(i.dataId);
    return result;
  } else {
    return fill2({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend: backend2 });
  }
}
var onesLikeConfig = {
  kernelName: OnesLike,
  backendName: "webgpu",
  kernelFunc: onesLike2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Pack.js
function pack(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { axis } = attrs;
  if (inputs.length === 1) {
    return expandDims2({ inputs: { input: inputs[0] }, backend: backend2, attrs: { dim: axis } });
  }
  const shape = inputs[0].shape;
  const dtype = inputs[0].dtype;
  inputs.forEach((t2) => {
    util_exports.assertShapesMatch(shape, t2.shape, "All tensors passed to stack must have matching shapes");
    util_exports.assert(dtype === t2.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const intermediateTensorInfos = [];
  const expandedTensors = inputs.map((t2) => {
    const expandedT = expandDims2({ inputs: { input: t2 }, backend: backend2, attrs: { dim: axis } });
    intermediateTensorInfos.push(expandedT);
    return expandedT;
  });
  const result = concat2({ inputs: expandedTensors, backend: backend2, attrs: { axis } });
  intermediateTensorInfos.forEach((t2) => backend2.disposeData(t2.dataId));
  return result;
}
var packConfig = {
  kernelName: Pack,
  backendName: "webgpu",
  kernelFunc: pack
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/pad_webgpu.js
function padCommon(shape, fillZero = false) {
  const rank = shape.length;
  const type = getCoordsDataType(rank);
  const start = shape.map((_, i) => `uniforms.pad${i}[0]`).join(",");
  const end = shape.map((_, i) => `uniforms.pad${i}[0] + uniforms.xShape${rank > 1 ? `[${i}]` : ""}`).join(",");
  const startValue = rank > 1 ? `${type}(${start})` : `${start}`;
  const endValue = rank > 1 ? `${type}(${end})` : `${end}`;
  const leftPadCondition = rank > 1 ? `any(paddedCoords < start)` : `paddedCoords < start`;
  const rightPadCondition = rank > 1 ? `any(paddedCoords >= end)` : `paddedCoords >= end`;
  const unpackedCoords = rank > 1 ? ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank) : "coords";
  return `
        let start = ${startValue};
        let end = ${endValue};
        if (${leftPadCondition} || ${rightPadCondition}) {
          setOutputAtIndex(index, ${fillZero ? 0 : "uniforms.constantValue"});
        } else {
          let coords = paddedCoords - start;
          setOutputAtIndex(index, getX(${unpackedCoords}));
        }
  `;
}
var PadProgram = class {
  constructor(xShape, paddings) {
    this.variableNames = ["x"];
    this.uniforms = "constantValue : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = paddings.map(
      (p, i) => p[0] + xShape[i] + p[1]
      /* afterPad */
    );
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    paddings.map((_, i) => {
      this.uniforms += ` pad${i} : vec2<i32>,`;
    });
    this.xShape = xShape;
    this.shaderKey = "pad";
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let paddedCoords = getCoordsFromIndex(index);
          ${padCommon(this.xShape)}
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/PadV2.js
var padV2 = (args) => {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { paddings, constantValue } = attrs;
  if (paddings.every((p) => util_exports.arraysEqual(p, [0, 0]))) {
    return identity({ inputs: { x }, backend: backend2 });
  }
  if (util_exports.sizeFromShape(x.shape) === 0) {
    const outputShape = paddings.map(
      (p, i) => p[0] + x.shape[i] + p[1]
      /* afterPad */
    );
    return fill2({
      backend: backend2,
      attrs: { shape: outputShape, value: constantValue, dtype: x.dtype }
    });
  }
  const uniformData = [{ type: "float32", data: [constantValue] }];
  paddings.map((p) => uniformData.push({ type: "int32", data: [p[0], p[1]] }));
  const program = new PadProgram(x.shape, paddings);
  return backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
};
var padV2Config = {
  kernelName: PadV2,
  backendName: "webgpu",
  kernelFunc: padV2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Pow.js
var pow2 = binaryKernelFunc({
  opType: BinaryOpType.POW
});
var powConfig = {
  kernelName: Pow,
  backendName: "webgpu",
  kernelFunc: pow2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Prelu.js
function prelu2(args) {
  const { inputs, backend: backend2 } = args;
  const { x, alpha } = inputs;
  const program = new BinaryOpProgram(BinaryOpType.PRELU, x.shape, alpha.shape);
  return backend2.runWebGPUProgram(program, [x, alpha], "float32");
}
var preluConfig = {
  kernelName: Prelu,
  backendName: "webgpu",
  kernelFunc: prelu2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Prod.js
function prod2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  return reduce(x, axis, keepDims, "prod", backend2);
}
var prodConfig = {
  kernelName: Prod,
  backendName: "webgpu",
  kernelFunc: prod2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Range.js
var range2 = (args) => {
  const { backend: backend2, attrs } = args;
  const { start, stop, step: step3, dtype } = attrs;
  const values = rangeImplCPU(start, stop, step3, dtype);
  return backend2.makeTensorInfo([values.length], dtype, values);
};
var rangeConfig = {
  kernelName: Range,
  backendName: "webgpu",
  kernelFunc: range2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/RealDiv.js
var realDiv = binaryKernelFunc({ opType: BinaryOpType.DIV });
var realDivConfig = {
  kernelName: RealDiv,
  backendName: "webgpu",
  kernelFunc: realDiv
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Reciprocal.js
var reciprocal2 = unaryKernelFunc({ opType: UnaryOpType.RECIPROCAL });
var reciprocalConfig = {
  kernelName: Reciprocal,
  backendName: "webgpu",
  kernelFunc: reciprocal2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Relu.js
var relu2 = unaryKernelFunc({ opType: UnaryOpType.RELU });
var reluConfig = {
  kernelName: Relu,
  backendName: "webgpu",
  kernelFunc: relu2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Relu6.js
var relu62 = unaryKernelFunc({ opType: UnaryOpType.RELU6 });
var relu6Config = {
  kernelName: Relu6,
  backendName: "webgpu",
  kernelFunc: relu62
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/resize_bilinear_webgpu.js
var ResizeBilinearProgram = class {
  constructor(inputShape, newHeight, newWidth) {
    this.variableNames = ["x"];
    this.uniforms = "adjustHeightWidth : vec2<f32>, halfPixelCenters : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = `resizeBilinear`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
          let b = coords[0];
          let d = coords[3];
          let rc = coords.yz;

          let effectiveInSize = vec2<f32>(
            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveOutSize = vec2<f32>(
            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveInputOverOutputRatioRC =
              effectiveInSize / effectiveOutSize;

          // Fractional source index
          let sourceFracIndexRC =
            (vec2<f32>(rc) + vec2<f32>(uniforms.halfPixelCenters)) *
            effectiveInputOverOutputRatioRC - vec2<f32>(uniforms.halfPixelCenters);

          // Compute the four integer indices.
          let sourceFloorRC = vec2<i32>(sourceFracIndexRC);
          let sourceCeilRC = vec2<i32>(
            min(vec2<f32>(uniforms.xShape.yz) - vec2<f32>(1.0), ceil(sourceFracIndexRC)));

          let topLeft = getX(b, sourceFloorRC.x, sourceFloorRC.y, d);
          let bottomLeft = getX(b, sourceCeilRC.x, sourceFloorRC.y, d);
          let topRight = getX(b, sourceFloorRC.x, sourceCeilRC.y, d);
          let bottomRight = getX(b, sourceCeilRC.x, sourceCeilRC.y, d);

          let fracRC = sourceFracIndexRC - vec2<f32>(sourceFloorRC);

          let top = topLeft + (topRight - topLeft) * fracRC.y;
          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
          let newValue = top + (bottom - top) * fracRC.x;

          setOutputAtIndex(index, newValue);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeBilinear.js
function resizeBilinear(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images } = inputs;
  const { alignCorners, size, halfPixelCenters } = attrs;
  const [newHeight, newWidth] = size;
  const adjustHeight = alignCorners && newHeight > 1 ? 1 : 0;
  const adjustWidth = alignCorners && newWidth > 1 ? 1 : 0;
  const halfPixelCentersValue = halfPixelCenters ? 0.5 : 0;
  const uniformData = [
    { type: "float32", data: [adjustHeight, adjustWidth] },
    { type: "float32", data: [halfPixelCentersValue] }
  ];
  const program = new ResizeBilinearProgram(images.shape, newHeight, newWidth);
  return backend2.runWebGPUProgram(program, [images], "float32", uniformData);
}
var resizeBilinearConfig = {
  kernelName: ResizeBilinear,
  backendName: "webgpu",
  kernelFunc: resizeBilinear
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/resize_bilinear_backprop_webgpu.js
var ResizeBilinearBackpropProgram = class {
  constructor(inputShape, alignCorners) {
    this.variableNames = ["dy"];
    this.uniforms = `effectiveXSize : vec2<i32>, effectiveYSize : vec2<i32>, heightScale : f32, widthScale : f32,
       invHeightScale : f32, invWidthScale : f32, winHeight : i32, winWidth : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = inputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.alignCorners = alignCorners;
    this.shaderKey = `resizeBilinearBackprop_${alignCorners}`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getOutputCoords();
          let b = coords[0];
          let d = coords[3];
          let r = coords[1];
          let c = coords[2];

          var accumulator = 0.0;

          // Compute bounds for where in dy we will look
          let startRLerp = floor(f32(r) * uniforms.invHeightScale);
          let startDyR = i32(startRLerp - f32(uniforms.winHeight / 2));

          let startCLerp = floor(f32(c) * uniforms.invWidthScale);
          let startDyC = i32(startCLerp - f32(uniforms.winWidth / 2));

          // Loop over dy
          for (var dyROffset = 0; dyROffset < uniforms.winHeight; dyROffset++) {
            let dyR = startDyR + dyROffset;

            // Guard against the window exceeding the bounds of dy
            if (dyR < 0 || dyR >= uniforms.dyShape[1]) {
              continue;
            }

            for (var dyCOffset = 0; dyCOffset < uniforms.winWidth; dyCOffset++) {
              let dyC = startDyC + dyCOffset;

              // Guard against the window exceeding the bounds of dy
              if (dyC < 0 || dyC >= uniforms.dyShape[2]) {
                continue;
              }

              let dxR = f32(dyR) * uniforms.heightScale;
              let topDxRIndex = i32(floor(dxR));
              let bottomDxRIndex = i32(min(ceil(dxR), f32(uniforms.outShape[1] - 1)));
              let dxRLerp = dxR - f32(topDxRIndex);
              let inverseDxRLerp = 1.0 - dxRLerp;

              let dxC = f32(dyC) * uniforms.widthScale;
              let leftDxCIndex = i32(floor(dxC));
              let rightDxCIndex = i32(min(ceil(dxC), f32(uniforms.outShape[2] - 1)));
              let dxCLerp = dxC - f32(leftDxCIndex);
              let inverseDxCLerp = 1.0 - dxCLerp;

              if (r == topDxRIndex && c == leftDxCIndex) {
                // topLeft
                accumulator +=
                  getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
              }

              if (r == topDxRIndex && c == rightDxCIndex) {
                // topRight
                accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
              }

              if (r == bottomDxRIndex && c == leftDxCIndex) {
                // bottomLeft
                accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
              }

              if (r == bottomDxRIndex && c == rightDxCIndex) {
                // bottomRight
                accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
              }
            }
          }
          // End loop over dy

          setOutputAtIndex(index, accumulator);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeBilinearGrad.js
function resizeBilinearGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  const [, xHeight, xWidth] = images.shape;
  const [, yHeight, yWidth] = dy.shape;
  const effectiveXSize = [
    alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
    alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
  ];
  const effectiveYSize = [
    alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
    alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
  ];
  const heightScale = effectiveXSize[0] / effectiveYSize[0];
  const widthScale = effectiveXSize[1] / effectiveYSize[1];
  const invHeightScale = 1 / heightScale;
  const invWidthScale = 1 / widthScale;
  const winHeight = Math.ceil(invHeightScale) * 2 + 2;
  const winWidth = Math.ceil(invWidthScale) * 2 + 2;
  const program = new ResizeBilinearBackpropProgram(images.shape, alignCorners);
  const uniformData = [
    { type: "int32", data: effectiveXSize },
    { type: "int32", data: effectiveYSize },
    { type: "float32", data: [heightScale] },
    { type: "float32", data: [widthScale] },
    { type: "float32", data: [invHeightScale] },
    { type: "float32", data: [invWidthScale] },
    { type: "int32", data: [winHeight] },
    { type: "int32", data: [winWidth] }
  ];
  return backend2.runWebGPUProgram(program, [dy], dy.dtype, uniformData);
}
var resizeBilinearGradConfig = {
  kernelName: ResizeBilinearGrad,
  backendName: "webgpu",
  kernelFunc: resizeBilinearGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/resize_nearest_neighbor_webgpu.js
var ResizeNearestNeighborProgram = class {
  constructor(inputShape, newHeight, newWidth, halfPixelCenters) {
    this.variableNames = ["x"];
    this.uniforms = "adjustHeightWidth : vec2<f32>, roundBase : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.halfPixelCenters = halfPixelCenters;
    this.shaderKey = `resizeNearest_${halfPixelCenters}`;
  }
  getUserCode() {
    let sourceFracIndexRC;
    if (this.halfPixelCenters) {
      sourceFracIndexRC = `max((vec2<f32>(rc) + vec2<f32>(0.5)) * effectiveInputOverOutputRatioRC, vec2<f32>(0.0))`;
    } else {
      sourceFracIndexRC = `vec2<f32>(rc) * effectiveInputOverOutputRatioRC`;
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let b = coords[0];
          let d = coords[3];
          let rc = coords.yz;

          let effectiveInSize = vec2<f32>(
            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveOutSize = vec2<f32>(
            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveInputOverOutputRatioRC =
              effectiveInSize / effectiveOutSize;

          // Fractional source index
          let sourceFracIndexRC = ${sourceFracIndexRC};

          // Compute the coordinators of nearest neighbor point.
          let inputShapeRC = vec2<f32>(f32(uniforms.xShape.y), f32(uniforms.xShape.z));
          let sourceNearestRC = vec2<i32>(
            min(inputShapeRC - 1.0, floor(sourceFracIndexRC + uniforms.roundBase)));
          let newValue = getX(b, sourceNearestRC.x, sourceNearestRC.y, d);

          setOutputAtIndex(index, newValue);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeNearestNeighbor.js
function resizeNearestNeighbor(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  const [newHeight, newWidth] = size;
  const adjustHeight = alignCorners && newHeight > 1 ? 1 : 0;
  const adjustWidth = alignCorners && newWidth > 1 ? 1 : 0;
  const roundBase = alignCorners ? 0.5 : 0;
  const uniformData = [
    { type: "float32", data: [adjustHeight, adjustWidth] },
    { type: "float32", data: [roundBase] }
  ];
  const program = new ResizeNearestNeighborProgram(images.shape, newHeight, newWidth, halfPixelCenters);
  return backend2.runWebGPUProgram(program, [images], images.dtype, uniformData);
}
var resizeNearestNeighborConfig = {
  kernelName: ResizeNearestNeighbor,
  backendName: "webgpu",
  kernelFunc: resizeNearestNeighbor
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/resize_nearest_neighbor_backprop_webgpu.js
var ResizeNearestNeigborBackpropProgram = class {
  constructor(inputShape, alignCorners) {
    this.variableNames = ["dy"];
    this.uniforms = `effectiveXSize : vec2<i32>, effectiveYSize : vec2<i32>, invHeightScale : f32, invWidthScale : f32,
       winHeight : i32, winWidth : i32,`;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = inputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.alignCorners = alignCorners;
    this.shaderKey = `resizeNearestNeigborBackprop_${alignCorners}`;
  }
  getUserCode() {
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getOutputCoords();
          let b = coords[0];
          let d = coords[3];
          let r = coords[1];
          let c = coords[2];

          var accumulator = 0.0;

          // Compute bounds for where in dy we will look
          let startRLerp = floor(f32(r) * uniforms.invHeightScale);
          let startDyR = i32(floor(startRLerp - f32(uniforms.winHeight / 2)));

          let startCLerp = floor(f32(c) * uniforms.invWidthScale);
          let startDyC = i32(floor(startCLerp - f32(uniforms.winWidth / 2)));

          // Loop over dy
          for (var dyROffset = 0; dyROffset < uniforms.winHeight; dyROffset++) {
            let dyR = startDyR + dyROffset;

            // Guard against the window exceeding the bounds of dy
            if (dyR < 0 || dyR >= uniforms.dyShape[1]) {
              continue;
            }

            for (var dyCOffset = 0; dyCOffset < uniforms.winWidth; dyCOffset++) {
              let dyC = startDyC + dyCOffset;

              // Guard against the window exceeding the bounds of dy
              if (dyC < 0 || dyC >= uniforms.dyShape[2]) {
                continue;
              }

              let sourceFracRow = f32(uniforms.effectiveXSize[0]) *
                  (f32(dyR) / f32(uniforms.effectiveYSize[0]));

              let sourceFracCol = f32(uniforms.effectiveXSize[1]) *
                  (f32(dyC) / f32(uniforms.effectiveYSize[1]));

              let sourceNearestRow =
                  i32(min(f32(uniforms.outShape[1] - 1),
                  ${this.alignCorners ? "floor(sourceFracRow + 0.5)" : "floor(sourceFracRow)"}));

              let sourceNearestCol =
                  i32(min(f32(uniforms.outShape[2] - 1),
                  ${this.alignCorners ? "floor(sourceFracCol + 0.5)" : "floor(sourceFracCol)"}));

              if (r == sourceNearestRow && c == sourceNearestCol) {
                accumulator += getDy(b, dyR, dyC, d);
              }
            }
          }
          // End loop over dy

          setOutputAtIndex(index, accumulator);
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeNearestNeighborGrad.js
function resizeNearestNeighborGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  const [, xHeight, xWidth] = images.shape;
  const [, yHeight, yWidth] = dy.shape;
  const effectiveXSize = [
    alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
    alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
  ];
  const effectiveYSize = [
    alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
    alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
  ];
  const heightScale = effectiveXSize[0] / effectiveYSize[0];
  const widthScale = effectiveXSize[1] / effectiveYSize[1];
  const invHeightScale = 1 / heightScale;
  const invWidthScale = 1 / widthScale;
  const winHeight = Math.ceil(invHeightScale) * 2 + 2;
  const winWidth = Math.ceil(invWidthScale) * 2 + 2;
  const program = new ResizeNearestNeigborBackpropProgram(images.shape, alignCorners);
  const uniformData = [
    { type: "int32", data: effectiveXSize },
    { type: "int32", data: effectiveYSize },
    { type: "float32", data: [invHeightScale] },
    { type: "float32", data: [invWidthScale] },
    { type: "int32", data: [winHeight] },
    { type: "int32", data: [winWidth] }
  ];
  return backend2.runWebGPUProgram(program, [dy], dy.dtype, uniformData);
}
var resizeNearestNeighborGradConfig = {
  kernelName: ResizeNearestNeighborGrad,
  backendName: "webgpu",
  kernelFunc: resizeNearestNeighborGrad
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/reverse_webgpu.js
var ReverseProgram = class {
  constructor(xShape) {
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = xShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.uniforms = ` axis : vec4<i32>,`;
    this.shaderKey = "reverse";
  }
  getUserCode() {
    const reverseCoordsSnippet = `
      // Using uniform variables as judging conditions, so the function has
      // coherent execution within all threads.
      fn getReverseCoords(coords : vec4<i32>) -> vec4<i32> {
        var reverseCoords = coords;
        if (uniforms.axis[0] == 1) {
          reverseCoords[0] = uniforms.xShape[0] - coords[0] - 1;
        }
        if (uniforms.axis[1] == 1) {
          reverseCoords[1] = uniforms.xShape[1] - coords[1] - 1;
        }
        if (uniforms.axis[2] == 1) {
          reverseCoords[2] = uniforms.xShape[2] - coords[2] - 1;
        }
        if (uniforms.axis[3] == 1) {
          reverseCoords[3] = uniforms.xShape[3] - coords[3] - 1;
        }

        return reverseCoords;
      }
    `;
    const userCode = `
      ${reverseCoordsSnippet}
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let reverseCoords = getReverseCoords(coords);
          setOutputAtIndex(index, getX(reverseCoords[0],
              reverseCoords[1], reverseCoords[2], reverseCoords[3]));
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Reverse.js
function reverse2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { dims } = attrs;
  const xRank = x.shape.length;
  if (xRank === 0) {
    return identity({ inputs: { x }, backend: backend2 });
  }
  const xShape = x.shape;
  const xShape4D = [1, 1, 1, 1];
  xShape.forEach((d, i) => {
    const index = i + 4 - xRank;
    xShape4D[index] = d;
  });
  const axes = util_exports.parseAxisParam(dims, x.shape);
  const dims4D = [0, 0, 0, 0];
  axes.forEach((ax) => {
    const index = ax + 4 - xRank;
    dims4D[index] = 1;
  });
  const uniformData = [{ type: "int32", data: dims4D }];
  const xReshaped = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: xShape4D } });
  const program = new ReverseProgram(xShape4D);
  const values = backend2.runWebGPUProgram(program, [xReshaped], xReshaped.dtype, uniformData);
  backend2.disposeData(xReshaped.dataId);
  const result = reshape2({ inputs: { x: values }, backend: backend2, attrs: { shape: xShape } });
  backend2.disposeData(values.dataId);
  return result;
}
var reverseConfig = {
  kernelName: Reverse,
  backendName: "webgpu",
  kernelFunc: reverse2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/rotate_webgpu.js
var RotateProgram = class {
  constructor(imageShape, fillValue) {
    this.outputShape = [];
    this.variableNames = ["x"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = imageShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.uniforms = `centerX : f32, centerY : f32, sinRadians : f32,
          cosRadians : f32,`;
    this.shaderKey = "rotate";
    this.outputShape = imageShape;
    if (typeof fillValue === "number") {
      this.uniforms += ` fillValue : f32,`;
      this.fillSnippet = `var outputValue = uniforms.fillValue;`;
      this.shaderKey += "_float";
    } else {
      this.uniforms += ` fillValue : vec3<f32>,`;
      this.fillSnippet = `var outputValue = uniforms.fillValue[coords[3]];`;
      this.shaderKey += "_vec3";
    }
  }
  getUserCode() {
    const userCode = `
        ${getMainHeaderString("index")} {
          if (index < uniforms.size) {
            let coords = getCoordsFromIndex(index);
            let coordXFloat = (f32(coords[2]) - uniforms.centerX) *
                uniforms.cosRadians - (f32(coords[1]) - uniforms.centerY) *
                uniforms.sinRadians;
            let coordYFloat = (f32(coords[2]) - uniforms.centerX) *
                uniforms.sinRadians + (f32(coords[1]) - uniforms.centerY) *
                uniforms.cosRadians;
            let coordX = i32(round(coordXFloat + uniforms.centerX));
            let coordY = i32(round(coordYFloat + uniforms.centerY));
            ${this.fillSnippet}
            if(coordX >= 0 && coordX < uniforms.xShape[2] && coordY >= 0 &&
                coordY < uniforms.xShape[1]) {
              outputValue = getX(coords[0], coordY, coordX, coords[3]);
            }
            setOutputAtIndex(index, outputValue);
          }
        }
      `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/RotateWithOffset.js
var rotateWithOffsetConfig = {
  kernelName: RotateWithOffset,
  backendName: "webgpu",
  kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
    const { image: image2 } = inputs;
    const { radians, fillValue, center } = attrs;
    const webgpuBackend = backend2;
    const program = new RotateProgram(image2.shape, fillValue);
    const [centerX, centerY] = backend_util_exports.getImageCenter(center, image2.shape[1], image2.shape[2]);
    const uniformData = [
      { type: "float32", data: [centerX] },
      { type: "float32", data: [centerY] },
      { type: "float32", data: [Math.sin(radians)] },
      { type: "float32", data: [Math.cos(radians)] }
    ];
    if (typeof fillValue === "number") {
      uniformData.push({ type: "float32", data: [Number.parseFloat(fillValue.toFixed(2))] });
    } else {
      uniformData.push({ type: "float32", data: fillValue });
    }
    const output = webgpuBackend.runWebGPUProgram(program, [image2], image2.dtype, uniformData);
    return output;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Round.js
var round2 = unaryKernelFunc({ opType: UnaryOpType.ROUND });
var roundConfig = {
  kernelName: Round,
  backendName: "webgpu",
  kernelFunc: round2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Rsqrt.js
var rsqrt2 = unaryKernelFunc({ opType: UnaryOpType.RSQRT, cpuKernelImpl: rsqrtImplCPU });
var rsqrtConfig = {
  kernelName: Rsqrt,
  backendName: "webgpu",
  kernelFunc: rsqrt2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/scatter_webgpu.js
var ScatterProgram = class {
  constructor(flattenXShape, sliceDim, indicesRank, updatesRank, strides, shape, outputDtype, sumDupeIndices = true) {
    this.variableNames = ["updates", "indices"];
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.outputShape = shape;
    this.type = outputDtype;
    this.sumDupeIndices = sumDupeIndices;
    this.dispatchLayout = flatDispatchLayout(flattenXShape);
    this.dispatch = computeDispatch(this.dispatchLayout, flattenXShape, this.workgroupSize);
    this.sliceDimGreaterThanOne = sliceDim > 1;
    this.shaderKey = `scatter_${indicesRank}_${updatesRank}_${this.sliceDimGreaterThanOne}_${outputDtype}_${sumDupeIndices}_${strides.length}`;
    const stridesType = getCoordsDataType(strides.length);
    this.uniforms = `sliceDim : i32, strides: ${stridesType}, updatesSize: i32,`;
    this.updatesRank = updatesRank;
    this.indicesRank = indicesRank;
  }
  getUserCode() {
    let indicesString = "";
    if (this.indicesRank === 1) {
      indicesString = "coords[0]";
    } else if (this.indicesRank === 2) {
      indicesString = "coords[0], j";
    }
    const indicesSnippet = `getIndices(${indicesString})`;
    const strideString = this.sliceDimGreaterThanOne ? "uniforms.strides[j]" : "uniforms.strides";
    let outCoordsString = "";
    let getUpdatesCoordsFromFlatIndex = "";
    if (this.dispatchLayout.x.length === 1) {
      outCoordsString = "flattenedIndex";
      getUpdatesCoordsFromFlatIndex = `
      fn getUpdatesCoordsFromFlatIndex(index : i32) -> i32 {
        return index;
      }
      `;
    } else if (this.dispatchLayout.x.length === 2) {
      outCoordsString = "vec2<i32>(flattenedIndex, coords[1])";
      getUpdatesCoordsFromFlatIndex = `
      fn getUpdatesCoordsFromFlatIndex(index : i32) -> vec2<i32> {
        // N.B. |updates| could be a scalar tensor, conceptually representing a
        // 2D tensor with all values equal to that. By design, its size must be
        // the same as |outShape[1]| in one dimension, and |indicesShape[0]|
        // gives the other.
        let sliceSize = uniforms.outShape[1];
        let d0 = index / sliceSize;
        let d1 = index - d0 * sliceSize;
        return vec2<i32>(d0, d1);
      }
      `;
    }
    const updatesString = Array.from({ length: this.updatesRank }, (_, idx) => `coords[${idx}]`);
    const updatesSnippet = `getUpdates(${updatesString.join(", ")})`;
    const userCode = `
    ${getUpdatesCoordsFromFlatIndex}
      ${getMainHeaderString("index")} {
        if (index < uniforms.updatesSize) {
          let coords = getUpdatesCoordsFromFlatIndex(index);
          var flattenedIndex = 0;
          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {
            let indexInside = i32(round(${indicesSnippet}));
            flattenedIndex = flattenedIndex + indexInside * ${strideString};
          }
          let updateValue =
              ${dataTypeToGPUType(this.type)}(${updatesSnippet});
          let flatIndex = getOutputIndexFromCoords(${outCoordsString});

          ${this.sumDupeIndices ? atomicAddSnippet("&result[flatIndex]", "updateValue", this.type) : `atomicStore(&result[flatIndex], bitcast<i32>(updateValue));`}
        }
      }`;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/ScatterNd.js
function scatterNd(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { indices, updates } = inputs;
  const { shape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, shape);
  const flattenShape = [outputSize / sliceSize, sliceSize];
  if (outputSize === 0) {
    return backend2.makeTensorInfo(shape, indices.dtype);
  }
  const flattenIndices = reshape2({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numUpdates, sliceRank] } });
  const flattenX = reshape2({ inputs: { x: updates }, backend: backend2, attrs: { shape: [numUpdates, sliceSize] } });
  const type = flattenX.dtype;
  const output = fill2({ backend: backend2, attrs: { shape: flattenShape, value: 0, dtype: type } });
  const size = util_exports.sizeFromShape(flattenX.shape);
  const uniformData = [
    { type: "int32", data: [sliceRank] },
    { type: "int32", data: strides },
    { type: "int32", data: [size] }
  ];
  const program = new ScatterProgram(flattenX.shape, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape, type);
  const res = backend2.runWebGPUProgram(program, [flattenX, flattenIndices], type, uniformData, output);
  const reshaped = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape } });
  backend2.disposeData(flattenIndices.dataId);
  backend2.disposeData(flattenX.dataId);
  backend2.disposeData(res.dataId);
  return reshaped;
}
var scatterNdConfig = {
  kernelName: ScatterNd,
  backendName: "webgpu",
  kernelFunc: scatterNd
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/search_sorted_webgpu.js
var SearchSortedProgram = class {
  constructor(outputShape, side) {
    this.outputShape = [];
    this.variableNames = ["sortedSequence", "values"];
    this.uniforms = "numInputs : i32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.side = side;
    this.shaderKey = `search_sorted_${side}`;
  }
  getUserCode() {
    const boundComparator = this.side === "left" ? "<" : "<=";
    const userCode = `
      fn findBound(batch: i32, value: f32) -> i32 {
        var left = i32(0);
        var right = uniforms.numInputs;
        while (left < right) {
          var mid = (left + right) / 2;
          if (getSortedSequence(batch, mid) ${boundComparator} value) {
            left = mid + 1;
          } else {
            right = mid;
          }
        }
        return right;
      }

      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let value = getValuesByOutputIndex(index);
          setOutputAtIndexI32(index, findBound(coords[0], value));
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SearchSorted.js
function searchSorted2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { sortedSequence, values } = inputs;
  const { side } = attrs;
  const program = new SearchSortedProgram([values.shape[0], values.shape[1]], side);
  const uniformData = [{ type: "int32", data: [sortedSequence.shape[1]] }];
  return backend2.runWebGPUProgram(program, [sortedSequence, values], "int32", uniformData);
}
var searchSortedConfig = {
  kernelName: SearchSorted,
  backendName: "webgpu",
  kernelFunc: searchSorted2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/select_webgpu.js
var SelectProgram = class {
  constructor(cRank, shape, rank) {
    this.variableNames = ["c", "a", "b"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.cRank = cRank;
    this.rank = rank;
    this.shaderKey = "select";
  }
  getUserCode() {
    let cCoords;
    let abCoords;
    if (this.rank > 4) {
      throw Error(`Where for rank ${this.rank} is not yet supported`);
    }
    if (this.rank === 1) {
      abCoords = `resRC`;
      cCoords = `resRC`;
    } else {
      const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
      const cCoordVars = [];
      const abCoordVars = [];
      for (let i = 0; i < this.outputShape.length; i++) {
        abCoordVars.push(`${currentCoords[i]}`);
        if (i < this.cRank) {
          cCoordVars.push(`${currentCoords[i]}`);
        }
      }
      cCoords = cCoordVars.join();
      abCoords = abCoordVars.join();
    }
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let resRC = getCoordsFromIndex(index);
          let cVal = getC(${cCoords});
          if (cVal >= 1.0) {
            setOutputAtIndex(index, getA(${abCoords}));
          } else {
            setOutputAtIndex(index, getB(${abCoords}));
          }
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Select.js
function select(args) {
  const { inputs, backend: backend2 } = args;
  const { condition, t: t2, e } = inputs;
  const program = new SelectProgram(condition.shape.length, t2.shape, t2.shape.length);
  return backend2.runWebGPUProgram(program, [condition, t2, e], upcastType(t2.dtype, e.dtype));
}
var selectConfig = {
  kernelName: Select,
  backendName: "webgpu",
  kernelFunc: select
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Selu.js
var selu2 = unaryKernelFunc({ opType: UnaryOpType.SELU });
var seluConfig = {
  kernelName: Selu,
  backendName: "webgpu",
  kernelFunc: selu2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sigmoid.js
var sigmoid2 = unaryKernelFunc({ opType: UnaryOpType.SIGMOID });
var sigmoidConfig = {
  kernelName: Sigmoid,
  backendName: "webgpu",
  kernelFunc: sigmoid2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sign.js
var sign2 = unaryKernelFunc({ opType: UnaryOpType.SIGN });
var signConfig = {
  kernelName: Sign,
  backendName: "webgpu",
  kernelFunc: sign2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sin.js
var sin2 = unaryKernelFunc({ opType: UnaryOpType.SIN });
var sinConfig = {
  kernelName: Sin,
  backendName: "webgpu",
  kernelFunc: sin2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sinh.js
var sinh2 = unaryKernelFunc({ opType: UnaryOpType.SINH });
var sinhConfig = {
  kernelName: Sinh,
  backendName: "webgpu",
  kernelFunc: sinh2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Softplus.js
var softplus2 = unaryKernelFunc({ opType: UnaryOpType.SOFTPLUS });
var softplusConfig = {
  kernelName: Softplus,
  backendName: "webgpu",
  kernelFunc: softplus2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/space_to_batchND_webgpu.js
var SpaceToBatchNDProgram = class {
  constructor(xShape, paddedXShape, paddings, reshapedPaddedXShape, newDim, paddedXShapeStridesShapeLength) {
    this.variableNames = ["x"];
    this.outputShape = [];
    this.uniforms = "";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    const outputShape = new Array(reshapedPaddedXShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = reshapedPaddedXShape[newDim[i]];
    }
    this.outputShape = outputShape;
    this.newDim = newDim;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.xShape = xShape;
    this.paddedXShape = paddedXShape;
    this.uniforms += `reshapedPaddedXShape : ${getCoordsDataType(reshapedPaddedXShape.length)}, paddedXShapeStrides : ${getCoordsDataType(paddedXShapeStridesShapeLength)}, `;
    paddings.map((_, i) => {
      this.uniforms += ` pad${i} : vec2<i32>,`;
    });
    this.shaderKey = `spaceToBatchND_${newDim}`;
  }
  getUserCode() {
    const dtype = getCoordsDataType(this.outputShape.length);
    const switched = getSwitchedCoords(this.newDim);
    const userCode = `
      ${getCoordsFromIndexSnippet(this.paddedXShape, "PaddedX")}
      ${getMainHeaderString("index")} {
        if(index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let switchedIndex = getIndexFromCoords${this.outputShape.length}D(${dtype}(${switched}), uniforms.reshapedPaddedXShape);
          let paddedCoords = getPaddedXCoordsFromIndex(switchedIndex);
          ${padCommon(this.xShape, true)}
        }
      }
    `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SpaceToBatchND.js
var spaceToBatchND2 = (args) => {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockShape, paddings } = attrs;
  util_exports.assert(x.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGPU backend not implemented yet");
  const prod3 = blockShape.reduce((a, b) => a * b);
  const completePaddings = [[0, 0]];
  completePaddings.push(...paddings);
  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
    completePaddings.push([0, 0]);
  }
  const paddedXShape = completePaddings.map(
    (p, i) => p[0] + x.shape[i] + p[1]
    /* afterPad */
  );
  const reshapedPaddedShape = backend_util_exports.getReshaped(paddedXShape, blockShape, prod3, false);
  const permutedReshapedPaddedPermutation = backend_util_exports.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
  const flattenShape = backend_util_exports.getReshapedPermuted(paddedXShape, blockShape, prod3, false);
  const paddedXShapeStrides = util_exports.computeStrides(paddedXShape);
  const program = new SpaceToBatchNDProgram(x.shape, paddedXShape, completePaddings, reshapedPaddedShape, permutedReshapedPaddedPermutation, paddedXShapeStrides.length);
  const uniformData = [
    { type: "int32", data: reshapedPaddedShape },
    { type: "int32", data: paddedXShapeStrides }
  ];
  completePaddings.map((p) => uniformData.push({ type: "int32", data: [p[0], p[1]] }));
  const paddedXT = backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
  const result = reshape2({ inputs: { x: paddedXT }, backend: backend2, attrs: { shape: flattenShape } });
  backend2.disposeData(paddedXT.dataId);
  return result;
};
var spaceToBatchNDConfig = {
  kernelName: SpaceToBatchND,
  backendName: "webgpu",
  kernelFunc: spaceToBatchND2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/sparse_segment_reduce_webgpu.js
var SparseSegmentSumProgram = class {
  constructor(outShape, sparseSize, outputDtype) {
    this.variableNames = ["input", "indices", "segmentIds"];
    this.outputShape = [];
    this.uniforms = "segmentSize : i32, sparseSize : i32,";
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.outputShape = outShape;
    this.type = outputDtype;
    this.dispatchLayout = flatDispatchLayout([sparseSize]);
    this.dispatch = computeDispatch(this.dispatchLayout, [sparseSize], this.workgroupSize);
    this.shaderKey = "sparseSegmentSum";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.sparseSize) {
        let indexInSegmentIds = index / uniforms.segmentSize;
        let indexInSegment = index % uniforms.segmentSize;
        let indexInInput = indices[indexInSegmentIds];
        let segmentId = segmentIds[indexInSegmentIds];

        let value = input[indexInInput * uniforms.segmentSize + indexInSegment];
        let outIndex = segmentId * uniforms.segmentSize + indexInSegment;
        ${atomicAddSnippet("&result[outIndex]", "value", this.type)}
      }
    }
  `;
    return userCode;
  }
};
var SparseSegmentIdCountProgram = class {
  constructor(outShape, segmentIdsShape) {
    this.variableNames = ["segmentIds"];
    this.outputShape = [];
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.outputShape = [outShape];
    this.dispatchLayout = flatDispatchLayout(segmentIdsShape);
    this.dispatch = computeDispatch(this.dispatchLayout, segmentIdsShape, this.workgroupSize);
    this.shaderKey = "sparseSegmentIdCountProgram";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.segmentIdsShape) {
        let segmentId = segmentIds[index];
        ${atomicAddSnippet("&result[segmentId]", "1", "int32")}
      }
    }
  `;
    return userCode;
  }
};
var SparseSegmentMeanProgram = class {
  constructor(outShape, outputDtype) {
    this.variableNames = ["segmentSum", "sameSegmentIdCount"];
    this.outputShape = [];
    this.uniforms = "segmentSize : i32";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = outShape;
    this.type = outputDtype;
    this.dispatchLayout = flatDispatchLayout(outShape);
    this.dispatch = computeDispatch(this.dispatchLayout, outShape, this.workgroupSize);
    this.shaderKey = "sparseSegmentMean";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.size) {
        let segmentId = index / uniforms.segmentSize;
        let count = sameSegmentIdCount[segmentId];
        if (count != 0) {
          ${this.type === "float32" ? "setOutputAtIndex(index, segmentSum[index] / f32(count));" : "setOutputAtIndexI32(index, segmentSum[index] / count);"}
        }
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/sparse_segment_reduce.js
function sparseSegmentReduce(input, indices, segmentIds, isSum = false, backend2) {
  const inputSize = util_exports.sizeFromShape(input.shape);
  const segmentSize = inputSize / input.shape[0];
  const dtype = input.dtype;
  const numIndices = util_exports.sizeFromShape(indices.shape);
  const $segmentIds = backend2.readSync(segmentIds.dataId);
  const lastSegmentIdPlusOne = numIndices > 0 ? $segmentIds[numIndices - 1] + 1 : 0;
  const outputRows = lastSegmentIdPlusOne;
  let program;
  const outputShape = input.shape.slice();
  outputShape[0] = outputRows;
  const sparseSize = numIndices * segmentSize;
  const sparseSegmentSum2 = fill2({ backend: backend2, attrs: { shape: outputShape, value: 0, dtype } });
  program = new SparseSegmentSumProgram(outputShape, sparseSize, dtype);
  let uniformData = [
    { type: "int32", data: [segmentSize] },
    { type: "int32", data: [sparseSize] }
  ];
  const $sparseSegmentSum = backend2.runWebGPUProgram(program, [input, indices, segmentIds], dtype, uniformData, sparseSegmentSum2);
  if (isSum) {
    return $sparseSegmentSum;
  }
  const sparseSegmentIdCount = fill2({ backend: backend2, attrs: { shape: [outputRows], value: 0, dtype: "int32" } });
  program = new SparseSegmentIdCountProgram(outputRows, segmentIds.shape);
  const $sparseSegmentIdCount = backend2.runWebGPUProgram(program, [segmentIds], "int32", null, sparseSegmentIdCount);
  const sparseSegmentMean2 = fill2({ backend: backend2, attrs: { shape: outputShape, value: 0, dtype } });
  program = new SparseSegmentMeanProgram(outputShape, dtype);
  uniformData = [{ type: "int32", data: [segmentSize] }];
  const $sparseSegmentMean = backend2.runWebGPUProgram(program, [$sparseSegmentSum, $sparseSegmentIdCount], dtype, uniformData, sparseSegmentMean2);
  backend2.disposeData($sparseSegmentSum.dataId);
  backend2.disposeData($sparseSegmentIdCount.dataId);
  return $sparseSegmentMean;
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SparseSegmentMean.js
function sparseSegmentMean(args) {
  const { inputs, backend: backend2 } = args;
  const { data, indices, segmentIds } = inputs;
  return sparseSegmentReduce(data, indices, segmentIds, false, backend2);
}
var sparseSegmentMeanConfig = {
  kernelName: SparseSegmentMean,
  backendName: "webgpu",
  kernelFunc: sparseSegmentMean
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SparseSegmentSum.js
function sparseSegmentSum(args) {
  const { inputs, backend: backend2 } = args;
  const { data, indices, segmentIds } = inputs;
  return sparseSegmentReduce(data, indices, segmentIds, true, backend2);
}
var sparseSegmentSumConfig = {
  kernelName: SparseSegmentSum,
  backendName: "webgpu",
  kernelFunc: sparseSegmentSum
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/tile_webgpu.js
var TileProgram = class {
  constructor(aShape, reps) {
    this.variableNames = ["A"];
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    const outputShape = new Array(aShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = aShape[i] * reps[i];
    }
    this.outputShape = outputShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.rank = this.outputShape.length;
    this.shaderKey = "tile";
  }
  getUserCode() {
    const sourceCoords = getSourceCoords2(this.rank, "uniforms.");
    const userCode = `
      ${getMainHeaderString("index")} {
        if (index < uniforms.size) {
          let resRC = getCoordsFromIndex(index);
          setOutputAtIndex(index, getA(${sourceCoords}));
        }
      }
    `;
    return userCode;
  }
};
function getSourceCoords2(rank, uniformPrefix = "") {
  if (rank >= 5) {
    throw Error(`Tile for rank ${rank} is not yet supported`);
  }
  if (rank === 1) {
    return `(resRC % ${uniformPrefix}aShape)`;
  }
  const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
  const sourceCoords = [];
  for (let i = 0; i < rank; i++) {
    sourceCoords.push(`(${currentCoords[i]} % ${uniformPrefix}aShape[${i}])`);
  }
  return sourceCoords.join();
}

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Tile.js
function tile2(params) {
  const { inputs, backend: backend2, attrs } = params;
  const { x } = inputs;
  const { reps } = attrs;
  if (backend2.shouldExecuteOnCPU([x]) || x.dtype === "string" || x.shape.length >= 5) {
    const data = backend2.readSync(x.dataId);
    const value = x.dtype === "string" ? data.map((d) => util_exports.decodeString(d)) : data;
    const buf = buffer(x.shape, x.dtype, value);
    const outBuf = tileImplCPU(buf, reps);
    return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  const program = new TileProgram(x.shape, reps);
  const output = backend2.runWebGPUProgram(program, [x], x.dtype);
  return output;
}
var tileConfig = {
  kernelName: Tile,
  backendName: "webgpu",
  kernelFunc: tile2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SparseToDense.js
function sparseToDense2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { sparseIndices, sparseValues, defaultValue } = inputs;
  const { outputShape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(sparseValues, sparseIndices, outputShape);
  const sumDupeIndices = false;
  if (sparseValues.dtype === "string") {
    const indicesBuf = backend2.bufferSync(sparseIndices);
    const updatesBuf = backend2.bufferSync(sparseValues);
    const $defaultValue2 = util_exports.decodeString(backend2.readSync(defaultValue.dataId)[0]);
    const outBuf = scatterImplCPU(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue2, sumDupeIndices);
    return backend2.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
  }
  const flattenShape = [outputSize / sliceSize, sliceSize];
  const $sparseIndices = reshape2({
    inputs: { x: sparseIndices },
    backend: backend2,
    attrs: { shape: [numUpdates, sliceRank] }
  });
  const $sparseValues = sparseValues.shape.length ? reshape2({
    inputs: { x: sparseValues },
    backend: backend2,
    attrs: { shape: [numUpdates, sliceSize] }
  }) : identity({ inputs: { x: sparseValues }, backend: backend2 });
  const type = $sparseValues.dtype;
  const zero = backend2.makeTensorInfo([], type, util_exports.makeZerosTypedArray(1, type));
  const $defaultValue = reshape2({
    inputs: { x: defaultValue },
    backend: backend2,
    attrs: { shape: Array(flattenShape.length).fill(1) }
  });
  const $denseValues = tile2({ inputs: { x: $defaultValue }, backend: backend2, attrs: { reps: flattenShape } });
  const size = util_exports.sizeFromShape([numUpdates, sliceSize]);
  const uniformData = [
    { type: "int32", data: [sliceRank] },
    { type: "int32", data: strides },
    { type: "int32", data: [size] }
  ];
  switch (numUpdates) {
    case 0:
      break;
    case 1:
      if (true) {
        const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length, $sparseValues.shape.length, strides, flattenShape, type, sumDupeIndices);
        backend2.runWebGPUProgram(program, [$sparseValues, $sparseIndices], type, uniformData, $denseValues);
      }
      break;
    default:
      if (true) {
        const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length, zero.shape.length, strides, flattenShape, type, sumDupeIndices);
        backend2.runWebGPUProgram(program, [zero, $sparseIndices], type, uniformData, $denseValues);
      }
      {
        const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length, $sparseValues.shape.length, strides, flattenShape, type);
        backend2.runWebGPUProgram(program, [$sparseValues, $sparseIndices], type, uniformData, $denseValues);
      }
  }
  const denseValues = reshape2({ inputs: { x: $denseValues }, backend: backend2, attrs: { shape: outputShape } });
  backend2.disposeData($sparseIndices.dataId);
  backend2.disposeData($sparseValues.dataId);
  backend2.disposeData($defaultValue.dataId);
  backend2.disposeData(zero.dataId);
  backend2.disposeData($denseValues.dataId);
  return denseValues;
}
var sparseToDenseConfig = {
  kernelName: SparseToDense,
  backendName: "webgpu",
  kernelFunc: sparseToDense2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SplitV.js
function splitV(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { numOrSizeSplits, axis } = attrs;
  const $axis = util_exports.parseAxisParam(axis, x.shape)[0];
  const splitSizes = backend_util_exports.prepareSplitSize(x, numOrSizeSplits, $axis);
  const xRank = x.shape.length;
  const begin = new Array(xRank).fill(0);
  const size = x.shape.slice();
  return splitSizes.map((s) => {
    const sliceSize = [...size];
    sliceSize[$axis] = s;
    const sliceT = slice2({ inputs: { x }, backend: backend2, attrs: { begin, size: sliceSize } });
    begin[$axis] += s;
    return sliceT;
  });
}
var splitVConfig = {
  kernelName: SplitV,
  backendName: "webgpu",
  kernelFunc: splitV
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sqrt.js
var sqrt2 = unaryKernelFunc({ opType: UnaryOpType.SQRT });
var sqrtConfig = {
  kernelName: Sqrt,
  backendName: "webgpu",
  kernelFunc: sqrt2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Square.js
var squareConfig = {
  kernelName: Square,
  backendName: "webgpu",
  kernelFunc: ({ inputs, backend: backend2 }) => {
    const { x } = inputs;
    const webGPUBackend = backend2;
    const program = new UnaryOpProgram(x.shape, UnaryOpType.SQUARE);
    return webGPUBackend.runWebGPUProgram(program, [x], x.dtype);
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/SquaredDifference.js
var squaredDifference2 = binaryKernelFunc({
  opType: BinaryOpType.SQUARED_DIFFERENCE
});
var squaredDifferenceConfig = {
  kernelName: SquaredDifference,
  backendName: "webgpu",
  kernelFunc: squaredDifference2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Step.js
function step2({ inputs, attrs, backend: backend2 }) {
  const { x } = inputs;
  const program = new UnaryOpProgram(x.shape, UnaryOpType.STEP, "stepAlpha : f32,");
  const uniformData = [{ type: "float32", data: [attrs.alpha] }];
  return backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
}
var stepConfig = {
  kernelName: Step,
  backendName: "webgpu",
  kernelFunc: step2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/strided_slice_webgpu.js
var StridedSliceProgram = class {
  constructor(destSize) {
    this.variableNames = ["x"];
    this.workPerThread = 1;
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = destSize;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
    const dtype = getCoordsDataType(this.outputShape.length);
    this.uniforms = `begin : ${dtype},  strides : ${dtype}, `;
    this.shaderKey = "stridedSlice";
  }
  getUserCode() {
    const rank = this.outputShape.length;
    let newCoords = "";
    if (rank === 1) {
      newCoords = "coords * uniforms.strides + uniforms.begin";
    } else {
      let outputAxis = 0;
      newCoords = this.outputShape.map((_, i) => {
        outputAxis++;
        return this.outputShape.length === 1 ? `coords * uniforms.strides[${i}] + uniforms.begin[${i}]` : `coords[${outputAxis - 1}] * uniforms.strides[${i}] + uniforms.begin[${i}]`;
      }).join(",");
    }
    const userCode = `
       ${getMainHeaderString("index")} {
         if (index < uniforms.size) {
           let coords = getCoordsFromIndex(index);
           setOutputAtIndex(index, getX(${newCoords}));
         }
       }
     `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/StridedSlice.js
function stridedSlice2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
  const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = slice_util_exports.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
  let result;
  if (isIdentity) {
    result = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: finalShape } });
  } else if (sliceDim0 || isSimpleSlice) {
    util_exports.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
    const size = slice_util_exports.computeOutShape($begin, $end, $strides);
    const sliced = slice2({ inputs: { x }, backend: backend2, attrs: { begin: $begin, size } });
    result = reshape2({ inputs: { x: sliced }, backend: backend2, attrs: { shape: finalShape } });
    backend2.disposeData(sliced.dataId);
  } else {
    const shouldExecuteOnCPU = backend2.shouldExecuteOnCPU([x]);
    if (shouldExecuteOnCPU) {
      const values = backend2.readSync(x.dataId);
      const xBuf = buffer(x.shape, x.dtype, values);
      const resultValues = stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);
      result = backend2.makeTensorInfo(finalShape, x.dtype, resultValues.values);
    } else {
      const program = new StridedSliceProgram(finalShapeSparse);
      const uniformData = [{ type: "int32", data: $begin }, { type: "int32", data: $strides }];
      const resultValues = backend2.runWebGPUProgram(program, [x], x.dtype, uniformData);
      result = reshape2({ inputs: { x: resultValues }, backend: backend2, attrs: { shape: finalShape } });
      backend2.disposeData(resultValues.dataId);
    }
  }
  return result;
}
var stridedSliceConfig = {
  kernelName: StridedSlice,
  backendName: "webgpu",
  kernelFunc: stridedSlice2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/StringNGrams.js
function stringNGrams(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences } = attrs;
  const { data, dataSplits } = inputs;
  const $data = backend2.readSync(data.dataId);
  const $dataSplits = backend2.readSync(dataSplits.dataId);
  const [nGrams, nGramsSplits] = stringNGramsImplCPU($data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences);
  return [
    backend2.makeTensorInfo([nGrams.length], "string", nGrams),
    backend2.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
  ];
}
var stringNGramsConfig = {
  kernelName: StringNGrams,
  backendName: "webgpu",
  kernelFunc: stringNGrams
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Sub.js
var sub2 = binaryKernelFunc({ opType: BinaryOpType.SUB, cpuKernelImpl: subImplCPU, supportsComplex: true });
var subConfig = {
  kernelName: Sub,
  backendName: "webgpu",
  kernelFunc: sub2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Tan.js
var tan2 = unaryKernelFunc({ opType: UnaryOpType.TAN });
var tanConfig = {
  kernelName: Tan,
  backendName: "webgpu",
  kernelFunc: tan2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Tanh.js
var tanh2 = unaryKernelFunc({ opType: UnaryOpType.TANH });
var tanhConfig = {
  kernelName: Tanh,
  backendName: "webgpu",
  kernelFunc: tanh2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/TensorScatterUpdate.js
function tensorScatterUpdate2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { tensor: tensor2, indices, updates } = inputs;
  const {} = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, tensor2.shape);
  const flattenShape = [outputSize / sliceSize, sliceSize];
  if (outputSize === 0) {
    return backend2.makeTensorInfo(tensor2.shape, indices.dtype);
  }
  const toDispose = [];
  const flattenIndices = reshape2({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numUpdates, sliceRank] } });
  toDispose.push(flattenIndices);
  const flattenX = reshape2({ inputs: { x: updates }, backend: backend2, attrs: { shape: [numUpdates, sliceSize] } });
  toDispose.push(flattenX);
  const flattenTensor = reshape2({ inputs: { x: tensor2 }, backend: backend2, attrs: { shape: flattenShape } });
  toDispose.push(flattenTensor);
  const output = tile2({
    inputs: { x: flattenTensor },
    backend: backend2,
    attrs: { reps: Array(flattenShape.length).fill(1) }
  });
  const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape, tensor2.dtype, false);
  const size = util_exports.sizeFromShape([numUpdates, sliceSize]);
  const uniformData = [
    { type: "int32", data: [sliceRank] },
    { type: "int32", data: strides },
    { type: "int32", data: [size] }
  ];
  const res = backend2.runWebGPUProgram(program, [flattenX, flattenIndices], flattenTensor.dtype, uniformData, output);
  toDispose.push(res);
  const reshaped = reshape2({ inputs: { x: res }, backend: backend2, attrs: { shape: tensor2.shape } });
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return reshaped;
}
var tensorScatterUpdateConfig = {
  kernelName: TensorScatterUpdate,
  backendName: "webgpu",
  kernelFunc: tensorScatterUpdate2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/top_k_webgpu.js
var SwapProgram = class {
  constructor(shape) {
    this.variableNames = ["x", "indices"];
    this.workgroupSize = [256, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.uniforms = `inputSize : i32, firstPass : i32, negativeInf : f32,
        dir : i32, inc : i32,`;
    this.shaderKey = "swap";
  }
  getUserCode() {
    const userCode = `
        ${getMainHeaderString("index")} {
          if (index < uniforms.size) {
            let outC = getCoordsFromIndex(index);
            let batch = outC[0];
            let elemIdx = outC[1];
            // We compare elements pair-wise within a group of size 2 * inc.
            // The comparing rule for each group alternates between ascending
            // and descending. Within each group, we compare each pair at
            // positions i and i+inc. To decide whether an element at position i
            // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
            // inc, it is in the first half of the group, we denote it as x0,
            // otherwise we denote it as x1.
            // For example, as shown in the Bitonic top K paper referenced
            // above, Figure5(a) shows that element[1] is in the second half of
            // the group when group size is 2, but it is in the first half of
            // the group when group size is 4.
            let isFirstInPair = elemIdx % (2 * uniforms.inc) < uniforms.inc;
            var i = 0;
            if (isFirstInPair) {
              i = elemIdx;
            } else {
              i = elemIdx - uniforms.inc;
            }

            var i0 = 0;
            if (uniforms.firstPass == 1) {
              i0 = i;
            } else {
              i0 = i32(getIndices(batch, i));
            }

            var i1 = 0;
            if (uniforms.firstPass == 1) {
              i1 = i + uniforms.inc;
            } else {
              i1 = i32(getIndices(batch, i + uniforms.inc));
            }

            var x0 = f32(0.0);
            var x1 = f32(0.0);
            if (i0 < uniforms.inputSize) {
              x0 = getX(batch, i0);
            } else {
              x0 = uniforms.negativeInf;
            }
            if (i1 < uniforms.inputSize) {
              x1 = getX(batch, i1);
            } else {
              x1 = uniforms.negativeInf;
            }

            let reverse = elemIdx % (2 * uniforms.dir) >= uniforms.dir;
            let isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
            if (reverse == isGreater) {
              // Elements in opposite order of direction
              let iTemp = i0;
              i0 = i1;
              i1 = iTemp;
            }
            if (isFirstInPair) {
              setOutputAtIndex(index, f32(i0));
            } else {
              setOutputAtIndex(index, f32(i1));
            }
          }
        }
      `;
    return userCode;
  }
};
var MergeProgram = class {
  constructor(shape) {
    this.variableNames = ["x", "indices"];
    this.workgroupSize = [256, 1, 1];
    this.size = true;
    this.outputShape = shape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.uniforms = `inputSize : i32, firstPass : i32, k : i32,`;
    this.shaderKey = "merge";
  }
  getUserCode() {
    const userCode = `
        ${getMainHeaderString("index")} {
          if (index < uniforms.size) {
            let outC = getCoordsFromIndex(index);
            let batch = outC[0];
            let elemIdx = outC[1];
            // The output size is half of the previous size.
            // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _
            // (k=4), we only need to output the indices at positions |, the
            // indices at positions _ can be thrown away, see Figure5(b) After
            // Phase 2 (Merge phase) in the Bitonic Top K paper referenced
            // above.
            // For example, the paper shows we only need to output the orange
            // bars. The output sequence should look like this | | | | | | | |.
            // Because the sequence is halved, to map the output index back to
            // the previous sequence to find the corresponding value, we need
            // to double the index. When we double the index, we basically
            // interpolate a position, so 2i looks like
            // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k
            // position of each 2k positions by - elemIdx % k. E.g. for output
            // at index 4,5,6,7, we want to get the corresponding element at
            // original index 8,9,10,11, for output at index 8,9,10,11,
            // we want to get the corresponding element at original index
            // 16,17,18,19, so on and so forth.

            var i = 0;
            if (elemIdx < uniforms.k) {
              i = elemIdx;
            } else {
              i = elemIdx * 2 - elemIdx % uniforms.k;
            }
            var i0 = 0;
            if (uniforms.firstPass == 1) {
              i0 = i;
            } else {
              i0 = i32(getIndices(batch, i));
            }
            var i1 = 0;
            if (uniforms.firstPass == 1) {
              i1 = i + uniforms.k;
            } else {
              i1 = i32(getIndices(batch, i + uniforms.k));
            }

            let x0 = getX(batch, i0);
            var x1 = f32(0.0);
            if (i1 < uniforms.inputSize) {
              x1 = getX(batch, i1);
            } else {
              x1 = x0;
            }

            if (x0 >= x1) {
              setOutputAtIndex(index, f32(i0));
            } else {
              setOutputAtIndex(index, f32(i1));
            }
          }
        }
      `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/TopK.js
function disposeIntermediateTensorInfoOrNull(backend2, tensorInfo) {
  if (tensorInfo !== null) {
    backend2.disposeData(tensorInfo.dataId);
  }
}
function roundUpToPow2(num) {
  let pow22 = 1;
  while (pow22 < num) {
    pow22 *= 2;
  }
  return pow22;
}
function topK(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { k, sorted } = attrs;
  const xShape = x.shape;
  const lastDim = xShape[xShape.length - 1];
  if (backend2.shouldExecuteOnCPU([x])) {
    const xVals = backend2.readSync(x.dataId);
    const [allTopKVals, allTopKIndices] = topKImplCPU(xVals, xShape, x.dtype, k, sorted);
    return [
      backend2.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
      backend2.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
    ];
  }
  if (k === 0) {
    xShape[xShape.length - 1] = 0;
    return [
      backend2.makeTensorInfo(xShape, x.dtype, []),
      backend2.makeTensorInfo(xShape, "int32", [])
    ];
  }
  if (lastDim === 1) {
    return [
      x,
      fill2({ attrs: { shape: xShape, dtype: "int32", value: 0 }, backend: backend2 })
    ];
  }
  const xSize = util_exports.sizeFromShape(xShape);
  const batch = xSize / lastDim;
  const x2D = reshape2({ inputs: { x }, attrs: { shape: [batch, lastDim] }, backend: backend2 });
  const kPow2 = roundUpToPow2(k);
  const lastDimPow2 = roundUpToPow2(lastDim);
  let indices = null;
  const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];
  const runSwap = (dir, inc, shape) => {
    const inputs2 = getInputs();
    const program = new SwapProgram(shape);
    const firstPass = indices === null ? 1 : 0;
    const uniformDataSwap = [
      { type: "int32", data: [lastDim] },
      { type: "int32", data: [firstPass] },
      { type: "float32", data: [Number.NEGATIVE_INFINITY] },
      { type: "int32", data: [dir] },
      { type: "int32", data: [inc] }
    ];
    const prevIndices2 = indices;
    indices = backend2.runWebGPUProgram(program, inputs2, "int32", uniformDataSwap);
    disposeIntermediateTensorInfoOrNull(backend2, prevIndices2);
  };
  for (let len = 1; len < kPow2; len *= 2) {
    const dir = len * 2;
    for (let inc = len; inc >= 1; inc /= 2) {
      runSwap(dir, inc, [batch, lastDimPow2]);
    }
  }
  for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {
    const inputs2 = getInputs();
    const mergeProgram = new MergeProgram([batch, indicesSize / 2]);
    const firstPass = indices === null ? 1 : 0;
    const uniformDataMerge = [
      { type: "int32", data: [lastDim] },
      { type: "int32", data: [firstPass] },
      { type: "int32", data: [kPow2] }
    ];
    const prevIndices2 = indices;
    indices = backend2.runWebGPUProgram(mergeProgram, inputs2, "int32", uniformDataMerge);
    disposeIntermediateTensorInfoOrNull(backend2, prevIndices2);
    const len = kPow2 / 2;
    const dir = len * 2;
    for (let inc = len; inc >= 1; inc /= 2) {
      runSwap(dir, inc, indices.shape);
    }
  }
  let prevIndices = indices;
  indices = slice2({ inputs: { x: indices }, backend: backend2, attrs: { begin: 0, size: [batch, k] } });
  disposeIntermediateTensorInfoOrNull(backend2, prevIndices);
  let values = gatherV2({ inputs: { x: x2D, indices }, backend: backend2, attrs: { axis: 1, batchDims: 1 } });
  disposeIntermediateTensorInfoOrNull(backend2, x2D);
  const newShape = xShape.slice(0, -1);
  newShape.push(k);
  prevIndices = indices;
  indices = reshape2({ inputs: { x: indices }, attrs: { shape: newShape }, backend: backend2 });
  disposeIntermediateTensorInfoOrNull(backend2, prevIndices);
  const prevValues = values;
  values = reshape2({ inputs: { x: values }, attrs: { shape: newShape }, backend: backend2 });
  disposeIntermediateTensorInfoOrNull(backend2, prevValues);
  return [values, indices];
}
var topKConfig = {
  kernelName: TopK,
  backendName: "webgpu",
  kernelFunc: topK
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/transform_webgpu.js
var TransformProgram = class {
  constructor(outShape) {
    this.variableNames = ["Image", "Transforms"];
    this.uniforms = "interpolationModeId : i32, fillModeId : i32, fillValue : f32,";
    this.workgroupSize = [64, 1, 1];
    this.size = true;
    this.outputShape = outShape;
    this.dispatchLayout = flatDispatchLayout(this.outputShape);
    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
    this.shaderKey = "transform";
  }
  getUserCode() {
    const userCode = `
          fn mapCoord(outCoord : f32, len : f32) -> f32{
            var inCoord = outCoord;
            if(uniforms.fillModeId == 2) {
              if (inCoord < 0.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz2 = 2.0 * len;
                  if (inCoord < sz2) {
                    inCoord = sz2 * f32(i32(f32(-inCoord / sz2))) +
                    inCoord;
                  }
                  if (inCoord < -len) {
                    inCoord = inCoord + sz2;
                  } else {
                    inCoord = -inCoord - 1.0;
                  }
                }
              } else if (inCoord > len - 1.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz2 = 2.0 * len;
                  inCoord = inCoord - sz2 * f32(i32(f32(inCoord / sz2)));
                  if (inCoord >= len) {
                    inCoord = sz2 - inCoord - 1.0;
                  }
                }
              }
              return clamp(inCoord, 0.0, len - 1.0);
            } else if (uniforms.fillModeId == 3) {
              if (inCoord < 0.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz = len - 1.0;
                  inCoord = inCoord + len * (f32(i32(f32(-inCoord / sz))) + 1.0);
                }
              } else if (inCoord > len - 1.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz = len - 1.0;
                  inCoord = inCoord - len * f32(i32(f32(inCoord / sz)));
                }
              }
              return clamp(inCoord, 0.0, len - 1.0);
            } else if (uniforms.fillModeId == 4) {
              return clamp(outCoord, 0.0, len - 1.0);
            }
            return outCoord;
          }
          fn readWithFillValue(batch : i32, coordY : i32, coordX : i32,
            channel : i32) -> f32 {
            var outputValue : f32;
            if (0 <= coordY && coordY < uniforms.imageShape[1] && 0 <= coordX && coordX < uniforms.imageShape[2]) {
                outputValue = getImage(batch, coordY, coordX, channel);
            } else {
              outputValue = uniforms.fillValue;
            }
            return outputValue;
          }

          ${getMainHeaderString("index")} {
            if (index < uniforms.size) {
              let coords = getCoordsFromIndex(index);
              var outputValue : f32;
              let batch = coords[0];
              let x = coords[2];
              let y = coords[1];
              let channel = coords[3];
              let xf = f32(x);
              let yf = f32(y);
              let a1 = getTransforms(batch, 0);
              let a2 = getTransforms(batch, 1);
              let a3 = getTransforms(batch, 2);
              let b1 = getTransforms(batch, 3);
              let b2 = getTransforms(batch, 4);
              let b3 = getTransforms(batch, 5);
              let c1 = getTransforms(batch, 6);
              let c2 = getTransforms(batch, 7);
              let projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = uniforms.fillValue;
              } else {
                let inX = (a1 * xf + a2 * yf + a3) / projection;
                let inY = (b1 * xf + b2 * yf + b3) / projection;
                let mapX = mapCoord(inX, f32(uniforms.imageShape[2]));
                let mapY = mapCoord(inY, f32(uniforms.imageShape[1]));

                if (uniforms.interpolationModeId == 1) {
                  let coordY = i32(round(mapY));
                  let coordX = i32(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  let yFloor = floor(mapY);
                  let xFloor = floor(mapX);
                  let yCeil = yFloor + 1.0;
                  let xCeil = xFloor + 1.0;
                  let valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, i32(yFloor), i32(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, i32(yFloor), i32(xCeil), channel);
                  let valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, i32(yCeil), i32(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, i32(yCeil), i32(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutputAtIndex(index, outputValue);
            }
          }
        `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Transform.js
function transform(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { image: image2, transforms } = inputs;
  const { interpolation, fillMode, fillValue, outputShape } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
  const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
  const outShape = [
    batch,
    outHeight,
    outWidth,
    numChannels
  ];
  const program = new TransformProgram(outShape);
  const interpolationModeId = interpolation === "nearest" ? 1 : 2;
  let fillModeId;
  switch (fillMode) {
    case "constant":
      fillModeId = 1;
      break;
    case "reflect":
      fillModeId = 2;
      break;
    case "wrap":
      fillModeId = 3;
      break;
    case "nearest":
      fillModeId = 4;
      break;
    default:
      fillModeId = 1;
      break;
  }
  const uniformData = [
    { type: "int32", data: [interpolationModeId] },
    { type: "int32", data: [fillModeId] },
    { type: "float32", data: [fillValue] }
  ];
  return backend2.runWebGPUProgram(program, [image2, transforms], "float32", uniformData);
}
var transformConfig = {
  kernelName: Transform,
  backendName: "webgpu",
  kernelFunc: transform
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/Unpack.js
function unpack(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { value } = inputs;
  let { axis } = attrs;
  if (axis < 0) {
    axis += value.shape.length;
  }
  const x = value;
  const xRank = x.shape.length;
  const num = value.shape[axis];
  const outShape = new Array(xRank - 1);
  let outIndex = 0;
  for (let i = 0; i < xRank; i++) {
    if (i !== axis) {
      outShape[outIndex++] = x.shape[i];
    }
  }
  const toDispose = [];
  const begin = new Array(xRank).fill(0);
  const size = x.shape.slice();
  size[axis] = 1;
  const res = new Array(num);
  for (let i = 0; i < res.length; i++) {
    begin[axis] = i;
    const sliced = slice2({ inputs: { x }, backend: backend2, attrs: { begin, size } });
    const reshaped = reshape2({ inputs: { x: sliced }, backend: backend2, attrs: { shape: outShape } });
    res[i] = reshaped;
    toDispose.push(sliced);
  }
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return res;
}
var unpackConfig = {
  kernelName: Unpack,
  backendName: "webgpu",
  kernelFunc: unpack
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/unsorted_segment_sum_webgpu.js
var UnsortedSegmentSumProgram = class {
  constructor(inShape, outShape, outputDtype) {
    this.outputShape = [];
    this.variableNames = ["x", "segmentIds"];
    this.uniforms = "numSegments : i32, xSize: i32,";
    this.workgroupSize = [64, 1, 1];
    this.atomic = true;
    this.outputShape = outShape;
    this.dispatchLayout = flatDispatchLayout(inShape);
    this.dispatch = computeDispatch(this.dispatchLayout, inShape, this.workgroupSize);
    if (outputDtype !== "float32" && outputDtype !== "int32") {
      throw new Error(`UnsortedSegmentSum only supports float32 and int32
              types, does not support ${outputDtype} type.`);
    }
    this.type = outputDtype;
    this.shaderKey = "unsortedSegmentSum";
  }
  getUserCode() {
    const userCode = `
    ${getMainHeaderString("index")} {
      if (index < uniforms.xSize) {
        let coords = getXCoordsFromIndex(index);
        let b = coords[0];
        let inCol = coords[1];

        let segmentId = i32(getSegmentIds(inCol));
        if (segmentId >= 0) {
          let flatIndex = b * uniforms.numSegments + segmentId % uniforms.numSegments;
          let value = getX(b, inCol);

          ${atomicAddSnippet("&result[flatIndex]", "value", this.type)}
        }
      }
    }
  `;
    return userCode;
  }
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/kernels/UnsortedSegmentSum.js
function unsortedSegmentSum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, segmentIds } = inputs;
  const { numSegments } = attrs;
  const xRank = x.shape.length;
  const toDispose = [];
  let axis = 0;
  const permutation = backend_util_exports.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation != null) {
    permutedX = transpose2({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
    toDispose.push(permutedX);
    axis = backend_util_exports.getInnerMostAxes(1, xRank)[0];
  }
  const outShape = backend_util_exports.segment_util.computeOutShape(permutedX.shape, axis, numSegments);
  const inSize = util_exports.sizeFromShape([permutedX.shape[axis]]);
  const a2D = reshape2({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
  toDispose.push(a2D);
  const dtype = x.dtype;
  const shape = [a2D.shape[0], numSegments];
  const output = fill2({ backend: backend2, attrs: { shape, value: 0, dtype } });
  const program = new UnsortedSegmentSumProgram(a2D.shape, shape, dtype);
  const uniformData = [
    { type: "int32", data: [numSegments] },
    { type: "int32", data: [util_exports.sizeFromShape(a2D.shape)] }
  ];
  const segResult = backend2.runWebGPUProgram(program, [a2D, segmentIds], dtype, uniformData, output);
  const reshaped = reshape2({ inputs: { x: segResult }, backend: backend2, attrs: { shape: outShape } });
  toDispose.push(segResult);
  let result = reshaped;
  if (permutation != null) {
    toDispose.push(reshaped);
    const perm = backend_util_exports.getUndoAxesPermutation(permutation);
    result = transpose2({ inputs: { x: result }, backend: backend2, attrs: { perm } });
  }
  toDispose.forEach((t2) => backend2.disposeData(t2.dataId));
  return result;
}
var unsortedSegmentSumConfig = {
  kernelName: UnsortedSegmentSum,
  backendName: "webgpu",
  kernelFunc: unsortedSegmentSum2
};

// node_modules/@tensorflow/tfjs-backend-webgpu/dist/register_all_kernels.js
var kernelConfigs = [
  _fusedMatMulConfig,
  absConfig,
  acosConfig,
  acoshConfig,
  addConfig,
  addNConfig,
  allConfig,
  anyConfig,
  argMaxConfig,
  argMinConfig,
  asinConfig,
  asinhConfig,
  atanConfig,
  atan2Config,
  atanhConfig,
  avgPoolConfig,
  avgPool3DConfig,
  avgPool3DGradConfig,
  avgPoolGradConfig,
  batchMatMulConfig,
  batchToSpaceNDConfig,
  bincountConfig,
  broadcastArgsConfig,
  castConfig,
  ceilConfig,
  clipByValueConfig,
  complexConfig,
  complexAbsConfig,
  concatConfig,
  conv2DConfig,
  conv2DBackpropFilterConfig,
  conv2DBackpropInputConfig,
  conv3DConfig,
  conv3DBackpropFilterV2Config,
  conv3DBackpropInputV2Config,
  cosConfig,
  coshConfig,
  cropAndResizeConfig,
  cumprodConfig,
  cumsumConfig,
  denseBincountConfig,
  depthToSpaceConfig,
  depthwiseConv2dNativeBackpropFilterConfig,
  depthwiseConv2dNativeBackpropInputConfig,
  depthwiseConv2dNativeConfig,
  diagConfig,
  dilation2DConfig,
  dilation2DBackpropFilterConfig,
  dilation2DBackpropInputConfig,
  drawConfig,
  einsumConfig,
  eluConfig,
  eluGradConfig,
  equalConfig,
  erfConfig,
  expConfig,
  expandDimsConfig,
  expm1Config,
  fftConfig,
  fillConfig,
  flipLeftRightConfig,
  fromPixelsConfig,
  floorConfig,
  floorDivConfig,
  fusedBatchNormConfig,
  fusedConv2DConfig,
  fusedDepthwiseConv2DConfig,
  gatherNdConfig,
  gatherV2Config,
  greaterConfig,
  greaterEqualConfig,
  identityConfig,
  ifftConfig,
  imagConfig,
  isFiniteConfig,
  isInfConfig,
  isNaNConfig,
  leakyReluConfig,
  lessConfig,
  lessEqualConfig,
  linSpaceConfig,
  log1pConfig,
  logConfig,
  logicalAndConfig,
  logicalNotConfig,
  logicalOrConfig,
  lrnConfig,
  lrnGradConfig,
  maxConfig,
  maximumConfig,
  maxPoolConfig,
  maxPoolGradConfig,
  maxPool3DConfig,
  maxPool3DGradConfig,
  maxPoolWithArgmaxConfig,
  meanConfig,
  minConfig,
  minimumConfig,
  mirrorPadConfig,
  modConfig,
  multinomialConfig,
  multiplyConfig,
  negConfig,
  nonMaxSuppressionV3Config,
  nonMaxSuppressionV5Config,
  notEqualConfig,
  oneHotConfig,
  onesLikeConfig,
  packConfig,
  padV2Config,
  powConfig,
  preluConfig,
  prodConfig,
  rangeConfig,
  realConfig,
  realDivConfig,
  reciprocalConfig,
  reluConfig,
  relu6Config,
  reshapeConfig,
  resizeBilinearConfig,
  resizeBilinearGradConfig,
  resizeNearestNeighborConfig,
  resizeNearestNeighborGradConfig,
  reverseConfig,
  rotateWithOffsetConfig,
  roundConfig,
  rsqrtConfig,
  scatterNdConfig,
  searchSortedConfig,
  selectConfig,
  seluConfig,
  sigmoidConfig,
  signConfig,
  sinConfig,
  sinhConfig,
  sliceConfig,
  stepConfig,
  stridedSliceConfig,
  stringNGramsConfig,
  softmaxConfig,
  softplusConfig,
  spaceToBatchNDConfig,
  sparseSegmentMeanConfig,
  sparseSegmentSumConfig,
  sparseToDenseConfig,
  splitVConfig,
  sqrtConfig,
  squareConfig,
  squaredDifferenceConfig,
  subConfig,
  sumConfig,
  tanConfig,
  tanhConfig,
  tensorScatterUpdateConfig,
  tileConfig,
  topKConfig,
  transformConfig,
  transposeConfig,
  unpackConfig,
  unsortedSegmentSumConfig,
  zerosLikeConfig
];
for (const kernelConfig of kernelConfigs) {
  registerKernel(kernelConfig);
}

// node_modules/@tensorflow-models/pose-detection/dist/pose-detection.esm.js
var L = function(t2, e) {
  return (L = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(t3, e2) {
    t3.__proto__ = e2;
  } || function(t3, e2) {
    for (var n in e2)
      Object.prototype.hasOwnProperty.call(e2, n) && (t3[n] = e2[n]);
  })(t2, e);
};
function V(t2, e) {
  if ("function" != typeof e && null !== e)
    throw new TypeError("Class extends value " + String(e) + " is not a constructor or null");
  function n() {
    this.constructor = t2;
  }
  L(t2, e), t2.prototype = null === e ? Object.create(e) : (n.prototype = e.prototype, new n());
}
var B = function() {
  return (B = Object.assign || function(t2) {
    for (var e, n = 1, i = arguments.length; n < i; n++)
      for (var r in e = arguments[n])
        Object.prototype.hasOwnProperty.call(e, r) && (t2[r] = e[r]);
    return t2;
  }).apply(this, arguments);
};
function N(t2, e, n, i) {
  return new (n || (n = Promise))(function(r, o) {
    function a(t3) {
      try {
        u(i.next(t3));
      } catch (t4) {
        o(t4);
      }
    }
    function s(t3) {
      try {
        u(i.throw(t3));
      } catch (t4) {
        o(t4);
      }
    }
    function u(t3) {
      var e2;
      t3.done ? r(t3.value) : (e2 = t3.value, e2 instanceof n ? e2 : new n(function(t4) {
        t4(e2);
      })).then(a, s);
    }
    u((i = i.apply(t2, e || [])).next());
  });
}
function D(t2, e) {
  var n, i, r, o, a = { label: 0, sent: function() {
    if (1 & r[0])
      throw r[1];
    return r[1];
  }, trys: [], ops: [] };
  return o = { next: s(0), throw: s(1), return: s(2) }, "function" == typeof Symbol && (o[Symbol.iterator] = function() {
    return this;
  }), o;
  function s(o2) {
    return function(s2) {
      return function(o3) {
        if (n)
          throw new TypeError("Generator is already executing.");
        for (; a; )
          try {
            if (n = 1, i && (r = 2 & o3[0] ? i.return : o3[0] ? i.throw || ((r = i.return) && r.call(i), 0) : i.next) && !(r = r.call(i, o3[1])).done)
              return r;
            switch (i = 0, r && (o3 = [2 & o3[0], r.value]), o3[0]) {
              case 0:
              case 1:
                r = o3;
                break;
              case 4:
                return a.label++, { value: o3[1], done: false };
              case 5:
                a.label++, i = o3[1], o3 = [0];
                continue;
              case 7:
                o3 = a.ops.pop(), a.trys.pop();
                continue;
              default:
                if (!(r = a.trys, (r = r.length > 0 && r[r.length - 1]) || 6 !== o3[0] && 2 !== o3[0])) {
                  a = 0;
                  continue;
                }
                if (3 === o3[0] && (!r || o3[1] > r[0] && o3[1] < r[3])) {
                  a.label = o3[1];
                  break;
                }
                if (6 === o3[0] && a.label < r[1]) {
                  a.label = r[1], r = o3;
                  break;
                }
                if (r && a.label < r[2]) {
                  a.label = r[2], a.ops.push(o3);
                  break;
                }
                r[2] && a.ops.pop(), a.trys.pop();
                continue;
            }
            o3 = e.call(t2, a);
          } catch (t3) {
            o3 = [6, t3], i = 0;
          } finally {
            n = r = 0;
          }
        if (5 & o3[0])
          throw o3[1];
        return { value: o3[0] ? o3[1] : void 0, done: true };
      }([o2, s2]);
    };
  }
}
function K(t2, e, n) {
  if (n || 2 === arguments.length)
    for (var i, r = 0, o = e.length; r < o; r++)
      !i && r in e || (i || (i = Array.prototype.slice.call(e, 0, r)), i[r] = e[r]);
  return t2.concat(i || Array.prototype.slice.call(e));
}
var U = ["nose", "left_eye", "right_eye", "left_ear", "right_ear", "left_shoulder", "right_shoulder", "left_elbow", "right_elbow", "left_wrist", "right_wrist", "left_hip", "right_hip", "left_knee", "right_knee", "left_ankle", "right_ankle"];
var j = ["nose", "left_eye_inner", "left_eye", "left_eye_outer", "right_eye_inner", "right_eye", "right_eye_outer", "left_ear", "right_ear", "mouth_left", "mouth_right", "left_shoulder", "right_shoulder", "left_elbow", "right_elbow", "left_wrist", "right_wrist", "left_pinky", "right_pinky", "left_index", "right_index", "left_thumb", "right_thumb", "left_hip", "right_hip", "left_knee", "right_knee", "left_ankle", "right_ankle", "left_heel", "right_heel", "left_foot_index", "right_foot_index"];
var H = { left: [1, 2, 3, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31], right: [4, 5, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32], middle: [0] };
var q = { left: [1, 3, 5, 7, 9, 11, 13, 15], right: [2, 4, 6, 8, 10, 12, 14, 16], middle: [0] };
var X = [[0, 1], [0, 2], [1, 3], [2, 4], [5, 6], [5, 7], [5, 11], [6, 8], [6, 12], [7, 9], [8, 10], [11, 12], [11, 13], [12, 14], [13, 15], [14, 16]];
var Y = [[0, 1], [0, 4], [1, 2], [2, 3], [3, 7], [4, 5], [5, 6], [6, 8], [9, 10], [11, 12], [11, 13], [11, 23], [12, 14], [14, 16], [12, 24], [13, 15], [15, 17], [16, 18], [16, 20], [15, 17], [15, 19], [15, 21], [16, 22], [17, 19], [18, 20], [23, 25], [23, 24], [24, 26], [25, 27], [26, 28], [27, 29], [28, 30], [27, 31], [28, 32], [29, 31], [30, 32]];
function W(t2) {
  return t2 instanceof SVGAnimatedLength ? t2.baseVal.value : t2;
}
function G(t2) {
  return N(this, void 0, void 0, function() {
    var i, r;
    return D(this, function(o) {
      switch (o.label) {
        case 0:
          return i = document.createElement("canvas"), t2 instanceof Tensor ? [4, browser_exports.toPixels(t2, i)] : [3, 2];
        case 1:
          return o.sent(), [3, 3];
        case 2:
          i.width = W(t2.width), i.height = W(t2.height), r = i.getContext("2d"), t2 instanceof ImageData ? r.putImageData(t2, 0, 0) : r.drawImage(t2, 0, 0), o.label = 3;
        case 3:
          return [2, i];
      }
    });
  });
}
function Q(t2) {
  return N(this, void 0, void 0, function() {
    var i, r, o, a, s, u;
    return D(this, function(h) {
      switch (h.label) {
        case 0:
          return t2 instanceof Tensor ? (i = t2.shape.slice(0, 2), r = i[0], o = i[1], a = ImageData.bind, [4, browser_exports.toPixels(t2)]) : [3, 2];
        case 1:
          return [2, new (a.apply(ImageData, [void 0, h.sent(), o, r]))()];
        case 2:
          return s = document.createElement("canvas"), u = s.getContext("2d"), s.width = W(t2.width), s.height = W(t2.height), u.drawImage(t2, 0, 0), [2, u.getImageData(0, 0, s.width, s.height)];
      }
    });
  });
}
function Z(t2) {
  return N(this, void 0, void 0, function() {
    var e, i;
    return D(this, function(r) {
      switch (r.label) {
        case 0:
          return t2 instanceof SVGImageElement || t2 instanceof OffscreenCanvas ? [4, G(t2)] : [3, 2];
        case 1:
          return i = r.sent(), [3, 3];
        case 2:
          i = t2, r.label = 3;
        case 3:
          return e = i, [2, browser_exports.fromPixels(e, 4)];
      }
    });
  });
}
function $(t2) {
  if (t2 < 0 || t2 >= 256)
    throw new Error("Mask value must be in range [0, 255] but got ".concat(t2));
  if (!Number.isInteger(t2))
    throw new Error("Mask value must be an integer but got ".concat(t2));
}
var J = { runtime: "mediapipe", enableSmoothing: true, enableSegmentation: false, smoothSegmentation: true, modelType: "full" };
var tt = function() {
  function t2(t3) {
    this.mask = t3;
  }
  return t2.prototype.toCanvasImageSource = function() {
    return N(this, void 0, void 0, function() {
      return D(this, function(t3) {
        return [2, this.mask];
      });
    });
  }, t2.prototype.toImageData = function() {
    return N(this, void 0, void 0, function() {
      return D(this, function(t3) {
        return [2, Q(this.mask)];
      });
    });
  }, t2.prototype.toTensor = function() {
    return N(this, void 0, void 0, function() {
      return D(this, function(t3) {
        return [2, Z(this.mask)];
      });
    });
  }, t2.prototype.getUnderlyingType = function() {
    return "canvasimagesource";
  }, t2;
}();
function et(t2) {
  return $(t2), "person";
}
var nt = function() {
  function i(e) {
    var n, i2 = this;
    switch (this.width = 0, this.height = 0, this.selfieMode = false, this.poseSolution = new import_pose.Pose({ locateFile: function(t2, n2) {
      if (e.solutionPath) {
        var i3 = e.solutionPath.replace(/\/+$/, "");
        return "".concat(i3, "/").concat(t2);
      }
      return "".concat(n2, "/").concat(t2);
    } }), e.modelType) {
      case "lite":
        n = 0;
        break;
      case "heavy":
        n = 2;
        break;
      case "full":
      default:
        n = 1;
    }
    this.poseSolution.setOptions({ modelComplexity: n, smoothLandmarks: e.enableSmoothing, enableSegmentation: e.enableSegmentation, smoothSegmentation: e.smoothSegmentation, selfieMode: this.selfieMode }), this.poseSolution.onResults(function(t2) {
      if (i2.height = t2.image.height, i2.width = t2.image.width, null == t2.poseLandmarks)
        i2.poses = [];
      else {
        var e2 = i2.translateOutput(t2.poseLandmarks, t2.poseWorldLandmarks);
        t2.segmentationMask && (e2.segmentation = { maskValueToLabel: et, mask: new tt(t2.segmentationMask) }), i2.poses = [e2];
      }
    });
  }
  return i.prototype.translateOutput = function(t2, e) {
    var n = this, i2 = { keypoints: t2.map(function(t3, e2) {
      return { x: t3.x * n.width, y: t3.y * n.height, z: t3.z, score: t3.visibility, name: j[e2] };
    }) };
    return null != e && (i2.keypoints3D = e.map(function(t3, e2) {
      return { x: t3.x, y: t3.y, z: t3.z, score: t3.visibility, name: j[e2] };
    })), i2;
  }, i.prototype.estimatePoses = function(t2, i2, r) {
    return N(this, void 0, void 0, function() {
      var o, a;
      return D(this, function(s) {
        switch (s.label) {
          case 0:
            return i2 && i2.flipHorizontal && i2.flipHorizontal !== this.selfieMode && (this.selfieMode = i2.flipHorizontal, this.poseSolution.setOptions({ selfieMode: this.selfieMode })), t2 instanceof Tensor ? (a = ImageData.bind, [4, browser_exports.toPixels(t2)]) : [3, 2];
          case 1:
            return o = new (a.apply(ImageData, [void 0, s.sent(), t2.shape[1], t2.shape[0]]))(), [3, 3];
          case 2:
            o = t2, s.label = 3;
          case 3:
            return t2 = o, [4, this.poseSolution.send({ image: t2 }, r)];
          case 4:
            return s.sent(), [2, this.poses];
        }
      });
    });
  }, i.prototype.dispose = function() {
    this.poseSolution.close();
  }, i.prototype.reset = function() {
    this.poseSolution.reset();
  }, i.prototype.initialize = function() {
    return this.poseSolution.initialize();
  }, i;
}();
function it(t2) {
  return N(this, void 0, void 0, function() {
    var e, n;
    return D(this, function(i) {
      switch (i.label) {
        case 0:
          return e = function(t3) {
            if (null == t3)
              return B({}, J);
            var e2 = B({}, t3);
            return e2.runtime = "mediapipe", null == e2.enableSegmentation && (e2.enableSegmentation = J.enableSegmentation), null == e2.enableSmoothing && (e2.enableSmoothing = J.enableSmoothing), null == e2.smoothSegmentation && (e2.smoothSegmentation = J.smoothSegmentation), null == e2.modelType && (e2.modelType = J.modelType), e2;
          }(t2), [4, (n = new nt(e)).initialize()];
        case 1:
          return i.sent(), [2, n];
      }
    });
  });
}
function rt(t2) {
  return t2 instanceof Tensor ? { height: t2.shape[0], width: t2.shape[1] } : { height: t2.height, width: t2.width };
}
function ot(t2) {
  return t2 - 2 * Math.PI * Math.floor((t2 + Math.PI) / (2 * Math.PI));
}
function at(t2) {
  return t2 instanceof Tensor ? t2 : browser_exports.fromPixels(t2);
}
function st(t2, e, n) {
  return ut(n, "inputResolution"), [1 / n.width * t2[0][0] * e.width, 1 / n.height * t2[0][1] * e.width, t2[0][3] * e.width, 1 / n.width * t2[1][0] * e.height, 1 / n.height * t2[1][1] * e.height, t2[1][3] * e.height, 0, 0];
}
function ut(t2, e) {
  util_exports.assert(0 !== t2.width, function() {
    return "".concat(e, " width cannot be 0.");
  }), util_exports.assert(0 !== t2.height, function() {
    return "".concat(e, " height cannot be 0.");
  });
}
function ht(t2, e, n) {
  var i = n.rotationVectorStartKeypointIndex, r = n.rotationVectorEndKeypointIndex, o = t2.locationData, a = o.relativeKeypoints[i].x * e.width, s = o.relativeKeypoints[i].y * e.height, u = o.relativeKeypoints[r].x * e.width, h = o.relativeKeypoints[r].y * e.height, l = 2 * Math.sqrt((u - a) * (u - a) + (h - s) * (h - s)), c = function(t3, e2, n2) {
    var i2, r2 = t3.locationData, o2 = n2.rotationVectorStartKeypointIndex, a2 = n2.rotationVectorEndKeypointIndex;
    i2 = n2.rotationVectorTargetAngle ? n2.rotationVectorTargetAngle : Math.PI * n2.rotationVectorTargetAngleDegree / 180;
    var s2 = r2.relativeKeypoints[o2].x * e2.width, u2 = r2.relativeKeypoints[o2].y * e2.height, h2 = r2.relativeKeypoints[a2].x * e2.width, l2 = r2.relativeKeypoints[a2].y * e2.height;
    return ot(i2 - Math.atan2(-(l2 - u2), h2 - s2));
  }(t2, e, n);
  return { xCenter: a / e.width, yCenter: s / e.height, width: l / e.width, height: l / e.height, rotation: c };
}
function lt(t2) {
  if (16 !== t2.length)
    throw new Error("Array length must be 16 but got ".concat(t2.length));
  return [[t2[0], t2[1], t2[2], t2[3]], [t2[4], t2[5], t2[6], t2[7]], [t2[8], t2[9], t2[10], t2[11]], [t2[12], t2[13], t2[14], t2[15]]];
}
function ct(t2, e, n, i, r, o, a) {
  return t2[e][r] * (t2[n][o] * t2[i][a] - t2[n][a] * t2[i][o]);
}
function pt(t2, e, n) {
  var i = (e + 1) % 4, r = (e + 2) % 4, o = (e + 3) % 4, a = (n + 1) % 4, s = (n + 2) % 4, u = (n + 3) % 4;
  return ct(t2, i, r, o, a, s, u) + ct(t2, r, o, i, a, s, u) + ct(t2, o, i, r, a, s, u);
}
function ft(t2, e, n) {
  void 0 === n && (n = { ignoreRotation: false });
  for (var i = [], r = 0, o = t2; r < o.length; r++) {
    var a = o[r], s = a.x - 0.5, u = a.y - 0.5, h = n.ignoreRotation ? 0 : e.rotation, l = Math.cos(h) * s - Math.sin(h) * u, c = Math.sin(h) * s + Math.cos(h) * u;
    l = l * e.width + e.xCenter, c = c * e.height + e.yCenter;
    var p = a.z * e.width, f = B({}, a);
    f.x = l, f.y = c, f.z = p, i.push(f);
  }
  return i;
}
function dt(t2, e) {
  var n = function(t3, e2, n2, i) {
    var r = e2 - t3, o = i - n2;
    if (0 === r)
      throw new Error("Original min and max are both ".concat(t3, ", range cannot be 0."));
    var a = o / r;
    return { scale: a, offset: n2 - t3 * a };
  }(0, 255, e[0], e[1]);
  return tidy(function() {
    return add(mul(t2, n.scale), n.offset);
  });
}
function mt(t2, e, n) {
  var i, o, a, c, p, f, d, m, g, y, v, x, w, k, b = e.outputTensorSize, M = e.keepAspectRatio, S = e.borderMode, T = e.outputTensorFloatRange, P = rt(t2), F = function(t3, e2) {
    return e2 ? { xCenter: e2.xCenter * t3.width, yCenter: e2.yCenter * t3.height, width: e2.width * t3.width, height: e2.height * t3.height, rotation: e2.rotation } : { xCenter: 0.5 * t3.width, yCenter: 0.5 * t3.height, width: t3.width, height: t3.height, rotation: 0 };
  }(P, n), _ = function(t3, e2, n2) {
    if (void 0 === n2 && (n2 = false), !n2)
      return { top: 0, left: 0, right: 0, bottom: 0 };
    var i2 = e2.height, r = e2.width;
    ut(e2, "targetSize"), ut(t3, "roi");
    var o2, a2, s = i2 / r, u = t3.height / t3.width, h = 0, l = 0;
    return s > u ? (o2 = t3.width, a2 = t3.width * s, l = (1 - u / s) / 2) : (o2 = t3.height / s, a2 = t3.height, h = (1 - s / u) / 2), t3.width = o2, t3.height = a2, { top: l, left: h, right: h, bottom: l };
  }(F, b, M), O = (i = F, o = P.width, a = P.height, c = false, p = i.width, f = i.height, d = c ? -1 : 1, m = Math.cos(i.rotation), g = Math.sin(i.rotation), y = i.xCenter, v = i.yCenter, x = 1 / o, w = 1 / a, (k = new Array(16))[0] = p * m * d * x, k[1] = -f * g * x, k[2] = 0, k[3] = (-0.5 * p * m * d + 0.5 * f * g + y) * x, k[4] = p * g * d * w, k[5] = f * m * w, k[6] = 0, k[7] = (-0.5 * f * m - 0.5 * p * g * d + v) * w, k[8] = 0, k[9] = 0, k[10] = p * x, k[11] = 0, k[12] = 0, k[13] = 0, k[14] = 0, k[15] = 1, lt(k));
  return { imageTensor: tidy(function() {
    var e2 = at(t2), n2 = tensor2d(st(O, P, b), [1, 8]), i2 = "zero" === S ? "constant" : "nearest", r = image.transform(expandDims(cast(e2, "float32")), n2, "bilinear", i2, 0, [b.height, b.width]);
    return null != T ? dt(r, T) : r;
  }), padding: _, transformationMatrix: O };
}
function gt(t2, e, n, i) {
  return 1 === i ? 0.5 * (t2 + e) : t2 + (e - t2) * n / (i - 1);
}
function yt(t2) {
  return tidy(function() {
    var e = function(t3) {
      return tidy(function() {
        return [slice(t3, [0, 0, 0], [1, -1, 1]), slice(t3, [0, 0, 1], [1, -1, -1])];
      });
    }(t2), n = e[0], i = e[1];
    return { boxes: squeeze(i), logits: squeeze(n) };
  });
}
function vt(t2) {
  return null != t2 && null != t2.currentTime;
}
function xt(t2) {
  for (var e = { locationData: { relativeKeypoints: [] } }, n = Number.MAX_SAFE_INTEGER, i = Number.MIN_SAFE_INTEGER, r = Number.MAX_SAFE_INTEGER, o = Number.MIN_SAFE_INTEGER, a = 0; a < t2.length; ++a) {
    var s = t2[a];
    n = Math.min(n, s.x), i = Math.max(i, s.x), r = Math.min(r, s.y), o = Math.max(o, s.y), e.locationData.relativeKeypoints.push({ x: s.x, y: s.y });
  }
  return e.locationData.relativeBoundingBox = { xMin: n, yMin: r, xMax: i, yMax: o, width: i - n, height: o - r }, e;
}
function wt(t2, e, n, i) {
  return N(this, void 0, void 0, function() {
    var i2, r, o, a, h;
    return D(this, function(l) {
      switch (l.label) {
        case 0:
          return t2.sort(function(t3, e2) {
            return Math.max.apply(Math, e2.score) - Math.max.apply(Math, t3.score);
          }), i2 = tensor2d(t2.map(function(t3) {
            return [t3.locationData.relativeBoundingBox.yMin, t3.locationData.relativeBoundingBox.xMin, t3.locationData.relativeBoundingBox.yMax, t3.locationData.relativeBoundingBox.xMax];
          })), r = tensor1d(t2.map(function(t3) {
            return t3.score[0];
          })), [4, image.nonMaxSuppressionAsync(i2, r, e, n)];
        case 1:
          return [4, (o = l.sent()).array()];
        case 2:
          return a = l.sent(), h = t2.filter(function(t3, e2) {
            return a.indexOf(e2) > -1;
          }), dispose([i2, r, o]), [2, h];
      }
    });
  });
}
function kt(t2, e) {
  return t2.map(function(t3) {
    var n = B(B({}, t3), { x: t3.x * e.width, y: t3.y * e.height });
    return null != t3.z && (n.z = t3.z * e.width), n;
  });
}
function bt(t2, e, n) {
  return N(this, void 0, void 0, function() {
    var i, r, o, a, s, u, h, l, c, f, d, m, g, y, v, x, w, k, b, M, S, T, P, F;
    return D(this, function(_) {
      switch (_.label) {
        case 0:
          if (i = squeeze(e, [0]), r = i.shape, o = r[0], a = r[1], s = r[2], t2.length !== s)
            throw new Error("Expected heatmap to have same number of channels as the number of landmarks. But got landmarks length: " + "".concat(t2.length, ", heatmap length: ").concat(s));
          return u = [], [4, i.buffer()];
        case 1:
          for (h = _.sent(), l = 0; l < t2.length; l++)
            if (c = t2[l], f = B({}, c), u.push(f), d = Math.trunc(f.x * a), m = Math.trunc(f.y * o), !(d < 0 || d >= a || m < 0 || d >= o)) {
              for (g = Math.trunc((n.kernelSize - 1) / 2), y = Math.max(0, d - g), v = Math.min(a, d + g + 1), x = Math.max(0, m - g), w = Math.min(o, m + g + 1), k = 0, b = 0, M = 0, S = 0, T = x; T < w; ++T)
                for (P = y; P < v; ++P)
                  F = h.get(T, P, l), k += F, S = Math.max(S, F), b += P * F, M += T * F;
              S >= n.minConfidenceToRefine && k > 0 && (f.x = b / a / k, f.y = M / o / k);
            }
          return i.dispose(), [2, u];
      }
    });
  });
}
function Mt(t2, e) {
  var n = e.left, i = e.top, r = e.left + e.right, o = e.top + e.bottom;
  return t2.map(function(t3) {
    return B(B({}, t3), { x: (t3.x - n) / (1 - r), y: (t3.y - i) / (1 - o), z: t3.z / (1 - r) });
  });
}
function St(t2, e, n) {
  return "webgl" === getBackend() ? function(t3, e2, n2) {
    var i = n2.combineWithPreviousRatio.toFixed(2), o = { variableNames: ["prevMask", "newMask"], outputShape: t3.shape, userCode: "\n  void main() {\n      ivec2 coords = getOutputCoords();\n      int height = coords[0];\n      int width = coords[1];\n\n      float prevMaskValue = getPrevMask(height, width);\n      float newMaskValue = getNewMask(height, width);\n\n      /*\n      * Assume p := newMaskValue\n      * H(p) := 1 + (p * log(p) + (1-p) * log(1-p)) / log(2)\n      * uncertainty alpha(p) =\n      *   Clamp(1 - (1 - H(p)) * (1 - H(p)), 0, 1) [squaring the\n      * uncertainty]\n      *\n      * The following polynomial approximates uncertainty alpha as a\n      * function of (p + 0.5):\n      */\n      const float c1 = 5.68842;\n      const float c2 = -0.748699;\n      const float c3 = -57.8051;\n      const float c4 = 291.309;\n      const float c5 = -624.717;\n      float t = newMaskValue - 0.5;\n      float x = t * t;\n\n      float uncertainty =\n        1.0 - min(1.0, x * (c1 + x * (c2 + x * (c3 + x * (c4 + x * c5)))));\n\n      float outputValue = newMaskValue + (prevMaskValue - newMaskValue) *\n                             (uncertainty * ".concat(i, ");\n\n      setOutput(outputValue);\n    }\n") }, a = backend();
    return tidy(function() {
      var n3 = a.compileAndRun(o, [t3, e2]);
      return engine().makeTensorFromDataId(n3.dataId, n3.shape, n3.dtype);
    });
  }(t2, e, n) : tidy(function() {
    var i = sub(e, 0.5), r = square(i), s = sub(1, minimum(1, mul(r, add(5.68842, mul(r, add(-0.748699, mul(r, add(-57.8051, mul(r, add(291.309, mul(r, -624.717)))))))))));
    return add(e, mul(sub(t2, e), mul(s, n.combineWithPreviousRatio)));
  });
}
function Tt(t2, e, n) {
  return N(this, void 0, void 0, function() {
    var i, s, u, h, l;
    return D(this, function(d) {
      switch (d.label) {
        case 0:
          return i = t2[0], s = t2[1], u = function(t3, e2, n2) {
            return tidy(function() {
              var i2, r, s2, u2;
              n2.reverseOutputOrder ? (r = squeeze(slice(t3, [0, n2.boxCoordOffset + 0], [-1, 1])), i2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 1], [-1, 1])), u2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 2], [-1, 1])), s2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 3], [-1, 1]))) : (i2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 0], [-1, 1])), r = squeeze(slice(t3, [0, n2.boxCoordOffset + 1], [-1, 1])), s2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 2], [-1, 1])), u2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 3], [-1, 1]))), r = add(mul(div(r, n2.xScale), e2.w), e2.x), i2 = add(mul(div(i2, n2.yScale), e2.h), e2.y), n2.applyExponentialOnBoxSize ? (s2 = mul(exp(div(s2, n2.hScale)), e2.h), u2 = mul(exp(div(u2, n2.wScale)), e2.w)) : (s2 = mul(div(s2, n2.hScale), e2.h), u2 = mul(div(u2, n2.wScale), e2.h));
              var h2 = sub(i2, div(s2, 2)), l2 = sub(r, div(u2, 2)), f = add(i2, div(s2, 2)), d2 = add(r, div(u2, 2)), m = concat([reshape(h2, [n2.numBoxes, 1]), reshape(l2, [n2.numBoxes, 1]), reshape(f, [n2.numBoxes, 1]), reshape(d2, [n2.numBoxes, 1])], 1);
              if (n2.numKeypoints)
                for (var g = 0; g < n2.numKeypoints; ++g) {
                  var v = n2.keypointCoordOffset + g * n2.numValuesPerKeypoint, x = void 0, w = void 0;
                  n2.reverseOutputOrder ? (x = squeeze(slice(t3, [0, v], [-1, 1])), w = squeeze(slice(t3, [0, v + 1], [-1, 1]))) : (w = squeeze(slice(t3, [0, v], [-1, 1])), x = squeeze(slice(t3, [0, v + 1], [-1, 1])));
                  var T = add(mul(div(x, n2.xScale), e2.w), e2.x), P = add(mul(div(w, n2.yScale), e2.h), e2.y);
                  m = concat([m, reshape(T, [n2.numBoxes, 1]), reshape(P, [n2.numBoxes, 1])], 1);
                }
              return m;
            });
          }(s, e, n), h = tidy(function() {
            var t3 = i;
            return n.sigmoidScore ? (null != n.scoreClippingThresh && (t3 = clipByValue(i, -n.scoreClippingThresh, n.scoreClippingThresh)), t3 = sigmoid(t3)) : t3;
          }), [4, Pt(u, h, n)];
        case 1:
          return l = d.sent(), dispose([u, h]), [2, l];
      }
    });
  });
}
function Pt(t2, e, n) {
  return N(this, void 0, void 0, function() {
    var i, r, o, a, s, u, h, l, c, p, f, d;
    return D(this, function(m) {
      switch (m.label) {
        case 0:
          return i = [], [4, t2.data()];
        case 1:
          return r = m.sent(), [4, e.data()];
        case 2:
          for (o = m.sent(), a = 0; a < n.numBoxes; ++a)
            if (!(null != n.minScoreThresh && o[a] < n.minScoreThresh || (s = a * n.numCoords, u = Ft(r[s + 0], r[s + 1], r[s + 2], r[s + 3], o[a], n.flipVertically, a), (h = u.locationData.relativeBoundingBox).width < 0 || h.height < 0))) {
              if (n.numKeypoints > 0)
                for ((l = u.locationData).relativeKeypoints = [], c = n.numKeypoints * n.numValuesPerKeypoint, p = 0; p < c; p += n.numValuesPerKeypoint)
                  f = s + n.keypointCoordOffset + p, d = { x: r[f + 0], y: n.flipVertically ? 1 - r[f + 1] : r[f + 1] }, l.relativeKeypoints.push(d);
              i.push(u);
            }
          return [2, i];
      }
    });
  });
}
function Ft(t2, e, n, i, r, o, a) {
  return { score: [r], ind: a, locationData: { relativeBoundingBox: { xMin: e, yMin: o ? 1 - n : t2, xMax: i, yMax: o ? 1 - t2 : n, width: i - e, height: n - t2 } } };
}
function _t(t2, e) {
  return "none" === t2 ? e : function(t3) {
    return 1 / (1 + Math.exp(-t3));
  }(e);
}
function Ot(t2, e, n, i) {
  return N(this, void 0, void 0, function() {
    var r, o, a, s, u, h, l, c;
    return D(this, function(p) {
      switch (p.label) {
        case 0:
          return n = n || e.flipHorizontally || false, i = i || e.flipVertically || false, r = t2.size, o = r / e.numLandmarks, [4, t2.data()];
        case 1:
          for (a = p.sent(), s = [], u = 0; u < e.numLandmarks; ++u)
            h = u * o, (c = { x: 0, y: 0 }).x = n ? e.inputImageWidth - a[h] : a[h], o > 1 && (c.y = i ? e.inputImageHeight - a[h + 1] : a[h + 1]), o > 2 && (c.z = a[h + 2]), o > 3 && (c.score = _t(e.visibilityActivation, a[h + 3])), s.push(c);
          for (l = 0; l < s.length; ++l)
            (c = s[l]).x = c.x / e.inputImageWidth, c.y = c.y / e.inputImageHeight, c.z = c.z / e.inputImageWidth / (e.normalizeZ || 1);
          return [2, s];
      }
    });
  });
}
function It(t2, e, n) {
  var i = t2.width, r = t2.height, o = t2.rotation;
  if (null == n.rotation && null == n.rotationDegree || (o = function(t3, e2) {
    null != e2.rotation ? t3 += e2.rotation : null != e2.rotationDegree && (t3 += Math.PI * e2.rotationDegree / 180);
    return ot(t3);
  }(o, n)), 0 === o)
    t2.xCenter = t2.xCenter + i * n.shiftX, t2.yCenter = t2.yCenter + r * n.shiftY;
  else {
    var a = (e.width * i * n.shiftX * Math.cos(o) - e.height * r * n.shiftY * Math.sin(o)) / e.width, s = (e.width * i * n.shiftX * Math.sin(o) + e.height * r * n.shiftY * Math.cos(o)) / e.height;
    t2.xCenter = t2.xCenter + a, t2.yCenter = t2.yCenter + s;
  }
  if (n.squareLong) {
    var u = Math.max(i * e.width, r * e.height);
    i = u / e.width, r = u / e.height;
  } else if (n.squareShort) {
    var h = Math.min(i * e.width, r * e.height);
    i = h / e.width, r = h / e.height;
  }
  return t2.width = i * n.scaleX, t2.height = r * n.scaleY, t2;
}
function At(t2, e) {
  return t2.map(function(t3) {
    var n = B(B({}, t3), { x: t3.x / e.width, y: t3.y / e.height });
    return null != t3.z && (t3.z = t3.z / e.width), n;
  });
}
var zt = function() {
  function t2(t3) {
    this.alpha = t3, this.initialized = false;
  }
  return t2.prototype.apply = function(t3, e) {
    var n;
    return this.initialized ? n = null == e ? this.storedValue + this.alpha * (t3 - this.storedValue) : this.storedValue + this.alpha * e * Math.asinh((t3 - this.storedValue) / e) : (n = t3, this.initialized = true), this.rawValue = t3, this.storedValue = n, n;
  }, t2.prototype.applyWithAlpha = function(t3, e, n) {
    return this.alpha = e, this.apply(t3, n);
  }, t2.prototype.hasLastRawValue = function() {
    return this.initialized;
  }, t2.prototype.lastRawValue = function() {
    return this.rawValue;
  }, t2.prototype.reset = function() {
    this.initialized = false;
  }, t2;
}();
var Ct = function() {
  function t2(t3) {
    this.frequency = t3.frequency, this.minCutOff = t3.minCutOff, this.beta = t3.beta, this.thresholdCutOff = t3.thresholdCutOff, this.thresholdBeta = t3.thresholdBeta, this.derivateCutOff = t3.derivateCutOff, this.x = new zt(this.getAlpha(this.minCutOff)), this.dx = new zt(this.getAlpha(this.derivateCutOff)), this.lastTimestamp = 0;
  }
  return t2.prototype.apply = function(t3, e, n) {
    if (null == t3)
      return t3;
    var i = Math.trunc(e);
    if (this.lastTimestamp >= i)
      return t3;
    0 !== this.lastTimestamp && 0 !== i && (this.frequency = 1 / (1e-6 * (i - this.lastTimestamp))), this.lastTimestamp = i;
    var r = this.x.hasLastRawValue() ? (t3 - this.x.lastRawValue()) * n * this.frequency : 0, o = this.dx.applyWithAlpha(r, this.getAlpha(this.derivateCutOff)), a = this.minCutOff + this.beta * Math.abs(o), s = null != this.thresholdCutOff ? this.thresholdCutOff + this.thresholdBeta * Math.abs(o) : null;
    return this.x.applyWithAlpha(t3, this.getAlpha(a), s);
  }, t2.prototype.getAlpha = function(t3) {
    return 1 / (1 + this.frequency / (2 * Math.PI * t3));
  }, t2;
}();
var Et = function() {
  function t2(t3) {
    this.config = t3;
  }
  return t2.prototype.apply = function(t3, e, n) {
    var i = this;
    if (null == t3)
      return this.reset(), null;
    this.initializeFiltersIfEmpty(t3);
    var r = 1;
    if (!this.config.disableValueScaling) {
      if (n < this.config.minAllowedObjectScale)
        return K([], t3, true);
      r = 1 / n;
    }
    return t3.map(function(t4, n2) {
      var o = B(B({}, t4), { x: i.xFilters[n2].apply(t4.x, e, r), y: i.yFilters[n2].apply(t4.y, e, r) });
      return null != t4.z && (o.z = i.zFilters[n2].apply(t4.z, e, r)), o;
    });
  }, t2.prototype.reset = function() {
    this.xFilters = null, this.yFilters = null, this.zFilters = null;
  }, t2.prototype.initializeFiltersIfEmpty = function(t3) {
    var e = this;
    null != this.xFilters && this.xFilters.length === t3.length || (this.xFilters = t3.map(function(t4) {
      return new Ct(e.config);
    }), this.yFilters = t3.map(function(t4) {
      return new Ct(e.config);
    }), this.zFilters = t3.map(function(t4) {
      return new Ct(e.config);
    }));
  }, t2;
}();
var Rt = function() {
  function t2(t3) {
    this.config = t3, this.window = [], this.lowPassFilter = new zt(1), this.lastValue = 0, this.lastValueScale = 1, this.lastTimestamp = -1;
  }
  return t2.prototype.apply = function(t3, e, n) {
    if (null == t3)
      return t3;
    var i, r = Math.trunc(e);
    if (this.lastTimestamp >= r)
      return t3;
    if (-1 === this.lastTimestamp)
      i = 1;
    else {
      for (var o = t3 * n - this.lastValue * this.lastValueScale, a = r - this.lastTimestamp, s = o, u = a, h = (1 + this.window.length) * (1e6 / 30), l = 0, c = this.window; l < c.length; l++) {
        var p = c[l];
        if (u + p.duration > h)
          break;
        s += p.distance, u += p.duration;
      }
      var f = s / (1e-6 * u);
      i = 1 - 1 / (1 + this.config.velocityScale * Math.abs(f)), this.window.unshift({ distance: o, duration: a }), this.window.length > this.config.windowSize && this.window.pop();
    }
    return this.lastValue = t3, this.lastValueScale = n, this.lastTimestamp = r, this.lowPassFilter.applyWithAlpha(t3, i);
  }, t2;
}();
var Lt = function() {
  function t2(t3) {
    this.config = t3;
  }
  return t2.prototype.apply = function(t3, e, n) {
    var i = this;
    if (null == t3)
      return this.reset(), null;
    var r = 1;
    if (!this.config.disableValueScaling) {
      if (n < this.config.minAllowedObjectScale)
        return K([], t3, true);
      r = 1 / n;
    }
    return this.initializeFiltersIfEmpty(t3), t3.map(function(t4, n2) {
      var o = B(B({}, t4), { x: i.xFilters[n2].apply(t4.x, e, r), y: i.yFilters[n2].apply(t4.y, e, r) });
      return null != t4.z && (o.z = i.zFilters[n2].apply(t4.z, e, r)), o;
    });
  }, t2.prototype.reset = function() {
    this.xFilters = null, this.yFilters = null, this.zFilters = null;
  }, t2.prototype.initializeFiltersIfEmpty = function(t3) {
    var e = this;
    null != this.xFilters && this.xFilters.length === t3.length || (this.xFilters = t3.map(function(t4) {
      return new Rt(e.config);
    }), this.yFilters = t3.map(function(t4) {
      return new Rt(e.config);
    }), this.zFilters = t3.map(function(t4) {
      return new Rt(e.config);
    }));
  }, t2;
}();
var Vt = function() {
  function t2(t3) {
    if (null != t3.velocityFilter)
      this.keypointsFilter = new Lt(t3.velocityFilter);
    else {
      if (null == t3.oneEuroFilter)
        throw new Error("Either configure velocityFilter or oneEuroFilter, but got " + "".concat(t3, "."));
      this.keypointsFilter = new Et(t3.oneEuroFilter);
    }
  }
  return t2.prototype.apply = function(t3, e, n, i, r) {
    if (void 0 === i && (i = false), null == t3)
      return this.keypointsFilter.reset(), null;
    var o = null != r ? function(t4, e2) {
      return (t4.width * e2.width + t4.height * e2.height) / 2;
    }(r, n) : 1, a = i ? kt(t3, n) : t3, s = this.keypointsFilter.apply(a, e, o);
    return i ? At(s, n) : s;
  }, t2;
}();
var Bt = function() {
  function t2(t3) {
    this.alpha = t3.alpha;
  }
  return t2.prototype.apply = function(t3) {
    var e = this;
    if (null == t3)
      return this.visibilityFilters = null, null;
    null != this.visibilityFilters && this.visibilityFilters.length === t3.length || (this.visibilityFilters = t3.map(function(t4) {
      return new zt(e.alpha);
    }));
    for (var n = [], i = 0; i < t3.length; ++i) {
      var r = t3[i], o = B({}, r);
      o.score = this.visibilityFilters[i].apply(r.score), n.push(o);
    }
    return n;
  }, t2;
}();
var Nt = { reduceBoxesInLowestlayer: false, interpolatedScaleAspectRatio: 1, featureMapHeight: [], featureMapWidth: [], numLayers: 5, minScale: 0.1484375, maxScale: 0.75, inputSizeHeight: 224, inputSizeWidth: 224, anchorOffsetX: 0.5, anchorOffsetY: 0.5, strides: [8, 16, 32, 32, 32], aspectRatios: [1], fixedAnchorSize: true };
var Dt = { runtime: "tfjs", modelType: "full", enableSmoothing: true, enableSegmentation: false, smoothSegmentation: true, detectorModelUrl: "https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/detector/1", landmarkModelUrl: "https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/full/2" };
var Kt = { maxPoses: 1, flipHorizontal: false };
var Ut = { applyExponentialOnBoxSize: false, flipVertically: false, ignoreClasses: [], numClasses: 1, numBoxes: 2254, numCoords: 12, boxCoordOffset: 0, keypointCoordOffset: 4, numKeypoints: 4, numValuesPerKeypoint: 2, sigmoidScore: true, scoreClippingThresh: 100, reverseOutputOrder: true, xScale: 224, yScale: 224, hScale: 224, wScale: 224, minScoreThresh: 0.5 };
var jt = 0.3;
var Ht = { shiftX: 0, shiftY: 0, scaleX: 1.25, scaleY: 1.25, squareLong: true };
var qt = { outputTensorSize: { width: 224, height: 224 }, keepAspectRatio: true, outputTensorFloatRange: [-1, 1], borderMode: "zero" };
var Xt = { outputTensorSize: { width: 256, height: 256 }, keepAspectRatio: true, outputTensorFloatRange: [0, 1], borderMode: "zero" };
var Yt = { numLandmarks: 39, inputImageWidth: 256, inputImageHeight: 256, visibilityActivation: "sigmoid", flipHorizontally: false, flipVertically: false };
var Wt = { numLandmarks: 39, inputImageWidth: 1, inputImageHeight: 1, visibilityActivation: "sigmoid", flipHorizontally: false, flipVertically: false };
var Gt = { kernelSize: 7, minConfidenceToRefine: 0.5 };
var Qt = { alpha: 0.1 };
var Zt = { oneEuroFilter: { frequency: 30, minCutOff: 0.05, beta: 80, derivateCutOff: 1, minAllowedObjectScale: 1e-6 } };
var $t = { oneEuroFilter: { frequency: 30, minCutOff: 0.01, beta: 10, derivateCutOff: 1, minAllowedObjectScale: 1e-6 } };
var Jt = { oneEuroFilter: { frequency: 30, minCutOff: 0.1, beta: 40, derivateCutOff: 1, minAllowedObjectScale: 1e-6, disableValueScaling: true } };
var te = { activation: "none" };
var ee = { combineWithPreviousRatio: 0.7 };
var ne = function() {
  function t2(t3) {
    this.mask = t3;
  }
  return t2.prototype.toCanvasImageSource = function() {
    return N(this, void 0, void 0, function() {
      return D(this, function(t3) {
        return [2, G(this.mask)];
      });
    });
  }, t2.prototype.toImageData = function() {
    return N(this, void 0, void 0, function() {
      return D(this, function(t3) {
        return [2, Q(this.mask)];
      });
    });
  }, t2.prototype.toTensor = function() {
    return N(this, void 0, void 0, function() {
      return D(this, function(t3) {
        return [2, this.mask];
      });
    });
  }, t2.prototype.getUnderlyingType = function() {
    return "tensor";
  }, t2;
}();
function ie(t2) {
  return $(t2), "person";
}
var re = function() {
  function t2(t3, e, n, i, r, o) {
    this.detectorModel = t3, this.landmarkModel = e, this.enableSmoothing = n, this.enableSegmentation = i, this.smoothSegmentation = r, this.modelType = o, this.regionOfInterest = null, this.prevFilteredSegmentationMask = null, this.anchors = function(t4) {
      null == t4.reduceBoxesInLowestLayer && (t4.reduceBoxesInLowestLayer = false), null == t4.interpolatedScaleAspectRatio && (t4.interpolatedScaleAspectRatio = 1), null == t4.fixedAnchorSize && (t4.fixedAnchorSize = false);
      for (var e2 = [], n2 = 0; n2 < t4.numLayers; ) {
        for (var i2 = [], r2 = [], o2 = [], a2 = [], s = n2; s < t4.strides.length && t4.strides[s] === t4.strides[n2]; ) {
          var u2 = gt(t4.minScale, t4.maxScale, s, t4.strides.length);
          if (0 === s && t4.reduceBoxesInLowestLayer)
            o2.push(1), o2.push(2), o2.push(0.5), a2.push(0.1), a2.push(u2), a2.push(u2);
          else {
            for (var h2 = 0; h2 < t4.aspectRatios.length; ++h2)
              o2.push(t4.aspectRatios[h2]), a2.push(u2);
            if (t4.interpolatedScaleAspectRatio > 0) {
              var l2 = s === t4.strides.length - 1 ? 1 : gt(t4.minScale, t4.maxScale, s + 1, t4.strides.length);
              a2.push(Math.sqrt(u2 * l2)), o2.push(t4.interpolatedScaleAspectRatio);
            }
          }
          s++;
        }
        for (var c = 0; c < o2.length; ++c) {
          var p = Math.sqrt(o2[c]);
          i2.push(a2[c] / p), r2.push(a2[c] * p);
        }
        var f = 0, d = 0;
        if (t4.featureMapHeight.length > 0)
          f = t4.featureMapHeight[n2], d = t4.featureMapWidth[n2];
        else {
          var m = t4.strides[n2];
          f = Math.ceil(t4.inputSizeHeight / m), d = Math.ceil(t4.inputSizeWidth / m);
        }
        for (var g = 0; g < f; ++g)
          for (var y = 0; y < d; ++y)
            for (var v = 0; v < i2.length; ++v) {
              var x = { xCenter: (y + t4.anchorOffsetX) / d, yCenter: (g + t4.anchorOffsetY) / f, width: 0, height: 0 };
              t4.fixedAnchorSize ? (x.width = 1, x.height = 1) : (x.width = r2[v], x.height = i2[v]), e2.push(x);
            }
        n2 = s;
      }
      return e2;
    }(Nt);
    var a = tensor1d(this.anchors.map(function(t4) {
      return t4.width;
    })), u = tensor1d(this.anchors.map(function(t4) {
      return t4.height;
    })), h = tensor1d(this.anchors.map(function(t4) {
      return t4.xCenter;
    })), l = tensor1d(this.anchors.map(function(t4) {
      return t4.yCenter;
    }));
    this.anchorTensor = { x: h, y: l, w: a, h: u }, this.prevFilteredSegmentationMask = this.enableSegmentation ? tensor2d([], [0, 0]) : null;
  }
  return t2.prototype.estimatePoses = function(t3, e, n) {
    return N(this, void 0, void 0, function() {
      var i, o, a, s, u, c, p, d, m, g, y, v, x, w, k, b, M, S, T, P, O, I, A;
      return D(this, function(z) {
        switch (z.label) {
          case 0:
            return i = function(t4) {
              var e2;
              if (null == (e2 = null == t4 ? Kt : B({}, t4)).maxPoses && (e2.maxPoses = 1), e2.maxPoses <= 0)
                throw new Error("Invalid maxPoses ".concat(e2.maxPoses, ". Should be > 0."));
              if (e2.maxPoses > 1)
                throw new Error("Multi-pose detection is not implemented yet. Please set maxPoses to 1.");
              return e2;
            }(e), null == t3 ? (this.reset(), [2, []]) : (this.maxPoses = i.maxPoses, this.timestamp = null != n ? 1e3 * n : vt(t3) ? 1e6 * t3.currentTime : null, o = rt(t3), a = tidy(function() {
              return cast(at(t3), "float32");
            }), null != (s = this.regionOfInterest) ? [3, 2] : [4, this.detectPose(a)]);
          case 1:
            if (0 === (u = z.sent()).length)
              return this.reset(), a.dispose(), [2, []];
            c = u[0], s = this.poseDetectionToRoi(c, o), z.label = 2;
          case 2:
            return [4, this.poseLandmarksByRoi(s, a)];
          case 3:
            return p = z.sent(), a.dispose(), null == p ? (this.reset(), [2, []]) : (d = p.landmarks, m = p.auxiliaryLandmarks, g = p.poseScore, y = p.worldLandmarks, v = p.segmentationMask, x = this.poseLandmarkFiltering(d, m, y, o), w = x.actualLandmarksFiltered, k = x.auxiliaryLandmarksFiltered, b = x.actualWorldLandmarksFiltered, M = this.poseLandmarksToRoi(k, o), this.regionOfInterest = M, S = this.smoothSegmentation && null != v ? this.poseSegmentationFiltering(v) : v, null != (T = null != w ? kt(w, o) : null) && T.forEach(function(t4, e2) {
              t4.name = j[e2];
            }), null != (P = b) && P.forEach(function(t4, e2) {
              t4.name = j[e2];
            }), O = { score: g, keypoints: T, keypoints3D: P }, null !== S && (I = tidy(function() {
              var t4 = expandDims(S, 2), e2 = pad(t4, [[0, 0], [0, 0], [0, 1]]);
              return mirrorPad(e2, [[0, 0], [0, 0], [0, 2]], "symmetric");
            }), this.smoothSegmentation || dispose(S), A = { maskValueToLabel: ie, mask: new ne(I) }, O.segmentation = A), [2, [O]]);
        }
      });
    });
  }, t2.prototype.poseSegmentationFiltering = function(t3) {
    var e = this.prevFilteredSegmentationMask;
    return 0 === e.size ? this.prevFilteredSegmentationMask = t3 : (this.prevFilteredSegmentationMask = St(e, t3, ee), dispose(t3)), dispose(e), this.prevFilteredSegmentationMask;
  }, t2.prototype.dispose = function() {
    this.detectorModel.dispose(), this.landmarkModel.dispose(), dispose([this.anchorTensor.x, this.anchorTensor.y, this.anchorTensor.w, this.anchorTensor.h, this.prevFilteredSegmentationMask]);
  }, t2.prototype.reset = function() {
    this.regionOfInterest = null, this.enableSegmentation && (dispose(this.prevFilteredSegmentationMask), this.prevFilteredSegmentationMask = tensor2d([], [0, 0])), this.visibilitySmoothingFilterActual = null, this.visibilitySmoothingFilterAuxiliary = null, this.landmarksSmoothingFilterActual = null, this.landmarksSmoothingFilterAuxiliary = null;
  }, t2.prototype.detectPose = function(t3) {
    return N(this, void 0, void 0, function() {
      var e, n, i, r, o, a, s, u, h, l;
      return D(this, function(c) {
        switch (c.label) {
          case 0:
            return e = mt(t3, qt), n = e.imageTensor, i = e.padding, r = this.detectorModel.predict(n), o = yt(r), a = o.boxes, [4, Tt([s = o.logits, a], this.anchorTensor, Ut)];
          case 1:
            return 0 === (u = c.sent()).length ? (dispose([n, r, s, a]), [2, u]) : [4, wt(u, this.maxPoses, jt)];
          case 2:
            return h = c.sent(), l = function(t4, e2) {
              void 0 === t4 && (t4 = []);
              for (var n2 = e2.left, i2 = e2.top, r2 = e2.left + e2.right, o2 = e2.top + e2.bottom, a2 = 0; a2 < t4.length; a2++) {
                var s2 = t4[a2], u2 = s2.locationData.relativeBoundingBox, h2 = (u2.xMin - n2) / (1 - r2), l2 = (u2.yMin - i2) / (1 - o2), c2 = u2.width / (1 - r2), p = u2.height / (1 - o2);
                u2.xMin = h2, u2.yMin = l2, u2.width = c2, u2.height = p, u2.xMax = h2 + c2, u2.yMax = l2 + p;
                var f = s2.locationData.relativeKeypoints;
                f && f.forEach(function(t5) {
                  var e3 = (t5.x - n2) / (1 - r2), a3 = (t5.y - i2) / (1 - o2);
                  t5.x = e3, t5.y = a3;
                });
              }
              return t4;
            }(h, i), dispose([n, r, s, a]), [2, l];
        }
      });
    });
  }, t2.prototype.poseDetectionToRoi = function(t3, e) {
    return 0, 1, It(ht(t3, e, { rotationVectorEndKeypointIndex: 1, rotationVectorStartKeypointIndex: 0, rotationVectorTargetAngleDegree: 90 }), e, Ht);
  }, t2.prototype.poseLandmarksByRoi = function(t3, e) {
    return N(this, void 0, void 0, function() {
      var n, i, r, o, a, s, u, h, l, c, p, d, m, g;
      return D(this, function(y) {
        switch (y.label) {
          case 0:
            if (n = rt(e), i = mt(e, Xt, t3), r = i.imageTensor, o = i.padding, a = i.transformationMatrix, "lite" !== this.modelType && "full" !== this.modelType && "heavy" !== this.modelType)
              throw new Error("Model type must be one of lite, full or heavy," + "but got ".concat(this.modelType));
            return s = ["ld_3d", "output_poseflag", "activation_heatmap", "world_3d"], this.enableSegmentation && s.push("activation_segmentation"), u = this.landmarkModel.execute(r, s), [4, this.tensorsToPoseLandmarksAndSegmentation(u)];
          case 1:
            return null == (h = y.sent()) ? (dispose(u), dispose(r), [2, null]) : (l = h.landmarks, c = h.auxiliaryLandmarks, p = h.poseScore, d = h.worldLandmarks, m = h.segmentationMask, [4, this.poseLandmarksAndSegmentationInverseProjection(n, t3, o, a, l, c, d, m)]);
          case 2:
            return g = y.sent(), dispose(u), dispose(r), [2, B({ poseScore: p }, g)];
        }
      });
    });
  }, t2.prototype.poseLandmarksAndSegmentationInverseProjection = function(t3, e, n, i, o, a, h, l) {
    return N(this, void 0, void 0, function() {
      var c, d, m, g, y, v;
      return D(this, function(x) {
        return c = Mt(o, n), d = Mt(a, n), m = ft(c, e), g = ft(d, e), y = function(t4, e2) {
          for (var n2 = [], i2 = 0, r = t4; i2 < r.length; i2++) {
            var o2 = r[i2], a2 = o2.x, s = o2.y, u = e2.rotation, h2 = Math.cos(u) * a2 - Math.sin(u) * s, l2 = Math.sin(u) * a2 + Math.cos(u) * s, c2 = B({}, o2);
            c2.x = h2, c2.y = l2, n2.push(c2);
          }
          return n2;
        }(h, e), v = null, this.enableSegmentation && (v = tidy(function() {
          var e2 = l.shape, n2 = e2[0], r = e2[1], o2 = function(t4) {
            var e3 = lt(new Array(16).fill(0));
            e3[0][0] = pt(t4, 0, 0), e3[1][0] = -pt(t4, 0, 1), e3[2][0] = pt(t4, 0, 2), e3[3][0] = -pt(t4, 0, 3), e3[0][2] = pt(t4, 2, 0), e3[1][2] = -pt(t4, 2, 1), e3[2][2] = pt(t4, 2, 2), e3[3][2] = -pt(t4, 2, 3), e3[0][1] = -pt(t4, 1, 0), e3[1][1] = pt(t4, 1, 1), e3[2][1] = -pt(t4, 1, 2), e3[3][1] = pt(t4, 1, 3), e3[0][3] = -pt(t4, 3, 0), e3[1][3] = pt(t4, 3, 1), e3[2][3] = -pt(t4, 3, 2), e3[3][3] = pt(t4, 3, 3);
            for (var n3 = t4[0][0] * e3[0][0] + t4[1][0] * e3[0][1] + t4[2][0] * e3[0][2] + t4[3][0] * e3[0][3], i2 = 0; i2 < e3.length; i2++)
              for (var r2 = 0; r2 < e3.length; r2++)
                e3[i2][r2] /= n3;
            return e3;
          }(i), a2 = tensor2d(st(o2, { width: r, height: n2 }, t3), [1, 8]), h2 = [1, n2, r, 1];
          return squeeze(image.transform(reshape(l, h2), a2, "bilinear", "constant", 0, [t3.height, t3.width]), [0, 3]);
        }), dispose(l)), [2, { landmarks: m, auxiliaryLandmarks: g, worldLandmarks: y, segmentationMask: v }];
      });
    });
  }, t2.prototype.tensorsToPoseLandmarksAndSegmentation = function(t3) {
    return N(this, void 0, void 0, function() {
      var e, n, i, o, a, s, h, l, c, f, d, m, g;
      return D(this, function(y) {
        switch (y.label) {
          case 0:
            return e = t3[0], n = t3[1], i = t3[2], o = t3[3], a = this.enableSegmentation ? t3[4] : null, [4, n.data()];
          case 1:
            return (s = y.sent()[0]) < 0.5 ? [2, null] : [4, Ot(e, Yt)];
          case 2:
            return [4, bt(y.sent(), i, Gt)];
          case 3:
            return h = y.sent(), l = h.slice(0, 33), c = h.slice(33, 35), [4, Ot(o, Wt)];
          case 4:
            return f = y.sent(), d = f.slice(0, 33), m = function(t4, e2, n2) {
              void 0 === n2 && (n2 = true);
              for (var i2 = [], r = 0; r < t4.length; r++) {
                var o2 = B({}, e2[r]);
                n2 && (o2.score = t4[r].score), i2.push(o2);
              }
              return i2;
            }(l, d, true), g = this.enableSegmentation ? function(t4, e2, n2) {
              return tidy(function() {
                var i2 = squeeze(t4, [0]), r = i2.shape[2];
                if (1 === r) {
                  var o2 = i2;
                  switch (e2.activation) {
                    case "none":
                      break;
                    case "sigmoid":
                      o2 = sigmoid(o2);
                      break;
                    case "softmax":
                      throw new Error("Softmax activation requires two channels.");
                    default:
                      throw new Error("Activation not supported (".concat(e2.activation, ")"));
                  }
                  var a2 = n2 ? image.resizeBilinear(o2, [n2.height, n2.width]) : o2;
                  return squeeze(a2, [2]);
                }
                throw new Error("Unsupported number of tensor channels ".concat(r));
              });
            }(a, te) : null, [2, { landmarks: l, auxiliaryLandmarks: c, poseScore: s, worldLandmarks: m, segmentationMask: g }];
        }
      });
    });
  }, t2.prototype.poseLandmarksToRoi = function(t3, e) {
    return It(ht(xt(t3), e, { rotationVectorStartKeypointIndex: 0, rotationVectorEndKeypointIndex: 1, rotationVectorTargetAngleDegree: 90 }), e, Ht);
  }, t2.prototype.poseLandmarkFiltering = function(t3, e, n, i) {
    var r, o, a;
    if (null != this.timestamp && this.enableSmoothing) {
      var s = ht(xt(e), i, { rotationVectorEndKeypointIndex: 0, rotationVectorStartKeypointIndex: 1, rotationVectorTargetAngleDegree: 90 });
      null == this.visibilitySmoothingFilterActual && (this.visibilitySmoothingFilterActual = new Bt(Qt)), r = this.visibilitySmoothingFilterActual.apply(t3), null == this.visibilitySmoothingFilterAuxiliary && (this.visibilitySmoothingFilterAuxiliary = new Bt(Qt)), o = this.visibilitySmoothingFilterAuxiliary.apply(e), a = this.visibilitySmoothingFilterActual.apply(n), null == this.landmarksSmoothingFilterActual && (this.landmarksSmoothingFilterActual = new Vt(Zt)), r = this.landmarksSmoothingFilterActual.apply(r, this.timestamp, i, true, s), null == this.landmarksSmoothingFilterAuxiliary && (this.landmarksSmoothingFilterAuxiliary = new Vt($t)), o = this.landmarksSmoothingFilterAuxiliary.apply(o, this.timestamp, i, true, s), null == this.worldLandmarksSmoothingFilterActual && (this.worldLandmarksSmoothingFilterActual = new Vt(Jt)), a = this.worldLandmarksSmoothingFilterActual.apply(n, this.timestamp);
    } else
      r = t3, o = e, a = n;
    return { actualLandmarksFiltered: r, auxiliaryLandmarksFiltered: o, actualWorldLandmarksFiltered: a };
  }, t2;
}();
function oe(t2) {
  return N(this, void 0, void 0, function() {
    var e, n, i, r, o, a;
    return D(this, function(s) {
      switch (s.label) {
        case 0:
          return e = function(t3) {
            var e2 = B({}, null == t3 ? Dt : t3);
            if (null == e2.enableSmoothing && (e2.enableSmoothing = Dt.enableSmoothing), null == e2.enableSegmentation && (e2.enableSegmentation = Dt.enableSegmentation), null == e2.smoothSegmentation && (e2.smoothSegmentation = Dt.smoothSegmentation), null == e2.modelType && (e2.modelType = Dt.modelType), null == e2.detectorModelUrl && (e2.detectorModelUrl = Dt.detectorModelUrl), null == e2.landmarkModelUrl)
              switch (e2.modelType) {
                case "lite":
                  e2.landmarkModelUrl = "https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/lite/2";
                  break;
                case "heavy":
                  e2.landmarkModelUrl = "https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/heavy/2";
                  break;
                case "full":
                default:
                  e2.landmarkModelUrl = "https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/full/2";
              }
            return e2;
          }(t2), n = "string" == typeof e.detectorModelUrl && e.detectorModelUrl.indexOf("https://tfhub.dev") > -1, i = "string" == typeof e.landmarkModelUrl && e.landmarkModelUrl.indexOf("https://tfhub.dev") > -1, [4, Promise.all([loadGraphModel(e.detectorModelUrl, { fromTFHub: n }), loadGraphModel(e.landmarkModelUrl, { fromTFHub: i })])];
        case 1:
          return r = s.sent(), o = r[0], a = r[1], [2, new re(o, a, e.enableSmoothing, e.enableSegmentation, e.smoothSegmentation, e.modelType)];
      }
    });
  });
}
var ae;
var se;
var ue = function() {
  function t2(t3) {
    !function(t4) {
      if (t4.maxTracks < 1)
        throw new Error("Must specify 'maxTracks' to be at least 1, but " + "encountered ".concat(t4.maxTracks));
      if (t4.maxAge <= 0)
        throw new Error("Must specify 'maxAge' to be positive, but " + "encountered ".concat(t4.maxAge));
      if (void 0 !== t4.keypointTrackerParams) {
        if (t4.keypointTrackerParams.keypointConfidenceThreshold < 0 || t4.keypointTrackerParams.keypointConfidenceThreshold > 1)
          throw new Error("Must specify 'keypointConfidenceThreshold' to be in the range [0, 1], but encountered " + "".concat(t4.keypointTrackerParams.keypointConfidenceThreshold));
        if (t4.keypointTrackerParams.minNumberOfKeypoints < 1)
          throw new Error("Must specify 'minNumberOfKeypoints' to be at least 1, but " + "encountered ".concat(t4.keypointTrackerParams.minNumberOfKeypoints));
        for (var e = 0, n = t4.keypointTrackerParams.keypointFalloff; e < n.length; e++) {
          var i = n[e];
          if (i <= 0)
            throw new Error("Must specify each keypoint falloff parameterto be positive " + "but encountered ".concat(i));
        }
      }
    }(t3), this.tracks = [], this.maxTracks = t3.maxTracks, this.maxAge = 1e3 * t3.maxAge, this.minSimilarity = t3.minSimilarity, this.nextID = 1;
  }
  return t2.prototype.apply = function(t3, e) {
    this.filterOldTracks(e);
    var n = this.computeSimilarity(t3);
    return this.assignTracks(t3, n, e), this.updateTracks(e), t3;
  }, t2.prototype.getTracks = function() {
    return this.tracks.slice();
  }, t2.prototype.getTrackIDs = function() {
    return new Set(this.tracks.map(function(t3) {
      return t3.id;
    }));
  }, t2.prototype.filterOldTracks = function(t3) {
    var e = this;
    this.tracks = this.tracks.filter(function(n) {
      return t3 - n.lastTimestamp <= e.maxAge;
    });
  }, t2.prototype.assignTracks = function(t3, e, n) {
    for (var i = Array.from(Array(e[0].length).keys()), r = [], o = 0, a = Array.from(Array(t3.length).keys()); o < a.length; o++) {
      var s = a[o];
      if (0 !== i.length) {
        for (var u = -1, h = -1, l = 0, c = i; l < c.length; l++) {
          var p = c[l], f = e[s][p];
          f >= this.minSimilarity && f > h && (u = p, h = f);
        }
        if (u >= 0) {
          var d = this.tracks[u];
          d = Object.assign(d, this.createTrack(t3[s], n, d.id)), t3[s].id = d.id;
          var m = i.indexOf(u);
          i.splice(m, 1);
        } else
          r.push(s);
      } else
        r.push(s);
    }
    for (var g = 0, y = r; g < y.length; g++) {
      s = y[g];
      var v = this.createTrack(t3[s], n);
      this.tracks.push(v), t3[s].id = v.id;
    }
  }, t2.prototype.updateTracks = function(t3) {
    this.tracks.sort(function(t4, e) {
      return e.lastTimestamp - t4.lastTimestamp;
    }), this.tracks = this.tracks.slice(0, this.maxTracks);
  }, t2.prototype.createTrack = function(t3, e, n) {
    var i = { id: n || this.nextTrackID(), lastTimestamp: e, keypoints: K([], t3.keypoints, true).map(function(t4) {
      return B({}, t4);
    }) };
    return void 0 !== t3.box && (i.box = B({}, t3.box)), i;
  }, t2.prototype.nextTrackID = function() {
    var t3 = this.nextID;
    return this.nextID += 1, t3;
  }, t2.prototype.remove = function() {
    for (var t3 = [], e = 0; e < arguments.length; e++)
      t3[e] = arguments[e];
    this.tracks = this.tracks.filter(function(e2) {
      return !t3.includes(e2.id);
    });
  }, t2.prototype.reset = function() {
    this.tracks = [];
  }, t2;
}();
var he = function(t2) {
  function e(e2) {
    return t2.call(this, e2) || this;
  }
  return V(e, t2), e.prototype.computeSimilarity = function(t3) {
    var e2 = this;
    return 0 === t3.length || 0 === this.tracks.length ? [[]] : t3.map(function(t4) {
      return e2.tracks.map(function(n) {
        return e2.iou(t4, n);
      });
    });
  }, e.prototype.iou = function(t3, e2) {
    var n = Math.max(t3.box.xMin, e2.box.xMin), i = Math.max(t3.box.yMin, e2.box.yMin), r = Math.min(t3.box.xMax, e2.box.xMax), o = Math.min(t3.box.yMax, e2.box.yMax);
    if (n >= r || i >= o)
      return 0;
    var a = (r - n) * (o - i);
    return a / (t3.box.width * t3.box.height + e2.box.width * e2.box.height - a);
  }, e;
}(ue);
var le = function(t2) {
  function e(e2) {
    var n = t2.call(this, e2) || this;
    return n.keypointThreshold = e2.keypointTrackerParams.keypointConfidenceThreshold, n.keypointFalloff = e2.keypointTrackerParams.keypointFalloff, n.minNumKeyoints = e2.keypointTrackerParams.minNumberOfKeypoints, n;
  }
  return V(e, t2), e.prototype.computeSimilarity = function(t3) {
    if (0 === t3.length || 0 === this.tracks.length)
      return [[]];
    for (var e2 = [], n = 0, i = t3; n < i.length; n++) {
      for (var r = i[n], o = [], a = 0, s = this.tracks; a < s.length; a++) {
        var u = s[a];
        o.push(this.oks(r, u));
      }
      e2.push(o);
    }
    return e2;
  }, e.prototype.oks = function(t3, e2) {
    for (var n = this.area(e2.keypoints) + 1e-6, i = 0, r = 0, o = 0; o < t3.keypoints.length; ++o) {
      var a = t3.keypoints[o], s = e2.keypoints[o];
      if (!(a.score < this.keypointThreshold || s.score < this.keypointThreshold)) {
        r += 1;
        var u = Math.pow(a.x - s.x, 2) + Math.pow(a.y - s.y, 2), h = 2 * this.keypointFalloff[o];
        i += Math.exp(-1 * u / (2 * n * Math.pow(h, 2)));
      }
    }
    return r < this.minNumKeyoints ? 0 : i / r;
  }, e.prototype.area = function(t3) {
    var e2 = this, n = t3.filter(function(t4) {
      return t4.score > e2.keypointThreshold;
    }), i = Math.min.apply(Math, K([1], n.map(function(t4) {
      return t4.x;
    }), false)), r = Math.max.apply(Math, K([0], n.map(function(t4) {
      return t4.x;
    }), false)), o = Math.min.apply(Math, K([1], n.map(function(t4) {
      return t4.y;
    }), false));
    return (r - i) * (Math.max.apply(Math, K([0], n.map(function(t4) {
      return t4.y;
    }), false)) - o);
  }, e;
}(ue);
function ce(t2) {
  switch (t2) {
    case se.BlazePose:
      return j.reduce(function(t3, e, n) {
        return t3[e] = n, t3;
      }, {});
    case se.PoseNet:
    case se.MoveNet:
      return U.reduce(function(t3, e, n) {
        return t3[e] = n, t3;
      }, {});
    default:
      throw new Error("Model ".concat(t2, " is not supported."));
  }
}
!function(t2) {
  t2.Keypoint = "keypoint", t2.BoundingBox = "boundingBox";
}(ae || (ae = {})), function(t2) {
  t2.MoveNet = "MoveNet", t2.BlazePose = "BlazePose", t2.PoseNet = "PoseNet";
}(se || (se = {}));
var pe = Object.freeze({ __proto__: null, getKeypointIndexBySide: function(t2) {
  switch (t2) {
    case se.BlazePose:
      return H;
    case se.PoseNet:
    case se.MoveNet:
      return q;
    default:
      throw new Error("Model ".concat(t2, " is not supported."));
  }
}, getAdjacentPairs: function(t2) {
  switch (t2) {
    case se.BlazePose:
      return Y;
    case se.PoseNet:
    case se.MoveNet:
      return X;
    default:
      throw new Error("Model ".concat(t2, " is not supported."));
  }
}, getKeypointIndexByName: ce });
var fe = ["SinglePose.Lightning", "SinglePose.Thunder", "MultiPose.Lightning"];
var de = { modelType: "SinglePose.Lightning", enableSmoothing: true };
var me = {};
var ge = { frequency: 30, minCutOff: 2.5, beta: 300, derivateCutOff: 2.5, thresholdCutOff: 0.5, thresholdBeta: 5, disableValueScaling: true };
var ye = { maxTracks: 18, maxAge: 1e3, minSimilarity: 0.2, keypointTrackerParams: { keypointConfidenceThreshold: 0.3, keypointFalloff: [0.026, 0.025, 0.025, 0.035, 0.035, 0.079, 0.079, 0.072, 0.072, 0.062, 0.062, 0.107, 0.107, 0.087, 0.087, 0.089, 0.089], minNumberOfKeypoints: 4 } };
var ve = { maxTracks: 18, maxAge: 1e3, minSimilarity: 0.15, trackerParams: {} };
function xe(t2, e, n, i) {
  for (var r = {}, o = 0, a = U; o < a.length; o++) {
    var s = a[o];
    r[s] = [e[n[s]].y * i.height, e[n[s]].x * i.width];
  }
  if (function(t3, e2) {
    return (t3[e2.left_hip].score > 0.2 || t3[e2.right_hip].score > 0.2) && (t3[e2.left_shoulder].score > 0.2 || t3[e2.right_shoulder].score > 0.2);
  }(e, n)) {
    var u = (r.left_hip[0] + r.right_hip[0]) / 2, h = (r.left_hip[1] + r.right_hip[1]) / 2, l = function(t3, e2, n2, i2, r2) {
      for (var o2 = ["left_shoulder", "right_shoulder", "left_hip", "right_hip"], a2 = 0, s2 = 0, u2 = 0; u2 < o2.length; u2++) {
        (f2 = Math.abs(i2 - n2[o2[u2]][0])) > a2 && (a2 = f2), (d2 = Math.abs(r2 - n2[o2[u2]][1])) > s2 && (s2 = d2);
      }
      for (var h2 = 0, l2 = 0, c2 = 0, p2 = Object.keys(n2); c2 < p2.length; c2++) {
        var f2, d2, m2 = p2[c2];
        if (!(t3[e2[m2]].score < 0.2))
          (f2 = Math.abs(i2 - n2[m2][0])) > h2 && (h2 = f2), (d2 = Math.abs(r2 - n2[m2][1])) > l2 && (l2 = d2);
      }
      return [a2, s2, h2, l2];
    }(e, n, r, u, h), c = l[0], p = l[1], f = l[2], d = l[3], m = Math.max(1.9 * p, 1.9 * c, 1.2 * f, 1.2 * d), g = [u - (m = Math.min(m, Math.max(h, i.width - h, u, i.height - u))), h - m];
    if (m > Math.max(i.width, i.height) / 2)
      return we(null == t2, i);
    var y = 2 * m;
    return { yMin: g[0] / i.height, xMin: g[1] / i.width, yMax: (g[0] + y) / i.height, xMax: (g[1] + y) / i.width, height: (g[0] + y) / i.height - g[0] / i.height, width: (g[1] + y) / i.width - g[1] / i.width };
  }
  return we(null == t2, i);
}
function we(t2, e) {
  var n, i, r, o;
  return t2 ? e.width > e.height ? (n = 1, i = e.height / e.width, r = 0, o = (e.width / 2 - e.height / 2) / e.width) : (n = e.width / e.height, i = 1, r = (e.height / 2 - e.width / 2) / e.height, o = 0) : e.width > e.height ? (n = e.width / e.height, i = 1, r = (e.height / 2 - e.width / 2) / e.height, o = 0) : (n = 1, i = e.height / e.width, r = 0, o = (e.width / 2 - e.height / 2) / e.width), { yMin: r, xMin: o, yMax: r + n, xMax: o + i, height: n, width: i };
}
function ke(t2) {
  var e, n = null == t2 ? de : B({}, t2);
  if (null == n.modelType)
    n.modelType = "SinglePose.Lightning";
  else if (fe.indexOf(n.modelType) < 0)
    throw new Error("Invalid architecture ".concat(n.modelType, ". ") + "Should be one of ".concat(fe));
  if (null == n.enableSmoothing && (n.enableSmoothing = true), null != n.minPoseScore && (n.minPoseScore < 0 || n.minPoseScore > 1))
    throw new Error("minPoseScore should be between 0.0 and 1.0");
  if (null != n.multiPoseMaxDimension && (n.multiPoseMaxDimension % 32 != 0 || n.multiPoseMaxDimension < 32))
    throw new Error("multiPoseMaxDimension must be a multiple of 32 and higher than 0");
  if ("MultiPose.Lightning" === n.modelType && null == n.enableTracking && (n.enableTracking = true), "MultiPose.Lightning" === n.modelType && true === n.enableTracking)
    if (null == n.trackerType && (n.trackerType = ae.BoundingBox), n.trackerType === ae.Keypoint)
      null != n.trackerConfig ? n.trackerConfig = function(t3) {
        var e2 = be(ye, t3);
        e2.keypointTrackerParams = B({}, ye.keypointTrackerParams), null != t3.keypointTrackerParams && (null != t3.keypointTrackerParams.keypointConfidenceThreshold && (e2.keypointTrackerParams.keypointConfidenceThreshold = t3.keypointTrackerParams.keypointConfidenceThreshold), null != t3.keypointTrackerParams.keypointFalloff && (e2.keypointTrackerParams.keypointFalloff = t3.keypointTrackerParams.keypointFalloff), null != t3.keypointTrackerParams.minNumberOfKeypoints && (e2.keypointTrackerParams.minNumberOfKeypoints = t3.keypointTrackerParams.minNumberOfKeypoints));
        return e2;
      }(n.trackerConfig) : n.trackerConfig = ye;
    else {
      if (n.trackerType !== ae.BoundingBox)
        throw new Error("Tracker type not supported by MoveNet");
      null != n.trackerConfig ? n.trackerConfig = (e = n.trackerConfig, be(ve, e)) : n.trackerConfig = ve;
    }
  return n;
}
function be(t2, e) {
  var n = { maxTracks: t2.maxTracks, maxAge: t2.maxAge, minSimilarity: t2.minSimilarity };
  return null != e.maxTracks && (n.maxTracks = e.maxTracks), null != e.maxAge && (n.maxAge = e.maxAge), null != e.minSimilarity && (n.minSimilarity = e.minSimilarity), n;
}
var Me = function() {
  function t2(t3, e) {
    this.moveNetModel = t3, this.modelInputResolution = { height: 0, width: 0 }, this.keypointIndexByName = ce(se.MoveNet), "SinglePose.Lightning" === e.modelType ? (this.modelInputResolution.width = 192, this.modelInputResolution.height = 192) : "SinglePose.Thunder" === e.modelType && (this.modelInputResolution.width = 256, this.modelInputResolution.height = 256), this.multiPoseModel = "MultiPose.Lightning" === e.modelType, this.multiPoseModel || (this.keypointFilter = new Et(ge), this.cropRegionFilterYMin = new zt(0.9), this.cropRegionFilterXMin = new zt(0.9), this.cropRegionFilterYMax = new zt(0.9), this.cropRegionFilterXMax = new zt(0.9)), this.enableSmoothing = e.enableSmoothing, e.minPoseScore ? this.minPoseScore = e.minPoseScore : this.minPoseScore = 0.25, e.multiPoseMaxDimension ? this.multiPoseMaxDimension = e.multiPoseMaxDimension : this.multiPoseMaxDimension = 256, this.enableTracking = e.enableTracking, this.multiPoseModel && this.enableTracking && (e.trackerType === ae.Keypoint ? this.tracker = new le(e.trackerConfig) : e.trackerType === ae.BoundingBox && (this.tracker = new he(e.trackerConfig)), this.enableSmoothing && (this.keypointFilterMap = /* @__PURE__ */ new Map()));
  }
  return t2.prototype.runSinglePersonPoseModel = function(t3) {
    return N(this, void 0, void 0, function() {
      var e, n, i, r, o;
      return D(this, function(a) {
        switch (a.label) {
          case 0:
            if (4 !== (e = this.moveNetModel.execute(t3)).shape.length || 1 !== e.shape[0] || 1 !== e.shape[1] || 17 !== e.shape[2] || 3 !== e.shape[3])
              throw e.dispose(), new Error("Unexpected output shape from model: [".concat(e.shape, "]"));
            return "webgpu" === getBackend() ? [3, 1] : (n = e.dataSync(), [3, 3]);
          case 1:
            return [4, e.data()];
          case 2:
            n = a.sent(), a.label = 3;
          case 3:
            for (e.dispose(), i = { keypoints: [], score: 0 }, r = 0, o = 0; o < 17; ++o)
              i.keypoints[o] = { y: n[3 * o], x: n[3 * o + 1], score: n[3 * o + 2] }, i.keypoints[o].score > 0.2 && (++r, i.score += i.keypoints[o].score);
            return r > 0 && (i.score /= r), [2, i];
        }
      });
    });
  }, t2.prototype.runMultiPersonPoseModel = function(t3) {
    return N(this, void 0, void 0, function() {
      var e, n, i, r, o, a, s, u;
      return D(this, function(h) {
        switch (h.label) {
          case 0:
            if (3 !== (e = this.moveNetModel.execute(t3)).shape.length || 1 !== e.shape[0] || 56 !== e.shape[2])
              throw e.dispose(), new Error("Unexpected output shape from model: [".concat(e.shape, "]"));
            return "webgpu" === getBackend() ? [3, 1] : (n = e.dataSync(), [3, 3]);
          case 1:
            return [4, e.data()];
          case 2:
            n = h.sent(), h.label = 3;
          case 3:
            for (e.dispose(), i = [], r = n.length / 56, o = 0; o < r; ++o)
              for (i[o] = { keypoints: [] }, a = 56 * o + 51, i[o].box = { yMin: n[a], xMin: n[a + 1], yMax: n[a + 2], xMax: n[a + 3], width: n[a + 3] - n[a + 1], height: n[a + 2] - n[a] }, s = 56 * o + 55, i[o].score = n[s], i[o].keypoints = [], u = 0; u < 17; ++u)
                i[o].keypoints[u] = { y: n[56 * o + 3 * u], x: n[56 * o + 3 * u + 1], score: n[56 * o + 3 * u + 2] };
            return [2, i];
        }
      });
    });
  }, t2.prototype.estimatePoses = function(t3, n, i) {
    return void 0 === n && (n = me), N(this, void 0, void 0, function() {
      var r, o, a, s, u, l;
      return D(this, function(c) {
        switch (c.label) {
          case 0:
            return n = function(t4) {
              return null == t4 ? me : B({}, t4);
            }(n), null == t3 ? (this.reset(), [2, []]) : (null == i ? vt(t3) && (i = 1e6 * t3.currentTime) : i *= 1e3, r = at(t3), o = rt(r), a = expandDims(r, 0), t3 instanceof Tensor || r.dispose(), s = [], this.multiPoseModel ? [3, 2] : [4, this.estimateSinglePose(a, o, i)]);
          case 1:
            return s = c.sent(), [3, 4];
          case 2:
            return [4, this.estimateMultiplePoses(a, o, i)];
          case 3:
            s = c.sent(), c.label = 4;
          case 4:
            for (u = 0; u < s.length; ++u)
              for (l = 0; l < s[u].keypoints.length; ++l)
                s[u].keypoints[l].name = U[l], s[u].keypoints[l].y *= o.height, s[u].keypoints[l].x *= o.width;
            return [2, s];
        }
      });
    });
  }, t2.prototype.estimateSinglePose = function(t3, e, n) {
    return N(this, void 0, void 0, function() {
      var i, o, a, h, c = this;
      return D(this, function(p) {
        switch (p.label) {
          case 0:
            return this.cropRegion || (this.cropRegion = we(null == this.cropRegion, e)), i = tidy(function() {
              var e2 = tensor2d([[c.cropRegion.yMin, c.cropRegion.xMin, c.cropRegion.yMax, c.cropRegion.xMax]]), n2 = zeros([1], "int32"), i2 = [c.modelInputResolution.height, c.modelInputResolution.width];
              return cast(image.cropAndResize(t3, e2, n2, i2, "bilinear", 0), "int32");
            }), t3.dispose(), [4, this.runSinglePersonPoseModel(i)];
          case 1:
            if (o = p.sent(), i.dispose(), o.score < this.minPoseScore)
              return this.reset(), [2, []];
            for (a = 0; a < o.keypoints.length; ++a)
              o.keypoints[a].y = this.cropRegion.yMin + o.keypoints[a].y * this.cropRegion.height, o.keypoints[a].x = this.cropRegion.xMin + o.keypoints[a].x * this.cropRegion.width;
            return null != n && this.enableSmoothing && (o.keypoints = this.keypointFilter.apply(o.keypoints, n, 1)), h = xe(this.cropRegion, o.keypoints, this.keypointIndexByName, e), this.cropRegion = this.filterCropRegion(h), [2, [o]];
        }
      });
    });
  }, t2.prototype.estimateMultiplePoses = function(t3, e, n) {
    return N(this, void 0, void 0, function() {
      var i, r, o, a, s, h, c, p, f, d, m, g = this;
      return D(this, function(y) {
        switch (y.label) {
          case 0:
            return 32, e.width > e.height ? (r = this.multiPoseMaxDimension, o = Math.round(this.multiPoseMaxDimension * e.height / e.width), i = image.resizeBilinear(t3, [o, r]), s = r, h = 32 * Math.ceil(o / 32), a = pad(i, [[0, 0], [0, h - o], [0, 0], [0, 0]])) : (r = Math.round(this.multiPoseMaxDimension * e.width / e.height), o = this.multiPoseMaxDimension, i = image.resizeBilinear(t3, [o, r]), s = 32 * Math.ceil(r / 32), h = o, a = pad(i, [[0, 0], [0, 0], [0, s - r], [0, 0]])), i.dispose(), t3.dispose(), c = cast(a, "int32"), a.dispose(), [4, this.runMultiPersonPoseModel(c)];
          case 1:
            for (p = y.sent(), c.dispose(), p = p.filter(function(t4) {
              return t4.score >= g.minPoseScore;
            }), d = 0; d < p.length; ++d)
              for (f = 0; f < p[d].keypoints.length; ++f)
                p[d].keypoints[f].y *= h / o, p[d].keypoints[f].x *= s / r;
            if (this.enableTracking && (this.tracker.apply(p, n), this.enableSmoothing)) {
              for (d = 0; d < p.length; ++d)
                this.keypointFilterMap.has(p[d].id) || this.keypointFilterMap.set(p[d].id, new Et(ge)), p[d].keypoints = this.keypointFilterMap.get(p[d].id).apply(p[d].keypoints, n, 1);
              m = this.tracker.getTrackIDs(), this.keypointFilterMap.forEach(function(t4, e2) {
                m.has(e2) || g.keypointFilterMap.delete(e2);
              });
            }
            return [2, p];
        }
      });
    });
  }, t2.prototype.filterCropRegion = function(t3) {
    if (t3) {
      var e = this.cropRegionFilterYMin.apply(t3.yMin), n = this.cropRegionFilterXMin.apply(t3.xMin), i = this.cropRegionFilterYMax.apply(t3.yMax), r = this.cropRegionFilterXMax.apply(t3.xMax);
      return { yMin: e, xMin: n, yMax: i, xMax: r, height: i - e, width: r - n };
    }
    return this.cropRegionFilterYMin.reset(), this.cropRegionFilterXMin.reset(), this.cropRegionFilterYMax.reset(), this.cropRegionFilterXMax.reset(), null;
  }, t2.prototype.dispose = function() {
    this.moveNetModel.dispose();
  }, t2.prototype.reset = function() {
    this.cropRegion = null, this.resetFilters();
  }, t2.prototype.resetFilters = function() {
    this.keypointFilter.reset(), this.cropRegionFilterYMin.reset(), this.cropRegionFilterXMin.reset(), this.cropRegionFilterYMax.reset(), this.cropRegionFilterXMax.reset();
  }, t2;
}();
function Se(t2) {
  return void 0 === t2 && (t2 = de), N(this, void 0, void 0, function() {
    var e, n, i, r;
    return D(this, function(o) {
      switch (o.label) {
        case 0:
          return e = ke(t2), i = true, e.modelUrl ? (i = "string" == typeof e.modelUrl && e.modelUrl.indexOf("https://tfhub.dev") > -1, [4, loadGraphModel(e.modelUrl, { fromTFHub: i })]) : [3, 2];
        case 1:
          return n = o.sent(), [3, 4];
        case 2:
          return r = void 0, "SinglePose.Lightning" === e.modelType ? r = "https://tfhub.dev/google/tfjs-model/movenet/singlepose/lightning/4" : "SinglePose.Thunder" === e.modelType ? r = "https://tfhub.dev/google/tfjs-model/movenet/singlepose/thunder/4" : "MultiPose.Lightning" === e.modelType && (r = "https://tfhub.dev/google/tfjs-model/movenet/multipose/lightning/1"), [4, loadGraphModel(r, { fromTFHub: i })];
        case 3:
          n = o.sent(), o.label = 4;
        case 4:
          return "webgl" === getBackend() && env().set("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", 0), [2, new Me(n, e)];
      }
    });
  });
}
var Te = { architecture: "MobileNetV1", outputStride: 16, multiplier: 0.75, inputResolution: { height: 257, width: 257 } };
var Pe = ["MobileNetV1", "ResNet50"];
var Fe = { MobileNetV1: [8, 16], ResNet50: [16] };
var _e = [8, 16, 32];
var Oe = { MobileNetV1: [0.5, 0.75, 1], ResNet50: [1] };
var Ie = [1, 2, 4];
var Ae = { maxPoses: 1, flipHorizontal: false };
var ze = { maxPoses: 5, flipHorizontal: false, scoreThreshold: 0.5, nmsRadius: 20 };
var Ce = [-123.15, -115.9, -103.06];
function Ee(t2) {
  return Math.floor(t2 / 2);
}
var Re = function() {
  function t2(t3, e) {
    this.priorityQueue = new Array(t3), this.numberOfElements = -1, this.getElementValue = e;
  }
  return t2.prototype.enqueue = function(t3) {
    this.priorityQueue[++this.numberOfElements] = t3, this.swim(this.numberOfElements);
  }, t2.prototype.dequeue = function() {
    var t3 = this.priorityQueue[0];
    return this.exchange(0, this.numberOfElements--), this.sink(0), this.priorityQueue[this.numberOfElements + 1] = null, t3;
  }, t2.prototype.empty = function() {
    return -1 === this.numberOfElements;
  }, t2.prototype.size = function() {
    return this.numberOfElements + 1;
  }, t2.prototype.all = function() {
    return this.priorityQueue.slice(0, this.numberOfElements + 1);
  }, t2.prototype.max = function() {
    return this.priorityQueue[0];
  }, t2.prototype.swim = function(t3) {
    for (; t3 > 0 && this.less(Ee(t3), t3); )
      this.exchange(t3, Ee(t3)), t3 = Ee(t3);
  }, t2.prototype.sink = function(t3) {
    for (; 2 * t3 <= this.numberOfElements; ) {
      var e = 2 * t3;
      if (e < this.numberOfElements && this.less(e, e + 1) && e++, !this.less(t3, e))
        break;
      this.exchange(t3, e), t3 = e;
    }
  }, t2.prototype.getValueAt = function(t3) {
    return this.getElementValue(this.priorityQueue[t3]);
  }, t2.prototype.less = function(t3, e) {
    return this.getValueAt(t3) < this.getValueAt(e);
  }, t2.prototype.exchange = function(t3, e) {
    var n = this.priorityQueue[t3];
    this.priorityQueue[t3] = this.priorityQueue[e], this.priorityQueue[e] = n;
  }, t2;
}();
function Le(t2, e, n, i, r, o) {
  for (var a = o.shape, s = a[0], u = a[1], h = true, l = Math.max(n - r, 0), c = Math.min(n + r + 1, s), p = l; p < c; ++p) {
    for (var f = Math.max(i - r, 0), d = Math.min(i + r + 1, u), m = f; m < d; ++m)
      if (o.get(p, m, t2) > e) {
        h = false;
        break;
      }
    if (!h)
      break;
  }
  return h;
}
function Ve(t2) {
  return N(this, void 0, void 0, function() {
    return D(this, function(e) {
      return [2, Promise.all(t2.map(function(t3) {
        return t3.buffer();
      }))];
    });
  });
}
function Be(t2, e, n, i) {
  return { y: i.get(t2, e, n), x: i.get(t2, e, n + 17) };
}
function Ne(t2, e, n) {
  var i = Be(t2.heatmapY, t2.heatmapX, t2.id, n), r = i.y, o = i.x;
  return { x: t2.heatmapX * e + o, y: t2.heatmapY * e + r };
}
function De(t2, e, n, i) {
  var r = n.x, o = n.y;
  return t2.some(function(t3) {
    var n2, a, s, u, h, l, c = t3.keypoints;
    return n2 = o, a = r, s = c[i].y, u = c[i].x, (h = s - n2) * h + (l = u - a) * l <= e;
  });
}
var Ke = U.reduce(function(t2, e, n) {
  return t2[e] = n, t2;
}, {});
var Ue = [["nose", "left_eye"], ["left_eye", "left_ear"], ["nose", "right_eye"], ["right_eye", "right_ear"], ["nose", "left_shoulder"], ["left_shoulder", "left_elbow"], ["left_elbow", "left_wrist"], ["left_shoulder", "left_hip"], ["left_hip", "left_knee"], ["left_knee", "left_ankle"], ["nose", "right_shoulder"], ["right_shoulder", "right_elbow"], ["right_elbow", "right_wrist"], ["right_shoulder", "right_hip"], ["right_hip", "right_knee"], ["right_knee", "right_ankle"]].map(function(t2) {
  var e = t2[0], n = t2[1];
  return [Ke[e], Ke[n]];
});
var je = Ue.map(function(t2) {
  return t2[1];
});
var He = Ue.map(function(t2) {
  return t2[0];
});
function qe(t2, e, n) {
  return t2 < e ? e : t2 > n ? n : t2;
}
function Xe(t2, e, n, i) {
  return { y: qe(Math.round(t2.y / e), 0, n - 1), x: qe(Math.round(t2.x / e), 0, i - 1) };
}
function Ye(t2, e) {
  return { x: t2.x + e.x, y: t2.y + e.y };
}
function We(t2, e, n, i, r, o, a, s) {
  void 0 === s && (s = 2);
  for (var u = i.shape, h = u[0], l = u[1], c = { y: e.y, x: e.x }, p = Ye(c, function(t3, e2, n2) {
    var i2 = n2.shape[2] / 2;
    return { y: n2.get(e2.y, e2.x, t3), x: n2.get(e2.y, e2.x, i2 + t3) };
  }(t2, Xe(c, o, h, l), a)), f = 0; f < s; f++) {
    var d = Xe(p, o, h, l), m = Be(d.y, d.x, n, r);
    p = Ye({ x: d.x * o, y: d.y * o }, { x: m.x, y: m.y });
  }
  var g = Xe(p, o, h, l), y = i.get(g.y, g.x, n);
  return { y: p.y, x: p.x, name: U[n], score: y };
}
function Ge(t2, e, n, i, r, o) {
  var a = e.shape[2], s = je.length, u = new Array(a), h = t2.part, l = t2.score, c = Ne(h, i, n);
  u[h.id] = { score: l, name: U[h.id], y: c.y, x: c.x };
  for (var p = s - 1; p >= 0; --p) {
    var f = je[p], d = He[p];
    u[f] && !u[d] && (u[d] = We(p, u[f], d, e, n, i, o));
  }
  for (p = 0; p < s; ++p) {
    f = He[p], d = je[p];
    u[f] && !u[d] && (u[d] = We(p, u[f], d, e, n, i, r));
  }
  return u;
}
function Qe(t2, e, n) {
  return n.reduce(function(n2, i, r) {
    var o = i.y, a = i.x, s = i.score;
    return De(t2, e, { y: o, x: a }, r) || (n2 += s), n2;
  }, 0) / n.length;
}
function Ze(t2, e, n, i, r, o, a, s) {
  return void 0 === a && (a = 0.5), void 0 === s && (s = 20), N(this, void 0, void 0, function() {
    var u, h, l, c, p, f, d, m, g, y, v, x;
    return D(this, function(w) {
      switch (w.label) {
        case 0:
          return [4, Ve([t2, e, n, i])];
        case 1:
          for (u = w.sent(), h = u[0], l = u[1], c = u[2], p = u[3], f = [], d = function(t3, e2, n2) {
            for (var i2 = n2.shape, r2 = i2[0], o2 = i2[1], a2 = i2[2], s2 = new Re(r2 * o2 * a2, function(t4) {
              return t4.score;
            }), u2 = 0; u2 < r2; ++u2)
              for (var h2 = 0; h2 < o2; ++h2)
                for (var l2 = 0; l2 < a2; ++l2) {
                  var c2 = n2.get(u2, h2, l2);
                  c2 < t3 || Le(l2, c2, u2, h2, e2, n2) && s2.enqueue({ score: c2, part: { heatmapY: u2, heatmapX: h2, id: l2 } });
                }
            return s2;
          }(a, 1, h), m = s * s; f.length < o && !d.empty(); )
            g = d.dequeue(), y = Ne(g.part, r, l), De(f, m, y, g.part.id) || (v = Ge(g, h, l, r, c, p), x = Qe(f, m, v), f.push({ keypoints: v, score: x }));
          return [2, f];
      }
    });
  });
}
function $e() {
  for (var t2, e = [], n = 0; n < arguments.length; n++)
    e[n] = arguments[n];
  switch (e.length) {
    case 0:
      t2 = "fn main() ";
      break;
    case 1:
      t2 = "fn main(".concat(e[0], " : i32)");
      break;
    default:
      throw Error("Unreachable");
  }
  return t2;
}
var Je = function() {
  function t2(t3) {
    this.variableNames = ["A", "B"], this.size = true;
    this.workgroupSize = [32, 1, 1], this.outputShape = [t3[0], 1], this.dispatchLayout = webgpu_util_exports.flatDispatchLayout(this.outputShape), this.dispatch = webgpu_util_exports.computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize), this.shaderKey = "getpointsConfidenceOp";
  }
  return t2.prototype.getUserCode = function() {
    return "\n        ".concat($e("index"), " {\n          if (index < uniforms.size) {\n            let y = B[index * 2];\n            let x = B[index * 2 + 1];\n            let outIndex = y * uniforms.aShape.x * uniforms.aShape.z + x * uniforms.aShape.z + index;\n            result[index] = A[outIndex];\n          }\n        }\n        ");
  }, t2;
}();
function tn(t2, e) {
  if (backend() instanceof WebGPUBackend)
    return function(t3, e2) {
      var n = backend(), i = new Je(e2.shape), r = n.runWebGPUProgram(i, [t3, e2], "float32");
      return engine().makeTensorFromTensorInfo(r);
    }(t2, e);
  throw new Error("getPointsConfidenceWebGPU is not supported in this backend!");
}
var en = function() {
  function t2(t3) {
    if (this.variableNames = ["A", "B"], this.size = true, this.supportedLastDimension = 2, 2 !== t3.length || t3[1] !== this.supportedLastDimension)
      throw new Error("GetOffsetVectorsProgram only supports shape of [x, ".concat(this.supportedLastDimension, "], but current shape is ").concat(t3));
    this.workgroupSize = [32, 1, 1], this.outputShape = t3;
    var e = [t3[0], 1];
    this.dispatchLayout = webgpu_util_exports.flatDispatchLayout(e), this.dispatch = webgpu_util_exports.computeDispatch(this.dispatchLayout, e, this.workgroupSize), this.shaderKey = "GetOffsetVectors";
  }
  return t2.prototype.getUserCode = function() {
    return "\n    fn getOffsetPoint(y: i32, x: i32, index: i32) -> vec2<i32> {\n      let outIndexY = y * uniforms.bShape.x * uniforms.bShape.y + x * uniforms.bShape.y + index;\n      let outIndexX = outIndexY + uniforms.bShape.z;\n      let outY = i32(B[outIndexY]);\n      let outX = i32(B[outIndexX]);\n      return vec2<i32>(outY, outX);\n    }\n\n    ".concat($e("index"), " {\n      if (index < uniforms.size) {\n        let indexY = index * ").concat(this.supportedLastDimension, ";\n        let indexX = indexY + 1;\n        let heatmapY = A[indexY];\n        let heatmapX = A[indexX];\n        let out = getOffsetPoint(i32(heatmapY), i32(heatmapX), index);\n        result[indexY] = f32(out[0]);\n        result[indexX] = f32(out[1]);\n      }\n    }\n    ");
  }, t2;
}();
function nn(t2, e) {
  if (backend() instanceof WebGPUBackend)
    return function(t3, e2) {
      var n = backend(), i = new en(t3.shape), r = n.runWebGPUProgram(i, [t3, e2], "float32");
      return engine().makeTensorFromTensorInfo(r);
    }(t2, e);
  throw new Error("getOffsetVectorsGPU is not supported in this backend!");
}
function rn(t2) {
  var e = t2.shape, n = e[0], i = e[1], o = e[2];
  return tidy(function() {
    var e2, s, u = reshape(t2, [n * i, o]), l = argMax(u, 0), c = expandDims(div(l, scalar(i, "int32")), 1), p = expandDims((e2 = l, s = i, tidy(function() {
      var t3 = div(e2, scalar(s, "int32"));
      return sub(e2, mul(t3, scalar(s, "int32")));
    })), 1);
    return concat([c, p], 1);
  });
}
function on(t2, e, n) {
  return tidy(function() {
    var i = function(t3, e2) {
      for (var n2 = [], i2 = 0; i2 < U.length; i2++) {
        var r = t3.get(i2, 0).valueOf(), o = t3.get(i2, 1).valueOf(), a = an(r, o, i2, e2), u = a.x, h = a.y;
        n2.push(h), n2.push(u);
      }
      return tensor2d(n2, [U.length, 2]);
    }(t2, n);
    return add(cast(mul(t2.toTensor(), scalar(e, "int32")), "float32"), i);
  });
}
function an(t2, e, n, i) {
  return { y: i.get(t2, e, n), x: i.get(t2, e, n + U.length) };
}
function sn(t2, e, n) {
  return N(this, void 0, void 0, function() {
    var i, r, o, a, s, u, h, l, c, p;
    return D(this, function(f) {
      switch (f.label) {
        case 0:
          return i = 0, r = rn(t2), [4, Promise.all([t2.buffer(), e.buffer(), r.buffer()])];
        case 1:
          return o = f.sent(), a = o[0], s = o[1], u = o[2], [4, (h = on(u, n, s)).buffer()];
        case 2:
          return l = f.sent(), c = Array.from(function(t3, e2) {
            for (var n2 = e2.shape[0], i2 = new Float32Array(n2), r2 = 0; r2 < n2; r2++) {
              var o2 = e2.get(r2, 0), a2 = e2.get(r2, 1);
              i2[r2] = t3.get(o2, a2, r2);
            }
            return i2;
          }(a, u)), p = c.map(function(t3, e2) {
            return i += t3, { y: l.get(e2, 0), x: l.get(e2, 1), score: t3, name: U[e2] };
          }), r.dispose(), h.dispose(), [2, { keypoints: p, score: i / p.length }];
      }
    });
  });
}
function un(t2, e, n) {
  return N(this, void 0, void 0, function() {
    var i, s, u;
    return D(this, function(h) {
      return i = rn(t2), s = function(t3, e2, n2) {
        return tidy(function() {
          var i2 = nn(t3, n2);
          return add(cast(mul(t3, scalar(e2, "int32")), "float32"), i2);
        });
      }(i, n, e), u = tn(t2, i), [2, [s, u]];
    });
  });
}
function hn(t2, e) {
  return (t2 - 1) % e == 0;
}
var ln = "https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/";
var cn = "https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/";
function pn(t2, e) {
  return function(t3, e2) {
    return (t3 - 1) % e2 == 0;
  }(t2, e) ? t2 : Math.floor(t2 / e) * e + 1;
}
var fn = function() {
  function t2(t3, e) {
    this.posenetModel = t3;
    var n = this.posenetModel.inputs[0].shape;
    util_exports.assert(-1 === n[1] && -1 === n[2], function() {
      return "Input shape [".concat(n[1], ", ").concat(n[2], "] ") + "must both be equal to or -1";
    });
    var r, o, a = (r = e.inputResolution, o = e.outputStride, { height: pn(r.height, o), width: pn(r.width, o) });
    !function(t4) {
      util_exports.assert(_e.indexOf(t4) >= 0, function() {
        return "outputStride of ".concat(t4, " is invalid. ") + "It must be either 8 or 16.";
      });
    }(e.outputStride), function(t4, e2) {
      util_exports.assert(hn(t4.height, e2), function() {
        return "height of ".concat(t4.height, " is invalid for output stride ") + "".concat(e2, ".");
      }), util_exports.assert(hn(t4.width, e2), function() {
        return "width of ".concat(t4.width, " is invalid for output stride ") + "".concat(e2, ".");
      });
    }(a, e.outputStride), this.inputResolution = a, this.outputStride = e.outputStride, this.architecture = e.architecture;
  }
  return t2.prototype.estimatePoses = function(t3, e) {
    return void 0 === e && (e = Ae), N(this, void 0, void 0, function() {
      return D(this, function(n) {
        return [2, this.estimatePosesGPU(t3, e, false)];
      });
    });
  }, t2.prototype.estimatePosesGPU = function(t3, e, n) {
    return void 0 === e && (e = Ae), void 0 === n && (n = false), N(this, void 0, void 0, function() {
      var i, r, a, s, u, h, l, c, d, m, g, y, v, x, w, k, b, M;
      return D(this, function(S) {
        switch (S.label) {
          case 0:
            return i = function(t4) {
              var e2 = t4;
              if (null == e2.maxPoses && (e2.maxPoses = 1), e2.maxPoses <= 0)
                throw new Error("Invalid maxPoses ".concat(e2.maxPoses, ". Should be > 0."));
              if (e2.maxPoses > 1) {
                if ((e2 = B(B({}, ze), e2)).scoreThreshold < 0 || e2.scoreThreshold > 1)
                  throw new Error("Invalid scoreThreshold ".concat(e2.scoreThreshold, ". ") + "Should be in range [0.0, 1.0]");
                if (e2.nmsRadius <= 0)
                  throw new Error("Invalid nmsRadius ".concat(e2.nmsRadius, "."));
              }
              return e2;
            }(e), null == t3 ? [2, n ? [[], []] : []] : (this.maxPoses = i.maxPoses, r = mt(t3, { outputTensorSize: this.inputResolution, keepAspectRatio: true, borderMode: "replicate" }), a = r.imageTensor, s = r.padding, u = "ResNet50" === this.architecture ? add(a, Ce) : dt(a, [-1, 1]), h = this.posenetModel.predict(u), "ResNet50" === this.architecture ? (l = squeeze(h[2], [0]), c = squeeze(h[3], [0]), d = squeeze(h[0], [0]), m = squeeze(h[1], [0])) : (l = squeeze(h[0], [0]), c = squeeze(h[1], [0]), d = squeeze(h[2], [0]), m = squeeze(h[3], [0])), g = sigmoid(c), 1 !== this.maxPoses ? [3, 5] : n ? [4, un(g, l, this.outputStride)] : [3, 2]);
          case 1:
            return v = S.sent(), w = v[0], x = v[1], y = [w, x], [3, 4];
          case 2:
            return [4, sn(g, l, this.outputStride)];
          case 3:
            w = S.sent(), y = [w], S.label = 4;
          case 4:
            return [3, 7];
          case 5:
            if (n)
              throw new Error("GPU renderer only supports single pose!");
            return [4, Ze(g, l, d, m, this.outputStride, this.maxPoses, i.scoreThreshold, i.nmsRadius)];
          case 6:
            y = S.sent(), S.label = 7;
          case 7:
            if (n) {
              if (true === i.flipHorizontal)
                throw new Error("flipHorizontal is not supported!");
              k = this.getCanvasInfo(rt(t3), this.inputResolution, s);
            } else
              M = rt(t3), b = function(t4, e2, n2, i2) {
                var r2 = e2.height, o = e2.width, a2 = r2 / (n2.height * (1 - i2.top - i2.bottom)), s2 = o / (n2.width * (1 - i2.left - i2.right)), u2 = -i2.top * n2.height, h2 = -i2.left * n2.width;
                if (1 === s2 && 1 === a2 && 0 === u2 && 0 === h2)
                  return t4;
                for (var l2 = 0, c2 = t4; l2 < c2.length; l2++)
                  for (var p = 0, f = c2[l2].keypoints; p < f.length; p++) {
                    var d2 = f[p];
                    d2.x = (d2.x + h2) * s2, d2.y = (d2.y + u2) * a2;
                  }
                return t4;
              }(y, M, this.inputResolution, s), i.flipHorizontal && (b = function(t4, e2) {
                for (var n2 = 0, i2 = t4; n2 < i2.length; n2++)
                  for (var r2 = 0, o = i2[n2].keypoints; r2 < o.length; r2++) {
                    var a2 = o[r2];
                    a2.x = e2.width - 1 - a2.x;
                  }
                return t4;
              }(b, M));
            return a.dispose(), u.dispose(), dispose(h), l.dispose(), c.dispose(), d.dispose(), m.dispose(), g.dispose(), [2, n ? [y, k] : b];
        }
      });
    });
  }, t2.prototype.getCanvasInfo = function(t3, e, n) {
    var i = t3.height, r = t3.width, o = i / (e.height * (1 - n.top - n.bottom)), a = r / (e.width * (1 - n.left - n.right)), s = -n.top * e.height;
    return [-n.left * e.width, s, a, o, t3.width, t3.height];
  }, t2.prototype.dispose = function() {
    this.posenetModel.dispose();
  }, t2.prototype.reset = function() {
  }, t2;
}();
function dn(t2) {
  return void 0 === t2 && (t2 = Te), N(this, void 0, void 0, function() {
    var e, n, i, r, o;
    return D(this, function(a) {
      switch (a.label) {
        case 0:
          return "ResNet50" !== (e = function(t3) {
            var e2 = t3 || Te;
            if (null == e2.architecture && (e2.architecture = "MobileNetV1"), Pe.indexOf(e2.architecture) < 0)
              throw new Error("Invalid architecture ".concat(e2.architecture, ". ") + "Should be one of ".concat(Pe));
            if (null == e2.inputResolution && (e2.inputResolution = { height: 257, width: 257 }), null == e2.outputStride && (e2.outputStride = 16), Fe[e2.architecture].indexOf(e2.outputStride) < 0)
              throw new Error("Invalid outputStride ".concat(e2.outputStride, ". ") + "Should be one of ".concat(Fe[e2.architecture], " ") + "for architecture ".concat(e2.architecture, "."));
            if (null == e2.multiplier && (e2.multiplier = 1), Oe[e2.architecture].indexOf(e2.multiplier) < 0)
              throw new Error("Invalid multiplier ".concat(e2.multiplier, ". ") + "Should be one of ".concat(Oe[e2.architecture], " ") + "for architecture ".concat(e2.architecture, "."));
            if (null == e2.quantBytes && (e2.quantBytes = 4), Ie.indexOf(e2.quantBytes) < 0)
              throw new Error("Invalid quantBytes ".concat(e2.quantBytes, ". ") + "Should be one of ".concat(Ie, " ") + "for architecture ".concat(e2.architecture, "."));
            if ("MobileNetV1" === e2.architecture && 32 === e2.outputStride && 1 !== e2.multiplier)
              throw new Error("When using an output stride of 32, you must select 1 as the multiplier.");
            return e2;
          }(t2)).architecture ? [3, 2] : (s = e.outputStride, u = e.quantBytes, h = "model-stride".concat(s, ".json"), n = 4 === u ? cn + "float/" + h : cn + "quant".concat(u, "/") + h, [4, loadGraphModel(e.modelUrl || n)]);
        case 1:
          return i = a.sent(), [2, new fn(i, e)];
        case 2:
          return r = function(t3, e2, n2) {
            var i2 = { 1: "100", 0.75: "075", 0.5: "050" }, r2 = "model-stride".concat(t3, ".json");
            return 4 === n2 ? ln + "float/".concat(i2[e2], "/") + r2 : ln + "quant".concat(n2, "/").concat(i2[e2], "/") + r2;
          }(e.outputStride, e.multiplier, e.quantBytes), [4, loadGraphModel(e.modelUrl || r)];
        case 3:
          return o = a.sent(), [2, new fn(o, e)];
      }
      var s, u, h;
    });
  });
}
function mn(t2, e) {
  return N(this, void 0, void 0, function() {
    var n, i;
    return D(this, function(r) {
      switch (t2) {
        case se.PoseNet:
          return [2, dn(e)];
        case se.BlazePose:
          if (i = void 0, null != (n = e)) {
            if ("tfjs" === n.runtime)
              return [2, oe(e)];
            if ("mediapipe" === n.runtime)
              return [2, it(e)];
            i = n.runtime;
          }
          throw new Error("Expect modelConfig.runtime to be either 'tfjs' " + "or 'mediapipe', but got ".concat(i));
        case se.MoveNet:
          return [2, Se(e)];
        default:
          throw new Error("".concat(t2, " is not a supported model name."));
      }
    });
  });
}
var gn = { keypointsToNormalizedKeypoints: At };
var yn = { modelType: { SINGLEPOSE_LIGHTNING: "SinglePose.Lightning", SINGLEPOSE_THUNDER: "SinglePose.Thunder", MULTIPOSE_LIGHTNING: "MultiPose.Lightning" } };
export {
  se as SupportedModels,
  ae as TrackerType,
  gn as calculators,
  mn as createDetector,
  yn as movenet,
  pe as util
};
/*! Bundled license information:

@tensorflow/tfjs-converter/dist/flags.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/data/compiled_api.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/custom_op/register.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/control.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/creation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/graph.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/image.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/logical.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/string.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/operation_mapper.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ops_for_converter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_array.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_list.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/hash_table.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/operation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/model_analysis.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/graph_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/graph_model.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-converter/dist/index.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/flags_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/adapter_info.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/buffer_manager.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/texture_manager.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/shader_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/webgpu_program.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/webgpu_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/backend_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/webgpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/base.js:
  (**
   * @license
   * Copyright 2022 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/binary_op_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/unary_op_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/activation_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/matmul_packed_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/matmul_reduce_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/matmul_small_output_size_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/matmul_splitK_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/fill_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Fill.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Reshape.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/BatchMatMul_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/_FusedMatMul.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/binary_op_complex_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/binary_op_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Identity.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Complex.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/unary_op_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/kernel_funcs_utils.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/shared.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Abs.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Acos.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Acosh.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Add.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/addn_packed_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/AddN.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/transpose_shared_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/transpose_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Transpose.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/reduce_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/reduce.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/All.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Any.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/argminmax_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ArgMax.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ArgMin.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Asin.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Asinh.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Atan.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Atan2.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Atanh.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/pool_filtersizeone_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/pool_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Max.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Mean.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Pool_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPool.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPool3D.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/avg_pool_backprop_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPool3DGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/AvgPoolGrad.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/BatchMatMul.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/slice_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Slice.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/BatchToSpaceND.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/bincount_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Bincount.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/broadcast_args_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/BroadcastArgs.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/NotEqual.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Real.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/int.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Cast.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Ceil.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/clip_vec4_webgpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/clip_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ClipByValue.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/complex_abs_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ComplexAbs.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/concat_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Imag.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Concat_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Concat.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/conv2d_mm_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/conv2d_naive_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/im2col_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2D_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2D.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/conv_backprop_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/conv_backprop_mm_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv2DBackpropInput.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/conv3d_naive_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv3D.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv3DBackpropFilterV2.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Conv3DBackpropInputV2.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Cos.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Cosh.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/crop_and_resize_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/CropAndResize.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/cum_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Cum_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Cumsum.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/DenseBincount.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/depth_to_space_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthToSpace.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/depthwise_conv2d_nchw_shared_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/depthwise_conv2d_vec4_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/depthwise_conv2d_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthwiseConv2dNative.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/conv_backprop_depthwise_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/diag_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Diag.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/dilation_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Dilation2D.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/dilation_backprop_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Dilation2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Dilation2DBackpropInput.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/draw_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Draw.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use backend file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Multiply.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Einsum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Elu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/EluGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Equal.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Erf.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Exp.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ExpandDims.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Expm1.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/fft_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FFT_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FFT.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/flip_left_right_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FlipLeftRight.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Floor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FloorDiv.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/from_pixels_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FromPixels.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use backend file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/batchnorm_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FusedBatchNorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FusedConv2D.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/FusedDepthwiseConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/gather_nd_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/GatherNd.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/gather_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/GatherV2.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Greater.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/GreaterEqual.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/IFFT.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/IsFinite.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/IsInf.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/IsNaN.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LeakyRelu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Less.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LessEqual.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/lin_space_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LinSpace.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Log.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Log1p.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LogicalAnd.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LogicalNot.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LogicalOr.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/lrn_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LRN.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/lrn_grad_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/LRNGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPool.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPool3D.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/max_pool_backprop_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPool3DGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPoolGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/MaxPoolWithArgmax.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Min.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Minimum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/mirror_pad_webgpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/MirrorPad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Mod.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/multinomial_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/softmax_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Softmax.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Multinomial.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Neg.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/NonMaxSuppressionV3.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/NonMaxSuppressionV5.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/onehot_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/OneHot.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ZerosLike.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/OnesLike.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Pack.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/pad_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/PadV2.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Pow.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Prelu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Prod.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Range.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/RealDiv.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Reciprocal.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Relu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Relu6.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/resize_bilinear_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeBilinear.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/resize_bilinear_backprop_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeBilinearGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/resize_nearest_neighbor_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeNearestNeighbor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/resize_nearest_neighbor_backprop_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ResizeNearestNeighborGrad.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/reverse_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Reverse.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/rotate_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/RotateWithOffset.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Round.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Rsqrt.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/scatter_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/ScatterNd.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/search_sorted_webgpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SearchSorted.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/select_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Select.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Selu.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sigmoid.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sign.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sin.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sinh.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Softplus.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/space_to_batchND_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SpaceToBatchND.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/sparse_segment_reduce_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernel_utils/sparse_segment_reduce.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SparseSegmentMean.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SparseSegmentSum.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/tile_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Tile.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SparseToDense.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SplitV.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sqrt.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Square.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/SquaredDifference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Step.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/strided_slice_webgpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/StridedSlice.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/StringNGrams.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Sub.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Tan.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Tanh.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/TensorScatterUpdate.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/top_k_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/TopK.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/transform_webgpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Transform.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/Unpack.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/unsorted_segment_sum_webgpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/kernels/UnsortedSegmentSum.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/register_all_kernels.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgpu/dist/index.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow-models/pose-detection/dist/pose-detection.esm.js:
  (**
      * @license
      * Copyright 2023 Google LLC. All Rights Reserved.
      * Licensed under the Apache License, Version 2.0 (the "License");
      * you may not use this file except in compliance with the License.
      * You may obtain a copy of the License at
      *
      * http://www.apache.org/licenses/LICENSE-2.0
      *
      * Unless required by applicable law or agreed to in writing, software
      * distributed under the License is distributed on an "AS IS" BASIS,
      * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      * See the License for the specific language governing permissions and
      * limitations under the License.
      * =============================================================================
      *)
*/
//# sourceMappingURL=@tensorflow-models_pose-detection.js.map
